{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e716a7e3831d85f1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Xian Jia Le, Ben 56214537"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a4e0917739d3f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b75a25b55add4f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Q1.1**\n",
    "\n",
    "**prompt 1**\n",
    "> Your task is to generate a dataset for training a knowledge-grounded dialogue generation model <br><br> Generate 10 records related to physic\n",
    "\n",
    "**answer 1**\n",
    "<blockquote>\n",
    "Creating a dataset for training a knowledge-grounded dialogue generation model typically involves providing a prompt or question and a corresponding answer or response. Here are 10 records related to physics:\n",
    "\n",
    "1. **Prompt:** What is the fundamental force responsible for holding electrons in orbit around the nucleus of an atom?\n",
    "   **Answer:** The fundamental force responsible for this is electromagnetic force.\n",
    "\n",
    "2. **Prompt:** Explain the concept of Einstein's theory of relativity.\n",
    "   **Answer:** Einstein's theory of relativity consists of two main theories: special relativity, which deals with objects moving at constant speeds, and general relativity, which describes the effect of gravity on space-time.\n",
    "\n",
    "3. **Prompt:** What is the speed of light in a vacuum, and why is it considered a universal constant?\n",
    "   **Answer:** The speed of light in a vacuum is approximately 299,792,458 meters per second (or about 186,282 miles per second). It is considered a universal constant because it remains the same for all observers, regardless of their relative motion.\n",
    "\n",
    "4. **Prompt:** Describe the process of nuclear fusion and its significance.\n",
    "   **Answer:** Nuclear fusion is the process by which two light atomic nuclei combine to form a heavier nucleus, releasing a tremendous amount of energy. It powers stars like our sun and is being researched for potential clean and sustainable energy sources on Earth.\n",
    "\n",
    "5. **Prompt:** What is the Heisenberg Uncertainty Principle in quantum mechanics?\n",
    "   **Answer:** The Heisenberg Uncertainty Principle states that it is impossible to simultaneously know the precise position and momentum of a particle. This fundamental principle highlights the inherent limitations of measurement in quantum mechanics.\n",
    "\n",
    "6. **Prompt:** Explain the concept of black holes and their formation.\n",
    "   **Answer:** Black holes are extremely dense regions in space where gravity is so strong that nothing, not even light, can escape their gravitational pull. They form when massive stars collapse under their own gravity.\n",
    "\n",
    "7. **Prompt:** How does the concept of conservation of energy apply to physical systems?\n",
    "   **Answer:** The conservation of energy states that in any isolated system, the total energy remains constant over time. Energy may change from one form to another (e.g., kinetic to potential), but the total energy remains unchanged.\n",
    "\n",
    "8. **Prompt:** What are the four fundamental forces in the universe?\n",
    "   **Answer:** The four fundamental forces are gravity, electromagnetism, the strong nuclear force, and the weak nuclear force. These forces govern the behavior of all matter and energy in the universe.\n",
    "\n",
    "9. **Prompt:** Describe the concept of dark matter and its role in the universe.\n",
    "   **Answer:** Dark matter is a mysterious and invisible substance that makes up a significant portion of the universe's mass. It doesn't emit, absorb, or interact with light, but its gravitational effects are essential for explaining the structure and motion of galaxies and galaxy clusters.\n",
    "\n",
    "10. **Prompt:** What is the concept of wave-particle duality in quantum physics?\n",
    "    **Answer:** Wave-particle duality is a fundamental principle in quantum physics that states that particles like electrons and photons exhibit both wave-like and particle-like properties, depending on how they are observed and measured. This duality challenges classical notions of particle behavior.\n",
    "</blockquote>\n",
    "\n",
    "**prompt 2**\n",
    "> You are data engineer and now your task is to generate a dataset for training a knowledge-grounded dialogue generation model <br> <br> give 10 records related to medical health with the following columns: <br> Prompt, Answer\n",
    "\n",
    "**answer 2**\n",
    "<blockquote>\n",
    "Certainly, here are 10 records related to medical health with the specified \"Prompt\" and \"Answer\" columns:\n",
    "\n",
    "1. **Prompt:** What are the common symptoms of influenza (the flu)?\n",
    "   **Answer:** Common symptoms of influenza include fever, cough, sore throat, body aches, fatigue, and sometimes, respiratory congestion.\n",
    "\n",
    "2. **Prompt:** Explain the importance of vaccination in preventing infectious diseases.\n",
    "   **Answer:** Vaccination is crucial because it helps build immunity against diseases without causing the illness itself, reducing the spread of infectious diseases and protecting individuals and communities.\n",
    "\n",
    "3. **Prompt:** Describe the primary risk factors for cardiovascular disease.\n",
    "   **Answer:** Primary risk factors for cardiovascular disease include high blood pressure, high cholesterol, smoking, obesity, and a sedentary lifestyle.\n",
    "\n",
    "4. **Prompt:** What is the recommended daily intake of water for adults, and why is staying hydrated important?\n",
    "   **Answer:** The recommended daily intake of water for adults is around 8-10 cups (64-80 ounces). Staying hydrated is essential as it supports bodily functions, regulates body temperature, and aids in digestion.\n",
    "\n",
    "5. **Prompt:** What is Type 2 diabetes, and what lifestyle changes can help manage it?\n",
    "   **Answer:** Type 2 diabetes is a chronic condition characterized by elevated blood sugar levels. Lifestyle changes such as maintaining a healthy diet, regular exercise, and weight management can help manage it.\n",
    "\n",
    "6. **Prompt:** Explain the difference between a virus and a bacterium.\n",
    "   **Answer:** Viruses are smaller than bacteria and require a host cell to reproduce. Bacteria are single-celled organisms capable of independent growth and reproduction.\n",
    "\n",
    "7. **Prompt:** Discuss the benefits of regular physical activity on mental health.\n",
    "   **Answer:** Regular physical activity can reduce stress, improve mood, boost self-esteem, and alleviate symptoms of anxiety and depression.\n",
    "\n",
    "8. **Prompt:** What are the potential risks associated with prolonged sitting and a sedentary lifestyle?\n",
    "   **Answer:** Prolonged sitting and a sedentary lifestyle can increase the risk of obesity, heart disease, diabetes, and musculoskeletal problems.\n",
    "\n",
    "9. **Prompt:** Describe the importance of early cancer detection and screening.\n",
    "   **Answer:** Early cancer detection through screening tests can lead to earlier treatment and better outcomes, as many cancers are more treatable in their early stages.\n",
    "\n",
    "10. **Prompt:** Explain the concept of herd immunity in the context of vaccination.\n",
    "    **Answer:** Herd immunity occurs when a significant portion of a population becomes immune to a disease, either through vaccination or previous infection. This reduces the spread of the disease and protects those who are vulnerable.\n",
    "</blockquote>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7615bd46946358",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Q1.2\n",
    "\n",
    "**prompt**\n",
    "\n",
    "<blockquote>\n",
    "{\n",
    "  \"date\": \"2018-02-20T19:15:08.841Z\", \n",
    "  \"history\": [\n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"hello\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:16.038Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"hello there, I have not seen this movie so im going to take a minute to look it over :)\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:36.022Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"Alright that is fine. What is the movie?\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:49.258Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"The movie is The Social Network\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:56.234Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"I have not seen that one either.\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:16:26.551Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"It appears to be like a biographical movie about Mark Zuckerberg and when he creates Facebook.\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:16:32.140Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"Ohh yes I remember hearing about that movie, but it was a long time ago it feels like.\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:17:04.252Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"Rotten Tomatoes has rated it 96% so that's decent, and it is a movie from 2010\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:17:08.213Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"may be worth watching!\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:17:21.342Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"Yes I think it could be, although I personally do not like facebook as a company.\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:18:05.350Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"the movie portrays the founding of social networking website Facebook and the resulting lawsuits. It even has Justin Timberlake in it, I don't think I've ever seen him act. \", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:18:11.549Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"I have not seen him in any movies in years\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:18:26.046Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"Any other big name actors in it?\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:19:35.351Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"hmm so I just got a scene described to me, it turns out Mark was dumped so he made a blog about her ... kind of childish.... then he made a site for people to \\\"rate\\\" women on looks...the college put him on porbation. and then that captured the attention of two classmates , that how the trio came to work on facebook I guess.\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:19:55.668Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"So it came out of Mark being kind of a douche, Makes sense when I think about the company \", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:20:34.278Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"Jesse Eisenberg, Andrew Garfield, Armie Hammer , and Max Minghella, not famailiar with any of those, id have to look on IMBD\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:20:42.059Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"I am not familiar\\n with any of them either\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:21:05.185Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"another scene came up, i guess this site was just for hrvard but then they expanded to Yale, Columbia, and Stanford... sounds very elite like lol\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:21:34.893Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"Seems like it was intended for the elite, but he saw the amount of money to be made by globalizing it\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:22:43.385Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"and go figure Sean Parker who co founded Napster is in on it with Mark to make Facebook, i guess he is the one who persuaded him to drop the THE  as it was called Thefacebook originally\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:22:44.601Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"removing the word \\\"the\\\" was a smart choice atleast\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:23:19.866Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"yeah, flows a bit better I suppose so you can say \\\"facebook me\\\" lol\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:23:46.092Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"ah new scene, talking about all the lawsuits that came against him. \", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:24:08.189Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"I feel like he has always been in trouble for the way he operates then\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:24:24.002Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"Now it is the way he markets ads by listening through the phones\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:24:38.500Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"ending sounds weird, they said it ends with him sending a friend request to his ex who dumped him.  ironic.\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:24:54.913Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"Im sure that was just for the hollywood effect\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:25:10.035Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"yeah, he is a very selfish type of person I think in reality\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:25:15.982Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"I agree\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:25:25.134Z\"\n",
    "    }\n",
    "  ], \n",
    "  \"rating\": 2, \n",
    "  \"status\": 1, \n",
    "  \"uid1LogInTime\": \"2018-02-20T19:15:08.841Z\", \n",
    "  \"uid1LogOutTime\": \"2018-02-20T19:25:26.348Z\", \n",
    "  \"uid1response\": {\n",
    "    \"feedback\": \"I hate facebook and mark as a company\", \n",
    "    \"response\": [\n",
    "      2, \n",
    "      3, \n",
    "      5\n",
    "    ], \n",
    "    \"type\": \"finish\"\n",
    "  }, \n",
    "  \"uid2LogInTime\": \"2018-02-20T19:15:08.854Z\", \n",
    "  \"uid2LogOutTime\": \"2018-02-20T19:25:42.640Z\", \n",
    "  \"uid2response\": {\n",
    "    \"feedback\": null, \n",
    "    \"response\": [\n",
    "      1, \n",
    "      2, \n",
    "      3, \n",
    "      5\n",
    "    ], \n",
    "    \"type\": \"finish\"\n",
    "  }, \n",
    "  \"user1_id\": \"USR1723\", \n",
    "  \"user2_id\": \"USR3213\", \n",
    "  \"whoSawDoc\": [\n",
    "    \"user2\"\n",
    "  ], \n",
    "  \"wikiDocumentIdx\": 17\n",
    "}\n",
    "\n",
    "The above is a json from CMU DoG dataset. Your task is to transform it into the following columns: user_id, text, docIdx and ascending order with docIdx \n",
    "</blockquote>\n",
    "\n",
    "**answer**\n",
    "<blockquote>\n",
    "Certainly, I can help you transform the provided JSON into the desired format with the columns: `user_id`, `text`, and `docIdx` in ascending order of `docIdx`. Here's the transformed data:\n",
    "\n",
    "```\n",
    "user_id   | text                                                                                     | docIdx\n",
    "----------|------------------------------------------------------------------------------------------|-------\n",
    "user1     | hello                                                                                    | 0\n",
    "user2     | hello there, I have not seen this movie so I'm going to take a minute to look it over :) | 0\n",
    "user1     | Alright that is fine. What is the movie?                                                  | 0\n",
    "user2     | The movie is The Social Network                                                           | 0\n",
    "user1     | I have not seen that one either.                                                           | 0\n",
    "user2     | It appears to be like a biographical movie about Mark Zuckerberg and when he creates Facebook. | 0\n",
    "user1     | Ohh yes I remember hearing about that movie, but it was a long time ago it feels like.    | 0\n",
    "user2     | Rotten Tomatoes has rated it 96% so that's decent, and it is a movie from 2010             | 0\n",
    "user2     | may be worth watching!                                                                    | 0\n",
    "user1     | Yes I think it could be, although I personally do not like Facebook as a company.        | 1\n",
    "user2     | the movie portrays the founding of the social networking website Facebook and the resulting lawsuits. It even has Justin Timberlake in it, I don't think I've ever seen him act. | 1\n",
    "user1     | I have not seen him in any movies in years                                                | 1\n",
    "user1     | Any other big name actors in it?                                                           | 1\n",
    "user2     | hmm so I just got a scene described to me, it turns out Mark was dumped so he made a blog about her ... kind of childish.... then he made a site for people to \"rate\" women on looks...the college put him on probation. and then that captured the attention of two classmates, that's how the trio came to work on Facebook I guess. | 1\n",
    "user1     | So it came out of Mark being kind of a douche, Makes sense when I think about the company   | 1\n",
    "user2     | Jesse Eisenberg, Andrew Garfield, Armie Hammer, and Max Minghella, not familiar with any of those, I'd have to look on IMDb | 2\n",
    "user1     | I am not familiar with any of them either                                                  | 2\n",
    "user2     | another scene came up, I guess this site was just for Harvard, but then they expanded to Yale, Columbia, and Stanford... sounds very elite-like lol | 2\n",
    "user1     | Seems like it was intended for the elite, but he saw the amount of money to be made by globalizing it | 2\n",
    "user2     | and go figure Sean Parker who co-founded Napster is in on it with Mark to make Facebook, I guess he is the one who persuaded him to drop the \"THE\" as it was called Thefacebook originally | 2\n",
    "user1     | removing the word \"the\" was a smart choice at least                                        | 2\n",
    "user2     | yeah, flows a bit better I suppose so you can say \"facebook me\" lol                       | 3\n",
    "user2     | ah new scene, talking about all the lawsuits that came against him.                         | 3\n",
    "user1     | I feel like he has always been in trouble for the way he operates then                     | 3\n",
    "user1     | Now it is the way he markets ads by listening through the phones                             | 3\n",
    "user2     | ending sounds weird, they said it ends with him sending a friend request to his ex who dumped him. ironic. | 3\n",
    "user1     | I'm sure that was just for the Hollywood effect                                              | 3\n",
    "user2     | yeah, he is a very selfish type of person I think in reality                                | 3\n",
    "user1     | I agree                                                                                       | 3\n",
    "```\n",
    "\n",
    "I've organized the data by user and sorted it in ascending order of `docIdx`. If you have any further requests or need additional assistance, please let me know!\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3aac379c3d5c95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Q1.3\n",
    "\n",
    "**prompt**\n",
    "<blockquote>\n",
    "Now you are a senior programmer. Your task is to write a Python program to read json and to transform the above json into the following columns: user_id, docIdx, text and ascending order with docIdx. Remember to do error checking and prevent exceptional cases and consider the reusability\n",
    "</blockquote>\n",
    "\n",
    "**answer**\n",
    "<blockquote>\n",
    "Certainly! To create a reusable Python program that reads JSON data and transforms it into the desired format while handling errors gracefully, you can encapsulate the transformation logic into a function. Here's a program with a reusable function:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "def transform_json_to_columns(json_data):\n",
    "    try:\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(json_data)\n",
    "\n",
    "        # Initialize a list to store the transformed data\n",
    "        transformed_data = []\n",
    "\n",
    "        # Extract relevant information from the JSON\n",
    "        history = data.get(\"history\", [])\n",
    "        for entry in history:\n",
    "            docIdx = entry.get(\"docIdx\")\n",
    "            text = entry.get(\"text\")\n",
    "            user_id = entry.get(\"uid\")\n",
    "\n",
    "            # Check if docIdx, text, and user_id are present\n",
    "            if docIdx is not None and text and user_id:\n",
    "                transformed_data.append({\n",
    "                    \"user_id\": user_id,\n",
    "                    \"docIdx\": docIdx,\n",
    "                    \"text\": text\n",
    "                })\n",
    "\n",
    "        # Sort the data by docIdx in ascending order\n",
    "        transformed_data.sort(key=lambda x: x[\"docIdx\"])\n",
    "\n",
    "        return transformed_data\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Provided JSON data\n",
    "json_data = '''\n",
    "{\n",
    "  \"date\": \"2018-02-20T19:15:08.841Z\", \n",
    "  \"history\": [\n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"hello\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:16.038Z\"\n",
    "    },\n",
    "    # ... (the rest of the JSON data)\n",
    "  ],\n",
    "  \"rating\": 2, \n",
    "  \"status\": 1, \n",
    "  \"uid1LogInTime\": \"2018-02-20T19:15:08.841Z\", \n",
    "  \"uid1LogOutTime\": \"2018-02-20T19:25:26.348Z\", \n",
    "  \"uid1response\": {\n",
    "    \"feedback\": \"I hate facebook and mark as a company\", \n",
    "    \"response\": [\n",
    "      2, \n",
    "      3, \n",
    "      5\n",
    "    ], \n",
    "    \"type\": \"finish\"\n",
    "  },\n",
    "  # ...\n",
    "}\n",
    "'''\n",
    "\n",
    "# Transform the JSON data\n",
    "transformed_data = transform_json_to_columns(json_data)\n",
    "\n",
    "# Display the transformed data\n",
    "for entry in transformed_data:\n",
    "    print(f\"user_id: {entry['user_id']}, docIdx: {entry['docIdx']}, text: {entry['text']}\")\n",
    "```\n",
    "\n",
    "In this program, the `transform_json_to_columns` function takes the JSON data as input and returns the transformed data as a list of dictionaries. Error handling is implemented to catch JSON parsing errors and other exceptions.\n",
    "\n",
    "You can reuse the `transform_json_to_columns` function with different JSON inputs by providing the JSON data as an argument to the function.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf9cf4e6685a028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T07:56:26.801969500Z",
     "start_time": "2023-10-04T07:56:26.754414500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: user1, docIdx: 0, text: hello\n",
      "user_id: user2, docIdx: 0, text: hello there, I have not seen this movie so im going to take a minute to look it over :)\n",
      "user_id: user1, docIdx: 0, text: Alright that is fine. What is the movie?\n",
      "user_id: user2, docIdx: 0, text: The movie is The Social Network\n",
      "user_id: user1, docIdx: 0, text: I have not seen that one either.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def transform_json_to_columns(json_data):\n",
    "    try:\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(json_data)\n",
    "\n",
    "        # Initialize a list to store the transformed data\n",
    "        transformed_data = []\n",
    "\n",
    "        # Extract relevant information from the JSON\n",
    "        history = data.get(\"history\", [])\n",
    "        for entry in history:\n",
    "            docIdx = entry.get(\"docIdx\")\n",
    "            text = entry.get(\"text\")\n",
    "            user_id = entry.get(\"uid\")\n",
    "\n",
    "            # Check if docIdx, text, and user_id are present\n",
    "            if docIdx is not None and text and user_id:\n",
    "                transformed_data.append({\n",
    "                    \"user_id\": user_id,\n",
    "                    \"docIdx\": docIdx,\n",
    "                    \"text\": text\n",
    "                })\n",
    "\n",
    "        # Sort the data by docIdx in ascending order\n",
    "        transformed_data.sort(key=lambda x: x[\"docIdx\"])\n",
    "\n",
    "        return transformed_data\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Provided JSON data\n",
    "json_data = r'''\n",
    "{\n",
    "  \"date\": \"2018-02-20T19:15:08.841Z\", \n",
    "  \"history\": [\n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"hello\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:16.038Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"hello there, I have not seen this movie so im going to take a minute to look it over :)\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:36.022Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"Alright that is fine. What is the movie?\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:49.258Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"The movie is The Social Network\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:15:56.234Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"I have not seen that one either.\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:16:26.551Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"It appears to be like a biographical movie about Mark Zuckerberg and when he creates Facebook.\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:16:32.140Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"Ohh yes I remember hearing about that movie, but it was a long time ago it feels like.\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:17:04.252Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"Rotten Tomatoes has rated it 96% so that's decent, and it is a movie from 2010\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:17:08.213Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 0, \n",
    "      \"text\": \"may be worth watching!\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:17:21.342Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"Yes I think it could be, although I personally do not like facebook as a company.\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:18:05.350Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"the movie portrays the founding of social networking website Facebook and the resulting lawsuits. It even has Justin Timberlake in it, I don't think I've ever seen him act. \", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:18:11.549Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"I have not seen him in any movies in years\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:18:26.046Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"Any other big name actors in it?\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:19:35.351Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"hmm so I just got a scene described to me, it turns out Mark was dumped so he made a blog about her ... kind of childish.... then he made a site for people to \\\"rate\\\" women on looks...the college put him on porbation. and then that captured the attention of two classmates , that how the trio came to work on facebook I guess.\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:19:55.668Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 1, \n",
    "      \"text\": \"So it came out of Mark being kind of a douche, Makes sense when I think about the company \", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:20:34.278Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"Jesse Eisenberg, Andrew Garfield, Armie Hammer , and Max Minghella, not famailiar with any of those, id have to look on IMBD\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:20:42.059Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"I am not familiar\\n with any of them either\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:21:05.185Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"another scene came up, i guess this site was just for hrvard but then they expanded to Yale, Columbia, and Stanford... sounds very elite like lol\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:21:34.893Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"Seems like it was intended for the elite, but he saw the amount of money to be made by globalizing it\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:22:43.385Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"and go figure Sean Parker who co founded Napster is in on it with Mark to make Facebook, i guess he is the one who persuaded him to drop the THE  as it was called Thefacebook originally\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:22:44.601Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 2, \n",
    "      \"text\": \"removing the word \\\"the\\\" was a smart choice atleast\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:23:19.866Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"yeah, flows a bit better I suppose so you can say \\\"facebook me\\\" lol\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:23:46.092Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"ah new scene, talking about all the lawsuits that came against him. \", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:24:08.189Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"I feel like he has always been in trouble for the way he operates then\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:24:24.002Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"Now it is the way he markets ads by listening through the phones\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:24:38.500Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"ending sounds weird, they said it ends with him sending a friend request to his ex who dumped him.  ironic.\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:24:54.913Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"Im sure that was just for the hollywood effect\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:25:10.035Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"yeah, he is a very selfish type of person I think in reality\", \n",
    "      \"uid\": \"user2\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:25:15.982Z\"\n",
    "    }, \n",
    "    {\n",
    "      \"docIdx\": 3, \n",
    "      \"text\": \"I agree\", \n",
    "      \"uid\": \"user1\", \n",
    "      \"utcTimestamp\": \"2018-02-20T19:25:25.134Z\"\n",
    "    }\n",
    "  ], \n",
    "  \"rating\": 2, \n",
    "  \"status\": 1, \n",
    "  \"uid1LogInTime\": \"2018-02-20T19:15:08.841Z\", \n",
    "  \"uid1LogOutTime\": \"2018-02-20T19:25:26.348Z\", \n",
    "  \"uid1response\": {\n",
    "    \"feedback\": \"I hate facebook and mark as a company\", \n",
    "    \"response\": [\n",
    "      2, \n",
    "      3, \n",
    "      5\n",
    "    ], \n",
    "    \"type\": \"finish\"\n",
    "  }, \n",
    "  \"uid2LogInTime\": \"2018-02-20T19:15:08.854Z\", \n",
    "  \"uid2LogOutTime\": \"2018-02-20T19:25:42.640Z\", \n",
    "  \"uid2response\": {\n",
    "    \"feedback\": null, \n",
    "    \"response\": [\n",
    "      1, \n",
    "      2, \n",
    "      3, \n",
    "      5\n",
    "    ], \n",
    "    \"type\": \"finish\"\n",
    "  }, \n",
    "  \"user1_id\": \"USR1723\", \n",
    "  \"user2_id\": \"USR3213\", \n",
    "  \"whoSawDoc\": [\n",
    "    \"user2\"\n",
    "  ], \n",
    "  \"wikiDocumentIdx\": 17\n",
    "}\n",
    "'''\n",
    "\n",
    "# Transform the JSON data\n",
    "transformed_data = transform_json_to_columns(json_data)\n",
    "\n",
    "# Display the transformed data\n",
    "for entry in transformed_data[0:5]:\n",
    "    print(f\"user_id: {entry['user_id']}, docIdx: {entry['docIdx']}, text: {entry['text']}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e25e4827bff0f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30713c98f76fdd30",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**2.1**\n",
    "\n",
    "p=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416367de",
   "metadata": {},
   "source": [
    "**2.2**\n",
    "\n",
    "![question 2.2](./Assets/Question%202.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4958e3",
   "metadata": {},
   "source": [
    "**Q2.3**\n",
    "\n",
    "![Question 2.3](./Assets/Question%202.3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b5dfb",
   "metadata": {},
   "source": [
    "**Q2.4**\n",
    "\n",
    "![Question 2.4](./Assets/Question%202.4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37db4be",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69408b3f",
   "metadata": {},
   "source": [
    "**1.**\n",
    "\n",
    "```SQL\n",
    "select h.hacker_id,h.name\n",
    "from Hackers h,\n",
    "    (select hacker_id,count(submission_id) as num from Submissions Group by hacker_id) mycount\n",
    "where\n",
    "    h.hacker_id = mycount.hacker_id and\n",
    "    mycount.num= (select max(countTable.num)\n",
    "                    from (select count(submission_id) as num from Submissions Group by hacker_id) countTable)\n",
    "order by h.hacker_id;\n",
    "\n",
    "```\n",
    "\n",
    "**2.**\n",
    "\n",
    "```SQL\n",
    "select t.task_id,t.task_description,mycount.num\n",
    "from    Tasks t,\n",
    "        (select task_id,count(submission_id) as num from Submissions Group by task_id) mycount\n",
    "where   t.task_id = mycount.task_id and\n",
    "        mycount.num=    (select max(countTable.num)\n",
    "                        from (select count(submission_id) as num from Submissions Group by task_id) countTable)\n",
    "order by t.task_id;\n",
    "```\n",
    "\n",
    "**3.**\n",
    "\n",
    "```SQL\n",
    "select s.submission_id, h.name, t.task_description\n",
    "from Submissions s, Hackers h, Tasks t\n",
    "where   s.hacker_id = h.hacker_id and\n",
    "        s.task_id = t.task_id and\n",
    "        s.score =(select max(score) from Submissions where submission_date = '2022-10-01') and\n",
    "        s.submission_date = '2022-10-01'\n",
    "order by s.submission_id;\n",
    "```\n",
    "\n",
    "**4.**\n",
    "\n",
    "```SQL\n",
    "select h.hacker_id, h.name\n",
    "from    Hackers h,\n",
    "        (\n",
    "            select scoreTable.hacker_id, sum(scoreTable.maxScore) as totalScore\n",
    "            from (select hacker_id, task_id, max(score) as maxScore\n",
    "                from Submissions\n",
    "                group by hacker_id, task_id) as scoreTable\n",
    "            group by scoreTable.hacker_id\n",
    "        ) as totalScoreTable\n",
    "where (\n",
    "        totalScoreTable.hacker_id = h.hacker_id and\n",
    "        totalScoreTable.totalScore =(\n",
    "                                        select max(sumScoreTable.totalScore)\n",
    "                                        from (\n",
    "                                            select sum(scoreTable.maxScore) as totalScore\n",
    "                                                    from (select hacker_id, max(score) as maxScore\n",
    "                                                            from Submissions\n",
    "                                                            group by hacker_id, task_id\n",
    "                                                            ) as scoreTable\n",
    "                                            group by scoreTable.hacker_id\n",
    "                                        ) as sumScoreTable\n",
    "                                    )\n",
    "        )\n",
    "order by h.hacker_id DESC;\n",
    "```\n",
    "\n",
    "**5.**\n",
    "\n",
    "```SQL\n",
    "select h.hacker_id, h.name, t.bouns\n",
    "from Hackers h, Tasks t,\n",
    "    (\n",
    "       select s1.submission_id, s2.hacker_id,s1.task_id, s2.fscore\n",
    "        from (select * \n",
    "                from Submissions\n",
    "                where task_id=25) as s1 right join\n",
    "            (\n",
    "                select hacker_id , max(score) as fscore\n",
    "                from Submissions\n",
    "                where task_id=25\n",
    "                Group by hacker_id\n",
    "            ) as s2\n",
    "        on (s1.hacker_id=s2.hacker_id and \n",
    "            s1.score = s2.fscore)\n",
    "        order by s2.fscore DESC, s1.submission_id\n",
    "        limit 3\n",
    "    ) as Top3Table\n",
    "where (\n",
    "        h.hacker_id=Top3Table.hacker_id and \n",
    "        t.task_id = Top3Table.task_id \n",
    "        )\n",
    "\n",
    "```\n",
    "\n",
    "**6.**\n",
    "\n",
    "```SQL\n",
    "select * \n",
    "from (\n",
    "        select t1.hacker_id, h.name,h.Bank_acount,sum(t2.bouns) as total_bonus\n",
    "        from Hackers h, \n",
    "            (select * from (\n",
    "                    select s1.task_id,s1.hacker_id, s1.fscore,row_number() over (partition by s1.task_id order by s1.fscore DESC) as ranking \n",
    "                    from (select task_id, hacker_id , max(score) as fscore \n",
    "                          from Submissions\n",
    "                           Group by task_id, hacker_id\n",
    "                        ) as s1\n",
    "                ) as rankTable\n",
    "                where ranking<=3\n",
    "            ) as t1\n",
    "            left join Tasks as t2\n",
    "            on t1.task_id = t2.task_id\n",
    "        where h.hacker_id = t1.hacker_id\n",
    "        group by t1.hacker_id\n",
    "        order by total_bonus DESC, h.hacker_id    \n",
    "    ) as ftable\n",
    "where ftable.total_bonus <> 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733d402229698d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14624527",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "**1**\n",
    "\n",
    "Content based approach used the given metadata from user and given meta from the content to construct a model for predicting the likeness of the content for the user and recommend similar content based on it. \n",
    "\n",
    "\n",
    "Collaborative filtering approach uses past interaction records between user and item, such as purchasing history, rating history etc, to generate model for predicting the likeness of the content and recommend similar content based on it. If someone who watch a certain movie, the one who is similar to him will be recommended to that movie\n",
    "\n",
    "\n",
    "**2**\n",
    "\n",
    "Cold start problem refers to that the system can not form the proper relationship between item and the user which result in giving wrong recommendation. There are two types of cold start problem: product cold-start and user cold-start. Product cold-start means there is no enough information about the new product and user cold-start means there is almost no data available on the user.\n",
    "\n",
    "To minimize the cold-start problem. There are the following method:\n",
    "\n",
    "1.  By analyzing the cookies of the new users to identify what website or ads they have watched before in order to form the features vector for them.\n",
    "2.  Assign the average feature vector from all user to the new user.\n",
    "3.  Recommend the popular item to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b618ac90af02ffa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T02:09:48.869435400Z",
     "start_time": "2023-10-12T02:09:48.822538Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (90570, 4)\n",
      "user id 1.0 item 1.0 rate :5.0 timestamp :1.0\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "shape= (1682, 943) first 3 [[5. 4. 0. ... 5. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 5.]\n",
      " [4. 0. 0. ... 0. 0. 0.]]\n",
      "move 1 --- user-1: 5.0 user-2: 4.0    ...... \n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "import numpy as np\n",
    "\n",
    "NUM_USERS=943\n",
    "NUM_MOVIES=1682\n",
    "\n",
    "def ReadFile(path:str,delimiter='\\t'):\n",
    "    try:\n",
    "        data = np.loadtxt(path, delimiter=delimiter, unpack=True,encoding=\"utf-8\")\n",
    "        return data.T\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# convert data into movie X user matrix \n",
    "def Convert_To_MovieUser(data, num_user, num_items):\n",
    "    records=data.tolist()\n",
    "    # dict\n",
    "    item_data = {}\n",
    "\n",
    "    for record in records: # loop record\n",
    "        user, item, rate, timestamp = record\n",
    "        if item not in item_data:\n",
    "            item_data[item] = {}\n",
    "        item_data[item][user] = rate\n",
    "\n",
    "    # Create a list of items and a list of users\n",
    "    items = sorted(item_data.keys()) # item id 1,2,3,\n",
    "    users = sorted(set(user for data in item_data.values() for user in data.keys()))\n",
    "    print(items[:5])\n",
    "    print(users[:5])\n",
    "    # create empty array\n",
    "    result =np.zeros(shape=(num_items,num_user)) \n",
    "    for i, item in enumerate(items):\n",
    "        for j, user in enumerate(users):\n",
    "            if user in item_data[item]: \n",
    "                result[int(item)-1][int(user)-1] = item_data[item][user]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "train_dataset=ReadFile(\"./ml-100k/ua.base\") # some movie is not rate\n",
    "print(f\"train shape = {train_dataset.shape}\")\n",
    "print(f\"user id {train_dataset[0][0]} item {train_dataset[0][1]} rate :{train_dataset[0][2]} timestamp :{train_dataset[0][0]}\")\n",
    "\n",
    "\n",
    "result = Convert_To_MovieUser(train_dataset,NUM_USERS,NUM_MOVIES)\n",
    "print(f\"shape= {result.shape} first 3 {result[:3]}\")\n",
    "train_dataset=result\n",
    "print(f\"move 1 --- user-1: {train_dataset[0][0]} user-2: {train_dataset[0][1]}    ...... \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa20a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix_with_mask(result, mask):\n",
    "    column_means = np.mean(result, axis=0)\n",
    "    normalized_result = np.where(mask, result - column_means, 0.0)\n",
    "    return normalized_result,column_means\n",
    "\n",
    "masked       = (train_dataset != 0).astype(int)\n",
    "Ynorm, Ymean = normalize_matrix_with_mask(train_dataset, masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fdac7bdfd48a69d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 5195875.7\n",
      "Training loss at iteration 20: 156253.2\n",
      "Training loss at iteration 40: 63458.3\n",
      "Training loss at iteration 60: 38068.9\n",
      "Training loss at iteration 80: 26439.2\n",
      "Training loss at iteration 100: 19927.0\n",
      "Training loss at iteration 120: 15888.8\n",
      "Training loss at iteration 140: 13242.2\n",
      "Training loss at iteration 160: 11439.3\n",
      "Training loss at iteration 180: 10170.7\n",
      "Training loss at iteration 200: 9251.7\n",
      "Training loss at iteration 220: 8568.0\n",
      "Training loss at iteration 240: 8046.5\n",
      "Training loss at iteration 260: 7639.2\n",
      "Training loss at iteration 280: 7314.0\n",
      "Training loss at iteration 300: 7048.9\n",
      "Training loss at iteration 320: 6828.6\n",
      "Training loss at iteration 340: 6642.3\n",
      "Training loss at iteration 360: 6482.4\n",
      "Training loss at iteration 380: 6343.4\n",
      "Training loss at iteration 400: 6221.0\n",
      "Training loss at iteration 420: 6112.4\n",
      "Training loss at iteration 440: 6015.2\n",
      "Training loss at iteration 460: 5927.5\n",
      "Training loss at iteration 480: 5848.1\n",
      "Training loss at iteration 500: 5775.8\n",
      "Training loss at iteration 520: 5709.6\n",
      "Training loss at iteration 540: 5648.8\n",
      "Training loss at iteration 560: 5592.8\n",
      "Training loss at iteration 580: 5541.1\n",
      "Training loss at iteration 600: 5493.4\n",
      "Training loss at iteration 620: 5449.1\n",
      "Training loss at iteration 640: 5408.1\n",
      "Training loss at iteration 660: 5370.2\n",
      "Training loss at iteration 680: 5335.0\n",
      "Training loss at iteration 700: 5302.4\n",
      "Training loss at iteration 720: 5272.4\n",
      "Training loss at iteration 740: 5244.5\n",
      "Training loss at iteration 760: 5218.8\n",
      "Training loss at iteration 780: 5195.2\n",
      "Training loss at iteration 800: 5173.6\n",
      "Training loss at iteration 820: 5153.8\n",
      "Training loss at iteration 840: 5135.8\n",
      "Training loss at iteration 860: 5119.4\n",
      "Training loss at iteration 880: 5104.6\n",
      "Training loss at iteration 900: 5091.2\n",
      "Training loss at iteration 920: 5079.0\n",
      "Training loss at iteration 940: 5068.1\n",
      "Training loss at iteration 960: 5058.3\n",
      "Training loss at iteration 980: 5049.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def cost_func(X, W, b, Y, R, lambda_):\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J\n",
    "\n",
    "\n",
    "\n",
    "num_movies, num_users = train_dataset.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)\n",
    "\n",
    "iterations = 1000\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        cost_value = cost_func(X, W, b, Ynorm, masked, lambda_)\n",
    "\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0845f517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      "[[4.47121744 3.90791312 2.58141951 ... 4.90594815 3.28004964 3.23715004]\n",
      " [2.46130921 2.39352505 2.84212171 ... 3.74988025 4.69602359 4.60846987]\n",
      " [3.40665383 3.04753257 2.82411685 ... 3.83060395 4.05399343 2.82923497]]\n",
      "train data set\n",
      "[[5. 4. 0. ... 5. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 5.]\n",
      " [4. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "prediction = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "print(f\"prediction:\")\n",
    "print(prediction[0:3])\n",
    "print(f\"train data set\")\n",
    "print(train_dataset[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "935c19bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1682, 943)\n",
      "[3.0413075  3.16251533 3.22947077 ... 2.62759055 2.16505899 2.94692104]\n",
      "[4. 4. 3. ... 2. 1. 1.]\n",
      "loss_with_prediction :8184.89339740904\n",
      "loss_with_original :33833.0\n",
      "Improvement : 25648.10660259096\n"
     ]
    }
   ],
   "source": [
    "test_dataset=ReadFile(\"./ml-100k/ua.test\")\n",
    "movie_user_test = Convert_To_MovieUser(test_dataset,NUM_USERS,NUM_MOVIES)\n",
    "print(movie_user_test[0:3])\n",
    "print(movie_user_test.shape)\n",
    "\n",
    "mask_test       = (movie_user_test != 0).astype(int)\n",
    "print(prediction[mask_test==1])\n",
    "print(movie_user_test[mask_test==1])\n",
    "\n",
    "\n",
    "loss_with_prediction = np.sum(np.abs(prediction[mask_test==1]-movie_user_test[mask_test==1]))\n",
    "print(f\"loss_with_prediction :{loss_with_prediction}\")\n",
    "\n",
    "loss_with_original = np.sum(np.abs(train_dataset[mask_test==1]-movie_user_test[mask_test==1]))\n",
    "print(f\"loss_with_original :{loss_with_original}\")\n",
    "\n",
    "print(f\"Improvement : {loss_with_original-loss_with_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
