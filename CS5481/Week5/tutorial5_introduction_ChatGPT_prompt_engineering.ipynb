{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5481 - Tutorial 5\n",
    "## Introduction to Prompt Engineering for ChatGPT\n",
    "\n",
    "Welcome to CS5481 tutorial. In this tutorial, you will get familiar with how to use ChatGPT to improve your efficiency by prompt engineering and you will see the ChatGPT's ability of In-Context Learning (zero-shot, few-shot) and Chain-of-Thought.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to access ChatGPT\n",
    "\n",
    "Due to the striction of OpenAI Policy, people in China mainland and Hong Kong are not allowed to register a ChatGPT official account. But, we still have some other approaches to access ChatGPT.\n",
    "\n",
    "1. https://poe.com\n",
    "2. CityU ChatGPT API (We have applied it for all students. It has a limitation on available token number 80K )\n",
    "\n",
    "In this tutorial, we use the first approach to show demos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.Prompt Engineering for ChatGPT\n",
    "Prompt engineering is the most crucial aspect of utilizing LLMs effectively and is a powerful tool for customizing the interactions with ChatGPT. It involves crafting clear and specific instructions or queries to elicit the desired responses from the language model. By carefully constructing prompts, users can guide ChatGPT’s output toward their intended goals and ensure more accurate and useful responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several foundational techniques to remember in the process of prompt optimization for ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Providing explicit instructions at the beginning of the prompt helps set the context and define the task for the model. Specifying the format or type of the expected answer is also beneficial. Additionally, you can enhance the interaction by incorporating system messages or role-playing techniques in the prompt.\n",
    "\n",
    "Below is an example prompt with the above techniques:\n",
    "\n",
    "        I would like you to generate 10 quick-prep dinner meal ideas for recipe blogs, with each idea including a title and a one sentence description of the meal. These blogs will be written for an audience of parents looking for easy-to-prepare family meals. Output the results as a bulleted list.\n",
    "\n",
    "Compare that prompt with the following:\n",
    "\n",
    "        Write 10 recipe blogs.\n",
    "2. Remember that you can improve the quality and relevance of the model’s responses by iteratively refining and experiment with prompts, creating more productive conversations. Don’t be afraid to test out potential prompts on ChatGPT directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Basic Prompt Engineering Principles\n",
    "### 3.1.1 Prompt Wording\n",
    "A prompt’s wording is paramount, as it guides the LLM in generating the desired output. It’s important to phrase the question or statement in a way that ChatGPT understands and can respond to accurately.\n",
    "\n",
    "For example, if a user is not an expert in an area and does not know the right term to phrase a question, ChatGPT may experience limitations on the answers they provide. It is similar to searching on the web without knowing the correct keyword.\n",
    "\n",
    "While it may be evident that additional information could be used to create better prompts, it may be less obvious that being overly verbose in general is not necessarily an optimal strategy. It’s best to think of prompt wording not as a separate technique but as a connecting thread through all other techniques\n",
    "\n",
    "### 3.1.2 Succinctness\n",
    "Succinctness in a prompt is important for clarity and precision. A well-crafted prompt should be concise and to the point, providing enough information for ChatGPT to understand the user’s intent without being overly verbose. However, ensuring the prompt is not too brief is vital, which may lead to ambiguity or misunderstanding. This balance between not enough and too much can be tricky to strike. Practice is probably the best way to master this skill.\n",
    "\n",
    "### 3.1.3 Roles and Goals\n",
    "In prompt engineering, roles are personas assigned for the LLM and the intended audience. For example, if one is interested in having ChatGPT write an outline for a blog post on machine learning classification metrics, explicitly stating that the LLM is to act as an expert machine learning practitioner and that its intended audience is data science newcomers would certainly help provide a fruitful response.\n",
    "\n",
    "### 3.1.4 Positive and Negative Prompting\n",
    "Positive and negative prompting is another set of framing methods to guide the model’s output. Positive prompts (“do this“) encourage the model to include specific types of output and generate certain types of responses. Negative prompts (“don’t do this“), on the other hand, discourage the model from including specific types of output and generating certain types of responses. Using positive and negative prompts can greatly influence the direction and quality of the model’s output.\n",
    "\n",
    "Consider the following example prompt:\n",
    "\n",
    "    You are to act as a real estate agent with 10 years experience in the Phoenix area. Your goal is to produce a one paragraph summary of each of the top 5 family neighborhoods in the Phoenix metropolitan area. The intended audience is inexperienced home buyers.\n",
    "\n",
    "The framing of the above prompt is positive in nature, providing guidance on what ChatGPT should generate. Let’s add some wording to discourage certain output, be it in content or format. An example of negative prompting geared toward content guidance could be the addition of the following to our above example:\n",
    "\n",
    "    Do not include any neighborhoods within 5 miles of downtown or adjacent to the airport.\n",
    "\n",
    "This additional constraint should be helpful in ChatGPT’s understanding of what output it should generate.\n",
    "\n",
    "\n",
    "## 3.2 Advanced Prompt Engineering Strategies\n",
    "Let’s look at a selection of more advanced prompt engineering strategies. While the previous section provided some general guidelines for interactions with LLMs, you can turn to a variety of contemporary strategies that are commonplace in the prompt engineer’s toolkit for the ability to interact with ChatGPT in a more complex manner.\n",
    "\n",
    "### 3.2.1 Input/Output Prompting \n",
    "\n",
    "The input/output prompting strategy involves defining the input that the user provides to the LLM and the output that the LLM is to generate in response. This strategy is fundamental to prompt engineering as it directly influences the quality and relevance of the ChatGPT’s response.\n",
    "\n",
    "For instance, the user might provide an input prompt asking ChatGPT to generate a Python script for a specific task, and the desired output would be the generated script.\n",
    "\n",
    "Below is an example of the most basic strategy: provide a single input and desire a single output.\n",
    "\n",
    "    Generate a Python script that takes a single mandatory command line argument ([project]) and performs the following tasks:\n",
    "    – creates a new folder named [project]\n",
    "    – creates a file within the new folder named [project].py\n",
    "    – writes a simple Python script file header to the [project].py file\n",
    "\n",
    "### 3.2.2 Zero-Shot Prompting\n",
    "\n",
    "The zero-shot strategy involves the LLM generating an answer without any examples or context. This strategy can be useful when the user wants a quick answer without providing additional detail, or when the topic is so general that examples would artificially limit the response. For example:\n",
    "\n",
    "    Generate 10 possible names for my new dog.\n",
    "\n",
    "### 3.2.3 One-Shot Prompting\n",
    "\n",
    "The one-shot strategy involves the LLM generating an answer based on a single example or piece of context provided by the user. This strategy can guide ChatGPT’s response and ensure it aligns with the user’s intent. The idea here would be that one example would provide more guidance to the model than none. For example:\n",
    "\n",
    "    Generate 10 possible names for my new dog.\n",
    "    A dog name that I like is Banana.\n",
    "\n",
    "\n",
    "### 3.2.4 Few-Shot Prompting\n",
    "\n",
    "The few-shot strategy involves the LLM generating an answer based on a few examples or pieces of context provided by the user. This strategy can guide ChatGPT’s response and ensure it aligns with the user’s intent. The idea here would be that several examples would provide more guidance to the model than one. For example:\n",
    "\n",
    "    Generate 10 possible names for my new dog.\n",
    "    Dog names that I like include:\n",
    "    – Banana\n",
    "    – Kiwi\n",
    "    – Pineapple\n",
    "    – Coconut\n",
    "\n",
    "As you can guess, the more examples the prompt included, the closer the generated output conforms to what is desired. With zero-shot, there may be no fruit names suggested; with one-shot, there may be several; and with few-shot, the suggestions may consist entirely of fruit-themed names.\n",
    "\n",
    "\n",
    "### 3.2.5 Chain-of-Thought Prompting\n",
    "The chain-of-thought strategy involves providing the LLM with a few examples that help to refine the original question and ensure a more accurate and comprehensive answer. Chain-of-thought prompts are so-called because they include a few chain-of-thought examples in the prompting. It is differentiated from the X-shot prompting techniques as chain-of-thought prompts are structured to encourage critical thinking, and are designed to help uncover new insights or approaches that ChatGPT may not have otherwise considered.\n",
    "\n",
    "The technique also encourages the LLM to output its critical reasoning. The calling card of chain-of-thought prompting is the phrase “Let’s think step by step” which is generally appended to the end of a prompt, which research suggests is enough to improve generated results.\n",
    "\n",
    "Consider the following one-shot prompt example:\n",
    "\n",
    "    Q: Joe has 20 eggs. He buys 2 more cartons of eggs. Each carton contains 12 eggs. How many eggs does Joe have now?\n",
    "    A: The answer is 44.\n",
    "\n",
    "    Q: Farmer John had 93 chickens. If he sold 20 to Farmer Bill and bought twice that number more, how many chickens does Farmer John have now?\n",
    "\n",
    "And consider ChatGPT’s incorrect output response:\n",
    "\n",
    "    The answer is 73.\n",
    "\n",
    "Now let’s look at the following chain of thought prompt, which is written to encourage critical thinking by the LLM:\n",
    "\n",
    "    Q: Joe has 20 eggs. He buys 2 more cartons of eggs. Each carton contains 12 eggs. How many eggs does Joe have now? Let’s think step by step.\n",
    "    A: Joe started with 20 eggs. 2 cartons of 12 eggs is 24 eggs. 20 + 24 = 44. Therefore, Joe has 44 eggs, and the answer is 44.\n",
    "\n",
    "    Q: Farmer John had 93 chickens. If he sold 20 to Farmer Bill and bought twice that number more, how many chickens does Farmer John have now? Let’s think step by step.\n",
    "\n",
    "ChatGPT’s response is different this time:\n",
    "\n",
    "    A: Farmer John sold 20 chickens to Farmer Bill, so he was left with 93 – 20 = 73 chickens. He then bought twice the number of chickens he sold, so he bought 2 * 20 = 40 chickens. Adding these newly bought chickens to his remaining stick, Farmer John now has 73 + 40 = 113 chickens.\n",
    "\n",
    "By providing an example of the critical thinking process needed to solve this problem, and coaching it to think step by step, ChatGPT could apply the same reasoning to our question and come up with the right answer this time.\n",
    "\n",
    "### 3.2.6 Self-Criticism\n",
    "\n",
    "The self-criticism strategy involves prompting the LLM to assess its output for potential inaccuracies or improvement areas. This strategy can ensure the information provided by ChatGPT is as accurate as possible. It can aid users in debugging their prompts and determining why they are not getting results that meet expectations.\n",
    "\n",
    "An example of such a prompt is as follows:\n",
    "\n",
    "    Please re-read your above response. Do you see any issues or mistakes with your response? If so, please identify these issues or mistakes and make the necessary edits.\n",
    "\n",
    "This example pertains to coaching ChatGPT to use self-criticism for debugging its buggy code:\n",
    "\n",
    "    Look at the code you have just generated. Currently it does not run. Are you able to see any syntax errors or flow control mistakes that you are able to rectify? If so, please identify the section of problematic code and re-generate it.\n",
    "\n",
    "Harnessing ChatGPT’s self-healing abilities is a prompt engineering technique you must not overlook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Practice\n",
    "### The iterative or expansive strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The iterative or expansive strategy involves prompting the LLM with follow-up prompts based on the output of an initial prompt. This involves iterating on the results by asking further questions or making additional requests from each successive response.\n",
    "\n",
    "For example, consider having ChatGPT assist in creating an outline for a book you are writing. The first prompt could like this:\n",
    "\n",
    "    I am writing a book on time travel theories. I have not settled on a specific topic. Generate 5 specific topic suggestions for such a book. For each suggestion, provide a title and one paragraph of description of what the book would cover. The book will be aimed at casual readers.\n",
    "\n",
    "Now, suppose one of the suggested topics is as follows:\n",
    "\n",
    "    Title: “Temporal Paradoxes: Navigating the Complexities of Time Travel”\n",
    "\n",
    "    Description: “Temporal Paradoxes” delves into the mind-bending intricacies of time travel paradoxes, exploring the fascinating conundrums they present. This book explores various paradoxes such as the Bootstrap Paradox, the Predestination Paradox, and the Information Paradox, among others. …\n",
    "\n",
    "You could then iterate on this using a follow-up prompt:\n",
    "\n",
    "    I will write the book you suggested, “Temporal Paradoxes: Navigating the Complexities of Time Travel”. Generate a chapter outline for this book, including sections and subsections.\n",
    "\n",
    "A possible output excerpt is below:\n",
    "\n",
    "    Introduction\n",
    "    – Defining temporal paradoxes\n",
    "    – Significance of temporal paradoxes in time travel narratives\n",
    "    – Overview of the chapter structure\n",
    "\n",
    "    Chapter 1: The Bootstrap Paradox\n",
    "    1.1 The essence of the Bootstrap Paradox\n",
    "    – Explaining the concept and its origin\n",
    "    – Key examples from literature, film, and real-life anecdotes\n",
    "    …\n",
    "\n",
    "This iteration can then continue. Further prompting could be:\n",
    "\n",
    "    Let’s flesh out the introduction. Generate a two paragraph summary of what each of the chapter’s sections will cover. The chapter outline for the introduction is below.\n",
    "    – – –\n",
    "    Introduction\n",
    "    – Defining temporal paradoxes\n",
    "    – Significance of temporal paradoxes in time travel narratives\n",
    "    – Overview of the chapter structure\n",
    "\n",
    "You could see how further iteration could continue in this example. \n",
    "\n",
    "Tips: A similar iteration could be used to have ChatGPT generate code: starting with an overview, iterating on the overview to generate modules, generating on the modules to generate functions, and finally generate the code within functions. Just as breaking big problems into smaller, more manageable problems is generally a prescription for success with humans, ChatGPT excels at completing larger tasks in more approachable chunks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
