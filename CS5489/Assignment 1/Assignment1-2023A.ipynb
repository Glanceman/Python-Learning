{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Xian Jia Le, Ben\n",
    "\n",
    "**EID:** 56214537\n",
    "\n",
    "**Kaggle Team Name:** Glanceman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Assignment 1 - SMS classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "In this assignment, the task is predict whether an SMS message is a real message, a spam message, or a phishing message (called smishing). Here are some examples:\n",
    "\n",
    "  - **Normal**: \"For real tho this sucks. I can't even cook my whole electricity is out. And I'm hungry.\"\n",
    "  - **Spam**: \"Had your mobile 10 mths? Update to latest Orange camera/video phones for FREE. Save Â£s with Free texts/weekend calls. Text YES for a callback orno to opt out\"\n",
    "  - **Smishing**: \"Todays Vodafone numbers ending 5347 are selected to receive a Rs.2,00,000 award. If you have a match please call 6299257179 quoting claim code 2041 standard rates apply\"\n",
    "\n",
    "\n",
    "Your goal is to train a classifier to predict the class from the SMS text. \n",
    "\n",
    "\n",
    "## Methodology\n",
    "You need to train classifiers using the training data, and then predict on the test data. You are free to choose the feature extraction method and classifier algorithm.  You are free to use methods that were not introduced in class.  You should probably do cross-validation to select a good parameters.\n",
    "\n",
    "\n",
    "## Evaluation on Kaggle\n",
    "\n",
    "You need to submit your test predictions to Kaggle for evaluation.  50% of the test data will be used to show your ranking on the live leaderboard.  After the assignment deadline, the remaining 50% will be used to calculate your final ranking. Also the top-ranked entries will be asked to give a short 5 minute presentation on what they did.\n",
    "\n",
    "The evaluation metric used on Kaggle is **balanced accuracy score**. This is because the dataset has some class imbalance as there are more normal samples than spam/smishing samples. See details for `sklearn.metrics.balanced_accuracy_score` [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html).\n",
    "\n",
    "To submit to Kaggle you need to create an account, and use the competition invitation that is posted to Canvas. You must submit your Kaggle account name to the \"Kaggle Username\" assignment on Canvas **1 week before the Assignment 1 deadline**. This is to prevent students from creating multiple Kaggle accounts to gain unfair advantage. \n",
    "\n",
    "**Note:** You can only submit 2 times per day to Kaggle!\n",
    "\n",
    "## What to hand in\n",
    "You need to turn in the following things:\n",
    "\n",
    "1. This ipynb file with your source code and documentation. _**You should write about all the various attempts that you make to find a good solution.**_ You may also submit python scripts as source code, but your documentation must be in the ipynb file.\n",
    "2. Your final csv submission file to Kaggle.\n",
    "3. The ipynb file `Assignment1-Final.ipynb`, which contains the code that generates the final submission file that you submit to Kaggle.  **This code will be used to verify that your Kaggle submission is reproducible.**\n",
    "4. Your Kaggle username (submitted to the \"Kaggle Username\" assignment on Canvas 1 week before the Assignment 1 deadline)\n",
    "\n",
    "Files should be uploaded to Assignment 1 on Canvas.\n",
    "\n",
    "## Grading\n",
    "The marks of the assignment are distributed as follows:\n",
    "- 45% - Results using various classifiers and feature representations.\n",
    "- 30% - Trying out feature representations (e.g. adding additional features) or classifiers not used in the tutorials/lectures.\n",
    "- 20% - Quality of the written report.  More points for insightful observations and analysis.\n",
    "- 5% - Final ranking on the Kaggle test data (private leaderboard). Only the Kaggle username submitted to Canvas on time will be considered. If a submission cannot be reproduced by the submitted code, it will not receive marks for ranking.\n",
    "- **Late Penalty:** 25 marks will be subtracted for each day late.\n",
    "\n",
    "**NOTE:** This is an _individual_ assignment.\n",
    "\n",
    "**NOTE:** you should start early! Some classifiers may take a while to train.\n",
    "\n",
    "\n",
    "## Kaggle Notebooks\n",
    "\n",
    "If you like, you can use Kaggle notebooks to run your code. Note that you still need to submit your code to Canvas for grading.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is in the text file `smishing_train.txt`.  This CSV file contains the SMS text and the class label. The class labels are: `0`, `1`, `2`, which are `normal`, `spam`, `smishing`. \n",
    "\n",
    "The testing data is in the text file `smishing_test.txt`, and only contains the SMS text.\n",
    "\n",
    "To submit to Kaggle, you need to generate a Kaggle submission files, which is CSV file with the following format: \n",
    "\n",
    "<pre>\n",
    "Id,Prediction\n",
    "1,0\n",
    "2,1\n",
    "3,0\n",
    "4,2\n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two helpful functions for reading the text data and writing the Kaggle submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T02:00:34.093545200Z",
     "start_time": "2023-09-20T02:00:26.907876300Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib_inline   # setup output image format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "import csv\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T02:00:36.691162Z",
     "start_time": "2023-09-20T02:00:36.685296700Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_text_data(fname):\n",
    "    txtdata = []\n",
    "    classes = []\n",
    "    with open(fname, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for row in reader:\n",
    "            # get the text\n",
    "            txtdata.append(row[0])\n",
    "            # get the class (convert to integer)\n",
    "            if len(row)>1:\n",
    "                classes.append(int(row[1]))\n",
    "        \n",
    "    return (txtdata, classes)\n",
    "\n",
    "def write_csv_kaggle_sub(fname, Y):\n",
    "    # fname = file name\n",
    "    # Y is a list/array with class entries\n",
    "    \n",
    "    # header\n",
    "    tmp = [['Id', 'Prediction']]\n",
    "    \n",
    "    # add ID numbers for each Y\n",
    "    for (i,y) in enumerate(Y):\n",
    "        tmp2 = [(i+1), y]\n",
    "        tmp.append(tmp2)\n",
    "        \n",
    "    # write CSV file\n",
    "    with open(fname, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will load the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T02:01:23.848517700Z",
     "start_time": "2023-09-20T02:01:23.827014300Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2985\n",
      "2986\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "(trainTxt, trainY) = read_text_data(\"smishing_train.txt\")\n",
    "(testX, _)   = read_text_data(\"smishing_test.txt\")\n",
    "\n",
    "print(len(trainTxt))\n",
    "print(len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T02:01:35.011942200Z",
     "start_time": "2023-09-20T02:01:34.999517200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# show the classnames\n",
    "classnames = unique(trainY)\n",
    "print(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T02:01:39.118860100Z",
     "start_time": "2023-09-20T02:01:39.102524900Z"
    }
   },
   "outputs": [],
   "source": [
    "classlabels = ['normal', 'spam', 'smishing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example to write a csv file with predictions on the test set.  These are random predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T02:02:31.449492600Z",
     "start_time": "2023-09-20T02:02:31.424062800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2986,)\n"
     ]
    }
   ],
   "source": [
    "# write your predictions on the test set\n",
    "i = random.randint(len(classnames), size=len(testX))\n",
    "print(i.shape)\n",
    "predY = classnames[i]\n",
    "write_csv_kaggle_sub(\"Output/my_submission.csv\", predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T03:24:51.371130Z",
     "start_time": "2023-09-13T03:24:51.359149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[normal]: Dunno da next show aft 6 is 850. Toa payoh got 650.\n",
      "[normal]: I.ll hand her my phone to chat wit u\n",
      "[normal]: I dont have i shall buy one dear\n",
      "[normal]: Nite...\n",
      "[normal]: Okï¿½congratsï¿½\n",
      "[spam]: I'd like to tell you my deepest darkest fantasies. Call me 09094646631 just 60p/min. To stop texts call 08712460324 (nat rate)\n",
      "[spam]: Santa Calling! Would your little ones like a call from Santa Xmas eve? Call 09058094583 to book your time.\n",
      "[spam]: Meet Top 35 US universities in Delhi at India Habitat Centre Lodhi Road on Nov 8th, 2 to 6 pm for student admission.Entry Free,  details contact 9911489000\n",
      "[spam]: SMS AUCTION You have won a Nokia 7250i. This is what you get when you win our FREE auction. To take part send Nokia to 86021 now. HG/Suite342/2Lands Row/W1JHL 16+\n",
      "[spam]: Call Germany for only 1 pence per minute! Call from a fixed line via access number 0844 861 85 86.\n",
      "[smishing]: WIN URGENT! Your mobile number has been awarded with a Â£2000 prize GUARANTEED call 09061790121 from land line. claim 3030 valid 12hrs only 150ppm\n",
      "[smishing]: Customer service annoncement. You have a New Years delivery waiting for you. Please call 07046744435 now to arrange delivery\n",
      "[smishing]: Todays Vodafone numbers ending 9167 are selected to receive a Rs.2,00,000 award. If you have a match please call 7044518857 quoting claim code 5001 standard rates apply\n",
      "[smishing]: \tFree 1st week entry 2 TEXTPOD 4 a chance 2 win 40GB iPod or Â£250 cash every wk. Txt VPOD to 81303 Ts&Cs www.textpod.net custcare 08712405020.\n",
      "[smishing]: 449050000301 You have won a Â£2,000 price! To claim, call 09050000301.\n"
     ]
    }
   ],
   "source": [
    "for c in classnames:\n",
    "    tmp = where(trainY==c)\n",
    "    for a in tmp[0][0:5]:\n",
    "        print('[{}]: {}'.format(classlabels[trainY[a]], trainTxt[a]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR CODE and DOCUMENTATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "All the text will be converted to lower case and remove all the symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-27T02:12:07.355376Z",
     "start_time": "2023-01-27T02:12:07.353861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[normal]: dunno da next show aft 6 is 850  toa payoh got 650\n",
      "[normal]: i ll hand her my phone to chat wit u\n",
      "[normal]: i dont have i shall buy one dear\n",
      "[normal]: nite\n",
      "[normal]: ok congrats\n",
      "[spam]: i'd like to tell you my deepest darkest fantasies  call me 09094646631 just 60p min  to stop texts call 08712460324  nat rate\n",
      "[spam]: santa calling  would your little ones like a call from santa xmas eve  call 09058094583 to book your time\n",
      "[spam]: meet top 35 us universities in delhi at india habitat centre lodhi road on nov 8th  2 to 6 pm for student admission entry free   details contact 9911489000\n",
      "[spam]: sms auction you have won a nokia 7250i  this is what you get when you win our free auction  to take part send nokia to 86021 now  hg suite342 2lands row w1jhl 16\n",
      "[spam]: call germany for only 1 pence per minute  call from a fixed line via access number 0844 861 85 86\n",
      "[smishing]: win urgent  your mobile number has been awarded with a  2000 prize guaranteed call 09061790121 from land line  claim 3030 valid 12hrs only 150ppm\n",
      "[smishing]: customer service annoncement  you have a new years delivery waiting for you  please call 07046744435 now to arrange delivery\n",
      "[smishing]: todays vodafone numbers ending 9167 are selected to receive a rs 2 00 000 award  if you have a match please call 7044518857 quoting claim code 5001 standard rates apply\n",
      "[smishing]: free 1st week entry 2 textpod 4 a chance 2 win 40gb ipod or  250 cash every wk  txt vpod to 81303 ts cs www textpod net custcare 08712405020\n",
      "[smishing]: 449050000301 you have won a  2 000 price  to claim  call 09050000301\n"
     ]
    }
   ],
   "source": [
    "# INSERT YOUR CODE HERE\n",
    "import re\n",
    "def cleanText(text:list):\n",
    "    cleanedText=[]\n",
    "    for sentence in text:\n",
    "        cleaned = re.sub(\"[^a-zA-Z0-9']\",\" \",sentence)\n",
    "        lowered = cleaned.lower()\n",
    "        stripped = lowered.strip()\n",
    "        cleanedText.append(stripped)\n",
    "    return cleanedText\n",
    "\n",
    "trainTxt=cleanText(trainTxt)\n",
    "testX = cleanText(testX)\n",
    "\n",
    "for c in classnames:\n",
    "    tmp = where(trainY==c)\n",
    "    for a in tmp[0][0:5]:\n",
    "        print('[{}]: {}'.format(classlabels[trainY[a]], trainTxt[a]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: CountVector + MultinomialNB (Kaggle 0.868)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test score : [0.92730318 0.92830821 0.92964824 0.93366834 0.9360134  0.94103853\n",
      " 0.94304858 0.94371859 0.9440536  0.94673367]\n",
      "0.9842546063651592\n"
     ]
    }
   ],
   "source": [
    "import sklearn.naive_bayes as NB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "trainXVec = vectorizer.fit_transform(trainTxt)\n",
    "\n",
    "\n",
    "Multi_clf= NB.MultinomialNB()\n",
    "\n",
    "param_grid = {'alpha': linspace(0,1,10)}\n",
    "# cross validation\n",
    "grid_search = GridSearchCV(Multi_clf, param_grid, cv=5, n_jobs=-1,verbose=1)\n",
    "grid_search.fit(trainXVec, trainY)\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY = estimator.predict(trainXVec)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "testXVec = vectorizer.transform(testX)\n",
    "predY = estimator.predict(testXVec)\n",
    "write_csv_kaggle_sub(\"Output/Submission-BoW+MultinomialNB.csv\", predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1.2: CountVector with SVM (Kaggle :0.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test score : [0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.8241206  0.82211055 0.82211055\n",
      " 0.87805695 0.82211055 0.82211055 0.92194305 0.82211055 0.82177554\n",
      " 0.93936348 0.82211055 0.8321608  0.94572864 0.82278057 0.86264657\n",
      " 0.94539363 0.86599665 0.88643216 0.94438861 0.93065327 0.90485762\n",
      " 0.94137353 0.94371859 0.91323283 0.94070352 0.94606365 0.91959799\n",
      " 0.94070352 0.94539363 0.92194305 0.94070352 0.94438861 0.92428811\n",
      " 0.94070352 0.94438861 0.92462312 0.94070352 0.94438861 0.92361809\n",
      " 0.94070352 0.94438861 0.92361809 0.94070352 0.94438861 0.92328308\n",
      " 0.94070352 0.94438861 0.92328308 0.94070352 0.94438861 0.92328308]\n",
      "0.9959798994974874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = CountVectorizer( max_features=1000)\n",
    "trainXVec = vectorizer.fit_transform(trainTxt)\n",
    "\n",
    "\n",
    "SVM_clf = SVC()\n",
    "\n",
    "param_grid = {\n",
    "    \"C\":logspace(-4,4,20),\n",
    "    \"kernel\":['linear','rbf','poly']\n",
    "    }\n",
    "# cross validation\n",
    "grid_search = GridSearchCV(SVM_clf, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(trainXVec, trainY)\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY = estimator.predict(trainXVec)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "testXVec = vectorizer.transform(testX)\n",
    "predY = estimator.predict(testXVec)\n",
    "write_csv_kaggle_sub(\"Output/Submission-CountVector+SVM.csv\", predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1.3: CountVector with logistic (Kaggle : 0.859)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "mean test score : [0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82244556 0.82546064 0.82579564 0.84656616 0.86063652 0.86097152\n",
      " 0.88509213 0.89849246 0.89916248 0.91323283 0.92261307 0.9239531\n",
      " 0.93031826 0.93701843 0.93701843 0.94070352 0.94438861 0.94472362\n",
      " 0.94539363 0.94572864 0.94606365 0.94572864 0.9440536  0.94639866\n",
      " 0.94472362 0.94237856 0.94505863 0.94237856 0.94070352 0.94271357\n",
      " 0.94036851 0.93668342 0.94271357 0.93936348 0.93534338 0.94271357\n",
      " 0.93802345 0.93366834 0.94271357 0.93735343 0.9319933  0.94304858\n",
      " 0.93668342 0.9319933  0.94271357 0.93668342 0.93232831 0.94237856]\n",
      "0.992964824120603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "trainXVec = vectorizer.fit_transform(trainTxt)\n",
    "testXVec = vectorizer.transform(testX)\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=1000) \n",
    "param_grid = {\n",
    "    'C': logspace(-4,4,20),  # Regularization parameter (smaller values for more regularization)\n",
    "    'solver': ['liblinear', 'lbfgs','saga'],  # Solver algorithm\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(trainXVec, trainY)\n",
    "\n",
    "\n",
    "estimator= grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY=estimator.predict(trainXVec)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "predY = estimator.predict(testXVec)\n",
    "write_csv_kaggle_sub(\"Output/Submission-CountVector+Logistic.csv\", predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1.4: CountVector with RandomForest (Kaggle :0.71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "0.9122278056951424\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble, metrics, model_selection\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "trainXVec = vectorizer.fit_transform(trainTxt)\n",
    "testXVec = vectorizer.transform(testX)\n",
    "\n",
    "rf=ensemble.RandomForestClassifier(random_state=7)\n",
    "paramgrid={\"n_estimators\":array([100,250,500]),\n",
    "\"max_depth\":stats.randint(15,35),\n",
    "\"min_samples_split\":[2, 6, 10],\n",
    "\"min_samples_leaf\": [1, 3, 4]\n",
    "}\n",
    "\n",
    "rfCV=model_selection.RandomizedSearchCV(rf,paramgrid,random_state=7,n_iter=1000,cv=5,n_jobs=-1,verbose=1)\n",
    "rfCV.fit(trainXVec,trainY)\n",
    "\n",
    "print(f\"mean test score : {rfCV.cv_results_['mean_test_score']}\")\n",
    "\n",
    "rfclf = rfCV.best_estimator_\n",
    "\n",
    "predY=rfclf.predict(trainXVec)\n",
    "print(metrics.accuracy_score(predY,trainY))\n",
    "predY=rfclf.predict(testXVec)\n",
    "write_csv_kaggle_sub(\"Output/Submission-CountVector+RandomForest.csv\", predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2.1: TF-IDF with MultinomialNB (Kaggle:0.38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test score : [0.95309883 0.91390285 0.82211055]\n",
      "0.9708542713567839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vectorizer_Tfidf = TfidfVectorizer(max_features=1000)\n",
    "train_X_tfidf = vectorizer_Tfidf.fit_transform(trainTxt)\n",
    "\n",
    "Multi_clf= NB.MultinomialNB()\n",
    "\n",
    "param_grid = {'alpha': [0.1, 2.0, 20.0]}\n",
    "# cross validation\n",
    "grid_search = GridSearchCV(Multi_clf, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(train_X_tfidf, trainY)\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY = estimator.predict(train_X_tfidf)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "test_X_tfidf = vectorizer_Tfidf.fit_transform(testX)\n",
    "predY = estimator.predict(test_X_tfidf)\n",
    "write_csv_kaggle_sub(\"Output/Submission-TF-IDF+MultinomialNB.csv\", predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2.2 : TF-IDF with SVM (Kaggle:0.822)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test score : [0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82278057 0.87068677 0.93668342 0.95075377 0.95142379\n",
      " 0.95108878 0.95108878 0.95108878 0.95108878 0.95108878 0.95108878\n",
      " 0.95108878 0.95108878]\n",
      "0.9963149078726968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vectorizer_Tfidf = TfidfVectorizer(max_features=1000)\n",
    "train_X_tfidf = vectorizer_Tfidf.fit_transform(trainTxt)\n",
    "\n",
    "SVM_clf = SVC()\n",
    "\n",
    "param_grid = {\n",
    "    \"C\":logspace(-4,4,20),\n",
    "    \"kernel\":['linear','rbf','poly']\n",
    "    }\n",
    "# cross validation\n",
    "grid_search = GridSearchCV(SVM_clf, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(train_X_tfidf , trainY)\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY = estimator.predict(train_X_tfidf)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "testX_Tfidf = vectorizer_Tfidf.transform(testX)\n",
    "predY = estimator.predict(testX_Tfidf)\n",
    "write_csv_kaggle_sub(\"Output/Submission-TF_IDF-SVM.csv\", predY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2.3 TF-IDF with logistic (Kaggle : 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "mean test score : [0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.8281407  0.84623116 0.88241206\n",
      " 0.90619765 0.9279732  0.93366834 0.94271357 0.94505863 0.94941374\n",
      " 0.94941374 0.95008375 0.94840871 0.94740369 0.94840871 0.94706868\n",
      " 0.94840871 0.94639866 0.94773869 0.94572864 0.94639866 0.94572864\n",
      " 0.94438861 0.94438861 0.9440536  0.94472362]\n",
      "0.9943048576214405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "train_X_tfidf = tfidf_vectorizer.fit_transform(trainTxt)\n",
    "test_X_tfidf = tfidf_vectorizer.transform(testX)\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=1000) \n",
    "\n",
    "# Define a grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'C': logspace(-4,4,20),  # Regularization parameter (smaller values for more regularization)\n",
    "    'solver': ['liblinear', 'lbfgs'],  # Solver algorithm\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(train_X_tfidf, trainY)\n",
    "\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY = estimator.predict(train_X_tfidf)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "predY = estimator.predict(test_X_tfidf)\n",
    "write_csv_kaggle_sub(\"Output/Submission-TF_IDF-Logistic.csv\", predY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3.1 Word embedding with Logistic Regression (Kaggle :0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# transform to word2vec\n",
    "def word2vec_Avg_Transform(word2vec_model,text:list):\n",
    "    doc=[]\n",
    "    for sentence in text:\n",
    "        sen=[]\n",
    "        for word in sentence.split():\n",
    "            if word in word2vec_model.wv:\n",
    "                vec = word2vec_model.wv[word]\n",
    "                sen.append(vec)\n",
    "        if(len(sen)!=0):\n",
    "            sen=np.mean(np.array(sen),axis=0)\n",
    "            doc.append(sen)\n",
    "        else:\n",
    "            sen=np.zeros(word2vec_model.vector_size)\n",
    "            doc.append(sen)\n",
    "    res=np.array(doc)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "mean test score : [0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.82211055 0.8241206  0.83886097\n",
      " 0.85226131 0.86532663 0.87705193 0.88308208 0.88542714 0.89447236\n",
      " 0.8958124  0.89916248 0.89916248 0.89849246]\n",
      "0.9182579564489112\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "tokenized_text = [text.split() for text in trainTxt]\n",
    "word2vec_model = Word2Vec(tokenized_text, vector_size=100, window=3, min_count=1)\n",
    "\n",
    "X_train_word2vec=word2vec_Avg_Transform(word2vec_model,trainTxt)\n",
    "X_test_word2vec=word2vec_Avg_Transform(word2vec_model,testX)\n",
    "\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=1000) \n",
    "\n",
    "# Define a grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'C': logspace(-4,4,20),  # Regularization parameter (smaller values for more regularization)\n",
    "    'solver': ['liblinear', 'lbfgs'],  # Solver algorithm\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_word2vec, trainY)\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY = estimator.predict(X_train_word2vec)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "predY = estimator.predict(X_test_word2vec)\n",
    "write_csv_kaggle_sub(\"Output/Submission-Word_Embeding+LogisticRegression.csv\", predY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3.2 Word embedding with SVM (0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token text : ['dunno', 'da', 'next', 'show', 'aft', '6', 'is', '850', 'toa', 'payoh', 'got', '650']\n",
      "mean test score : [0.82211055 0.82211055 0.82211055 0.82211055 0.82211055 0.82211055\n",
      " 0.82211055 0.82211055 0.82211055 0.83283082 0.89681742 0.91423786\n",
      " 0.92462312]\n",
      "0.9386934673366835\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "tokenized_text = [text.split() for text in trainTxt]\n",
    "print(f\"token text : {tokenized_text[0]}\")\n",
    "word2vec_model = Word2Vec(tokenized_text, vector_size=100)\n",
    "\n",
    "\n",
    "\n",
    "X_train_word2vec=word2vec_Avg_Transform(word2vec_model,trainTxt)\n",
    "X_test_word2vec=word2vec_Avg_Transform(word2vec_model,testX)\n",
    "\n",
    "SVM_clf = SVC()\n",
    "param_grid = {\"C\":logspace(-3,3,13)}\n",
    "# cross validation\n",
    "grid_search = GridSearchCV(SVM_clf, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_word2vec , trainY)\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY = estimator.predict(X_train_word2vec)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "predY = estimator.predict(X_test_word2vec)\n",
    "write_csv_kaggle_sub(\"Output/Submission-Word_Embeding-SVM.csv\", predY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3.3: Word embedding with Random Forest (Kaggle:0.46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "mean test score : [0.86465662 0.86465662 0.86532663 0.86365159 0.86432161 0.86264657\n",
      " 0.85561139 0.85762144 0.85896147 0.86599665 0.86097152 0.86499162\n",
      " 0.86197655 0.86264657 0.86063652 0.85929648 0.85929648 0.85661642\n",
      " 0.85628141 0.85628141 0.85628141 0.85561139 0.85561139 0.85762144\n",
      " 0.85628141 0.8559464  0.8519263  0.84857621 0.84690117 0.84623116\n",
      " 0.84958124 0.84690117 0.84522613 0.84455611 0.84489112 0.84254606\n",
      " 0.84656616 0.84623116 0.84656616 0.84690117 0.84422111 0.84623116\n",
      " 0.84254606 0.84321608 0.84087102 0.84221106 0.84154104 0.84187605\n",
      " 0.84154104 0.84120603 0.84288107 0.84053601 0.84120603 0.84187605\n",
      " 0.86566164 0.86465662 0.86465662 0.86633166 0.86700168 0.86432161\n",
      " 0.8559464  0.85862647 0.86063652 0.86063652 0.86298157 0.86465662\n",
      " 0.86365159 0.86264657 0.86365159 0.8599665  0.85829146 0.85728643\n",
      " 0.85795645 0.85728643 0.85527638 0.85896147 0.85561139 0.85561139\n",
      " 0.85561139 0.85393635 0.85393635 0.86432161 0.86599665 0.86666667\n",
      " 0.86499162 0.86465662 0.86599665 0.85695142 0.8599665  0.8599665\n",
      " 0.86231156 0.8639866  0.86264657 0.86365159 0.86231156 0.86231156\n",
      " 0.85728643 0.85862647 0.85728643 0.85728643 0.85795645 0.85728643\n",
      " 0.85460637 0.85695142 0.85695142 0.85427136 0.85226131 0.85427136]\n",
      "0.9919597989949749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tokenized_text = [text.split() for text in trainTxt]\n",
    "word2vec_model = Word2Vec(tokenized_text, vector_size=100, window=3, min_count=1)\n",
    "\n",
    "X_train_word2vec=word2vec_Avg_Transform(word2vec_model,trainTxt)\n",
    "X_test_word2vec=word2vec_Avg_Transform(word2vec_model,testX)\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RFC, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_word2vec , trainY)\n",
    "\n",
    "estimator = grid_search.best_estimator_\n",
    "print(f\"mean test score : {grid_search.cv_results_['mean_test_score']}\")\n",
    "\n",
    "predY = estimator.predict(X_train_word2vec)\n",
    "print(accuracy_score(predY,trainY))\n",
    "\n",
    "predY = estimator.predict(X_test_word2vec)\n",
    "write_csv_kaggle_sub(\"Output/Submission-Word_Embeding-RandomForest.csv\", predY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In our pursuit of effective spam email classification, we embarked on a series of experiments employing various classification techniques. These experiments aimed to discern the most suitable method for discriminating between spam and legitimate emails. Below, we provide an overview of the three primary methods we explored:\n",
    "\n",
    "**Method 1: CountVector with Machine Learning Models**\n",
    "\n",
    "In Method 1, we harnessed the CountVectorization technique in combination with a range of machine learning models. This approach involved converting email texts into numerical feature vectors based on word frequency counts. Subsequently, we applied diverse machine learning algorithms to classify the emails.\n",
    "\n",
    "**Method 2: TF-IDF (Term Frequency-Inverse Document Frequency) with Various Models**\n",
    "\n",
    "Approach 2 leveraged the TF-IDF technique, designed to reduce the significance of non-relevant words in the classification process. TF-IDF assigns weights to words based on their importance within individual emails and across the entire dataset. We then employed multiple machine learning models to evaluate the effectiveness of this approach.\n",
    "\n",
    "**Method 3: Word Embedding Technique**\n",
    "\n",
    "In \"Method 3,\" we delved into the word embedding technique, which considers word order in the text data to potentially yield improved results. This method takes into account the context in which words appear, enhancing the classification accuracy.\n",
    "\n",
    "**Analyzing Experimental Results**\n",
    "\n",
    "Following an in-depth analysis of the results obtained from these experiments, a consistent performance trend emerged. Method 1 consistently outperformed Methods 2 and 3 in terms of average performance. This observation underscores the superiority of CountVectorization as a vectorization technique for our dataset. Notably, our dataset predominantly comprises short email sentences with unique words, making it challenging for classifiers to identify similarities. While TF-IDF excels at eliminating common words, it proved less effective in this specific scenario.\n",
    "\n",
    "Furthermore, it is essential to note that all our experimental models exhibited varying degrees of overfitting. While they demonstrated high accuracy during validation, their performance significantly degraded when tested on new data.\n",
    "\n",
    "Proposed Measures for Improvement\n",
    "\n",
    "To address these challenges and enhance the reliability of our spam email classification system, we propose the following measures:\n",
    "\n",
    "1. **Exploration of Different Text Data Vectorization Techniques**: To mitigate overfitting issues, we should experiment with alternative text data vectorization methods. Exploring techniques like word embeddings, Doc2Vec, or more advanced vectorization schemes may yield improved results.\n",
    "\n",
    "2. **Consideration of Simpler Classifier Models: Reducing classifier** complexity by adopting smaller and shallower models, such as Random Forest or XGBoost, can enhance the generalizability of our spam classification system. These models often exhibit robust performance and are less prone to overfitting.\n",
    "\n",
    "3. **Consideration of adding english dictionary** : lower the weight of mispelled words\n",
    "   \n",
    "These adaptations are crucial for ensuring the effectiveness of our spam classification system, especially in the face of diverse email content and the persistent challenge of overfitting in our experimental work."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "238px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
