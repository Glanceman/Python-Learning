{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c90261",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-03T13:33:54.722437Z",
     "iopub.status.busy": "2023-12-03T13:33:54.721652Z",
     "iopub.status.idle": "2023-12-03T13:34:00.115579Z",
     "shell.execute_reply": "2023-12-03T13:34:00.114774Z"
    },
    "papermill": {
     "duration": 5.402216,
     "end_time": "2023-12-03T13:34:00.117830",
     "exception": false,
     "start_time": "2023-12-03T13:33:54.715614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from itertools import combinations  # For creating combinations of elements\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit,train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "import catboost as cbt\n",
    "import lightgbm as lgb \n",
    "\n",
    "# tool functions \n",
    "def reduce_mem_usage(df, verbose=0):\n",
    "    \"\"\"\n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "    # ðŸ“ Calculate the initial memory usage of the DataFrame\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    # ðŸ”„ Iterate through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        # Check if the column's data type is not 'object' (i.e., numeric)\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            # Check if the column's data type is an integer\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                # Check if the column's data type is a float\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    # â„¹ï¸ Provide memory optimization information if 'verbose' is True\n",
    "    if verbose:\n",
    "        print(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        print(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    # ðŸ”„ Return the DataFrame with optimized memory usage\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0d0314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T13:34:00.128486Z",
     "iopub.status.busy": "2023-12-03T13:34:00.127794Z",
     "iopub.status.idle": "2023-12-03T13:34:18.166915Z",
     "shell.execute_reply": "2023-12-03T13:34:18.166002Z"
    },
    "papermill": {
     "duration": 18.046561,
     "end_time": "2023-12-03T13:34:18.169152",
     "exception": false,
     "start_time": "2023-12-03T13:34:00.122591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape (5237980, 17)\n",
      "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0         0        0                  0      3180602.69   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                        1         0.999812   13380276.64        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target  \\\n",
      "0         NaN   0.999812   60651.5   1.000026   8493.03  1.0 -3.029704   \n",
      "\n",
      "   time_id row_id  \n",
      "0        0  0_0_0  \n"
     ]
    }
   ],
   "source": [
    "# input data\n",
    "df_train = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n",
    "print(f\"original shape {df_train.shape}\")\n",
    "print(df_train[0:1])\n",
    "# reduce mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001095b2",
   "metadata": {
    "papermill": {
     "duration": 0.004133,
     "end_time": "2023-12-03T13:34:18.177710",
     "exception": false,
     "start_time": "2023-12-03T13:34:18.173577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **data cleaning functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84882c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T13:34:18.187479Z",
     "iopub.status.busy": "2023-12-03T13:34:18.187187Z",
     "iopub.status.idle": "2023-12-03T13:34:18.195917Z",
     "shell.execute_reply": "2023-12-03T13:34:18.194858Z"
    },
    "papermill": {
     "duration": 0.016382,
     "end_time": "2023-12-03T13:34:18.198353",
     "exception": false,
     "start_time": "2023-12-03T13:34:18.181971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop the unneccassary columns\n",
    "def record_filter(df:pd.DataFrame)->pd.DataFrame:\n",
    "    if('target'in df):\n",
    "        df.dropna(subset=['target'],inplace=True) # drop record target =null\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def feature_selection(df:pd.DataFrame,NotIncludeAtrs=['row_id', 'time_id','date_id','stock_id'])->pd.DataFrame:\n",
    "    cols = [c for c in df.columns if c not in NotIncludeAtrs]\n",
    "    tmp = df[cols] \n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27174dd",
   "metadata": {
    "papermill": {
     "duration": 0.00432,
     "end_time": "2023-12-03T13:34:18.207812",
     "exception": false,
     "start_time": "2023-12-03T13:34:18.203492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **feature engineering functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6a18e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T13:34:18.217765Z",
     "iopub.status.busy": "2023-12-03T13:34:18.217511Z",
     "iopub.status.idle": "2023-12-03T13:34:18.834744Z",
     "shell.execute_reply": "2023-12-03T13:34:18.834015Z"
    },
    "papermill": {
     "duration": 0.624736,
     "end_time": "2023-12-03T13:34:18.836932",
     "exception": false,
     "start_time": "2023-12-03T13:34:18.212196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True) #faster \n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "\n",
    "    #  Loop through all combinations of triplets\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        \n",
    "        # Loop through rows of the DataFrame\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            \n",
    "            # Prevent division by zero\n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "def calculate_triplet_imbalance_numba(price:[], df:pd.DataFrame):\n",
    "    # Convert DataFrame to numpy array for Numba compatibility\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "\n",
    "    # Calculate the triplet imbalance using the Numba-optimized function\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "\n",
    "    return features\n",
    "\n",
    "# feature engineering\n",
    "def feature_engineering_ver1(df:pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    #df_copy['trend']=df['imbalance_size'] * df['imbalance_buy_sell_flag']\n",
    "    df[\"volume\"] = df[\"ask_size\"] +df[\"bid_size\"]\n",
    "    df[\"mid_price\"] = (df['ask_price']+df['bid_price'])/2\n",
    "    df[\"liquidity_imbalance\"] = (df['bid_size']-df['ask_size'])/(df['bid_size']+df['ask_size'])\n",
    "    df[\"matched_imbalance\"] = (df['imbalance_size']-df['matched_size'])/(df['matched_size']+df['imbalance_size'])\n",
    "    df[\"size_imbalance\"] = df['bid_size'] / df['ask_size']\n",
    "   \n",
    "    \n",
    "    # create different pariwise combination of imbalance prices \n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    for c in combinations(prices, 2):\n",
    "        #df_copy[f'{c[0]}_-_{c[1]}'] = (df_copy[f'{c[0]}'] - df_copy[f'{c[1]}']).astype(np.float32) ## difference between the different prices \n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "        \n",
    "    #create triplet of imbalance\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "    \n",
    "    \n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_velocity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance'] # showing the how hit of the stock in the market\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    \n",
    "    # Calculate various statistical aggregation features\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "    \n",
    "    # time related feature\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [1, 2, 3,10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window) # keep track for previous value\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
    "    \n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n",
    "        for window in [1, 2, 3,10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
    "\n",
    "    \n",
    "    # adding day for haveing trading\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes  \n",
    "    #global feature \n",
    "    global_stock_id_feats = {\n",
    "        \"median_size\": df.groupby(\"stock_id\")[\"bid_size\"].median() + df.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "        \"std_size\": df.groupby(\"stock_id\")[\"bid_size\"].std() + df.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "        \"ptp_size\": df.groupby(\"stock_id\")[\"bid_size\"].max() - df.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "        \"median_price\": df.groupby(\"stock_id\")[\"bid_price\"].median() + df.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "        \"std_price\": df.groupby(\"stock_id\")[\"bid_price\"].std() + df.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "        \"ptp_price\": df.groupby(\"stock_id\")[\"bid_price\"].max() - df.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "    }\n",
    "    for key, value in global_stock_id_feats.items():\n",
    "            df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "    \n",
    "    df.replace([np.inf, -np.inf], 0,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e7b2a9",
   "metadata": {
    "papermill": {
     "duration": 0.004012,
     "end_time": "2023-12-03T13:34:18.845554",
     "exception": false,
     "start_time": "2023-12-03T13:34:18.841542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b2395c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T13:34:18.854924Z",
     "iopub.status.busy": "2023-12-03T13:34:18.854645Z",
     "iopub.status.idle": "2023-12-03T13:35:23.373290Z",
     "shell.execute_reply": "2023-12-03T13:35:23.372439Z"
    },
    "papermill": {
     "duration": 64.525867,
     "end_time": "2023-12-03T13:35:23.375541",
     "exception": false,
     "start_time": "2023-12-03T13:34:18.849674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numba/core/ir_utils.py:2149: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'comb_indices' of function 'compute_triplet_imbalance'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"../../tmp/ipykernel_27/1084247445.py\", line 3:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/opt/conda/lib/python3.10/site-packages/numba/core/ir_utils.py:2149: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'comb__indices' of function '__numba_parfor_gufunc_0x78e0b7fb9e70'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"<string>\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:81: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window) # percentage change with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    }
   ],
   "source": [
    "def preproccess(df:pd.DataFrame,NotIncludeAtrs=['row_id', 'time_id','date_id','stock_id']):\n",
    "    df=record_filter(df) \n",
    "    df=feature_engineering_ver1(df)\n",
    "    df=feature_selection(df,NotIncludeAtrs)\n",
    "    df=reduce_mem_usage(df)\n",
    "    df=df.fillna(0)\n",
    "    return df\n",
    "df_train=preproccess(df_train,NotIncludeAtrs=['row_id', 'time_id','stock_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b39dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T13:35:23.389318Z",
     "iopub.status.busy": "2023-12-03T13:35:23.389001Z",
     "iopub.status.idle": "2023-12-03T13:53:27.061817Z",
     "shell.execute_reply": "2023-12-03T13:53:27.060754Z"
    },
    "papermill": {
     "duration": 1083.682675,
     "end_time": "2023-12-03T13:53:27.064474",
     "exception": false,
     "start_time": "2023-12-03T13:35:23.381799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape (1294779, 123) valid.shape (32505, 123)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 9.72964\n",
      "[200]\tvalid_0's l1: 9.66512\n",
      "[300]\tvalid_0's l1: 9.63859\n",
      "[400]\tvalid_0's l1: 9.62467\n",
      "[500]\tvalid_0's l1: 9.61674\n",
      "[600]\tvalid_0's l1: 9.61186\n",
      "[700]\tvalid_0's l1: 9.61053\n",
      "[800]\tvalid_0's l1: 9.60946\n",
      "[900]\tvalid_0's l1: 9.60935\n",
      "[1000]\tvalid_0's l1: 9.60769\n",
      "[1100]\tvalid_0's l1: 9.60723\n",
      "Early stopping, best iteration is:\n",
      "[1031]\tvalid_0's l1: 9.60717\n",
      "append model of fold 0\n",
      "train.shape (1306195, 123) valid.shape (32835, 123)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 5.91934\n",
      "[200]\tvalid_0's l1: 5.90024\n",
      "[300]\tvalid_0's l1: 5.89266\n",
      "[400]\tvalid_0's l1: 5.88686\n",
      "[500]\tvalid_0's l1: 5.88536\n",
      "[600]\tvalid_0's l1: 5.88401\n",
      "[700]\tvalid_0's l1: 5.88385\n",
      "[800]\tvalid_0's l1: 5.88318\n",
      "[900]\tvalid_0's l1: 5.88313\n",
      "[1000]\tvalid_0's l1: 5.88306\n",
      "[1100]\tvalid_0's l1: 5.88321\n",
      "Early stopping, best iteration is:\n",
      "[1033]\tvalid_0's l1: 5.88266\n",
      "append model of fold 1\n",
      "train.shape (1316974, 123) valid.shape (33000, 123)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 6.12338\n",
      "[200]\tvalid_0's l1: 6.0977\n",
      "[300]\tvalid_0's l1: 6.0842\n",
      "[400]\tvalid_0's l1: 6.07468\n",
      "[500]\tvalid_0's l1: 6.07022\n",
      "[600]\tvalid_0's l1: 6.06633\n",
      "[700]\tvalid_0's l1: 6.06414\n",
      "[800]\tvalid_0's l1: 6.06366\n",
      "[900]\tvalid_0's l1: 6.06256\n",
      "Early stopping, best iteration is:\n",
      "[898]\tvalid_0's l1: 6.06248\n",
      "append model of fold 2\n",
      "train.shape (1286944, 123) valid.shape (33000, 123)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 5.21699\n",
      "[200]\tvalid_0's l1: 5.20051\n",
      "[300]\tvalid_0's l1: 5.19147\n",
      "[400]\tvalid_0's l1: 5.18652\n",
      "[500]\tvalid_0's l1: 5.18389\n",
      "[600]\tvalid_0's l1: 5.18156\n",
      "[700]\tvalid_0's l1: 5.17986\n",
      "[800]\tvalid_0's l1: 5.17824\n",
      "[900]\tvalid_0's l1: 5.1762\n",
      "[1000]\tvalid_0's l1: 5.17602\n",
      "[1100]\tvalid_0's l1: 5.17528\n",
      "[1200]\tvalid_0's l1: 5.17479\n",
      "[1300]\tvalid_0's l1: 5.17379\n",
      "[1400]\tvalid_0's l1: 5.17367\n",
      "Early stopping, best iteration is:\n",
      "[1360]\tvalid_0's l1: 5.17348\n",
      "append model of fold 3\n",
      "average_best_iteration 1080\n",
      "all train.shape (5237892, 123)\n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "def trainEnsembleModels(folds=5,data:pd.DataFrame=None):\n",
    "    models=[]\n",
    "    data=data.copy()\n",
    "    max_date=data['date_id'].max()\n",
    "    folds=folds-1\n",
    "    date_bins = pd.cut(data['date_id'], bins=folds, labels=False)\n",
    "    for fold in range(folds):\n",
    "        \n",
    "        if fold >= folds-1:\n",
    "            subData = data.loc[(date_bins == fold)] #block\n",
    "            date = subData['date_id'].max()-3 # use 3 date for validation\n",
    "            trainingData=subData[subData['date_id']<=date]\n",
    "            validData=subData[subData['date_id']>date]\n",
    "            del subData\n",
    "        else:\n",
    "            trainingData = data.loc[(date_bins == fold)] #block\n",
    "            temp = data.loc[(date_bins >= (fold+1))]\n",
    "            minDate = temp[\"date_id\"].min()\n",
    "            validData=temp[temp[\"date_id\"]<(minDate+3)]\n",
    "        \n",
    "        trainingData=trainingData.drop(columns='date_id')# give date_id\n",
    "        validData=validData.drop(columns='date_id')\n",
    "        \n",
    "        x_train=trainingData.drop(columns='target')\n",
    "        y_train=trainingData['target'].values\n",
    "        \n",
    "        x_valid=validData.drop(columns='target')\n",
    "        y_valid=validData['target'].values\n",
    "        \n",
    "        print(f\"train.shape {x_train.shape} valid.shape {x_valid.shape}\")\n",
    "        #train model\n",
    "        model = lgb.LGBMRegressor(n_estimators= 5500,objective='mae',learning_rate=0.00871,num_leaves=256,subsample=0.6,colsample_bytree=0.8,max_depth=11,importance_type= \"gain\",verbosity= -1,device=\"gpu\",seed= 42)\n",
    "        model.fit(x_train,y_train,\n",
    "                  eval_set=[(x_valid,  y_valid)],\n",
    "                  callbacks=[\n",
    "                        lgb.callback.early_stopping(stopping_rounds=100),\n",
    "                        lgb.callback.log_evaluation(period=100),\n",
    "                    ],\n",
    "                 )\n",
    "        models.append(model)\n",
    "        print(f\"append model of fold {fold}\")\n",
    "        del x_train,y_train,x_valid,y_valid,trainingData,validData\n",
    "    \n",
    "    #train all data again\n",
    "    average_best_iteration = int(np.mean([model.best_iteration_ for model in models]))\n",
    "    print(f\"average_best_iteration {average_best_iteration}\")\n",
    "    all_y_train = data['target'].values\n",
    "    all_x_train = data.drop(columns=['target','date_id'])\n",
    "    print(f\"all train.shape {all_x_train.shape}\")\n",
    "    model = lgb.LGBMRegressor(n_estimators= average_best_iteration,objective='mae',learning_rate=0.00871,num_leaves=256,subsample=0.6,colsample_bytree=0.8,max_depth=11,importance_type= \"gain\",verbosity= -1,device=\"gpu\",seed= 42)\n",
    "    model.fit(all_x_train,all_y_train,\n",
    "                callbacks=[\n",
    "                    lgb.callback.log_evaluation(period=100),\n",
    "                ],\n",
    "            )\n",
    "    models.append(model) # total is k models + 1 final model\n",
    "    return models\n",
    "\n",
    "y_min = df_train['target'].min()\n",
    "y_max = df_train['target'].min()\n",
    "models=trainEnsembleModels(folds=5,data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f41560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T13:53:27.087256Z",
     "iopub.status.busy": "2023-12-03T13:53:27.086924Z",
     "iopub.status.idle": "2023-12-03T13:53:27.092850Z",
     "shell.execute_reply": "2023-12-03T13:53:27.092059Z"
    },
    "papermill": {
     "duration": 0.01912,
     "end_time": "2023-12-03T13:53:27.094640",
     "exception": false,
     "start_time": "2023-12-03T13:53:27.075520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)  # ðŸ§® Calculate standard error based on volumes\n",
    "    step = np.sum(prices) / np.sum(std_error)  # ðŸ§® Calculate the step size based on prices and standard error\n",
    "    out = prices - std_error * step  # ðŸ’° Adjust prices by subtracting the standardized step size\n",
    "    return out\n",
    "\n",
    "def zero_sum_prediction(predY,data):\n",
    "    predY = zero_sum(predY, data['bid_size'] + data['ask_size'])\n",
    "    clipped_predictions = np.clip(predY, -64, 64)\n",
    "    return clipped_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6318e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T13:53:27.116732Z",
     "iopub.status.busy": "2023-12-03T13:53:27.116467Z",
     "iopub.status.idle": "2023-12-03T13:55:07.178280Z",
     "shell.execute_reply": "2023-12-03T13:55:07.177352Z"
    },
    "papermill": {
     "duration": 100.075466,
     "end_time": "2023-12-03T13:55:07.180479",
     "exception": false,
     "start_time": "2023-12-03T13:53:27.105013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "------counter :0-----------\n",
      "(200, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numba/core/ir_utils.py:2149: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'comb_indices' of function 'compute_triplet_imbalance'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"../../tmp/ipykernel_27/1084247445.py\", line 3:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/opt/conda/lib/python3.10/site-packages/numba/core/ir_utils.py:2149: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'comb__indices' of function '__numba_parfor_gufunc_0x78e00ae62e30'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"<string>\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49928786  2.00450398  2.88617441 -0.59328987 -0.66364197  0.1828317\n",
      "  1.30624319 -3.34288366 -2.36343669  1.78506156 -0.02583075 -3.58476951\n",
      " -0.94310311 -1.25062005 -0.62238419 -0.09801277 -0.86525588  1.73308589\n",
      "  1.48477888  5.23814711  0.62098899  0.10947733 -1.13797233 -4.22912334\n",
      " -0.33638737  1.5063893  -1.7283274  -0.18798193  0.54385447  1.73738263\n",
      " -0.04317951 -5.68021804 -2.42942958 -0.50566502  4.21138843 -0.74024154\n",
      " -0.31778277 -0.03067026 -1.04863765  2.80367027 -0.52778536  0.73107198\n",
      " -0.74034224  2.07644734 -0.32684344 -1.06747228 -1.17328332  3.32951188\n",
      "  1.93800908 -0.88845477 -3.50788192 -3.89925894  0.01486392 -0.62506447\n",
      "  1.57647503 -0.40922506 -0.06405479 -0.07172021  0.44823519  0.08227457\n",
      " -0.79112605  1.5439489   3.71076854  0.2026549  -1.57207041 -0.97918041\n",
      " -0.0628934   0.37694566 -0.08421949 -1.59053764  3.30382052  2.09276285\n",
      " -1.44339335 -0.93300569  0.42432437  2.39226771 -1.16911336  3.49052045\n",
      " -1.72421997 -1.25666359 -1.96595292 -0.07889635 -0.33243366 -1.92017672\n",
      " -1.06006549  0.35881422  1.4266961   1.64756304  1.73066857  1.23566933\n",
      " -0.06106942 -0.09921974 -0.57242046  1.06491696  1.90151021 -0.72469179\n",
      " -3.06846179 -1.18167261 -1.46417044 -1.31040433 -0.86117149  8.69397004\n",
      "  5.26367504 -2.23700134 -1.48445757 -0.28784387  0.40920935  0.34063846\n",
      "  2.04415653 -0.82814117  0.31671142 -2.33286024 -1.57779965  0.15720257\n",
      "  3.16039505 -0.57912548 -2.85998186 -3.39802486 -0.43052722  4.08847134\n",
      "  0.08753423 -0.49127055 -1.63933628 -0.48417023  1.07263279  3.71414603\n",
      " -1.18094748  4.99254414 -1.03583848 -1.34925476 -0.62897735  0.16004279\n",
      "  0.29958415 -2.26072456 -1.67678134  0.96271211  0.6954842   0.4467175\n",
      " -0.13266986  1.1618504  -0.25577193 -1.46335211  0.42969698  1.15682878\n",
      " -0.62319571 -0.81214033 -1.23989353 -0.75548271 -0.58800657 -0.68923016\n",
      "  0.21261167 -0.54005294  2.15234248 -1.34671574 -1.20188415  0.45058178\n",
      " -0.49884774  3.87694745  8.14065225  3.33598548 -1.20495269 -1.50909782\n",
      " -3.63984554 -0.52263215 -0.97774198 -1.859864   -1.03155335  2.8805863\n",
      " -0.96363319  3.36431873  0.56266626  2.44005537 -3.51877259  1.70809423\n",
      " -1.12543807 -1.63718006 -0.31446371 -2.19486904 -0.54561127 -0.90395808\n",
      "  0.11479288  0.17680359 -0.22595384  0.06013571 -0.09393631  0.6786118\n",
      " -1.24945998  3.15461192 -0.34997821 -0.43474698 -0.68653105 -0.96201327\n",
      "  0.89014917 -0.67206426 -1.18425816 -0.72001454  0.39641589  1.11528216\n",
      " -1.32299883 -0.98194142]\n",
      "------counter :1-----------\n",
      "(400, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.46947619e-01  1.73415760e+00  5.43119583e-01 -1.85162201e-01\n",
      " -4.79230212e-01 -2.61425034e-04 -3.51629093e-01  1.10155436e+00\n",
      "  2.29539006e+00  1.00168453e+00 -5.14552255e-01 -6.41950009e-01\n",
      " -2.68853563e-01 -1.46695441e-01  1.07798022e+00 -9.35484650e-01\n",
      " -2.54621431e+00  2.75530788e+00 -8.94972296e-01  4.46036394e+00\n",
      "  7.51617801e-01 -7.01840422e-02 -6.27016635e-02 -6.42565211e-01\n",
      " -4.00359910e-01  1.09744465e+00 -1.13580012e+00  1.20041129e+00\n",
      " -9.36181334e-01  1.68974475e+00  2.63006477e-02 -4.89723597e+00\n",
      "  1.04602841e-01 -1.04045412e+00 -2.31527497e+00  5.18027667e-02\n",
      " -5.69884164e-01  3.78593501e-01 -2.45405562e-01  1.46179070e-01\n",
      " -8.50270582e-01 -4.96969889e+00 -6.73631771e-01  2.91049923e+00\n",
      "  4.56251730e-01 -4.54363080e-01 -3.05767895e-01  1.22138996e+00\n",
      " -7.90505313e-01 -1.04838507e+00  3.64079151e-01 -1.05265164e+00\n",
      "  5.53796753e-01 -2.64988526e-01  2.77234477e+00 -4.04150399e-01\n",
      "  1.17639305e-01 -4.61621125e+00  2.90352522e-01  4.92076959e-01\n",
      " -1.29602193e-01  9.75844029e-02 -1.03256979e+00 -2.25767438e-01\n",
      "  6.14674841e-01 -1.53154521e+00 -2.45246411e-01  1.50286746e+00\n",
      "  1.98282736e-01 -6.12380478e-01 -7.26097269e+00  2.15738001e+00\n",
      " -1.44691679e+00 -8.79991780e-01 -2.22985811e+00  9.36740460e-01\n",
      " -3.93958197e-01 -1.85563472e+00  1.44859697e-01 -9.18436718e-01\n",
      " -8.18541626e-01  5.91050970e-01 -7.18639088e-01 -2.04639097e+00\n",
      " -4.76855579e-01  8.27093765e-01  3.87461709e+00 -6.33173164e-01\n",
      "  1.07418318e+00  3.14919691e+00  7.01784433e-01  7.60837253e-01\n",
      " -2.39434942e+00  1.19781714e+00  3.33671723e-01  2.16085239e-01\n",
      " -8.53940810e-01  2.20350709e-01 -9.54570450e-01 -1.10732633e+00\n",
      "  2.35831614e-01  5.96620870e+00  3.23592755e+00 -2.55974391e+00\n",
      " -9.12244078e-01 -2.59091979e-01  3.32371195e-01  2.34507095e+00\n",
      "  3.98326796e-01 -1.41057840e+00 -4.06750289e-01  2.11598835e+00\n",
      " -1.02967056e+00 -8.04271610e-01  8.13487664e-01 -2.23348181e+00\n",
      " -5.24762356e-01 -2.54065913e+00  2.54170603e+00  2.10098941e+00\n",
      " -2.03411621e-01 -5.13342649e-01 -1.33082781e+00 -3.25826820e-01\n",
      "  3.62244863e+00  2.31333484e+00 -1.06287777e+00  3.00068614e+00\n",
      "  8.59223446e-02 -2.89046093e-01 -1.90262348e-01  2.50936083e-01\n",
      "  6.64078612e-01  1.86323427e+00 -1.18669163e+00  6.45093921e-01\n",
      " -1.83888466e+00 -2.81092012e-01  7.32327439e-01  2.29067135e+00\n",
      " -4.39306220e-01  1.01216715e-02 -1.13726450e+00  2.25881176e-01\n",
      " -5.90256833e-01 -4.78060376e-01 -1.26326489e+00 -9.78314539e-01\n",
      " -3.52861142e-01  4.26744756e-01 -1.13588126e-01 -8.23001272e-01\n",
      " -1.17893719e+00 -1.10978120e+00 -4.01711937e-01  1.69602976e-01\n",
      " -4.62506302e-01 -5.22599546e-01  1.51764054e+00 -3.17501114e-01\n",
      " -4.67154787e-01 -1.32562946e+00  2.44401835e-01 -6.18973408e-01\n",
      "  7.73719094e-02 -9.28681676e-01 -7.00641504e-01 -3.50120219e-01\n",
      " -9.55421239e-01  3.60794212e+00  4.43953022e-01  1.55429393e+00\n",
      "  1.64454008e+00  5.48328503e+00  7.57562754e-01 -9.25505326e-01\n",
      " -2.58791482e-01  2.08972261e+00 -3.43580719e-01  1.44795162e-01\n",
      "  1.23171694e+00 -2.20226189e-01  1.31695092e-02  3.58551050e-01\n",
      "  1.48887826e-01  4.93985695e-01 -8.68580485e-01  2.83712914e-01\n",
      " -1.11530794e+00 -4.56391020e-01 -1.16936378e+00  6.20239272e-02\n",
      "  2.59476750e-01 -6.41502513e-01 -8.20311110e-01 -2.69260974e-01\n",
      "  4.24223309e-01  1.48042147e+00 -6.95468088e-01 -4.67652811e-01]\n",
      "------counter :2-----------\n",
      "(600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82302856  0.60954778  0.48757654 -0.65251789 -0.46532686 -0.21601488\n",
      " -0.34854022  0.96732464  1.32291507 -1.39353664 -0.46319423 -0.63323963\n",
      "  0.05322886  0.50045455 -0.29092569  0.55438657 -2.21253866  1.64529612\n",
      "  0.12859789  0.24592497 -0.3586465   0.05115482  1.13295151  0.26338479\n",
      "  0.50925629  0.12708506 -0.84004017  0.19602917  1.44301272  0.39117997\n",
      "  0.40334786 -4.75255264  0.33835248 -1.0964037   2.81107033  0.55848497\n",
      "  0.69604939 -0.02226845 -0.06849415  2.60621363  0.09032111 -0.04231255\n",
      " -0.53472283  4.12726945  0.26870228 -0.12099012  0.77595236 -0.01259675\n",
      " -1.00978939 -0.87734539 -0.43711463 -0.42553946 -0.87775599  0.04706774\n",
      "  1.24385909 -0.00872254  0.84309564 -2.87993043  1.089085    0.49189931\n",
      " -0.5714763  -0.22164532 -2.81542818  0.45759769  1.70979573 -0.87338029\n",
      " -0.50230184  0.95271637  0.30646329 -0.29726542 -0.16734699  1.40325164\n",
      "  0.79820755 -0.4839757   0.72743379  0.45027585  0.03916914 -1.9272394\n",
      "  0.48549958 -1.09169464  0.49886285 -0.44365141 -0.49542042 -2.05445143\n",
      " -0.24328509 -0.85978475  2.07796578  0.20625194 -0.33263134  3.30837758\n",
      "  1.00388074  0.4319655   1.13848279  0.86720783  1.04705153  0.25479477\n",
      " -0.41010344 -2.18278012 -1.26262349 -0.80434259 -0.55350936 -5.6737024\n",
      "  1.16687621  0.29292854 -0.94746504  0.23620536  0.44506367  1.89112677\n",
      "  3.0744744  -0.63864909  0.2121171   0.89550502 -0.53779824  0.23515026\n",
      " -0.03302154  0.01045923  0.03695528 -2.05342916 -0.23697875  1.4833493\n",
      "  0.04942072 -0.30083602 -1.25250558 -0.15217356  0.64791051  7.67134316\n",
      " -0.53104906 -0.36853117 -0.0550453   0.3519628  -0.14884174  0.2567756\n",
      "  0.33992921 -1.28898332 -0.88631928  0.09862355 -1.84416794 -0.08270122\n",
      " -0.41890985 -0.21253239 -0.31044306  0.23564026 -2.94209157  0.67378905\n",
      "  0.13073959 -0.40507427 -0.77748745 -0.55038591 -0.1848959   0.12220802\n",
      "  0.02338569 -0.72466929  2.22404554 -1.26140019 -0.79404018  0.50058885\n",
      " -0.40768929  2.72076505 -1.50176666  0.06401934  0.92516052 -1.11168057\n",
      "  0.02391762  0.08888396  0.38560986 -0.57963562 -0.05457106 -0.36453875\n",
      " -0.62892966  1.16260927  0.2886117   0.07431401  0.65128224 -1.1925245\n",
      " -0.02714612  0.02023174  0.08240363 -1.22192968  0.36856759  0.05302526\n",
      " -4.4733398   0.63445637 -0.02262438  0.81352694  0.15913498 -1.20456199\n",
      " -0.48967764  0.51566452 -0.74207152  0.72135303 -0.07455437 -0.12641587\n",
      "  1.0740576  -0.59138775 -0.49233739  0.22694537  0.05669268  0.48006069\n",
      " -0.21683784 -0.13247933]\n",
      "------counter :3-----------\n",
      "(800, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.37530917e-01  1.96889545e+00 -5.30644276e-01 -1.36463987e-01\n",
      "  2.78940776e-01  6.28957482e-01 -4.75676326e-01  2.56907603e+00\n",
      "  2.54704021e+00  1.22561663e+00 -2.53629801e-01 -2.99882209e-01\n",
      " -2.29381195e-01 -6.63012946e-02 -1.14984917e-01  8.68352342e-02\n",
      " -1.28028912e+00  2.43901322e+00  2.17615022e-02  4.13026571e-03\n",
      "  1.46263600e+00  5.08580573e-02  2.44291642e-01  8.32829493e-01\n",
      " -1.59467995e-01 -5.49780569e-01 -9.41173167e-01 -6.57537758e-02\n",
      "  9.21530771e-01 -1.45913030e+00  3.94798834e-01 -4.12537360e+00\n",
      "  1.15722829e-02 -1.18511528e+00 -2.53076031e-01  7.36094058e-02\n",
      "  5.81172463e-01  2.00948361e+00  9.87131039e-02  1.12626939e+00\n",
      " -4.75592274e-02  2.99575835e-01 -2.38873985e-01  3.83533455e+00\n",
      " -1.09935847e-01  1.26396531e-01  3.67399422e-01  7.94244664e-02\n",
      "  8.27920346e-01 -5.16215447e-01  2.82494657e-01 -9.92565148e-01\n",
      " -1.03208879e+00  1.24603819e-01 -2.30639957e-01 -1.57125789e-01\n",
      "  5.27703641e-01 -1.62991005e+00 -4.00016970e-01  2.41729441e-01\n",
      " -7.71681092e-01 -1.18523710e+00  2.42760323e+00  4.22446847e-01\n",
      "  6.13809955e-01 -6.61981081e-01 -3.01663120e-01 -8.05825620e-01\n",
      "  3.00625871e-01 -6.94529126e-01  8.17423086e-01  1.72465169e+00\n",
      " -4.50154548e-01 -7.51372308e-01 -3.60975286e+00 -1.82706524e-02\n",
      " -6.40978330e-01 -1.83814463e+00  2.99607404e-01 -7.88403507e-01\n",
      "  1.74412945e+00 -4.73238182e-01 -6.73054542e-01 -1.31637774e+00\n",
      " -1.09195915e-01 -1.70960035e+00  1.47411052e+00  3.60409633e-01\n",
      "  1.41431688e+00  5.07241874e-01 -1.38499969e-01 -1.82505580e+00\n",
      " -7.30023705e+00  5.94971218e-01  1.93831505e-01  5.33609391e-01\n",
      " -2.10033843e-01 -2.15222648e+00 -6.70294196e-01 -7.88976625e-01\n",
      " -4.09391671e-01  6.56657801e+00  3.83368147e+00  1.61774848e+00\n",
      " -1.00922716e+00  4.08815602e-03  5.00042160e-01  2.57610349e+00\n",
      "  2.18006175e+00 -7.49740686e-01  2.40062919e-01  8.11810480e-01\n",
      " -6.88476793e+00  3.09326398e-01 -1.96842329e+00 -1.30333545e+00\n",
      " -7.85476987e-01 -2.26136019e+00  2.14373583e-02  2.42338440e+00\n",
      " -2.83286135e-01  5.69140822e-02 -4.62334051e-01  2.06784344e-02\n",
      " -1.11475463e-01  2.12282738e+00 -2.60715058e-01  3.55405333e+00\n",
      " -5.09548235e-01  2.28810367e-01  2.21762583e-01  6.96795080e-01\n",
      "  5.31163807e-01  8.85469650e-01 -1.11154003e+00 -2.25081517e-01\n",
      " -2.05620201e+00 -8.45918857e-01 -3.91890365e+00  1.51694258e-01\n",
      " -4.58787442e-01  6.48894201e-01 -7.50347393e-01  6.64559190e-01\n",
      " -1.65644505e-01 -6.23039186e-01 -1.87936092e+00 -5.22061108e-01\n",
      " -3.04946851e-01  2.58020085e-02  2.00037866e-01 -3.51436801e-01\n",
      "  1.68486762e+00 -1.10566395e+00 -6.94035801e-01  4.85890518e-01\n",
      " -3.53534504e-01  3.16847876e-01 -1.19071629e+00  6.67309271e-01\n",
      "  7.07148025e-01 -1.53870630e+00 -8.98475702e-01  5.50739920e-01\n",
      "  1.93429882e-01 -7.33576193e-01 -5.26914277e-02 -8.72764139e-02\n",
      " -2.39610414e-01 -3.32477607e+00  8.26011714e-01  8.33001565e-01\n",
      "  6.96682498e-01  6.17605150e+00 -1.74786970e-01  7.86443663e-03\n",
      "  6.56427927e-01  1.32693946e+00  3.08571418e-01  8.87915359e-01\n",
      " -1.61594678e+00  2.65717644e+00  6.68426905e-01  7.46672106e-01\n",
      " -2.46750437e-01 -6.96019989e-01 -4.14877886e-02  6.73823897e-01\n",
      " -1.03211060e+00  1.18567517e-01 -2.66695449e-01 -2.50710976e-01\n",
      "  1.07850993e+00 -6.39891519e-02 -6.39138465e-01  1.25809310e-01\n",
      "  4.17515117e-01 -8.58407481e-01 -4.32440416e-01  5.28182987e-02]\n",
      "------counter :4-----------\n",
      "(1000, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.54857189e-01  2.68104458e+00 -2.71457364e-01 -8.34553665e-01\n",
      " -3.55816609e-01 -2.53816606e-01  4.41303561e-01  1.05455172e+00\n",
      " -2.32824795e-01  2.92572293e-01 -5.03899330e-01 -5.52829153e-01\n",
      "  2.31799306e-01  6.47037212e-01 -4.19679177e-01 -1.94313842e-01\n",
      " -7.77349168e-01  2.54139695e+00 -4.09943652e-01  1.75412648e-01\n",
      "  5.37535819e-01  6.73007799e-02  5.83669517e-01  8.53455476e-01\n",
      "  4.25155080e-01  1.93240509e-01 -1.72461970e+00  4.85223092e-01\n",
      "  3.91386882e-01 -1.21865885e+00  4.34739184e-01 -4.39019041e+00\n",
      " -2.17154399e-01 -8.81612817e-01  7.25939301e-02  2.03443890e-01\n",
      " -9.54434044e-02  1.27553787e-01 -1.10940492e-01  1.19053522e+00\n",
      "  1.54643203e-01  1.01712782e+00 -7.73094471e-02  5.38572690e-01\n",
      " -3.16108740e-02  1.36593377e-01  6.25985260e-01 -5.53610548e-01\n",
      "  9.57264635e-01 -2.96844315e-01 -3.19319287e-01 -3.15081400e+00\n",
      " -1.29114478e+00 -8.77049484e-02 -1.16449779e+00 -3.29546810e-01\n",
      "  4.15777907e-01 -1.37096883e+00 -7.56214440e-01 -2.10740567e-01\n",
      "  6.03336002e-01 -1.44364380e+00  1.99813696e+00  1.69490777e-01\n",
      "  1.45211883e+00 -7.38796425e-01 -5.07364867e-02 -3.44992895e-01\n",
      "  3.35345041e-01 -2.56031954e-01  4.02236650e-01  6.38762044e-01\n",
      "  1.17696611e+00 -1.09372454e+00 -3.60227172e+00 -3.74093956e-01\n",
      " -3.00500277e-01 -2.00986789e+00  1.50896235e-01 -7.24565261e-01\n",
      " -2.74528933e-01 -7.05443203e-01  1.21069293e-01 -1.58217577e+00\n",
      "  1.49637758e-02 -9.83932266e-01  1.43383683e+00  1.34032900e-01\n",
      "  7.94924744e-01  1.75719973e-01  1.47073717e-01  8.18455273e-02\n",
      " -4.96216336e+00  7.87921322e-01 -1.00132085e-01  9.28453997e-01\n",
      " -6.03223776e-01 -1.54724203e+00 -1.35877412e+00 -7.73201757e-01\n",
      "  8.44357327e-01  8.39771074e+00  1.88403457e+00  1.07694990e+00\n",
      " -3.63080366e-01  1.11397403e-01  1.33450522e-01  8.16765059e-01\n",
      "  6.72335291e-01 -1.01406603e+00  4.23125989e-01  6.38705293e-01\n",
      " -3.47498528e-01 -5.80965679e-01  1.98270172e+00 -2.46559871e+00\n",
      " -9.70990114e-01 -1.62744151e+00 -3.64304403e-01  1.15208850e+00\n",
      " -4.31202976e-01 -5.66929513e-01 -1.90304745e+00  6.16873501e-01\n",
      "  4.28506855e-01  1.96213631e+00 -3.15759590e-01  2.24449818e+00\n",
      " -6.63977339e-02  7.15489192e-01  2.77454158e-01  4.20176161e-01\n",
      "  4.44375482e-01  1.40809391e+00 -1.38181950e+00 -5.06500386e-02\n",
      " -3.92179074e-01 -1.25542373e+00 -9.55414529e-02  1.29528009e+00\n",
      " -1.46534671e-01  2.59801069e-01  2.12405686e+00  6.97882452e-01\n",
      "  1.62389336e-01 -4.74835716e-01 -1.30475664e+00 -5.05370880e-01\n",
      " -2.51731635e-02 -7.36707066e-01  3.88131728e-01 -6.59337366e-01\n",
      "  1.24379361e+00 -9.69230806e-01 -7.42460067e-01  4.93217108e-01\n",
      " -6.76235911e-01 -1.80420166e-01 -4.43343103e-01  7.53074010e-01\n",
      "  3.54848039e-01 -2.70017203e+00 -1.01671624e+00  5.38751997e-01\n",
      "  4.58776507e-01 -1.34598303e+00  2.27866542e-03 -2.19852564e-01\n",
      " -6.15792739e-01 -2.28663405e+00  1.05819352e-01  5.01696251e-01\n",
      " -1.10948324e-01  5.21437806e+00  2.77587315e-01 -1.29361649e-01\n",
      " -1.92278671e-01  2.19612841e+00 -2.41721035e-01  1.40936519e-01\n",
      "  4.78401472e-01  6.20362276e-02  4.15489042e-01  3.66729655e-01\n",
      "  1.45371379e+00  2.43855860e+00 -4.47847696e-01  3.77022933e-01\n",
      " -1.52896536e-01 -4.31172843e-02 -1.29426548e-01  4.22094734e-01\n",
      "  4.38805250e-01  1.79305257e-01 -6.09907763e-01 -1.20979046e-01\n",
      "  5.37505496e-01 -1.73268814e+00 -5.48852662e-01  9.33036711e-03]\n",
      "------counter :5-----------\n",
      "(1200, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.94317257e-01 -1.54381855e+00  5.25787311e-01  5.00061733e-01\n",
      " -4.57339788e-01  3.87008588e-01 -2.16155593e+00  2.14950278e+00\n",
      " -5.02790647e-01 -1.13461734e+00  3.70886958e-02  7.53230612e-01\n",
      "  4.15005004e-01 -4.46396940e-02  1.74946183e-01  3.62977366e-01\n",
      " -1.03302301e-01  3.57761945e+00 -8.45887062e-01  2.04461959e+00\n",
      "  1.43073715e+00 -4.77633004e-01  3.27149270e-01  9.09799863e-01\n",
      "  6.22752316e-01  1.29441167e+00 -1.26648092e+00 -6.34704603e-01\n",
      "  1.27096776e+00 -6.88633582e-01  5.66779375e-01 -4.21213060e+00\n",
      "  2.35574182e-01 -1.08186656e+00  2.87220387e+00 -3.75685065e-02\n",
      "  1.36274201e-01  7.00418243e-01  4.46839441e-01  2.77885294e+00\n",
      "  7.66949364e-02  7.33430002e-01 -5.59231223e-01 -5.51243627e-01\n",
      "  8.89562098e-01  2.20870978e-01  3.47268744e-01 -5.65875903e-01\n",
      "  1.35554904e+00 -2.45888912e-01 -3.86607289e-01 -5.50826203e-01\n",
      " -4.73289159e-01  4.37841482e-01  2.49075905e-01 -4.19726626e-01\n",
      " -1.94233120e-01 -1.23618780e+00 -3.96082110e-01  1.61244024e-01\n",
      "  7.39968278e-01 -9.81005253e-01  1.13811772e+00  7.20047627e-01\n",
      "  6.02902279e-01 -3.16044838e-01 -1.01171740e+00  3.22212314e-01\n",
      "  1.09558703e-01 -3.20452872e-01 -4.29597372e-03  1.85642304e+00\n",
      "  1.97572480e-01 -8.40440283e-01 -1.96055042e+00  6.20754596e-01\n",
      " -1.52027371e-01  1.81671085e+00  4.27236078e-01 -1.39796388e+00\n",
      "  4.41011738e-01 -5.02020178e-01  2.50151713e-01 -1.43521662e+00\n",
      " -2.56774521e-02 -2.90445227e+00  9.53072981e-01  1.18711622e+00\n",
      " -9.84485646e-02  2.80262060e+00 -6.63578019e-01 -5.43662988e-01\n",
      "  7.56521203e+00  5.03639941e-01 -1.81592187e+00 -3.61163575e-02\n",
      " -3.89155710e-01  4.58199434e-01 -1.94648941e+00 -1.41953691e+00\n",
      "  7.10061872e-01 -2.95917625e+00 -1.81721263e-01  2.57675441e-01\n",
      " -3.65848563e-01 -2.99249835e-03  1.96616326e-02 -2.39401878e+00\n",
      "  9.05138709e-01 -5.77131567e-01  4.25209770e-01  6.53022835e-01\n",
      "  1.30448603e-02 -7.63258828e-01 -8.63926863e-01 -1.84788892e-01\n",
      " -4.72282926e-01 -1.98488086e+00  1.37549383e-01  9.65659237e-01\n",
      " -1.11681166e-01  1.14374436e-01 -1.82492871e+00  5.17303316e-01\n",
      " -1.17923588e+00 -4.19040644e+00 -3.71743110e-02 -2.06667433e+00\n",
      " -9.30958682e-01 -1.04293723e+00  5.51065499e-01  5.16566616e-01\n",
      "  9.36093929e-01  1.69442290e-01 -1.04847845e+00 -5.09209437e-02\n",
      "  1.86735926e-02 -9.55200898e-01  4.72843831e-01  1.49815897e+00\n",
      " -1.80727839e-01  5.87496901e-01  1.21221336e+00  1.08331290e+00\n",
      "  3.11829937e-01 -8.17376118e-01  6.00878331e-01 -3.25004746e-01\n",
      "  3.28097569e-01 -7.03178220e-01  8.82021188e-01 -1.74526041e-01\n",
      "  2.58669445e-01 -7.87210777e-01 -6.00746407e-01 -1.37237823e-01\n",
      " -6.26242037e-01 -1.43855140e+00 -3.51342450e-01  1.13008251e+00\n",
      "  1.14946101e+00 -2.57501545e+00 -1.29855521e+00  2.03332750e-01\n",
      "  4.13704308e-01 -7.36800219e-01  2.82187222e-01  7.23063512e-01\n",
      "  1.78994606e-01 -2.09915040e+00  1.56555603e-01 -4.34954878e-01\n",
      " -8.17026009e-01  1.54025120e+00  5.68057596e-01  9.86042890e-02\n",
      "  1.38995720e-02 -1.59953108e+00 -2.08639807e-01  6.05930753e-01\n",
      " -1.10750207e-01  6.98333341e-01  5.67830039e-01  1.29921565e+00\n",
      "  2.69491082e-01  1.93704973e+00 -2.90067606e-01  9.09457681e-01\n",
      " -9.75421545e-01  3.36180616e-01 -2.07011504e-02  6.43407810e-01\n",
      "  3.78210495e-01  9.33572837e-02 -2.64176872e-01  1.02143706e-02\n",
      "  9.21604469e-01  7.86550035e-01 -7.09181070e-01 -5.24087215e-02]\n",
      "------counter :6-----------\n",
      "(1400, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34197772  2.57185928  0.50430075 -0.08692767  0.16397779 -1.31536676\n",
      " -1.38784552  2.10199918 -0.48785816 -0.99047696 -0.3365238   0.21162632\n",
      " -0.05694097  0.91959885  0.30081173  0.12935977 -1.63482045  1.5155994\n",
      " -1.66337627  4.31706589  0.97988687  0.11501197  0.67029463  1.16042511\n",
      "  0.4780032   1.18717055 -1.04320001 -1.21963825 -1.32227113 -2.24682887\n",
      " -0.79715997 -4.49039786  0.13980177 -0.08585341  3.65005767  0.18636271\n",
      "  0.93145649  0.40646295  0.08014167  2.23814521 -0.16140947  0.73405172\n",
      " -0.62070608 -0.78171043  0.45979604  0.37109134 -1.18902319  0.333659\n",
      "  2.01417261 -0.62699428 -0.20195912  0.15768713 -1.62494173  0.15699127\n",
      " -0.49708042 -0.30222116 -0.02043054 -1.50725228 -0.74955909  0.09672733\n",
      "  0.49124231 -0.5149768   2.52263141  0.60652656  2.59487494 -0.54198583\n",
      " -0.22064332 -0.64302256 -0.22931208 -1.23466406  0.30696667  0.47383932\n",
      "  0.96014329 -1.16664043 -0.81013731 -0.02916689 -0.1699525   0.626695\n",
      "  0.08146662 -1.30916927 -0.40705929  0.50374745 -0.22134818 -1.1982908\n",
      " -0.13436655 -1.75767094  0.93471171 -0.50763352  2.19838423 -0.90656924\n",
      " -1.20049077 -0.10069282 -3.66274312  0.67943074 -1.05310832  0.64764815\n",
      " -0.31128377  1.45874918 -2.19828253 -1.34248631  0.38600145 -2.95140624\n",
      " -0.42135098  0.06267766 -0.59056861  0.11960035  0.34726948  3.52671475\n",
      "  0.95068526 -0.97085066  0.39943816  0.52233905 -0.24173367 -1.32123338\n",
      "  1.23820152 -2.14292512  0.47589136 -1.66543362  0.9503849   0.89444634\n",
      " -0.53506073 -0.12781221 -1.35202403  0.57001261 -0.22775848  0.71109899\n",
      " -0.30479397  4.67193026 -0.45622497 -2.91896409  0.39333256  0.10037462\n",
      "  0.52444226  0.61117965 -1.2356962  -0.01543119 -0.64466383 -0.41367264\n",
      "  4.41163309 -2.22137245  0.17394387 -0.06965389 -2.08017677  0.84850492\n",
      "  0.08658117 -0.57304599  0.46041118 -0.43437732  0.13491639 -0.87137154\n",
      "  0.45444561 -0.493387    0.24412921 -1.04072396 -0.71427005  0.25030726\n",
      " -1.44359933  1.03477567 -0.69682138  0.36420189  1.31334771 -2.33144429\n",
      "  0.43784316  0.31095219  0.55443757 -0.74152239  0.03006513  0.74798352\n",
      "  0.14792217 -0.73752425 -0.04807393  1.74094301 -1.66697311  2.379482\n",
      "  0.77648147 -0.09546904 -0.11124416 -1.36538945  0.69353211  1.02356235\n",
      "  1.07449317  2.25987139  0.34175882  0.4397533   1.34130113  1.90481729\n",
      " -0.53441985  0.65369668 -1.38408819  0.74154373 -1.34984843  0.73930015\n",
      "  0.75194614 -0.12011008 -0.79217981  0.13061263  0.23228286 -0.74366167\n",
      " -0.7274366  -0.15417213]\n",
      "------counter :7-----------\n",
      "(1600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.66835784e-01  1.74321960e+00  2.36106643e-01 -5.11756858e-01\n",
      "  2.61074008e-02  1.86895142e-01 -4.18143224e+00  1.96625140e+00\n",
      "  1.71786228e+00 -1.28204608e-01 -2.90008524e-01  2.42027690e-01\n",
      " -1.10517133e-01  7.25517395e-01 -6.23062768e-02  2.22647225e-01\n",
      " -9.26056500e-01 -4.56675955e-01 -1.71385914e+00  3.55983117e+00\n",
      "  1.10838194e-01 -1.21588038e+00  5.19283633e-01  6.66936877e-01\n",
      "  3.12563000e-01 -2.20754177e+00 -2.57879616e-01 -2.65556199e+00\n",
      "  1.16019273e+00  2.97343727e+00  1.05210614e-01 -3.68829958e+00\n",
      " -1.68131798e-01  2.72744767e-02  3.81009738e+00  2.26195155e-01\n",
      "  5.54255497e-01 -6.61967916e-01  1.53135759e-01  1.40221637e+00\n",
      "  1.76893708e-01  8.36077807e-01  3.54832261e+00 -1.20784954e+00\n",
      "  3.61951348e-01  4.52331856e-01 -4.96641950e-01  6.36939187e-02\n",
      "  1.91809187e+00 -2.39629272e-01  3.30514582e-01 -1.94119793e-01\n",
      " -9.93895681e-01  4.21273643e-02  2.67162436e-01 -1.28637939e-01\n",
      "  2.82052865e-01 -1.41443210e+00 -6.32189500e-01  2.18582344e-01\n",
      "  1.04466503e-01 -3.68903832e-01  1.71099881e-01  9.57000571e-01\n",
      "  1.73348500e+00 -5.08869692e-01 -1.95835785e-01 -6.84068729e-01\n",
      "  2.80041978e-01 -2.15445839e+00 -1.72333530e+00  1.83220283e+00\n",
      "  4.86097368e-01 -7.49130202e-01 -5.55431846e-01  1.27277010e+00\n",
      "  2.03018140e-01  1.25884545e+00 -1.35862342e-01  8.24498581e-02\n",
      " -1.04914698e+00 -1.94584231e-01  1.12244667e-01 -1.16835565e+00\n",
      " -1.36923779e-01  2.03107381e+00  1.00600115e+00 -6.17606513e-01\n",
      "  7.47990451e-02  1.13738692e-01 -1.46716910e+00  2.97418960e-01\n",
      " -2.29935383e+00  5.59852187e-01  1.76240347e-01  4.95200761e-01\n",
      "  1.64940987e-02 -1.40281081e-01 -1.69734754e+00 -1.12885577e+00\n",
      "  4.36405065e-01 -8.49366338e-01 -9.10946364e-01  1.61322358e-01\n",
      " -2.47868588e-01  2.55625131e-02 -1.05084036e-01  2.36881410e+00\n",
      "  1.09570024e+00  5.34015164e-02 -1.43902018e-01  7.34410095e-01\n",
      "  2.48400572e-01  2.80726371e-01  1.49962447e+00 -1.34536803e+00\n",
      " -1.68854594e+00 -1.24880217e+00  7.75119005e-01 -3.22586709e-01\n",
      "  5.57747140e-02  4.26419575e-01 -4.27592953e-01  2.82175888e-02\n",
      "  1.68220780e-02 -2.34626107e+00  2.07147530e-01  4.13680318e+00\n",
      "  8.69250362e-02 -1.34051324e-01  1.44904969e-01  5.92691949e-01\n",
      "  3.64029126e-01 -1.25949408e-01 -8.33714865e-01  2.60672600e-01\n",
      " -6.00976513e-01  2.47441445e-02  2.33474250e+00 -6.44048126e-01\n",
      "  2.51915623e-01 -3.21574958e-01 -2.20236388e+00  1.86517703e+00\n",
      "  1.07582889e-01 -8.13165146e-01 -7.96026849e-01 -8.22306594e-01\n",
      "  1.85327331e-02 -8.47208231e-01  9.33741114e-01 -8.26624114e-02\n",
      "  5.19283889e-01 -6.41261600e-01 -8.27808600e-01  4.00168471e-01\n",
      " -8.59564409e-01 -1.41409886e+00 -8.36268719e-02  5.34581336e-01\n",
      "  1.33278270e+00 -2.41894057e+00 -9.17067983e-01  5.40614607e-01\n",
      "  3.27324258e-01 -6.89688903e-01  7.57196742e-02  8.43264646e-01\n",
      "  3.31185345e-01 -1.61163362e+00  3.75903575e-01 -1.15244115e+00\n",
      " -1.67996839e+00  2.84258726e-01  5.95079058e-01 -3.86975247e-02\n",
      "  4.71524992e-01 -2.60816023e+00 -7.93307272e-01  8.68483468e-01\n",
      "  1.47694248e+00  1.08722921e+00 -5.84127099e-03  4.18032355e-01\n",
      " -3.90159847e-01  1.22351208e+00 -3.88324928e-01  5.27888413e-01\n",
      " -1.04024479e+00  2.64257853e-01 -4.78341766e-02  3.04572075e-01\n",
      " -1.32379498e-01  3.06095471e-01 -4.24939707e-01  3.89240388e-01\n",
      "  2.10068166e-01 -2.43273576e-01 -2.33228395e-01  2.34611583e-04]\n",
      "------counter :8-----------\n",
      "(1800, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.61592161e-02 -2.22361948e+00 -7.05022960e-01  2.74202331e-01\n",
      "  1.82961072e-01 -2.18134288e-01 -3.90037554e+00  1.48217700e+00\n",
      "  2.83595186e+00  5.86881933e-01 -1.01513684e+00 -6.10669167e-01\n",
      " -1.42966712e-02  1.46043711e-01  6.17552380e-01  3.24115521e-01\n",
      " -1.21656245e+00  3.21729953e+00 -1.22315085e+00 -1.71122643e+00\n",
      "  2.03367023e+00 -5.96934398e-01  2.08502949e-01 -5.27335942e-01\n",
      " -5.93087336e-02  4.69330744e-01 -1.17198122e+00  8.21776273e-01\n",
      "  7.95501316e-01 -2.73296069e-01  2.12645224e-01 -4.19080240e+00\n",
      " -5.27896166e-02 -1.31037214e+00  3.84969138e+00 -7.61662616e-01\n",
      "  7.62978730e-03 -3.49548955e-02 -6.00622576e-02  2.33953851e-01\n",
      "  9.48876774e-02  5.43846517e-01  4.79420061e+00 -3.66431679e-01\n",
      "  1.63180051e-01  7.04502623e-01  4.57551630e-01 -3.43816277e-01\n",
      "  8.91486497e-02 -6.25915988e-01 -4.23285614e-01 -4.17395116e-01\n",
      " -5.87830601e-01 -2.54216262e-01  2.77734959e-01 -4.09636532e-01\n",
      " -2.60543019e+00  4.86930819e-01 -2.98628324e-01  7.54373403e-01\n",
      "  3.28800197e-01 -1.46095791e+00 -4.30065147e-01  2.63142663e-01\n",
      "  2.11154962e+00 -9.57372190e-01 -4.66750467e-01 -1.02000611e+00\n",
      "  3.16444806e-02 -1.10127309e+00 -7.60608706e-01  8.05589010e-01\n",
      "  1.25842546e+00 -1.03211438e+00 -4.81103196e-01  5.25591703e-01\n",
      " -2.19495264e-01 -1.62706295e+00 -3.57612274e-01  3.40777575e-01\n",
      " -8.24654073e-01  2.79863975e-01 -4.32074632e-01 -1.22236151e+00\n",
      "  6.06821737e-01  1.25827931e+00  2.49535790e+00  6.02893261e-01\n",
      "  4.38783220e-01  1.19271078e+00 -4.36722500e-01  4.84384723e-02\n",
      "  2.90580819e+00  1.09518743e+00  4.94728825e-03  5.28905287e-01\n",
      " -1.18811427e-01 -1.93456627e-01 -1.78806300e+00 -1.19158294e+00\n",
      "  1.44333344e+00 -9.01845324e-01 -2.88798458e+00  1.23720914e+00\n",
      " -3.78056266e-01 -5.01429576e-01 -2.90301168e-01  3.60141543e+00\n",
      "  5.09842923e+00 -6.13911119e-01 -3.25420494e-01  2.52018466e-01\n",
      "  1.15079211e-01 -2.51490261e-01  5.31289731e-01 -1.43329300e+00\n",
      " -3.84826220e-01 -2.39267960e+00 -4.12485883e+00  3.20204231e+00\n",
      " -3.62704741e-01 -2.38691392e-01 -5.88093669e-01 -4.52537752e-02\n",
      " -2.18267496e-01  4.14167638e-01 -1.64508153e-01  3.88357884e+00\n",
      " -5.92008440e-01 -2.20499535e+00  1.33305646e-01  3.19537760e-01\n",
      "  8.58932960e-01  8.10339856e-01 -1.93136198e+00  1.23511701e-01\n",
      " -4.17014942e-02 -2.59102503e-01 -8.96291649e-01  2.32920565e-02\n",
      "  5.47730150e-01  9.11312434e-02 -1.06721346e+00  8.41446785e-01\n",
      " -4.55439583e-01 -5.60442348e-01 -9.02014872e-01 -1.00695561e+00\n",
      " -4.75250333e-01 -6.09946923e-01  8.06938405e-01 -5.36305573e-01\n",
      "  3.05564811e+00 -9.03338879e-01 -1.00006465e+00 -1.48196251e+00\n",
      " -1.32499369e+00 -9.45891022e-01  1.34777238e+00 -1.20943857e-01\n",
      "  1.24549478e+00 -2.12936781e+00  2.46203784e+00 -1.86569349e-01\n",
      "  3.48366420e-01 -6.36185643e-01 -3.15999476e-01 -6.35711857e-01\n",
      " -4.48947976e-01  3.69863684e+00  7.69671189e-01 -1.62496474e-02\n",
      " -1.78342303e+00  2.70450229e+00  4.51121366e-01  1.88706836e-01\n",
      " -4.26868333e-01  7.48486153e-01 -3.69325912e-01  5.30813911e-01\n",
      "  1.10774206e+00  9.86847765e-01 -5.94807637e-02  6.58164981e-01\n",
      " -1.36621583e-01  5.69677182e-01 -3.67941522e-01  4.27899605e-01\n",
      " -1.08639574e+00 -1.31143854e-01 -2.73856363e-01  8.28177400e-02\n",
      "  8.78065929e-02 -4.77605126e-01 -9.92238027e-01  5.39630273e-01\n",
      "  4.23430771e-01 -1.40098971e+00 -6.59747291e-01 -2.56668146e-01]\n",
      "------counter :9-----------\n",
      "(2000, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05982472  2.04363938  0.20843468 -0.24152288 -0.57934585 -2.13753037\n",
      " -4.45676679  1.50338835 -0.28543889  0.71511296 -0.72609121 -0.37048207\n",
      " -1.33969915  0.7032      0.22866703  0.54679266 -1.65446805  2.0605363\n",
      " -0.51048433  2.62708367 -1.07455468 -0.32936584  0.58406318  0.43523397\n",
      " -0.18231219 -0.36514251 -1.20160738  0.69606849  0.74613169  0.86755346\n",
      " -0.83087308 -4.07096867  0.15384416 -0.71245646  0.39901114 -0.64827046\n",
      "  0.18562242  0.77399636 -0.14988606  1.97177856 -0.25727759  0.62118506\n",
      "  5.86240626 -0.64286548 -0.05642341  0.21320548 -1.36817454 -0.32180932\n",
      " -2.20403454 -0.6320653   0.38119416 -0.37445228 -0.93514575 -0.09539766\n",
      " -1.43706671 -0.16032675  0.78409979 -1.61502467  0.18129368  0.22255687\n",
      " -0.1530994  -1.10847106  1.61629009  0.61952527  2.14780601 -0.67792326\n",
      " -0.75387294 -0.44855922  0.6921834  -0.12259851 -4.28915781  2.14232426\n",
      "  1.08263263 -0.52919198  2.34708352 -1.20118645 -0.82956926  1.90512455\n",
      "  0.02645495  0.53651782 -1.37385015  0.39838583  0.14275023 -0.90843225\n",
      " -0.26564755 -4.4194232   2.2541489   0.93022852  1.06486656  2.13040114\n",
      "  0.59394588 -0.9732057   0.76907816  2.11428285  0.18582877  0.39526263\n",
      "  0.14869249 -0.18126618 -1.15517906 -0.71237552  1.94916006 -0.73430523\n",
      "  1.87758623  0.77296381 -1.42142485 -0.44010286 -0.38487524  4.62805432\n",
      "  2.49405249 -0.28379004  0.0132815   0.20036567 -0.03389381  0.25097689\n",
      " -2.41377762 -0.59501216 -0.02052276 -1.96485401 -3.15196351  2.6728776\n",
      " -0.25473493 -0.11177981 -0.07265232 -0.04939971 -0.30163896 -1.45965516\n",
      "  0.37572495  2.23534682 -0.58698576 -2.16621042 -0.01427524  0.19920754\n",
      " -0.26427759 -1.30811432 -1.40035987  0.2425573   0.53032751 -0.72508841\n",
      " -0.78431887 -1.66907495  0.9272559  -0.04149731  0.57969544  1.1504507\n",
      "  0.18777447 -0.48566125  0.99919575 -0.73551568 -0.35781333 -0.30341634\n",
      "  0.26199272 -0.44977394  3.43145669 -0.35281916 -0.88380403  0.02660565\n",
      " -1.20954055  1.04667082  1.6651974   0.12095464  1.19642493 -1.7209652\n",
      " -1.17200749  1.02702693  0.32018966 -0.84744571 -0.27018714  1.15519698\n",
      " -0.37746435  1.83081224  0.48277364 -0.07286475 -1.44723922  0.57282368\n",
      "  0.12466871 -0.28208865 -0.38924936 -0.77435821  0.40334986  0.02009405\n",
      "  1.39733693  0.40685524  0.03509687  0.28420933  0.58934862  1.39770805\n",
      " -0.48929368  0.11940033 -1.12502665  0.32600881 -1.49356028  0.0909908\n",
      " -0.1230647  -0.02773766 -0.64845373  0.49973649  0.16465462 -0.00736099\n",
      " -0.04207505 -0.37081589]\n",
      "------counter :10-----------\n",
      "(2200, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.74407264e-01  1.90523955e+00 -3.38241846e-01  3.09529809e-01\n",
      "  7.64798424e-04 -2.98088006e-01 -3.48935864e+00  9.94134080e-01\n",
      " -1.67160526e+00  6.16211992e-01 -2.18812862e-01  4.36560570e-01\n",
      " -1.35600400e+00  1.28972972e+00  2.13833347e-01  1.36561716e-01\n",
      " -1.52681308e+00 -1.07296692e-01 -4.30391964e-01  3.98186121e+00\n",
      "  2.34133346e-01 -2.87196264e-01  7.16989476e-01  8.12074078e-01\n",
      "  2.44118991e-02  1.07477284e+00 -1.08622617e+00  4.43384659e-01\n",
      " -3.11744110e-01 -1.32617337e+00 -6.55041757e-02 -3.42201632e+00\n",
      "  8.59888688e-02  3.92499442e-01 -3.29989267e+00  1.53835955e-01\n",
      "  1.29549226e-01 -8.41990190e-01 -4.50073933e-01  1.10917631e+00\n",
      " -4.80913354e-01 -1.68833628e-01  5.02245781e+00 -2.16726202e+00\n",
      "  2.73047048e-01 -1.03629455e-01 -1.58985676e+00 -7.70420857e-01\n",
      "  5.23370049e-01 -4.01284566e-02  1.02760507e-01 -4.66566097e-01\n",
      " -1.17602341e+00 -1.98489538e-01  1.40669965e+00 -1.66684663e-01\n",
      " -1.90449438e-01  1.63142073e+00 -4.40121174e-02  3.36603091e-01\n",
      "  3.84838779e-01 -6.46665361e-01 -1.52089309e+00  3.39837501e-01\n",
      "  1.12027337e+00 -3.02755136e-01 -5.06141620e-01 -6.33451173e-02\n",
      "  1.77996139e-01  4.86661276e-01 -6.58310274e-01  1.52010529e+00\n",
      " -1.70216839e+00 -1.62192330e-01  3.23817506e+00  2.54719791e-01\n",
      " -5.28122089e-01 -1.55510580e-01  5.13830239e-01  8.95703048e-01\n",
      "  5.35506718e-01  6.62499600e-01  6.19795447e-01  3.45170668e-01\n",
      "  4.99018161e-01 -2.32312422e+00  7.40917707e-01  9.07068671e-01\n",
      " -1.43421025e+00  1.11501486e+00  8.77169192e-01 -3.57469568e-01\n",
      " -8.67620709e-01  1.49001554e+00  2.16430288e-01  1.04759360e+00\n",
      "  4.19644605e-01 -2.26881978e-01 -3.63259429e-01  2.88802518e-01\n",
      "  2.06768031e+00 -1.05945881e+00 -3.82562393e-01  3.58745366e-01\n",
      " -6.11345713e-01 -2.78975225e-01 -9.71835099e-01  3.92748674e-01\n",
      "  2.77545092e+00  1.67100790e-01  4.07215528e-01  4.77787432e-01\n",
      "  6.39951231e-02 -2.52537638e+00  1.51999783e+00 -2.34568074e+00\n",
      " -4.34052142e-01 -9.00795201e-01 -3.00275986e+00  2.54759649e+00\n",
      " -1.27995973e-01  4.85718099e-01  5.20658371e-01  5.63857755e-02\n",
      " -2.26411250e-01 -3.23950060e+00  7.23510126e-01  3.57993025e+00\n",
      " -2.03444555e-01 -5.75628584e-01  1.24865966e-01  4.02272779e-01\n",
      " -1.89661055e-01 -1.58948504e+00 -8.57662105e-01  5.36639574e-01\n",
      "  1.39598307e+00 -4.08460644e-01 -1.36735870e+00  7.51860016e-01\n",
      "  4.70467867e-01  1.34698403e-01  6.06828260e-02  2.28908167e+00\n",
      "  1.92486947e-01 -1.38067054e+00 -2.43870903e+00 -1.03983134e-01\n",
      " -2.91386967e-01 -6.29855367e-01 -6.75924594e-01 -3.88797254e-01\n",
      "  1.05838449e+00 -2.14066296e-01 -4.16498689e-01  3.14735651e-01\n",
      " -3.95351179e-01  1.66513476e+00  1.48518776e+00  7.67515606e-03\n",
      "  1.07249115e+00 -1.33029689e+00  2.05240785e+00 -1.28254630e+00\n",
      "  9.53525379e-01 -5.30833425e-01 -2.87133802e-01 -1.00906003e-01\n",
      " -4.19433483e-02  1.42417606e+00  4.97447173e-01 -4.71086627e-01\n",
      " -1.50394394e+00  8.65180620e-01  1.51212675e-01  2.87635313e-01\n",
      "  4.86607904e-01 -6.61807055e-01 -1.82521522e-02 -4.66922757e-01\n",
      " -2.44817656e+00 -9.65973265e-01 -1.25073327e-01  1.00458262e+00\n",
      " -6.74670205e-02  1.03949584e+00  1.00541500e-01  1.90922808e-01\n",
      " -9.19457573e-01 -2.70277927e-01 -1.89857277e-01 -5.45048070e-02\n",
      " -1.99570633e-02 -4.41861777e-01 -5.21908589e-01  4.96819261e-01\n",
      "  5.32952590e-01  2.22174676e-01 -9.66532595e-02 -3.32930657e-01]\n",
      "------counter :11-----------\n",
      "(2400, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.01925448e-01  2.57632910e+00 -1.69687041e+00 -5.05543853e-02\n",
      " -2.23204988e-01 -2.77058805e-01 -3.25690409e+00  6.40305928e-01\n",
      " -3.10273460e+00  2.44743458e-01 -1.66189205e-01 -1.66273038e-01\n",
      " -8.96772588e-01  8.23984829e-01  4.51742308e-01 -1.98140386e-01\n",
      " -2.16232250e+00  1.67247196e+00 -3.80019489e-01  3.31120982e+00\n",
      " -5.41371414e-01  3.18268659e-01  5.50311124e-01  5.20412426e-01\n",
      "  8.62809695e-02 -1.51270087e+00 -3.79602488e-01  1.07641878e+00\n",
      "  8.53297462e-01 -1.19929857e+00  2.68529413e-01 -3.21074616e+00\n",
      "  1.03208403e-01 -1.87707336e-01  4.20536787e+00  5.34387320e-01\n",
      " -1.50533473e-01 -2.29130638e-01 -4.00493388e-01  2.13685300e+00\n",
      "  2.38959510e-01  7.55814680e-01 -4.10179472e+00 -2.00740166e+00\n",
      " -2.25535513e-01 -1.10336627e-01 -1.37001895e+00  2.11900449e-01\n",
      " -3.21055993e+00 -9.14256577e-02 -4.83930488e-01  1.65137461e-01\n",
      " -1.11942091e+00 -7.81201473e-04  4.98023186e-01  2.35603130e-01\n",
      " -3.88899359e-01 -5.18657679e-02 -4.04477687e-01  7.18935678e-01\n",
      "  1.88964698e-01  1.05792889e-01  2.07393808e+00  7.68162190e-01\n",
      " -2.33572671e+00  9.70687689e-02  8.88114510e-01  2.47073499e-01\n",
      "  8.89525661e-02  3.65612336e-01  1.93569985e+00  9.52154769e-01\n",
      "  1.08273603e+00  3.24782528e-03  1.89386756e+00 -1.09548340e-01\n",
      " -4.83847705e-02  1.06079441e+00  5.60402191e-01  1.04862939e+00\n",
      " -7.60971068e-01  6.41314286e-01  2.99580784e+00  8.21116719e-01\n",
      "  2.17341229e-01 -4.42973244e+00  2.37206822e+00 -1.52241177e+00\n",
      " -3.71174493e-01  1.44942414e+00  2.89059184e-01 -1.91377293e-01\n",
      " -5.26703543e-01  1.01058841e+00  2.15836943e-01  7.88590273e-01\n",
      " -2.28551377e-01 -2.26567442e-01 -8.86637717e-01  4.86281517e-01\n",
      " -2.46554541e-01 -5.11150931e-01  6.66125774e-01  1.15487787e+00\n",
      " -4.51960519e-01 -1.55907273e-01 -3.13931549e-01 -8.08280281e+00\n",
      " -3.94817252e+00  3.76112434e-01  1.84328764e-01  7.11067961e-01\n",
      "  1.52865993e-01 -1.37664866e+00  1.94156100e+00 -8.89256592e-01\n",
      " -2.87645272e-01 -5.96138265e-01 -1.81873901e+00 -9.84532665e-01\n",
      "  6.13547298e-01  6.01851297e-01  5.10714016e-01 -2.57181376e-01\n",
      " -1.16125086e-01 -7.98191915e-01  9.33408153e-01 -1.41119095e+00\n",
      " -8.27481849e-01 -2.17343841e-01 -1.15368316e-02  9.34888078e-01\n",
      " -1.40410601e-01  1.49200932e+00 -3.44525796e-01  1.22738965e+00\n",
      "  1.37714873e+00 -1.57987728e-01 -6.85701987e-01 -2.00289867e+00\n",
      "  1.01366437e-01  3.04640170e-01 -1.60070504e+00  2.65560632e+00\n",
      "  3.33358494e-01 -8.71722652e-01 -1.01847206e-01 -1.04148332e-01\n",
      " -1.24554078e-01 -1.19878354e+00  5.36921337e-01 -6.86751650e-02\n",
      " -3.58323994e-01 -1.79426481e-01 -2.28710088e-01  5.93941112e-01\n",
      "  1.54809149e-01  1.38098516e+00  1.22782969e+00  9.82738348e-01\n",
      "  1.07188323e+00 -1.29887530e+00 -9.88092342e-02 -1.21328469e+00\n",
      "  9.36963270e-01 -3.49032370e-01 -6.83408902e-02  1.39515451e-01\n",
      "  1.09783892e-01  1.26201791e+00  2.49320059e-01  3.30336091e-02\n",
      " -1.58051332e+00  8.05357120e-01  6.29323636e-01 -7.29300704e-03\n",
      "  1.37268058e+00 -7.85959297e-01  2.15432659e-01 -2.68953224e-01\n",
      "  1.89468883e+00 -1.83560740e-01 -3.38287244e-01  1.01371916e+00\n",
      "  6.69617443e-01  1.10688126e+00 -4.20190012e-02  2.84338895e-01\n",
      " -6.10170631e-01  1.04925367e+00 -1.21492104e+00  3.14916785e-01\n",
      "  6.46253100e-01 -1.04969666e-01 -3.24419199e-01  1.14919433e+00\n",
      "  9.24811684e-01  1.03288136e+00 -4.81686505e-02 -1.05816683e-01]\n",
      "------counter :12-----------\n",
      "(2600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.38045263e-01  1.96843774e+00  2.38335920e+00  1.52596460e-01\n",
      " -2.79040665e-01 -4.86121949e-01 -1.87660541e+00  2.53164809e-01\n",
      " -3.87111949e+00 -1.43437557e-01 -6.03453613e-02 -8.30309529e-01\n",
      " -1.10552101e+00  7.08259444e-01  2.18811025e-01  5.86404620e-01\n",
      " -1.90957770e+00 -1.83811781e+00 -2.35088136e-01 -5.34435928e-02\n",
      "  1.38221134e+00  3.36767419e-01 -2.84452689e-01  4.12918741e-01\n",
      " -6.27729828e-01 -7.94758265e-01  6.86579907e-01  9.42668894e-01\n",
      "  6.52305680e-01  1.93287706e+00  1.37118393e-01 -2.89044542e+00\n",
      " -1.81647199e-01 -2.57918875e-01  2.98099091e+00 -2.41857274e-02\n",
      " -3.16025778e-01 -5.43960731e-01 -5.84241900e-01  3.14816524e+00\n",
      " -8.24494116e-02 -5.91132522e-01 -2.70605400e+00  1.36170043e+00\n",
      "  2.92860261e-02 -5.83427526e-01 -2.44877225e-01  2.53160960e-01\n",
      " -1.18464645e-01 -1.47218911e-01  5.93034066e-01 -1.40056693e+00\n",
      " -7.47935567e-01 -6.16537884e-02 -1.93725409e+00 -3.62687160e-01\n",
      " -2.30075762e+00 -7.12069357e-01 -7.59584808e-01  7.10802718e-01\n",
      "  5.83930455e-02 -1.45664149e-01  2.90528224e-01  9.39661705e-01\n",
      " -6.96080732e-01  2.19474619e-01  6.01638479e-01  3.65893108e-01\n",
      " -6.74517831e-01  1.06919656e+00 -8.77707384e-01  1.88074580e+00\n",
      "  3.59087890e-01  1.37145725e-01  2.49044137e+00 -2.38613871e-01\n",
      " -4.12640275e-01 -1.39281767e+00 -5.62807254e-02  1.06669414e+00\n",
      "  1.09644136e+00  8.59717060e-01  1.52020966e-02  1.02886255e+00\n",
      "  5.62921314e-01 -2.63414855e+00  1.31085076e-01 -3.78759571e-01\n",
      " -2.41719650e+00  1.31694982e+00 -1.95262829e+00  1.17527655e-01\n",
      " -1.64747183e+00 -3.38106990e+00  2.30527517e-01  5.10626239e-01\n",
      " -5.03868215e-01 -4.62990381e-01 -9.46935830e-01  6.93283839e-01\n",
      "  4.45241041e+00 -2.06040064e-01 -4.80058878e+00 -1.11506199e+00\n",
      " -2.02402168e-01  1.53045392e-01  9.78124116e-02  3.96236491e+00\n",
      "  2.62075299e+00  6.39308550e-01  2.71530833e-01  9.45816527e-01\n",
      " -2.49648009e-01  6.93632985e-01  2.24129949e+00 -2.53442858e+00\n",
      "  5.94727489e-01 -1.89288800e-01  1.32107376e+00 -1.46601109e+00\n",
      "  7.60441285e-01  9.91679434e-01  7.36069086e-02 -3.35286425e-01\n",
      " -1.13704182e+00 -5.62450729e-01  6.38083224e-01  3.72973978e+00\n",
      " -3.45184929e-01 -1.13910593e+00 -7.64010915e-01  2.59333388e-01\n",
      " -5.76340181e-01  1.71483460e+00 -2.99095023e-01  9.54838055e-01\n",
      "  1.41317343e+00 -1.29029905e+00  2.11074027e+00  1.01321906e-01\n",
      "  1.36911093e+00 -8.46227552e-02 -1.73875313e-01  2.87237128e+00\n",
      "  2.44068578e-01 -8.81627821e-01 -2.66987522e+00 -3.37857679e-01\n",
      "  2.61349516e-01 -1.95125549e-01  8.37731921e-01 -3.88148809e-01\n",
      "  1.07563827e+00 -2.42320974e-01 -1.34440495e-01  6.85419109e-01\n",
      "  2.88296381e-01  1.12200164e+00 -3.34749235e+00  1.21023288e+00\n",
      "  1.13063932e+00 -2.42626056e+00  1.27599723e+00  5.30872624e-01\n",
      " -1.30312066e-01  2.14476023e-01 -5.27024179e-02 -1.09811925e+00\n",
      "  1.03671006e-01 -1.33617400e+00 -3.33272308e-01 -1.23589477e+00\n",
      " -3.15067781e+00  3.36215807e+00  5.45642080e-01  1.16860032e-01\n",
      "  1.41747727e+00  1.13438563e+00 -3.00437546e-01 -4.95251411e-01\n",
      " -4.56779747e-01  1.62080003e+00 -3.82344552e-01  7.20790987e-01\n",
      "  7.67645685e-01 -1.70019049e+00 -5.79427012e-02  6.11328183e-02\n",
      " -2.33514847e+00  2.81635683e-03  9.40070524e-01  8.13764121e-03\n",
      " -2.19241992e-01 -1.12783429e-01 -1.44125938e-01  3.34413265e-01\n",
      "  3.15855432e-01  3.63054967e-01 -1.50950034e-02 -8.90260759e-01]\n",
      "------counter :13-----------\n",
      "(2800, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.08021458e-01 -1.12812282e+00  5.35868096e-01 -7.23057968e-02\n",
      "  4.31037995e-01 -6.08731366e-01  2.78982700e-01 -1.53927699e-01\n",
      " -4.09164933e+00 -6.39583605e-01 -4.91140465e-01  3.93734111e-01\n",
      " -1.27455425e+00  1.63142124e+00  2.64020157e-01  7.03750633e-01\n",
      " -2.07491862e+00  1.63524147e+00 -5.38259667e-01  3.83054184e+00\n",
      " -1.18587930e+00  2.49958713e-01  4.24879354e-01  4.74221655e-01\n",
      "  7.67317509e-02 -2.83746870e-01  7.86666481e-02  1.50400011e+00\n",
      "  7.94640140e-01  5.43473032e-01  3.91602179e-01 -3.34660357e+00\n",
      "  2.57734045e-01 -5.99391002e-01  8.87949865e-01  2.47820340e-01\n",
      "  3.19022231e-03 -8.80792270e-01 -7.55278107e-01  2.60218142e+00\n",
      "  5.05834841e-02 -5.76723117e-01 -5.44233626e+00 -7.02008289e-01\n",
      " -5.02676756e-01 -2.02956228e-01 -5.45838511e-01  5.07673837e-01\n",
      "  3.30725536e+00 -9.77235055e-01  4.85323745e-01  4.25239789e-01\n",
      " -9.23654507e-01 -5.85752532e-01  8.03169568e-01 -4.55485454e-01\n",
      "  2.54492140e-01 -1.31281156e+00 -5.97933624e-01  2.95894636e-01\n",
      " -9.42226416e-02 -2.09155532e-01 -2.54506623e+00  8.60819360e-01\n",
      " -3.64091429e+00 -3.23658871e-01  6.84021085e-01  2.17852068e-01\n",
      " -8.71350582e-01 -1.92369953e-01 -3.71117454e+00  9.52762949e-01\n",
      " -1.09436910e+00 -1.16686068e-01  1.67526322e+00 -5.65735801e-01\n",
      " -3.95510531e-01 -1.37185367e+00  5.83576492e-01  6.38327165e-01\n",
      " -2.41055039e-01  4.64929073e-01  4.41634136e+00  4.55464891e-01\n",
      " -2.46748376e-01  7.45454814e-01  6.03515328e-02  6.50311927e-02\n",
      " -1.27248642e+00  2.33505012e+00 -7.43281973e-01 -6.26489000e-01\n",
      " -4.19114855e+00  3.76101916e-01 -1.05488295e+00  9.94195538e-01\n",
      " -8.84314024e-02 -1.03279841e+00 -9.80681271e-01  5.63049134e-01\n",
      "  1.07112420e+00 -9.22319083e-01 -3.75623696e+00  2.23386609e+00\n",
      " -6.80256668e-01 -5.85106667e-01 -5.13213474e-01  6.26246526e+00\n",
      " -4.08628595e+00 -1.00781127e-01 -2.85744577e-01  7.91158641e-01\n",
      " -1.90711355e-02  9.78584801e-01  1.56526603e+00  1.24830280e+00\n",
      "  8.81187213e-01 -8.77801397e-02 -1.14497271e-01  1.42188363e+00\n",
      "  3.34102358e-01  4.60342036e-01 -7.69274491e-01 -2.59960929e-01\n",
      " -1.06183607e-02  5.29673477e-01  2.81971740e-01  7.82798363e-01\n",
      " -5.07883211e-01 -2.31219707e-01 -3.94959843e-01  4.89060037e-01\n",
      "  2.08451253e-01 -8.98021303e-01 -5.65883477e-01  4.77861898e-01\n",
      "  1.20855894e+00 -6.65581628e-01  1.99424296e+00  2.09112999e-01\n",
      "  7.50111161e-01  8.63166716e-02  4.81747826e-01  2.41021235e+00\n",
      "  5.05099387e-01 -1.03835287e+00 -7.33438709e-01 -4.10716705e-01\n",
      " -5.18312825e-01  1.80114968e+00 -5.19947816e-01 -4.60919006e-01\n",
      " -6.35882796e-01 -7.50156890e-01 -2.65709464e-01 -5.52374105e-02\n",
      " -6.69695445e-01  2.08421566e+00  8.41682666e-01  6.16616209e-01\n",
      "  1.26596688e+00 -5.74667468e-02 -3.34067830e+00 -1.61185721e-01\n",
      "  6.08418990e-01 -8.29607659e-02 -4.51510043e-01  1.90910429e+00\n",
      " -1.79146892e-01  3.21614734e+00  1.24652709e-01  2.40594342e-02\n",
      " -1.11838764e+00  4.02729631e+00  8.28517541e-01 -1.66581276e-01\n",
      "  2.78959111e-01  2.16478552e+00 -3.19619709e-01 -6.70897287e-01\n",
      " -1.46747581e+00  5.32594357e-01 -5.43836413e-01  1.04359524e+00\n",
      " -9.07716370e-01  1.08274716e+00 -1.51171385e-01 -4.04561539e-01\n",
      " -9.84057191e-01 -4.93958313e-01 -4.34093782e-01  2.68341755e-01\n",
      "  7.28637019e-01 -4.63328806e-01 -5.57042702e-01  6.11445796e-01\n",
      "  6.54409779e-01 -1.25078118e+00 -3.98735978e-01  4.99313611e-02]\n",
      "------counter :14-----------\n",
      "(3000, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.49386539e-01  2.25957116e+00  3.08604389e-01 -4.31656554e-02\n",
      "  2.51898697e-01 -8.02242610e-01  1.55812358e+00  2.72861360e+00\n",
      " -3.46456007e+00 -9.28569582e-01 -4.35502976e-01  1.51939030e+00\n",
      " -6.27942221e-01  4.81332259e-01  5.62861222e-01  4.73913855e-02\n",
      " -2.13698743e+00  2.69264404e+00 -8.96462914e-01  3.75709386e+00\n",
      "  2.30414562e-02  3.66634794e-02  3.59970155e-01  3.32981532e-01\n",
      " -1.65868077e-01  6.74473073e-01  1.89027440e-01  1.15833338e-01\n",
      "  6.97136550e-01  2.33985709e-01  1.96440931e-03 -2.97832341e+00\n",
      "  5.35014401e-01 -7.26767746e-01  1.40198597e+00  6.51402998e-02\n",
      "  3.57881384e-01 -1.26780680e+00 -5.97969470e-01  2.03315541e+00\n",
      " -4.39897272e-01 -3.56226633e-01  6.29346960e+00 -1.52696519e-01\n",
      " -1.38929170e+00  1.05941435e-01 -4.36736167e-01 -4.46601142e-01\n",
      "  8.03573576e-02 -8.96031412e-01 -2.66194577e-01 -2.69565788e-01\n",
      " -1.14264051e+00 -6.90373379e-01 -1.06363782e+00 -6.56110317e-01\n",
      " -6.74708360e-01 -9.48219753e-01 -4.61551153e-01  1.04738845e+00\n",
      " -2.03898069e-01 -6.55409723e-02 -2.19367757e+00  5.82680178e-01\n",
      " -3.60820823e+00 -6.48053684e-01  7.61837164e-01 -6.40940350e-01\n",
      " -5.65253183e-01  7.25156926e-02 -2.30405795e+00  1.05512421e+00\n",
      "  9.54364304e-01 -2.42661984e-01  2.66594924e+00 -1.54869168e+00\n",
      " -4.67867374e-01 -7.14428161e-01  1.05772360e+00  7.37319891e-01\n",
      " -2.81182254e-01 -1.27709765e-01  4.33595468e+00  3.32225631e-01\n",
      "  1.94818954e-01 -3.98223602e+00  1.83246093e+00  4.94914467e-01\n",
      " -1.18554895e+00  1.48951094e+00  7.63645370e-01 -7.77959637e-01\n",
      " -4.66902412e-01  7.58467150e-01 -8.44764087e-01  9.35622009e-01\n",
      " -5.26616845e-01 -4.01641394e-01 -4.96442032e-01  4.46458518e-01\n",
      " -6.98729913e-02 -7.61202634e-01 -1.09550757e+00  6.26481212e-01\n",
      " -6.56903263e-01 -5.50429284e-01  2.43128492e-01  2.58051307e+00\n",
      " -8.50198429e-01 -2.69064348e-03 -5.03886418e-03  7.53227879e-01\n",
      " -1.35838881e-01  1.35181938e+00  1.38647430e+00 -7.34328030e-01\n",
      "  2.22940395e-01 -5.76193777e-01 -2.10693302e-01  9.74880189e-01\n",
      "  2.36546897e-01  6.40845682e-01 -4.23773884e-01 -4.47249027e-01\n",
      " -8.11857211e-01  1.49883996e+00 -2.63296319e-01  1.20622858e+00\n",
      " -4.50803286e-01  3.49477786e-01 -6.47177172e-01  5.75278558e-01\n",
      " -1.50215572e+00 -1.29903541e+00 -6.01525951e-01  1.05820761e-01\n",
      "  1.29169752e+00 -3.16871047e-01 -1.31775266e+00 -1.01710851e+00\n",
      "  6.21795033e-01 -1.14122147e-01  1.64107042e+00  2.26572536e+00\n",
      " -6.46163407e-02 -1.14401709e+00  1.28332993e+00 -3.82693743e-01\n",
      " -4.86061372e-01 -4.65957638e-01  4.55195780e-01 -7.76250220e-01\n",
      " -1.49525451e+00 -1.52620999e+00 -3.28212577e-01  2.34286361e-02\n",
      " -7.80458987e-01  1.51537258e+00 -1.19358519e+00  7.56748720e-02\n",
      "  1.25315353e+00 -1.26253066e-01 -1.01775547e+00  2.35787630e-01\n",
      "  4.89553728e-01  8.21816557e-02 -6.05897264e-01  9.31606265e-02\n",
      " -1.95797917e-01 -5.40555193e+00 -1.03090033e-01 -5.29346076e-01\n",
      " -1.17698797e+00  4.08962742e+00  1.11764406e+00 -2.98078883e-01\n",
      " -1.44500719e-03  4.03042648e+00  3.54103470e-02 -4.74739965e-01\n",
      " -1.61525305e+00 -6.37880053e-02 -7.58647926e-01 -3.28131868e-02\n",
      "  9.16288617e-01  1.12329216e+00 -2.62043394e-01 -1.12055183e-03\n",
      " -9.64160405e-01 -5.21460973e-01 -1.30000236e-01  4.31781727e-02\n",
      "  8.41159219e-01  1.32329951e-01 -7.24796523e-01  7.15611237e-01\n",
      "  5.50986142e-01 -2.23051780e-01 -6.33427682e-01 -4.23341548e-01]\n",
      "------counter :15-----------\n",
      "(3200, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.71219560e-01  1.29785011e+00  4.01236893e-01 -4.04615873e-01\n",
      "  4.66654188e-01 -8.83770527e-01  9.23421031e-02 -3.16337351e+00\n",
      " -3.39007018e-01  6.36736046e-02 -4.52098547e-01  3.93753131e-03\n",
      " -3.15402415e-01  9.98734874e-01  3.14221199e-01  2.45294748e-01\n",
      " -1.66720475e+00 -9.76954390e-01 -2.89236701e-01  3.63776340e+00\n",
      " -1.37415238e+00  5.20812786e-01  1.25447174e+00  7.03814897e-01\n",
      " -4.79057506e-01 -1.45895514e+00 -3.90402860e-01  4.00448892e-01\n",
      "  2.68538990e-01 -3.22043632e-01  1.12004883e-01 -2.94920379e+00\n",
      "  1.84580745e-01 -1.37678203e-01  8.63353742e-01  9.41044103e-02\n",
      "  1.15993038e-03 -5.87232758e-01 -6.71611553e-01 -2.18307743e-01\n",
      "  8.03210635e-01  4.66119978e-01  3.03339937e+00 -7.82986669e-01\n",
      "  1.24747154e+00  3.09986026e-01 -5.21162849e-01  6.49304308e-01\n",
      "  1.35412616e+00 -1.94112903e-01  1.05641489e+00  2.17702915e-02\n",
      " -9.90790251e-01  5.44572941e-01  3.14889117e-01 -1.62039130e-01\n",
      "  8.57306339e-02 -1.83723204e+00 -2.88530981e-01  6.33166450e-01\n",
      " -1.75096937e-01  1.30678749e-01 -3.00229317e+00  7.82647903e-01\n",
      " -1.88211153e+00 -4.20498530e-01  8.66057711e-01 -1.47929123e-02\n",
      "  6.92509423e-01  3.18941932e-02 -2.10386937e+00  9.76296216e-01\n",
      " -1.71081448e-01 -1.77198557e-01 -4.58562452e+00 -7.96152126e-01\n",
      " -7.86915810e-02 -1.06653572e+00  7.56656915e-01  1.21259752e+00\n",
      " -5.08322145e-01  3.74067059e-01  2.82706619e+00  1.86653456e-01\n",
      "  3.14498456e-01 -3.74242915e+00  2.44075504e+00 -1.97047477e+00\n",
      "  7.34075474e-01  1.09956595e+00 -3.90712783e-02 -9.02912939e-01\n",
      " -6.01805917e-01  2.00678744e+00  1.26409693e+00  1.31242668e+00\n",
      " -2.48108264e-01 -9.88629761e-02  1.45072306e+00  3.24819386e-01\n",
      "  3.96098091e+00 -1.01599820e+00 -3.49044757e+00  6.66878872e-01\n",
      " -3.10081542e-01  4.96243145e-01 -2.55214489e-01  4.26117214e+00\n",
      " -2.11313552e+00  1.72149594e-01  9.25042850e-02  6.80819055e-01\n",
      "  5.27314598e-02 -5.10200951e-01  1.34810292e+00  3.82601673e-01\n",
      "  1.14203970e+00 -4.90750010e-01  1.62066210e+00  8.31684565e-01\n",
      "  4.85450597e-01  8.11361424e-01 -3.57254251e-01 -1.96455621e-01\n",
      "  1.04886390e+00 -4.23522663e+00  9.51989402e-02  1.46503316e+00\n",
      "  3.88556323e-01  3.41268167e-01  5.54098922e-02  6.45953949e-01\n",
      " -2.03968316e-01  1.17345749e+00 -5.01308594e-01  4.92637794e-01\n",
      " -1.62867028e+00 -6.55076984e-01 -1.85743890e+00  2.43720726e-01\n",
      "  8.40992429e-01  4.42286553e-01 -1.30171678e+00  2.50681401e+00\n",
      "  1.42987394e-02 -5.95200367e-01 -7.22176577e-01  4.57360396e-02\n",
      " -4.73142107e-01 -8.88007541e-01  5.50598573e-01 -3.53504323e-01\n",
      "  1.30080282e+00 -9.84098035e-01 -3.49534491e-01  3.78261691e-01\n",
      " -6.10039853e-01 -3.67189042e+00 -5.04201689e-01 -2.03934814e-01\n",
      "  1.56330807e+00 -3.06366944e-01 -1.52418645e+00 -2.12470318e-01\n",
      "  6.03717219e-01  9.75532061e-01 -4.06003869e-01  9.72450670e-01\n",
      "  2.64013713e-01 -1.41099703e+00  2.11919045e-02  6.77666558e-01\n",
      " -1.35719160e+00  2.08919135e+00  1.18524067e+00  1.38128499e-01\n",
      "  1.10652722e-01  3.84347754e+00  5.56652747e-01 -3.58029164e-01\n",
      " -6.17354820e-01 -1.35505439e+00 -4.16524873e-01 -3.29193372e-01\n",
      "  7.09527611e-01 -2.10827931e+00 -6.43956811e-02 -1.11392621e-01\n",
      " -4.93182109e-01  2.34244836e-02 -2.82991998e-01 -5.30010113e-01\n",
      "  7.79643376e-01  1.32430602e-01 -6.68449041e-01  8.21437849e-01\n",
      "  3.52886149e-01 -8.41750419e-01 -2.86840438e-01 -3.12226247e-01]\n",
      "------counter :16-----------\n",
      "(3400, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.75380761e-01 -3.39609118e+00 -1.38433230e+00  1.09830223e+00\n",
      "  7.73298621e-01 -5.26854107e-01  1.59276475e+00  1.01113744e+00\n",
      " -1.71289773e+00  4.11474422e-01 -8.60234774e-01 -3.59304452e-01\n",
      " -6.44622707e-01  8.60998774e-01 -1.50334147e+00  5.61283486e-01\n",
      "  1.31996588e+00  2.05661345e+00 -1.43333020e+00  3.33499040e+00\n",
      "  1.10102274e+00  2.16430884e-01  1.52546466e+00  5.59210626e-01\n",
      "  6.18391175e-01  6.71903334e-02 -1.01245141e+00  1.46716217e+00\n",
      " -2.97119411e-01  5.90761837e-01  5.97882812e-01 -3.88710934e+00\n",
      " -2.79048762e-01  6.18640166e-01 -2.28278432e+00 -3.10616478e-01\n",
      " -2.10419277e-01 -5.18154990e-02 -1.48361646e+00 -3.95990708e-01\n",
      "  4.71029680e-01  3.00262389e-01  4.11718529e+00 -3.34103704e-01\n",
      "  5.56616414e-02 -5.73650207e-01  1.21996290e+00  3.11175668e-02\n",
      "  1.25348020e-01 -8.46366278e-01  9.43955894e-01 -6.54772219e-01\n",
      " -3.60079229e-01 -3.64374080e-02 -3.67373307e-01 -5.79923418e-01\n",
      "  3.19990211e-01 -3.32647302e+00 -2.33252375e-01 -3.21374115e-01\n",
      "  9.84359925e-01 -1.19901189e+00 -1.54210777e+00  7.30861521e-01\n",
      " -1.08481142e-01 -1.21919132e+00 -3.11705523e-01  2.67995719e-01\n",
      " -3.22338043e-01 -5.39376677e-01 -2.02734309e+00  1.80898795e+00\n",
      " -1.02980655e+00 -5.19378375e-01  4.46790824e-01 -1.05120759e+00\n",
      " -4.62214893e-01  1.09809502e+00  1.04010586e+00 -1.04822061e-01\n",
      "  1.11667218e+00  1.75309276e-01  3.12125851e+00 -1.95987814e-01\n",
      " -4.95349664e-01 -6.55080600e-01  1.77193680e-01 -6.91170876e-02\n",
      "  1.93593788e+00  1.29077913e+00  1.25975141e-01  1.22601463e+00\n",
      "  3.56111455e+00  1.52039949e+00 -2.10197835e+00  6.23759051e-01\n",
      " -1.26979282e-02 -2.75082828e-01 -3.13695996e-01  4.13603006e-01\n",
      "  4.35097242e+00 -1.63729994e+00 -5.27692185e-01 -6.00282478e-01\n",
      " -3.89998259e-01 -8.39256767e-01  3.50923170e-01  3.06574656e+00\n",
      " -2.15531458e+00  3.68478413e-01 -3.38262579e-02  7.17785195e-01\n",
      " -4.75883042e-01 -7.65823371e-01  2.15121462e+00 -1.72482472e+00\n",
      " -6.24456547e-01 -1.87863196e+00  1.15016409e+00  5.94122959e-01\n",
      " -4.13345363e-01  2.24726712e-01 -3.03166834e-01 -2.36298875e-01\n",
      "  5.09378913e-01 -1.21829892e+00 -4.00846679e-03  4.65202037e-01\n",
      "  9.74874827e-03 -3.16739834e-02 -3.05985387e-01  6.13492606e-01\n",
      " -5.40221186e-01 -1.20556457e+00 -1.51420479e+00  2.20033994e+00\n",
      " -5.38511983e-02 -1.06776990e-01  3.06893248e+00 -1.27607062e-01\n",
      "  4.63598181e-01  8.56563192e-01 -2.37513291e+00  1.32950808e+00\n",
      " -1.56803716e-01  8.35989146e-01  1.94971933e+00  4.95728151e-02\n",
      " -8.04947631e-01  1.82180241e-01  3.57701593e-01 -6.25644199e-01\n",
      " -1.59856228e+00 -7.78701113e-01  6.57530427e-01 -3.64690212e-01\n",
      " -1.43527541e+00  1.55688738e+00 -1.65515732e+00 -1.70273408e-02\n",
      "  1.14547968e+00 -6.36041147e-01 -9.57484193e-01 -2.03501913e+00\n",
      "  6.74087476e-01 -3.36360416e-01 -8.11510081e-01 -4.76145757e-01\n",
      " -3.46053478e-01  2.28653332e+00  1.33648044e-01 -2.17420430e-01\n",
      " -2.81174176e-01  1.72637442e-01  1.36607344e+00 -1.40822961e-01\n",
      "  2.80236375e-01 -5.76777255e+00 -2.87594932e-01 -1.22460084e+00\n",
      "  3.78778177e-01  4.31398613e-01 -1.20774219e+00  3.46250131e-01\n",
      "  8.21127857e-01  1.32879952e+00  8.00128866e-02  1.29699191e-01\n",
      " -5.57416655e-01  1.37848910e-01 -1.80288708e-01 -4.35568186e-01\n",
      " -1.65431034e-01 -6.20276848e-01  1.06163420e-02  4.59967065e-01\n",
      "  9.39232879e-01  3.92635933e-01 -5.71439089e-01 -4.87158655e-02]\n",
      "------counter :17-----------\n",
      "(3600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99250537 -2.69627493 -0.19679364  0.05007045  0.3921274   0.3034268\n",
      " -0.23082847  2.19395271 -0.26077232  0.16269443 -0.486581    0.02723743\n",
      " -0.49788018  0.70043023  0.19062713 -0.09133723 -4.52423765  2.94440461\n",
      " -1.24296216  3.0512821  -0.07841374  0.25635784  0.13914103  0.12940624\n",
      " -0.21285067 -0.38115138 -1.27467473 -0.29196303  0.73005681 -0.31831621\n",
      "  0.39943291 -4.14168545  0.49025559 -1.40825681  0.82342517 -0.08799\n",
      " -0.05705454 -1.07939055 -1.05246357 -0.02435422  0.71490088 -0.71622484\n",
      "  4.29217378  1.45137691 -1.46803178 -1.14484484  0.22038796  0.06046598\n",
      "  1.09296687 -0.31589931  1.12539417 -0.69655509 -1.53646957 -0.41733747\n",
      "  1.08041948 -0.69242571  0.19696536 -1.10854108 -1.01175608  0.22746939\n",
      " -0.0089325   2.49148713  4.10334197  0.90966308 -1.45168282 -1.07707371\n",
      " -1.55269052 -0.65984886  0.13256332  0.31459067 -3.45362091  1.17055613\n",
      "  0.25690492 -0.06141483 -1.34040131  1.31884712 -0.44166635 -0.54052029\n",
      "  1.01951118 -0.07308084  1.93292037  0.48319108  1.78616137 -0.61437449\n",
      " -0.02899497 -1.3367663   2.48930908 -0.89642732 -0.37540093  0.50220691\n",
      "  0.4895358  -0.76341824  5.21737175  1.83518026 -0.80878863  0.33308018\n",
      " -0.58039027 -0.80302916 -0.67504362 -0.75974244  4.32225593 -0.04991394\n",
      "  2.22219611 -0.53878193 -0.80352754 -0.88406946  0.50707028  3.17419853\n",
      " -2.0526891  -0.44997722  0.186278    0.05118422 -0.97358185  1.10124418\n",
      "  0.16693577  0.40355022 -0.42856029 -1.95778603  2.27260486  1.06364499\n",
      "  0.30967483 -0.14906205 -0.28530822  0.01478928  0.01045995 -0.53050333\n",
      " -0.69039159  1.41822518 -0.24252768 -0.51367668 -0.69104819  0.3009189\n",
      " -1.44450794  0.795498   -1.55386681  1.65856251  0.46928649 -0.23740975\n",
      "  0.1196562   0.47798654  0.48230111 -0.00922766 -3.05089867  1.46681444\n",
      " -0.25958825 -0.09079386  1.92377402  0.97634804 -0.56942083 -0.32138526\n",
      "  0.37390942 -0.95526141 -1.80784752 -0.99151212  0.49146847 -0.70446985\n",
      " -0.80874113 -1.80920126 -1.23253642  0.36762081  1.05754569 -1.05092058\n",
      " -5.57881976 -0.15162042  0.46258978 -0.48138579 -1.20724304  0.49577876\n",
      " -0.63632014 -0.22882631  0.11017009  0.14240075 -0.40948983  1.18540963\n",
      "  0.98900351 -0.53597233 -0.21198588  3.27397922 -0.28619165 -1.55349415\n",
      "  0.67556088  2.2254214  -0.5921007   0.06767072  1.56903923  1.696379\n",
      " -0.26925765 -0.52069083 -0.4537681  -0.1699779   0.08150738 -0.61810451\n",
      "  1.02595918 -0.90133237  0.02297907  0.22068739  0.74745038 -0.57811179\n",
      " -0.93148639  0.08404556]\n",
      "------counter :18-----------\n",
      "(3800, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32969241 -1.4722198  -2.16163424 -0.79701193 -0.32463791  0.37952073\n",
      " -0.4124087   0.20385785 -6.06496965 -0.6211658  -1.07565087  1.00975863\n",
      " -0.41956696  0.60793005  0.11925734  0.22269656 -2.0271105   2.36742406\n",
      " -0.4018895   3.93549839  0.45187783  0.19077691  0.1307885  -0.08129171\n",
      " -0.61649894 -0.04512543 -1.19755176  0.32457844 -1.0356267   0.52556773\n",
      " -0.55448042 -3.66936439 -0.51891773  2.43138987 -0.61524961  0.44830954\n",
      " -0.65685435 -0.92194132 -0.98623566  2.05322468 -1.28931088 -0.76859582\n",
      "  4.81105585  1.3413776  -0.62127139 -1.05383448 -0.06914727  1.63094054\n",
      " -2.90713513 -1.11297097  0.56025572 -1.48618716 -0.49565012  0.68884803\n",
      " -3.11497821 -0.56094406  0.39313186  2.31970394 -0.5427546  -0.31353739\n",
      " -0.11825649  1.91282298  5.94305669  0.83772481 -2.57044952 -1.08280177\n",
      " -0.33251964 -0.50953544 -1.04533285  0.75056537 -2.75517607  1.90007051\n",
      " -1.24272443  0.51639158 -0.80225391  0.24146539 -0.52883732  0.24172499\n",
      " -0.12674199  0.33894603  1.2126663   0.20504915  1.37488358 -0.45546001\n",
      " -0.58161709  1.36831247  2.05964966  0.09026506  0.2162664  -1.88021452\n",
      "  0.09316064  0.444808    3.39618912  0.97062804  1.40256449  0.04492821\n",
      " -1.09826906 -1.45961054 -0.66076667  1.35749212  0.53131051 -3.41194329\n",
      "  2.96251344  2.13409297 -0.8497482  -0.86856536 -0.35213219  3.82326281\n",
      " -2.08913474 -0.47068963  0.07880691  0.12563894 -0.58472084  1.86336814\n",
      " -0.56535514  0.28210021  0.1154049  -1.94333612  3.17032753  0.52675617\n",
      " -0.27032748  0.6500621  -0.43278028 -0.21586821  0.51962677 -0.53635939\n",
      " -0.22803558  1.52250088  0.17891583 -0.90818794 -0.44847012  0.52984598\n",
      "  1.12371813  2.37809703  0.56997601 -0.86910466 -0.72947009 -1.56641937\n",
      " -1.73633849 -2.71683991  0.55812937 -0.0780044  -1.28246096  1.73070073\n",
      " -0.13748407 -0.95098704 -0.37262659 -0.29606959 -0.60078657 -1.45761743\n",
      "  0.6644828  -0.88558396  1.91860953 -0.83326881  1.08620577  0.3836864\n",
      "  0.57050268  2.66798217  0.17997562  0.43828518  0.8243539   0.70888682\n",
      "  1.09056173  0.81955607  0.5586251   0.14644874 -0.98381748  0.16743629\n",
      " -0.54325913  4.07138671  0.02719427 -0.21402224 -0.87706945 -2.04291702\n",
      "  2.12397785 -0.62945803  0.10539204  4.39286792 -0.38451866 -1.04257331\n",
      " -0.24108978 -0.60278986 -1.3506993  -0.20427956 -0.36105741  0.8872758\n",
      "  0.9402287  -0.06769853 -1.28902793 -2.08311245 -0.3359367  -0.74914674\n",
      " -0.80074847 -1.05106493 -0.28928354  0.72190681 -0.14388578  0.63162481\n",
      " -0.78216448 -1.21769308]\n",
      "------counter :19-----------\n",
      "(4000, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.78562907e-01 -2.32981132e+00 -1.02923288e+00  2.68336840e-01\n",
      " -3.79826068e-01  2.49617935e+00  1.24009276e+00 -1.44004371e+00\n",
      " -4.57392139e+00  6.98421561e-01 -6.22470737e-01 -4.53589157e-01\n",
      "  6.58905444e-01 -3.49843033e-02 -1.23500916e+00 -4.81439390e-01\n",
      "  7.18999442e-01  1.40677704e+00 -7.29521825e-01  4.37245686e+00\n",
      " -1.39239388e+00  6.29792892e-01  3.88519872e-01  2.16638369e-01\n",
      " -1.61705180e-01  1.60083909e+00  3.18604288e-01  5.52076855e-01\n",
      " -1.60338681e-01 -1.19730414e-02  1.01230511e+00 -3.62169860e+00\n",
      " -4.58213550e-01  1.07016624e+00 -1.27083964e+00  5.55990192e-02\n",
      "  6.06619746e-01  7.06242114e-01 -3.56466060e-01  4.61889749e-01\n",
      " -7.85922938e-01  4.32999517e-01  2.24357372e+00  2.18320228e+00\n",
      " -6.59826018e-01 -8.04518415e-01  7.32995640e-01  1.28513419e+00\n",
      " -7.05643484e-01 -1.02430757e+00  1.11995383e-01 -9.40577864e-01\n",
      " -4.87336687e+00  4.92173833e-01  2.74375007e+00 -5.68580482e-01\n",
      " -6.00563332e-01  9.38249355e-02 -1.32319156e+00 -1.61493007e+00\n",
      " -5.12153722e-01  1.51459974e+00 -1.03167168e+00  6.52380458e-01\n",
      " -2.59681708e+00 -1.62975573e+00 -5.32608448e-02 -1.16989732e+00\n",
      " -6.64426688e-01  5.07879358e-01 -3.13087476e+00  4.42032360e-01\n",
      "  3.60873379e-02  1.90681599e-01 -5.72283539e+00 -1.53397020e-01\n",
      " -1.23374071e+00 -1.01060943e+00  4.89053914e-01  2.43245175e-01\n",
      "  1.08870606e+00  8.00831536e-01  1.15964777e+00 -2.47446966e-01\n",
      "  2.28656025e-01  1.02870147e+00  1.98828559e+00  6.62837264e-02\n",
      " -8.63312285e-01  2.91550331e+00 -2.17273397e-01 -1.23304532e+00\n",
      "  3.56355633e+00 -8.59759510e-02  5.41144989e+00  4.14677626e-03\n",
      " -8.86986759e-02 -8.30923345e-01 -4.54949213e-01  3.19987275e-01\n",
      " -9.26063665e-01  6.03483333e+00  3.98006705e-01  2.46454172e-01\n",
      " -7.96372670e-03 -5.69564545e-01 -2.96921303e-01 -1.23509170e+00\n",
      " -2.64643493e+00 -6.28039786e-01  5.28508194e-01  1.44266703e-01\n",
      " -5.12610974e-01  4.55281980e-01  1.74208570e+00 -1.49216045e+00\n",
      " -1.93806575e-01 -3.01424091e-01  4.06980211e+00  4.08532461e-01\n",
      " -3.94502431e-02  1.36951332e-01 -1.37842043e+00  2.46368823e-02\n",
      "  1.08283676e-01 -1.35275482e+00 -6.12920463e-01 -1.34576497e+00\n",
      " -5.40598697e-01 -6.23394456e-01 -7.20030247e-01  6.08998284e-01\n",
      "  1.36517738e-01 -1.19654555e+00  7.41997121e-01 -3.91934721e-01\n",
      " -1.31444277e+00 -7.37736538e-02  7.47265008e-01  2.02766764e-01\n",
      "  4.51403315e-01  2.33231827e-01  5.72378609e-01  2.60057075e+00\n",
      "  9.37046588e-01  8.40661797e-01  8.27529271e-01  1.52602749e-01\n",
      " -2.56643449e-01 -3.20431704e-01  8.79944177e-01 -9.74613914e-01\n",
      "  4.67878698e+00 -9.47432161e-01 -9.78662766e-02 -7.91243758e-02\n",
      "  5.63303535e-01  3.69279023e+00  4.18391197e-02  6.49301598e-01\n",
      "  1.15419443e+00 -9.17590291e-02 -8.91368578e-01 -1.29945499e+00\n",
      " -1.76497524e-02  1.88501862e-01 -5.87999655e-01  1.32972763e+00\n",
      " -4.38869357e-01 -2.24923973e+00 -4.09646864e-01 -8.63896563e-02\n",
      " -3.16686048e-01 -1.78876496e+00  1.56428169e+00  3.81202393e-01\n",
      " -3.87808337e-01  8.90342512e-01 -3.65448912e-01 -9.50433223e-01\n",
      " -1.46999859e+00  2.52696995e+00 -9.00731191e-01 -3.44183020e-02\n",
      "  2.12642396e+00 -4.35989742e-01  2.72611931e-01 -3.48794535e-01\n",
      " -9.88692047e-01 -1.32542925e+00 -1.57380957e-01 -5.78138191e-01\n",
      " -1.02164641e+00 -7.74538132e-01 -3.72965976e-01  1.02106500e+00\n",
      " -6.33550287e-02  3.96355882e-01 -3.91185949e-01 -5.83540213e-01]\n",
      "------counter :20-----------\n",
      "(4200, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.61877036e-01 -1.26836954e+00  3.49006302e-01  1.63546015e-02\n",
      " -9.28105780e-01  4.75083426e-02 -1.22946770e+00 -2.54195721e-01\n",
      "  1.94542931e+00  1.68409460e-01 -3.36772429e-01 -5.68844082e-01\n",
      "  5.47315110e-02  3.61102845e-01 -1.44855457e+00  1.07086110e+00\n",
      "  3.12036514e+00  1.22044799e+00 -1.07259802e-01  3.74264180e+00\n",
      " -1.26486951e+00 -3.50027083e-01  2.50948488e-01  4.76734855e-01\n",
      " -3.28261214e-01  3.21893646e-01  4.62882668e-01  6.15424658e-01\n",
      "  1.42021742e+00  5.37764822e-01  5.75871041e-01 -2.49279598e+00\n",
      "  1.46421316e-01  1.24713764e+00  6.33329611e-01 -2.86179207e-02\n",
      "  3.51489094e-01  7.84742266e-01 -6.30063441e-01  3.20603073e-01\n",
      " -4.67063070e-01  4.07074628e-01  1.69616723e+00  7.22615538e-01\n",
      "  1.02587073e-01 -4.87234443e-01 -4.22492489e-01  9.26320022e-01\n",
      " -1.16548391e+00 -7.61280375e-01  6.11394372e-01 -6.93210708e-01\n",
      "  1.29293870e-03  2.00735685e-01  3.28425249e-02 -7.79923964e-01\n",
      " -5.27971595e-01 -1.03257546e+00  8.45433678e-01 -6.94987559e-01\n",
      "  5.16757067e-02  9.97499855e-01 -2.11750921e+00  1.10508023e+00\n",
      "  6.60209402e+00 -4.66100772e-01 -2.69527630e-01 -5.69179534e-01\n",
      " -5.30877191e-01  5.23632643e-01 -2.89593587e+00  2.45758067e+00\n",
      "  8.96641366e-01 -1.86978862e-01 -4.12977460e+00 -7.23942295e-01\n",
      "  1.51248664e-01  1.43408673e+00  9.60975818e-01  6.03103837e-01\n",
      " -2.39711851e+00  7.25746719e-02  9.35237429e-01 -4.90838175e-01\n",
      " -7.61369232e-02  3.29501562e-01  1.66278198e+00  9.46877109e-01\n",
      " -9.07778377e-01  6.48824339e-01  1.19196953e-01 -8.91231581e-01\n",
      "  9.97582397e-01  2.56701613e+00 -1.70772579e+00  4.21572715e-01\n",
      " -6.29537063e-01 -6.46541857e-01 -3.88666929e-01  4.71222842e-01\n",
      " -1.58136627e+00 -6.09268269e+00  1.43701124e+00 -3.26654669e-01\n",
      "  3.34772339e-01 -4.47514244e-01 -5.36745334e-01  2.77347058e+00\n",
      "  1.33429835e+00 -3.73093067e-01  1.84904105e-01  9.15384731e-01\n",
      " -1.25196190e-01  9.78386452e-01 -1.32816515e+00 -1.38830352e+00\n",
      " -9.44615750e-01  1.34628840e-01  5.86656567e+00 -1.90847308e+00\n",
      "  3.33996385e-02  5.21001148e-01 -9.91461091e-03 -9.55610375e-02\n",
      " -1.49301229e-01 -3.85377311e-01 -1.29555787e-01  3.80884484e+00\n",
      " -9.64826160e-01 -1.15018578e+00 -5.44342848e-01  1.86409114e+00\n",
      " -1.28984544e-02 -1.92689697e-01  2.09347046e-01 -3.72390282e-02\n",
      " -2.29136853e-01  2.03599125e-01 -1.39722241e+00 -6.03290874e-01\n",
      "  3.73582822e-01 -1.76193768e-01 -7.94421164e-01  2.47191428e+00\n",
      "  9.61847197e-02  2.81834332e-01  4.65719125e-01  8.62965939e-01\n",
      " -2.26591743e-01 -1.27143144e+00  1.87015821e-01 -6.70376240e-01\n",
      " -2.10857763e+00 -9.95208396e-01 -8.92283859e-02  2.41366810e-01\n",
      "  4.99771593e-01  1.16211983e+00 -1.61602640e+00  1.41510720e-01\n",
      "  1.19430866e+00 -2.40320008e-01 -1.09921168e+00  1.27517126e+00\n",
      " -3.03721681e-01 -5.62403172e-01  1.43377416e-01  7.05808079e-01\n",
      " -3.89859119e-02 -1.77360831e+00 -3.36429999e-01 -1.70531629e-01\n",
      "  7.33117182e-01 -1.48750373e+00  9.55845956e-01  2.26848633e-01\n",
      " -1.37268388e-01 -1.10030566e+00  1.21365393e-01 -1.06327835e+00\n",
      " -7.43172488e-01 -2.14637206e+00 -6.43512193e-01 -1.78974622e-01\n",
      "  9.38989570e-02  5.82881334e-01  6.29956595e-02 -1.87231735e-02\n",
      " -3.59306080e-01 -8.37539228e-01 -4.18469024e-01 -7.15297540e-01\n",
      " -1.26920066e+00 -7.14258364e-01 -7.03988949e-01  5.61538143e-01\n",
      " -3.68246416e-02  3.41470546e-01 -3.79331037e-01 -1.90456498e-01]\n",
      "------counter :21-----------\n",
      "(4400, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.74004300e-01  2.36605053e+00  2.97816921e-01  4.18997163e-02\n",
      " -8.05284555e-01 -8.44700865e-01 -1.66295432e+00  8.41177366e-01\n",
      " -1.34840349e+00 -8.70225748e-01 -3.71815607e-01 -5.12459412e-03\n",
      " -2.32261336e-01  4.39128203e-01 -1.45458964e+00  1.66978052e+00\n",
      " -3.46360646e+00 -4.06463850e-01 -2.62768007e-01  3.56747218e+00\n",
      "  2.76238169e-01 -1.86493445e-01 -5.01289522e-01 -2.46109067e-03\n",
      " -4.51557437e-01  4.94756290e-01  2.83181890e-01  7.85728726e-01\n",
      " -6.71513106e-02 -1.36114515e+00  3.24836248e-01 -2.50964446e+00\n",
      "  1.94792818e-01 -2.75604964e+00  4.91228036e-01 -2.56399086e-01\n",
      " -2.04927691e-01 -1.23412665e+00 -9.54953511e-01 -1.78273771e+00\n",
      " -5.36789762e-01 -7.55380996e-01 -7.32897487e-01  3.40673045e-01\n",
      " -3.00755247e-01 -9.83406962e-01  7.86819392e-01  1.69846061e-01\n",
      " -6.33565474e-01 -5.94881063e-01  2.03395071e-01 -2.55418530e-01\n",
      "  2.50631427e+00  4.88483233e-02 -1.12675387e+00 -4.53976515e-01\n",
      " -5.29269725e-01  4.77949365e-01  2.66119198e-01 -7.49113869e-01\n",
      " -1.96441106e-01  9.41557971e-01 -5.22354254e+00  6.38220771e-01\n",
      "  2.25763449e+00 -3.65277503e-01 -1.89219428e-01 -6.86085134e-01\n",
      " -6.17044725e-01  2.03624024e-01 -1.05530458e+00  2.90149044e+00\n",
      "  6.15702491e-01 -1.90265266e+00 -1.89172803e+00 -7.02810582e-01\n",
      "  3.96413213e-02  1.91788937e+00  8.13213358e-01  7.78804629e-01\n",
      "  4.85378946e-01  2.58109371e-01  9.32602947e-01 -1.95007634e-01\n",
      " -3.14739842e-01  2.08388157e-01  6.14413683e-01 -4.14894318e-01\n",
      "  6.83681617e-01  2.60875529e+00 -1.64277757e+00 -1.26962495e+00\n",
      "  8.71136448e-01  7.80821421e-01 -5.55954722e-01  1.89141803e-01\n",
      " -3.32656335e-01  1.01058374e+00 -1.06001152e-01 -3.84634502e-01\n",
      "  6.40902718e+00  7.16084010e-01  2.86585372e-01 -1.91338334e+00\n",
      "  3.25923553e-01 -5.80649120e-01 -7.02391336e-02  3.59816724e+00\n",
      "  2.35868641e+00 -5.46963325e-01  4.77923971e-02  8.21560533e-01\n",
      " -3.45037501e-01 -2.61735519e-01 -1.41799712e+00 -2.87433577e+00\n",
      " -5.73768566e-01  3.75099533e-01  5.12868606e+00  3.04234020e+00\n",
      " -6.56378031e-01  5.32028421e-01 -2.11716632e-01 -2.81152883e-01\n",
      " -7.75785921e-01 -1.35116137e+00 -3.12778666e-01  5.16386695e+00\n",
      " -8.79571715e-01 -6.70844205e-01 -7.14692682e-01  5.91551224e-01\n",
      "  1.12056464e-01 -1.86204614e+00 -8.77089537e-02 -2.34224729e-02\n",
      "  4.28241645e-01 -1.75841271e+00  2.06770740e-01 -4.84539945e-02\n",
      "  6.51145408e-01 -3.66925054e-01 -5.98886542e-01  2.56444663e+00\n",
      "  5.28764765e-02 -4.59570751e-02  2.70370786e-01  7.25336226e-01\n",
      " -4.01096401e-01 -1.74668652e-01  1.31289587e-01 -4.50102877e-01\n",
      " -6.55028154e-01 -7.97429978e-01 -2.14921853e-01  2.50219853e-01\n",
      "  6.40761020e-01  1.89953844e+00  7.75374175e-01  2.11226112e-01\n",
      "  1.15012364e+00 -3.93769979e-01 -2.44304327e+00  1.12893825e+00\n",
      " -1.74359933e-01 -4.01130340e-01 -9.33950438e-02  1.06434510e+00\n",
      " -5.80619398e-02  1.44357692e+00  2.31859154e-02  3.78086155e-02\n",
      " -8.75990853e-01  2.70677111e+00  9.58714889e-01  1.46958863e-01\n",
      "  9.85856116e-02 -2.15541131e+00 -4.15340739e-01 -1.09981731e+00\n",
      " -1.86350140e-01  2.49100014e-02 -4.81867450e-01 -7.13561364e-01\n",
      "  2.50495068e-01  7.76436166e-01  6.26752492e-02 -1.12896038e-01\n",
      "  6.11468751e-01 -4.44201469e-01 -4.76476308e-01 -7.66720505e-01\n",
      "  7.97568100e-01 -7.49920797e-01 -1.61744040e-01  5.19764344e-01\n",
      " -7.33203330e-01 -1.02968273e+00 -3.91715035e-01 -3.92565297e-01]\n",
      "------counter :22-----------\n",
      "(4600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.95170486  2.23267232  0.22913112 -0.15037405 -0.26981928  1.03545912\n",
      " -1.0072562   2.98185791 -2.78763518 -0.90504515 -0.6904101   0.02434368\n",
      "  0.82266391  1.14695562 -1.53393153  1.18062028 -0.44808616 -0.97183017\n",
      " -0.56862714  1.66048157  1.31108113 -0.3903067  -0.37229148  0.04339753\n",
      " -0.39826276  0.37132632  0.24903182  1.52771955  0.02999076  1.22746778\n",
      "  0.6714525  -2.07145277  0.49043022 -0.10508787 -0.75579923 -0.04281642\n",
      " -0.21699857 -1.7575906  -0.53247169 -1.78768053 -1.06784938 -0.21386539\n",
      " -0.28169459 -0.44467346 -0.22022089 -0.72921975  0.23521234  0.80090489\n",
      " -1.412653   -0.67876255  0.60881218 -1.53311278 -1.98425063  0.08619929\n",
      "  0.83120824 -0.20221929  0.86682291 -0.45405937  0.26302343 -0.93507335\n",
      "  0.07494918  1.05207637 -4.72489574  0.51034228  6.09101208  0.01003162\n",
      " -0.84025174  0.02225028 -0.92267701 -0.14869747  0.41446449  2.78213161\n",
      " -0.0107176  -1.45233179 -4.0803484  -0.93948234 -0.18411682  1.8167541\n",
      "  1.17905511  0.72300583 -0.61174798 -0.35603631  1.13934538  0.15238137\n",
      " -0.18334197  0.33708236  0.75202992 -2.53532714 -1.2652627   1.88774006\n",
      " -0.40451481 -0.54367547  2.33521001  1.75010691 -1.45175915 -0.17591253\n",
      " -0.88533537 -0.07513209 -0.6146269   0.44255935  0.99664725  4.46967776\n",
      "  0.79683721 -0.67017627  0.50991649 -0.92888189 -1.89348178  3.01433648\n",
      "  0.82699502 -0.56351545  0.21474522  0.89257522 -0.50775312 -0.06106884\n",
      " -1.54224629 -0.60073463  0.4512926   0.24741829  4.06034406 -0.75174648\n",
      " -0.27167945  0.59122747  0.28881438  0.51005952  1.07451181 -0.56245299\n",
      "  0.21505865  1.25619134 -0.69477949  0.59820243 -0.62368457  0.86769376\n",
      "  0.88865069 -1.67122951 -0.51388619  0.88196096 -1.87243219 -0.95209897\n",
      " -1.1014613  -1.34152438  0.78529618 -0.73200506 -0.35599496  2.83807101\n",
      "  0.080052    0.3070971   0.75065778  0.96046558 -0.50278629 -0.05451802\n",
      "  0.70215233 -0.77056048  1.92258633 -1.29577997  0.04078601  0.41772142\n",
      "  0.55270525  0.83290616 -0.25564969 -0.00793353  1.2540703  -0.24562136\n",
      " -0.86715783  0.61269729  0.16113234 -0.14594137 -0.44676583  0.43016957\n",
      "  0.14811484 -1.25160295 -0.00773437 -0.53315906 -0.13557799  2.34376548\n",
      "  1.01791927  0.38864423  0.06417323 -1.53144281 -0.19325853 -1.30820523\n",
      " -0.65093201 -0.5494997  -0.53676727  0.070626    0.17450026 -0.36856848\n",
      "  0.04903324 -0.15090318  0.52832527  0.55770052 -0.49170972 -0.8983074\n",
      "  0.32175792 -0.9456594  -0.27150294  0.789405   -0.51367085 -1.45391488\n",
      " -0.47180536 -0.80738868]\n",
      "------counter :23-----------\n",
      "(4800, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.02778542e+00  2.32867597e+00  2.46895696e-01 -8.51520958e-02\n",
      "  8.64198310e-01  8.92048688e-01 -2.73587645e+00  2.39998657e+00\n",
      " -3.26434593e+00 -4.85330917e-01 -6.11332475e-01 -9.73009239e-02\n",
      "  4.53209139e-01  1.60319792e+00 -1.84472490e+00  2.42067587e-01\n",
      "  2.28962685e+00  6.87359105e-01 -1.90763613e+00  1.85686580e+00\n",
      "  5.37158067e-01 -4.09345521e-01  5.83131904e-02 -1.51898154e-01\n",
      " -3.02492192e-01 -5.10254036e-01  3.93428253e-01 -8.99513964e-01\n",
      "  5.49549094e-01 -2.24473826e-01 -6.18964589e-03 -2.06564874e+00\n",
      "  4.93287081e-01  6.19673233e-01  3.70873563e+00  7.34740114e-02\n",
      "  4.84942426e-01 -2.57099335e-01 -8.28910958e-01 -1.22788089e+00\n",
      " -8.48786180e-01 -4.43246297e-01  1.10742474e+00 -1.47559878e+00\n",
      " -5.37442510e-01 -8.02933318e-01  1.06062272e-01  8.32154306e-01\n",
      "  1.72935920e+00 -1.04623087e+00  8.42369169e-01 -1.58298771e+00\n",
      "  1.95346942e+00 -1.54971203e-03 -7.13007349e-01 -1.31470936e-01\n",
      "  1.45892884e-01 -5.96324573e-01  4.65617257e-01 -8.24878525e-01\n",
      " -3.60006526e-01  1.30647724e+00 -3.80046571e+00  6.55772299e-01\n",
      " -1.38077799e+00  1.74545978e-01 -4.23036123e-01  1.30255607e+00\n",
      " -9.93137884e-01 -9.52577415e-01 -5.35509427e-01  3.09681581e+00\n",
      " -4.23727996e-01 -1.09237259e+00 -4.22297716e+00 -2.75712215e-01\n",
      " -7.38559485e-01  8.18528894e-01  1.63932010e+00  6.89739648e-01\n",
      " -1.07163523e+00 -3.48183448e-01  1.45277272e+00  5.76600511e-01\n",
      " -5.47249295e-02 -2.01803658e+00  2.29095644e+00 -1.50168666e+00\n",
      " -8.44719457e-01  2.25000425e+00 -3.40592768e-02 -6.87810180e-01\n",
      "  2.25260008e+00  2.01105832e+00  4.95899814e+00  4.86785647e-01\n",
      " -5.99249454e-01  2.86243617e-01 -5.55207140e-02 -7.70451390e-02\n",
      "  9.10556435e-01  4.73079558e+00 -2.97460128e+00 -2.34505202e+00\n",
      "  6.31116678e-01 -3.05985224e-01 -7.33661238e-01 -1.94988237e+00\n",
      " -8.90709769e-01 -1.29114670e-01 -3.78531443e-02  1.24455715e+00\n",
      " -4.53840199e-01  1.17365469e-01 -3.74118203e-01  6.07749914e-01\n",
      " -2.21188149e-01  2.66211767e-01  3.05792987e+00 -3.58327494e+00\n",
      " -4.48511520e-02  9.65928012e-01  5.71386530e-01 -3.28299230e-02\n",
      " -8.30754852e-01 -6.59633878e-01  1.67409465e-02 -3.76377487e+00\n",
      " -2.11299953e-01 -1.54255178e+00 -3.75702268e-01  9.05383865e-01\n",
      " -6.14491653e-01 -1.86752548e+00 -6.03237387e-01  1.42510696e+00\n",
      " -5.38696114e-01 -1.72144103e+00 -2.43487608e+00  1.00680541e+00\n",
      "  8.63934407e-01 -3.13856469e-01 -5.01742725e-01  3.40648860e+00\n",
      "  1.72378703e-01  6.69895484e-01  1.08915828e-01  1.22011869e+00\n",
      " -3.98294761e-01 -2.82762988e-01  7.64962298e-01 -4.88466431e-01\n",
      "  3.25216448e+00 -1.14323592e+00  1.89296120e-01  5.80678504e-01\n",
      "  1.10099231e+00  1.79891428e+00 -5.17718397e-01  1.38221183e-01\n",
      "  1.28732565e+00 -2.80489941e-01 -1.21898722e+00 -3.89408894e-01\n",
      "  2.99114335e-01  5.18613189e-01 -6.46727316e-01 -9.68572554e-01\n",
      " -3.58326781e-02  3.95636679e-01  3.08296121e-01 -1.68156065e-01\n",
      "  5.28035764e-01 -1.97061205e+00  1.66150818e+00  4.01114497e-01\n",
      "  7.25287624e-01 -7.54561601e-01 -4.76487006e-01 -1.40174085e+00\n",
      "  2.72155931e-01  3.25851418e+00 -1.56833348e+00  1.98656561e-01\n",
      "  9.95174647e-01  4.79418913e-01  3.30489593e-01 -2.40750411e-01\n",
      "  3.88760766e-01 -7.51836878e-01 -2.90584435e-01 -4.65021030e-01\n",
      " -3.11469919e-01 -1.02883947e+00  9.92424669e-02  1.07791410e+00\n",
      "  9.79426912e-02 -1.57437451e+00  3.32096527e-02 -4.26832143e-01]\n",
      "------counter :24-----------\n",
      "(5000, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28807413  1.76697096  0.46320824  1.1128676   0.59187598 -0.48016628\n",
      "  1.08365742 -1.45966977 -2.68395322  0.11910145 -0.20606887  1.2810929\n",
      "  0.71820677  0.91528171 -0.37398934  1.11566291 -4.38814506 -0.85498666\n",
      " -0.70765048  0.3012135   0.71210441  0.19399881 -0.20774801 -0.65112962\n",
      " -0.09864723 -1.12642172  0.49717352  1.01283028  0.80549571 -0.76954861\n",
      "  0.33163086 -2.09279061 -0.08483253  1.17412434 -1.19366033 -0.23640126\n",
      " -0.91848456 -1.4132578   0.14704734 -0.95969634 -0.65480107  0.66379346\n",
      "  0.69336619  0.1310659   0.41632022 -0.61435231  0.40137105  0.25414827\n",
      "  0.73661936  0.11337703 -0.19701143 -0.61185821 -2.30488378  1.25582504\n",
      "  0.57829434 -0.0473882   0.56188932 -1.50445312 -1.93265073 -1.51444966\n",
      "  0.3751241   0.84385797 -3.6467764   1.13467711 -5.6049453   0.35815775\n",
      " -0.86579486  1.75557799 -0.89459434 -0.16251965  0.06663738  1.9954383\n",
      " -0.38240108 -0.63919961 -4.99935359 -1.06935733 -0.836033    0.22063377\n",
      "  2.19638872  1.16843547 -1.4984159  -0.28230669  1.36590576  1.74283622\n",
      "  0.11443484 -2.43614544  0.16908774 -1.23892809  1.54471065 -1.12167981\n",
      " -1.24907881 -0.29685744  5.89973265  2.9463903   3.10428069  0.08123828\n",
      " -0.40997312  0.00989698  0.1678444  -0.45269172  2.52539561  4.39675693\n",
      " -0.966931   -0.73282612  1.12764537 -0.50665191 -1.2160776  -2.3546431\n",
      " -0.52429729  0.97610074  0.0082741   1.35178692 -0.5084098  -0.0760777\n",
      " -1.24339067  0.3018577  -0.34066843  0.12122957 -1.27521486 -1.39696811\n",
      "  0.33574444  1.88524147  1.01132943  0.16610543  0.13979087  0.97766394\n",
      " -2.10228513 -2.69705429  0.13921874 -1.3697414  -0.65279755  0.74464907\n",
      " -0.6768459   2.49245161 -0.11821423  0.6226704  -0.08587102 -1.35256907\n",
      "  0.34284832  0.41716311  0.77458418 -0.38230605 -0.58798318  3.84104571\n",
      "  0.81927739  0.55556663  1.05912657  0.58420197  0.0810446  -0.09640046\n",
      " -0.56811671  0.58787098  1.64890106 -0.71735541  0.19566393  2.15584181\n",
      "  1.50944984  1.48362098 -1.07016239 -0.03307541  1.31676544 -0.42488088\n",
      " -1.01859407  0.66480843 -0.08829024  0.4509515   0.30799507 -0.15494402\n",
      "  0.67037239  3.55141285 -0.2071063   0.26226915  0.36809518 -2.62999317\n",
      "  2.0213599   0.58406346  1.01477725 -0.64325771  0.5166033  -1.01670799\n",
      " -3.12055541  1.98123362 -1.45515704 -0.11087249  1.33552746 -0.59562263\n",
      " -0.29281529 -1.12703362 -2.02191222 -0.29000502 -0.04869698 -1.14943038\n",
      "  0.70576818 -0.79062466 -0.15073868  0.80987162  1.18900314 -1.26007413\n",
      "  0.27247759 -0.47605426]\n",
      "------counter :25-----------\n",
      "(5200, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99279981 -1.16501654  0.35460032  0.56886188  0.1369345  -0.04005469\n",
      "  2.22356808 -1.43846243 -0.40100701  2.0841866  -0.58074072 -0.66084273\n",
      "  1.04819825  1.50958936  0.09889813  1.57789873 -3.32120155 -0.36503066\n",
      " -0.48854505  0.9569888   0.27128846  0.11935059  0.40835423  0.57635998\n",
      "  0.24501749 -0.86542826 -0.03375855  1.24738796  1.18547007  0.79298713\n",
      "  0.69801303 -2.84558537  0.98007896 -0.36910112  3.23841296  0.14228837\n",
      "  0.21387251 -0.47056411 -0.3473519  -2.17423388  0.66650041  0.23897062\n",
      " -0.68141087 -0.17209694  0.21467878 -0.25304381  1.21419651  0.1359954\n",
      " -1.65446641 -0.123792   -0.90077114  0.65001702 -1.53031231  1.20161469\n",
      " -0.68763624 -0.30666083  0.60271869  0.64775858 -2.24708277 -0.24155338\n",
      " -0.19481934  1.31421855 -5.56364992  0.97858248  1.1536617   0.87586696\n",
      " -0.48540189 -0.21177044 -2.39466068 -0.28918357 -5.64898006  2.45285949\n",
      "  0.25346941 -0.40744079 -5.31209304  0.17094248 -1.07634642  1.0576002\n",
      "  2.16000542 -1.07679803 -1.0624707  -0.59118985  1.33289895  0.52183262\n",
      "  0.2399222   1.46825115  1.5219133  -1.1934723  -1.8972125  -1.09852613\n",
      " -1.17565166 -0.65002826 -2.81997559  2.43928616  1.21086045  0.29756597\n",
      " -0.69427486 -1.10681238 -0.48106164  0.1746965   2.90169428 -0.6388547\n",
      "  1.2189112  -0.19320962  1.12720925 -0.72996441 -1.77349641 -2.09738645\n",
      "  0.5638529   0.82630452 -0.83738084  1.21498045 -0.26382307  1.1621165\n",
      " -0.43723697 -0.30691532  0.05675548  0.2755654   2.9634445  -0.72194773\n",
      " -0.1140112   1.16428272  0.43101472  0.16386515  0.3306741  -0.08490538\n",
      " -1.29783277  2.04649325  0.33120567 -1.93404644 -0.57607533  0.36730002\n",
      "  0.14442749  1.37694907 -0.02167864  1.0729471   0.1462683   0.47434233\n",
      " -1.31315998  0.41415267  0.6111792  -0.06931872 -0.61423422  4.15141563\n",
      "  0.39349644  1.10549702  1.05201689  0.76368935  0.08024952 -0.31003171\n",
      "  0.62406317 -0.38461642 -0.25489678 -0.96060805  0.26682822  0.85971176\n",
      "  0.6349721   0.17590998 -1.73673384  0.37152522  1.02853289 -0.6188887\n",
      " -1.05926211  0.06428204 -0.06802902  0.07427065 -0.02330188 -0.57339899\n",
      "  0.58985255 -0.27493529 -0.70420702  1.13535326  1.31996885 -3.0219281\n",
      "  1.55932578  0.89992365  0.78790301 -1.42281389  0.41652304 -0.56065329\n",
      " -1.84491019  1.52929908 -1.31778572  0.37291198  1.24242555  2.33384509\n",
      " -0.05840577  0.23828115 -1.13625304  0.98529995 -0.16395699 -0.45224803\n",
      " -0.20640409 -0.77596392 -0.3463222   0.58602179  0.89090126 -2.13413973\n",
      "  0.09858285 -0.65336257]\n",
      "------counter :26-----------\n",
      "(5400, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.20346821e-01  3.54656874e-01 -2.35667534e-01  7.21144316e-02\n",
      "  4.38388998e-01  3.88390162e-01  1.39959628e+00  1.78074333e+00\n",
      " -1.56207248e+00  2.06560389e-01 -8.72824682e-01 -7.40721773e-01\n",
      "  3.81235507e-01  1.08021760e+00 -1.42525683e+00  7.30385338e-01\n",
      " -3.60724077e+00  3.07826672e+00 -6.02683500e-01  2.39648535e+00\n",
      " -2.48204374e-01  1.89113194e-01  7.48695204e-01 -5.66315210e-02\n",
      " -3.20416506e-01  2.75766935e-01 -1.35139055e-01 -1.21813643e+00\n",
      " -2.43555279e-01 -1.08081722e+00  1.21227655e-01 -3.20899966e+00\n",
      " -1.04401140e-01 -1.74685948e-01  3.75196027e+00  5.15207311e-01\n",
      " -1.72099835e+00 -5.99194985e-01 -7.95861470e-01  9.98288248e-01\n",
      "  9.35173922e-02  4.20817613e-01 -3.05431814e-01 -5.27227520e-01\n",
      " -5.44927731e-01 -1.92406860e-01  1.35471858e+00  8.10575316e-02\n",
      "  2.17425151e-01  2.71166054e-01  4.38391704e-01  7.74006713e-02\n",
      " -9.86113730e-01  4.84215031e-01 -3.31591878e-01 -4.24721702e-01\n",
      "  2.75574340e-01 -4.44083482e-01 -1.44054772e+00 -1.41571081e+00\n",
      " -4.75726461e-01  7.73747325e-01 -1.09718355e+01  7.18705799e-01\n",
      "  2.44169211e-01  2.91600131e-01 -1.50084544e-03 -2.39582422e-01\n",
      " -7.18370201e-01  4.48925888e-02 -8.00499573e-01  1.88293716e+00\n",
      "  5.51207974e-01 -7.36290829e-01 -3.89001026e+00  3.97770057e-02\n",
      " -1.35975459e+00 -1.45725047e+00  1.60260392e+00 -2.76965842e-01\n",
      " -6.03676313e-01  7.14767252e-01  1.92054196e+00  5.02176677e-01\n",
      "  2.11836464e-01  4.02842268e-01  4.24714487e-01 -1.43016723e+00\n",
      " -1.09331889e+00  1.24229158e+00 -1.52649648e+00 -2.16371678e-02\n",
      " -1.72581658e+00  2.45043877e+00 -4.06011913e+00  5.32394545e-01\n",
      " -7.12764103e-01  7.68993516e-02 -8.56465980e-01  5.10131436e-01\n",
      "  6.23938237e+00 -6.60709091e-01  3.67591276e-01  4.11640802e-01\n",
      " -5.52070230e-01 -7.83194323e-01 -1.42296874e+00 -1.66940529e+00\n",
      "  1.16729663e+00  7.84779496e-01  4.51264950e-02  1.05375796e+00\n",
      " -4.39769927e-01  6.86285388e-01  2.06797932e+00 -1.73684932e+00\n",
      "  1.53494179e+00 -1.85294727e-01  2.01170208e+00 -2.76346064e+00\n",
      " -4.31146187e-01  8.50408965e-01  1.97400529e-01  3.16730655e-01\n",
      "  4.83205972e-01  2.32832070e+00 -1.58216809e+00  1.49965995e+00\n",
      "  8.37233580e-02 -8.82349259e-01 -6.59431571e-01  4.99947976e-01\n",
      "  5.10850484e-02 -5.65135100e-01  1.17189704e-01 -2.53806694e-01\n",
      " -5.42847501e-01  9.32984739e-01  2.93196205e-01 -3.42330312e-01\n",
      "  3.57352474e-01  4.51188871e-01 -5.92688604e-01  3.49373225e+00\n",
      "  2.23764015e-01  1.45148380e+00  9.20293562e-01  7.70430922e-01\n",
      " -1.31923694e-01  1.10080925e-01  2.05314133e-02 -6.32241012e-01\n",
      "  1.57690123e-02 -4.60637830e-01  3.10899622e-01  8.01766093e-01\n",
      "  9.91183780e-01  7.34957336e-01 -6.21193993e-01  5.94745013e-01\n",
      "  1.35145312e+00  1.42629777e+00  8.63823196e-01  4.11858424e-01\n",
      " -1.09792994e-01 -1.22647102e+00 -7.71366827e-01 -5.90662739e-01\n",
      "  4.61101711e-01  3.78429826e+00 -7.49233496e-01 -2.99382264e-01\n",
      "  1.69957983e+00  1.78377222e-01  1.42072959e+00  6.09045614e-01\n",
      "  3.18812042e-01 -1.52385186e+00  3.30591146e-01 -1.09487148e+00\n",
      " -1.92255300e+00  1.01115538e+00 -1.41526415e+00  1.86608794e-01\n",
      "  1.48277282e+00  3.96473191e-02  8.17121544e-02 -4.31051842e-01\n",
      " -9.10461618e-01  7.09666435e-01 -4.23546422e-01 -1.39454296e-01\n",
      " -2.88773213e-02 -1.19234175e+00 -5.69668401e-01  9.12875271e-01\n",
      "  9.23943551e-01 -1.83124048e+00 -3.01754356e-01  5.10517318e-01]\n",
      "------counter :27-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15500813 -0.04849851 -0.22013876 -0.2584335   0.07216864  1.11255178\n",
      "  1.14648027 -2.23916719  0.94653963  0.7916992  -0.84231516 -0.42493272\n",
      " -0.45898204  0.40239847 -0.71674564  0.68689283  1.2527534   0.24647221\n",
      "  0.40347098  3.10794811 -0.64652653 -0.06627185 -0.21078746  0.33208869\n",
      " -0.42531804 -0.2371057  -0.19980746 -1.4584699   0.3208125   1.55876721\n",
      "  0.77309987 -2.8016588  -1.43030735  0.22390958  2.85785714  0.2798547\n",
      " -0.52533718 -0.54793447 -0.59891925  0.93981092  0.67850409 -0.00929091\n",
      " -3.52287039 -0.46626719 -1.14311035 -0.17691419  0.65619896  0.28132546\n",
      "  0.25252864 -0.43268726 -0.96391262  0.49712115 -3.44987545  0.388037\n",
      " -1.47719912 -0.50184186 -0.28724752  0.45777383 -0.6142031  -0.76466935\n",
      "  0.16333135  0.40933368 -2.3043718   0.4896259   0.20010574 -0.19929504\n",
      " -0.55285811  0.69801996 -1.43667414  0.01829616 -3.39997635  1.46684498\n",
      "  0.9061987  -0.75603667 -3.18551394  2.0693549  -1.29228786 -0.27391348\n",
      "  1.48383962 -1.31612045 -0.58443105  0.22391096  1.13233648  0.8380469\n",
      "  0.18083584 -0.5321653   0.69284703 -0.76809875 -0.17468128  0.48239061\n",
      " -1.43891356  0.90556708  1.35054132  2.52821552 -3.88084367  0.51432259\n",
      " -0.65465272 -0.90419188  0.15939326 -0.20917795  6.6968805  -0.75290742\n",
      " -0.30780218 -0.29447857 -1.25284422 -1.00187603 -1.24996286 -1.77676889\n",
      " -3.21361059  0.014108   -0.32785657  1.2933946  -0.41568628 -0.11665253\n",
      "  1.68010612 -1.15517179  0.31684784 -0.02314737  1.06670156  4.45839079\n",
      "  0.37033554  0.44649744 -0.01635023 -0.24939577 -0.64168231 -2.49486379\n",
      " -1.89927053  0.17551526 -0.2874176   1.38587165 -0.3467419  -0.01407046\n",
      " -0.04611614  1.4290919  -0.4503664   0.54382138 -0.4105655  -0.24480722\n",
      "  2.87672385  0.22281811  0.80013307 -0.25062082 -0.82708998  4.16624526\n",
      " -0.01233422  0.30772809  1.45550345 -0.73336361  0.91020165  0.26493007\n",
      "  0.39092585 -0.79172894  0.3317218  -0.49714777  0.17616875  0.90171686\n",
      "  0.62692197  0.72149956 -1.05959678  0.87489369  1.2468917   1.99033589\n",
      "  0.2109469   0.55544848  0.02251218 -0.17733773 -0.87183839 -1.05700326\n",
      "  0.33994642 -1.41425249  0.33806918  0.22426251 -0.41179879  1.28887015\n",
      "  1.37929145  0.48125638  0.27992609  3.89152783  0.15257453 -0.47353688\n",
      " -1.85568845  0.39192949 -2.36333427 -0.30402458  1.49958832 -0.59084566\n",
      "  0.27102473 -0.72282626 -0.62204272 -0.1752335   0.41998781 -0.09260296\n",
      "  1.17663569 -1.37937239 -0.63308686  1.29602345  0.53182596 -0.54794394\n",
      " -0.64544214 -1.09754436]\n",
      "------counter :28-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53249431  3.60861376  0.10098842 -0.3363161  -1.35996447  0.31283915\n",
      " -0.40937919  1.31777627 -3.12791649  0.23950511  0.6515858  -0.37164374\n",
      " -0.75915213 -0.66704744  0.48995065 -0.19549657  0.19688685  2.12241812\n",
      "  0.73625075  4.82126269 -1.42625419  0.72354052  0.21373225 -0.05078076\n",
      "  0.19421306  0.41938826  1.79983696 -1.78442395 -1.03883778 -0.3026111\n",
      " -1.12080319 -1.57039474 -1.05277107  2.86971215 -2.876829    1.68310489\n",
      "  0.93115376 -0.47365281 -0.55735031  1.87489431 -0.40506843 -0.34431198\n",
      " -1.17562545 -0.13075468 -0.3730604   0.83975625  1.28731209 -0.1971796\n",
      " -2.12643178  1.52727487 -0.22804649 -0.51161655 -0.62367228  0.66825049\n",
      " -4.12499228  1.71518526  0.06957851 -3.98096204  0.43125823  1.39948678\n",
      "  1.84278233 -0.3267265  -4.05273963 -0.6567944   1.40060757  0.29695522\n",
      " -0.71354524 -0.43795804 -0.6260982  -0.90809124 -1.12632704  1.31617335\n",
      " -2.95952859 -1.29737772 -2.80759995 -0.13726187 -2.03171535 -2.69452203\n",
      "  0.08296417  1.0055261  -0.20804974 -2.27858995  1.1680046   0.14532782\n",
      "  1.22679376  1.53637962  2.92117962  1.07929502  1.01687634  0.6763722\n",
      " -2.67244183 -0.84816759  1.79808979  1.63662416 -3.1467339  -0.66176733\n",
      " -0.84696401 -3.28080429 -0.71222828 -0.15017147  2.95301148 -1.7296418\n",
      " -0.48675218 -1.98945131 -1.83067631 -0.64888691 -0.9843077  -2.16688541\n",
      " -1.99108704 -0.71047189 -0.47573797  0.08845932  1.36823742  0.8999509\n",
      " -2.75117033 -1.51360935 -0.33766424  1.17618149  0.80960575  4.64549172\n",
      " -0.31259499  0.9895325  -0.78104719 -1.3450238   0.13930474  1.52586622\n",
      " -2.21054282 -0.73785645 -0.58951321  0.30878061 -0.41081239  1.12174185\n",
      " -0.07710767 -0.67103596  0.91027419  0.48016674 -0.24337237 -1.89055815\n",
      "  1.20043318  2.0784891  -1.09284775 -0.36630636  0.40787079  2.91712752\n",
      " -0.52613695  1.45825119 -0.78184691  1.27940759 -0.02486729  0.25137301\n",
      " -1.15709438  0.36611285  0.93851589 -0.7523307  -0.68701301  0.25545904\n",
      " -0.30304801 -0.12453507 -0.61982295 -0.41853082  1.48011085 -0.27414303\n",
      "  1.40302275  0.88845894 -0.98917359 -0.3179161   1.14453531  0.29736566\n",
      "  0.35181125  0.58026905  0.381743    2.00738314  0.55193814 -0.5136729\n",
      "  2.62427625  0.08547316 -0.28480425  1.08168489  0.24556002 -0.14547624\n",
      "  0.71926501  3.53455983  0.89133753 -2.50893452  0.11968793  0.36578907\n",
      "  1.3965601  -0.20213587  0.04586504  0.01890856 -0.52842737 -0.48938099\n",
      "  0.36192234  0.59392208  1.71740162 -0.42448981  1.96194764  2.31279488\n",
      " -0.05679486  1.09964704]\n",
      "------counter :29-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7954564  -2.13668446  0.46385901  1.6566949  -0.38773716  1.1498186\n",
      " -0.81985861 -2.34169236  0.40992762  0.47341886  1.13255788 -1.51788078\n",
      "  0.04977257 -1.80341087  2.40361682 -1.0853676  -0.91471247 -1.85773844\n",
      " -0.18380084 -1.37387199 -2.52719554 -0.06929859 -0.78531127 -1.53880249\n",
      "  0.8348079  -0.55973051  1.12398621 -3.18224887 -1.38657611  0.20607169\n",
      "  0.36677671 -0.59879927 -0.60145446  1.01524688  3.71093086  0.04040922\n",
      "  0.26633055  1.09657761 -0.18526883  0.07817638  0.51853188  0.24057167\n",
      "  1.64724167  1.68661706  0.31494722  0.74480052  0.43725168 -1.96289306\n",
      " -0.64250119  0.76135226 -0.16592631  0.61155404 -1.59117688  1.07901154\n",
      "  0.09141198  0.61203548 -0.81617302 -1.68347584 -3.70129685  2.20124718\n",
      "  1.30222586 -1.78740715  4.48903894  0.37715726 -1.48122915  0.83398702\n",
      " -1.85649969  0.2583013   0.40321187  1.01673649 -4.70224671 -0.6985735\n",
      " -2.48739325 -0.86638765 -1.56844825 -2.22589969 -0.33351686 -1.95296438\n",
      "  1.22889349  0.58988178  0.22945537  0.00892083  1.02749492  0.51756846\n",
      "  1.36000226 -4.7889763   2.12233285  0.53688512 -0.12967766  0.93371901\n",
      " -1.27183834  1.44667639 -2.21878755  1.03830509  3.21613968 -0.80677705\n",
      " -1.3361636  -0.19893365 -0.52665639 -0.61789897  3.60624027  1.41907925\n",
      "  0.40572857 -0.93891612 -1.04692428 -0.30135796 -1.95675998  0.54032494\n",
      "  0.56567258  0.24905106 -0.82049533 -1.05089532  1.00346462  0.87768458\n",
      " -0.62365999 -0.51941991  0.51126618  0.9007745   1.73246696  2.30352928\n",
      "  0.31359235 -1.17406815 -0.50349677 -0.15408154 -1.66198499  2.59829913\n",
      " -0.90719955  1.86970424 -1.53577398 -0.2965792  -1.08662069  1.45842935\n",
      "  0.33470943  3.37396463  1.00452481 -1.47630602  0.10408945  0.77101005\n",
      " -1.22138766  1.23505914 -2.59533959  0.26046315  0.88643257  3.77620072\n",
      "  0.28365775  1.73383435  1.70130675  0.1058572   0.37852011 -0.78267286\n",
      " -0.18038168  0.87918389 -1.19414762  0.01158884  0.01756119  0.0955652\n",
      "  1.1336969   1.22747641 -3.55023989 -0.08321939  1.14547812  0.30751653\n",
      " -2.08127839 -2.45477782 -0.06538393  0.69610327  1.7999746  -1.04634119\n",
      "  0.39077757  0.44564755 -0.75435484  0.39024952 -0.67149707  5.42087344\n",
      "  2.20695905  0.2257291   0.08112694  0.69849094  0.16127374 -0.43551892\n",
      " -0.35348727 -3.91594409  0.04322213 -1.96534073 -1.98616136 -1.7469381\n",
      "  1.37318155  1.14442916 -1.06622226  0.94132834 -0.1856745   0.30880296\n",
      " -0.24470625  1.01994238  0.03416378 -0.79963096  1.03235136  1.629567\n",
      "  0.43351162  0.95369068]\n",
      "------counter :30-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.72033430e-01  3.27113848e+00  1.33373642e+00  1.22355168e+00\n",
      "  1.47727211e+00 -5.76545234e-01  2.82731732e+00  1.36474546e-01\n",
      " -3.08281482e+00 -2.55085174e+00  9.86535042e-01  7.43729329e-01\n",
      " -1.13886426e+00  5.54668796e-01 -6.31255340e-01 -9.35226961e-01\n",
      "  3.92480481e-01  2.93280112e+00  3.63845617e+00  1.97428185e+00\n",
      " -7.13278444e-01  9.47376851e-01  9.61561325e-02  1.61735979e+00\n",
      "  1.25944765e+00  1.50577552e+00 -1.59654369e+00 -4.64672435e+00\n",
      " -2.43305896e+00 -1.39013686e+00  6.84207911e-01 -5.69047825e+00\n",
      " -9.21071872e-01 -3.58061933e+00 -3.12248169e+00 -2.36500953e+00\n",
      "  1.15830434e+00  1.17951008e-01  5.73891928e-01  6.92163239e+00\n",
      "  4.26426820e-01 -1.18049143e+00  4.23404222e+00 -1.44137787e+00\n",
      "  1.38581828e+00 -1.00639327e+00  4.83207351e-01 -1.97319346e+00\n",
      "  4.50184718e+00  1.88732260e-01 -7.19914378e-01 -1.03714014e+00\n",
      " -3.52866322e-01  8.71693183e-01 -2.37816115e-01 -1.88451721e+00\n",
      "  2.00541574e+00 -2.95884133e+00  4.01531855e+00 -2.74993071e-01\n",
      "  1.97120878e+00 -2.53510250e+00 -1.01777308e+00  1.08502562e+00\n",
      "  4.44316593e+00 -2.52812625e-01  1.23570155e+00 -8.76873516e-02\n",
      " -1.26398856e+00  7.40397016e-01 -3.61054181e+00 -3.99542873e+00\n",
      " -6.12809206e-01 -3.96159570e-01 -3.32194254e+00  8.46519943e-01\n",
      " -1.28704807e-01  4.54394120e+00 -2.37450028e-01  1.30099429e+00\n",
      " -7.86068148e-01 -4.87335446e+00 -5.78123636e-02  2.70993804e-01\n",
      " -1.13498202e-01 -5.34458464e+00  5.85090690e-01  1.10543049e+00\n",
      "  3.97536988e+00  1.55686667e+00  6.42658462e-01 -9.46254564e-01\n",
      " -5.51105262e+00  1.49765791e+00  2.79543280e+00  1.33115445e+00\n",
      " -2.59200855e+00  9.89145486e-01 -6.34449446e-01  6.21671636e-01\n",
      "  9.93555367e-01  5.57381270e+00 -4.71571063e-02 -2.85973880e+00\n",
      " -8.27960345e-01 -2.09250495e+00  1.05874978e+00 -5.02988178e+00\n",
      "  2.32034834e+00  3.92543434e-03 -1.03997108e-01 -7.12796422e-01\n",
      " -3.00961886e-01 -5.07925953e-01  7.44056565e-01 -1.23637515e-01\n",
      " -2.89596845e-01 -5.29852748e-01  3.27307584e+00  3.44126283e+00\n",
      " -1.04476286e+00  5.13816509e-01 -2.87456374e+00 -1.74395286e+00\n",
      "  6.26160120e-01 -2.82936554e+00 -2.06270139e+00  2.40757321e+00\n",
      " -1.28925189e+00 -1.44004327e+00  8.89838211e-01  2.00850081e+00\n",
      "  8.51027111e-01  9.61703125e-01 -9.85711813e-02 -9.77331977e-01\n",
      "  1.04559103e+00  3.34375797e-01  6.83674022e+00 -4.75255682e+00\n",
      "  4.48423709e-01 -5.28183951e-01  1.43379158e+00  1.39204546e-01\n",
      " -1.08377122e+00  1.43513301e+00 -4.43971018e+00 -2.17051202e+00\n",
      " -7.71893638e-01 -5.89397751e-01  1.54459929e+00 -4.45835677e-01\n",
      "  6.42975252e-01 -1.34070778e+00  1.33800225e+00  2.00036635e+00\n",
      "  3.88211063e-01  2.37764486e+00 -2.92255490e+00 -2.05626107e+00\n",
      "  2.09915916e+00  4.90969111e-01 -3.70742746e-01 -2.50821581e+00\n",
      "  1.33267462e+00 -2.10401460e-01  1.24043455e+00 -1.18388224e+00\n",
      " -7.22538526e-01 -4.85925718e+00 -9.84209184e-01  1.20190709e+00\n",
      "  1.70595365e+00  2.43004391e-01  7.95614483e-01  1.38619977e+00\n",
      "  2.01031303e+00 -1.45368494e+00  1.24802604e+00  2.02474271e-01\n",
      " -4.38818973e+00  2.55344722e+00 -3.73680972e-01  1.43836716e+00\n",
      " -2.50229319e+00  4.53002413e+00  1.98030565e+00  1.27268926e+00\n",
      " -1.21621101e+00 -1.04184592e+00 -3.19345525e-01  7.33366766e-01\n",
      " -2.87685129e+00  6.62916036e-01 -2.02536548e-01 -3.75019919e-01\n",
      "  1.17333583e+00  2.42060133e+00 -7.63570347e-01  9.47173067e-02]\n",
      "------counter :31-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.11580752e-01  3.29145570e-01  1.50277905e+00 -2.26858459e-01\n",
      "  8.40702584e-01  4.23823111e-01 -1.85494601e+00  1.35849656e+00\n",
      "  3.38559007e+00  3.89589415e-01 -5.46936066e-02 -6.69297155e-01\n",
      "  5.54512060e-02  4.17497230e-01 -1.66336838e+00  4.27043665e-01\n",
      "  1.40441370e+00 -2.73540852e+00  1.24062680e+00  8.97362010e-01\n",
      " -2.34048910e+00  3.44612042e-01 -4.04825044e-02 -3.30665660e-01\n",
      " -4.02281300e-01  4.81764695e-01 -1.84870333e+00 -1.19260005e+00\n",
      " -2.89983411e-01 -4.60629651e+00 -4.31556498e-01 -4.92019344e+00\n",
      " -1.05545157e+00  7.05009717e-02  2.62986875e+00 -1.60436476e+00\n",
      " -7.34362595e-01  1.85326561e-01 -1.78229865e-01  2.37095496e+00\n",
      "  9.90131517e-01 -9.04491274e-01 -1.63329294e+00  1.21035996e+00\n",
      " -3.27504579e-02 -1.01726925e+00 -1.48442393e-01  1.07638458e-03\n",
      "  3.07235382e+00 -6.39139208e-02  4.53593980e-01  1.89775753e+00\n",
      " -3.54623628e-01  3.74567576e-01 -1.00719671e+00 -1.99517292e-01\n",
      "  1.01418696e+00  2.07399097e-01 -3.94777326e+00  1.94397555e-01\n",
      " -1.72980477e+00 -1.71900535e+00 -2.17176903e+00 -3.83483608e-01\n",
      "  3.23966094e+00 -9.64095939e-01  1.14677365e+00 -1.19053802e+00\n",
      " -1.82168599e+00 -7.52712976e-01 -5.46611647e-01  1.35097770e-01\n",
      "  9.29662503e-01 -2.16788980e-01 -3.42887264e+00 -1.47619730e+00\n",
      " -3.36503570e-01 -3.06928764e+00 -1.60947134e+00  2.54661096e-01\n",
      " -5.61131087e-01 -4.26993981e-01  4.37786330e-01 -8.94871039e-01\n",
      " -1.85435164e-01 -5.83832450e+00 -8.61908629e-02  8.46273307e-01\n",
      "  4.31897390e-01 -6.44658939e-01 -2.41919938e+00 -3.01539148e-01\n",
      " -6.48369635e+00  9.18518606e-01  3.21285878e+00 -3.78790269e-01\n",
      " -8.55108307e-01  8.49946983e-01 -5.78190495e-02  8.47006095e-01\n",
      "  4.43693511e-01  3.22373337e+00 -1.52517306e+00 -3.18416812e-01\n",
      " -6.87159321e-01 -1.96325723e+00 -9.75205240e-01 -7.40773911e-01\n",
      "  4.06243440e+00 -9.12075070e-01 -3.62860615e-01  3.52863498e-02\n",
      " -7.26162261e-01 -1.85567753e-01  2.83603553e+00  2.62559570e+00\n",
      "  8.23255510e-01 -1.86563821e+00  3.00879393e+00  2.26789001e+00\n",
      " -1.65087216e-01 -4.65336681e-01 -1.49271586e+00 -1.42999551e+00\n",
      "  1.61858767e-01  6.95563253e+00 -1.86763732e+00  3.59469661e+00\n",
      " -4.17860907e-01  4.37728887e-01  2.70585564e-02  2.38020073e-01\n",
      "  7.67594563e-01  2.18312646e+00 -1.82379612e-01 -2.24629228e-01\n",
      "  1.09166935e+00 -7.13694972e-02  7.19870731e-01 -2.19269082e+00\n",
      " -2.12434459e-01  8.20743088e-02  1.05546737e+00 -4.45223161e-01\n",
      " -4.46455352e-01 -2.17882523e-01  5.07975895e+00 -6.52671661e-01\n",
      " -2.22925334e-01  5.00401084e-02  6.89472715e-01 -1.00984830e+00\n",
      "  9.99520328e-02 -4.44369147e-01 -1.12358052e-01  3.21086505e-01\n",
      "  1.27986732e+00  9.94100095e-01  5.30192910e-01 -6.97648288e-01\n",
      "  9.07224780e-01  2.07685454e-02  1.18763318e+00 -3.78165745e-01\n",
      " -2.84157357e-01 -8.82138086e-01 -3.65823452e-01 -4.23625396e-01\n",
      " -1.01386135e+00 -3.24678146e-01 -8.57703658e-01  8.46044800e-01\n",
      "  2.27955889e+00  1.24373397e+00  1.20879355e+00 -4.80414217e-01\n",
      "  1.37711911e-01  4.80199376e+00 -2.25100473e-01 -7.35812088e-01\n",
      "  3.11357599e+00  1.94876507e+00 -3.85663317e-01 -5.25870728e-01\n",
      "  4.36904886e-01  1.77995923e+00 -2.67053580e-01  3.59445662e-01\n",
      "  4.29125614e-01  7.73352436e-01 -1.27054892e-01  5.45631737e-01\n",
      " -1.03440535e+00 -3.07708498e-01  3.15879748e-01 -5.56915200e-01\n",
      "  1.65008297e+00  2.43676671e-01 -1.74198238e+00 -6.56915080e-01]\n",
      "------counter :32-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47189494 -1.41478583 -0.26273841 -0.58695144 -0.22344305  0.37214142\n",
      " -1.39768898  2.02620103  2.49264791 -1.56585023  0.28668648  0.12218359\n",
      " -0.42033434 -0.49801993 -1.10816028  0.17346306  1.08680428 -2.30371378\n",
      "  0.70556998 -0.65166479 -0.69176754  0.35975348  0.07061102  0.22262404\n",
      " -0.48374963  0.08399131 -1.22194631 -1.45537226  0.7719716   0.04108647\n",
      " -1.16456239 -3.28767039 -0.07082664 -0.50457333  1.32920947 -1.87245901\n",
      " -0.78842783 -0.79337463 -0.28496025  1.68045474  0.26322483 -0.5617953\n",
      "  1.40204882  1.89735119 -0.56227577 -1.05538372 -1.11784931  0.4540393\n",
      " -1.5317312  -0.06785626 -0.32560969  0.05502484  0.30945375  0.47577167\n",
      "  2.45216357 -0.18669731  1.28628127 -0.20704673 -0.85676554 -0.09669134\n",
      " -0.01632715 -0.78196528  1.17233897 -0.43943225  4.4885686  -0.83178975\n",
      "  0.89695323 -0.29277472 -1.37563849 -0.22473654 -1.64010134  0.67770318\n",
      "  0.3044755   1.14635749 -4.32669996 -0.38029285 -0.35298365 -4.07059869\n",
      " -0.59113938  0.40795692 -0.0967186  -1.05257436  1.04191682 -0.68889249\n",
      " -0.29622976  1.66530746  1.28686423 -0.40684259  0.45585274 -0.50891237\n",
      " -0.69491827  0.36354563 -2.96576301  2.88070948  4.16884947  0.40087068\n",
      " -1.06118516 -0.081633   -0.67719223  0.98391289  0.81912867 -3.41476434\n",
      "  1.35552368 -1.85899614 -0.58613741 -1.92479969 -1.33159883 -2.31885169\n",
      "  6.29804981 -0.4283983  -0.60521149 -0.09103572 -0.3791732  -0.16272357\n",
      "  0.80224024  0.46055939  0.72443431 -1.50679144  1.0714606   0.53223265\n",
      " -0.81690387  0.36185405 -0.95152294 -1.23956498  0.07975392  5.91760222\n",
      " -1.21501763  3.05204351 -0.46678883 -0.00819471 -0.17028795  0.21937613\n",
      " -0.12198186 -0.46944841  0.11045961 -0.77084702 -0.52607089 -0.12857723\n",
      "  2.68012812 -2.38094336 -0.09766562 -0.00635395  1.90076623 -0.2904287\n",
      " -0.52622764  0.1437473   3.76438858 -0.54961808 -0.51273827 -0.34803566\n",
      "  0.18571183 -0.83791025 -0.52823022 -0.58882482 -0.01705453  0.83381827\n",
      "  1.74380178  0.45400322 -3.24844439 -0.57630793  1.07795174 -0.64325307\n",
      "  1.36805823  0.28436247 -0.09878365 -1.02198538 -0.13519105 -0.50098963\n",
      " -0.57010349  0.3330228  -0.62940011 -0.53377139  2.31815541  2.43799539\n",
      "  2.07318312 -0.37453941  0.13848013  3.86211772 -0.87977557 -0.735198\n",
      " -2.15134408  2.78225645 -0.39432915  0.10636634  0.30641811  3.25571802\n",
      " -0.06748247  0.50025044 -1.89299142  0.76903773  0.11037     0.57090444\n",
      " -0.09263017 -0.61712425 -0.29358649 -0.68313967  1.80831366 -1.37662625\n",
      " -1.655622   -0.0204601 ]\n",
      "------counter :33-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.72200816e-01 -4.02772735e+00  1.30675740e+00 -1.32536094e-01\n",
      " -6.45448630e-01  1.44195204e+00 -1.07822100e+00  1.18339425e+00\n",
      "  5.19693807e-01 -8.46454732e-01  9.58589792e-01  2.20997873e+00\n",
      " -1.32441860e-01 -2.70565011e-01 -6.75764111e-01 -7.48321430e-01\n",
      " -1.89532025e+00 -2.74863709e+00  3.39495813e-01 -2.30874814e+00\n",
      "  3.01830562e-01  6.00041303e-01  1.02710597e-01  3.73586209e-01\n",
      " -2.67864323e-01 -3.39893336e-01 -5.02955138e-01 -3.80599332e-01\n",
      " -9.64315863e-02  1.79693507e+00 -5.67873560e-01 -2.62446750e+00\n",
      "  1.76084020e-01 -3.52027530e-01 -1.09158885e+00 -1.50778200e+00\n",
      " -7.24894990e-01 -3.80963549e-01 -2.25269957e-02  1.94434408e+00\n",
      " -4.26014463e-02 -6.31834525e-01  1.27376106e+00  2.10996454e+00\n",
      " -3.75020940e-01 -3.48079420e-01 -6.53239630e-01 -1.87888542e+00\n",
      " -1.19404608e+00 -2.11427277e-01 -2.47629635e-01  6.52363398e-02\n",
      "  1.20723251e-01  3.48556664e-01  2.72480380e+00 -2.57870105e-01\n",
      "  7.95110852e-01 -2.14767339e+00  2.61257971e+00  5.33182398e-01\n",
      "  2.11783795e-01 -9.36249882e-01  6.37948624e-03 -1.09520327e+00\n",
      "  3.95590410e+00  1.09115311e-01  5.01548530e-01  2.53262965e-01\n",
      " -1.63335924e+00  8.70733417e-02 -1.55250038e+00 -1.06315615e+00\n",
      "  4.33049609e-01  1.07993735e+00 -4.03376119e+00 -9.90225542e-01\n",
      " -2.16396814e-01 -3.00623476e+00 -2.78839378e-01  1.39243750e+00\n",
      "  8.02701796e-02 -5.23478149e-01  1.17888731e+00 -6.51100161e-01\n",
      "  7.78380110e-02  2.04350572e+00  8.41260093e-01 -1.90638075e+00\n",
      " -8.52346276e-02 -5.63772135e-01  4.00954191e-01  8.85696068e-01\n",
      " -1.17173332e-01  1.09978926e+00  1.73574806e+00  1.08958888e+00\n",
      " -1.80181089e+00  6.65660170e-01 -9.04957957e-01  1.11155017e+00\n",
      "  1.51491131e+00 -2.23500396e+00  1.90144693e+00  2.59150437e-01\n",
      " -1.31321472e+00 -1.16001382e+00 -1.34190264e+00 -7.49244769e-01\n",
      "  2.59998142e+00 -6.28822160e-01 -6.06348338e-01  7.76544865e-02\n",
      " -1.76848092e-01  2.67229504e-01  3.81073694e-01 -1.63916121e+00\n",
      "  5.57099118e-01 -1.08563010e+00 -2.11968966e+00  9.98818009e-01\n",
      " -4.02321026e-01  7.37879438e-01 -3.38743893e-01 -9.09772414e-01\n",
      "  8.34381941e-01  5.06094872e+00 -8.68836722e-01  2.96095424e+00\n",
      " -1.00450246e+00 -8.79830336e-01 -7.74818424e-04  5.14583285e-01\n",
      " -5.64183650e-01  4.09898615e-01  1.94722065e-01 -8.07396248e-01\n",
      " -5.74596955e-01 -4.22369356e-01  1.93812553e-01 -1.57963935e+00\n",
      "  4.84160758e-01 -2.18032764e-01 -9.65026771e-01  3.98840816e-01\n",
      " -5.28823597e-01  6.21380825e-02 -4.35733743e-01  1.92010576e-01\n",
      " -2.59719576e-04  7.11431969e-02  1.14527528e+00 -5.26398633e-01\n",
      " -5.74016061e-03 -5.83916710e-01 -6.87087298e-02  9.25162163e-01\n",
      "  2.34030634e+00  8.25490981e-02 -2.40197999e+00 -5.83161829e-01\n",
      "  1.30527563e+00 -7.48952412e-01  3.56414887e-01 -7.57810084e-02\n",
      "  8.63325088e-03  6.93005142e-01 -2.71708299e-02 -1.55843653e-01\n",
      " -4.15920525e-01  6.09590152e-02 -5.48259290e-01  7.16696835e-01\n",
      "  2.00459571e+00  3.43217785e-01  1.89656237e+00 -1.68222736e-01\n",
      "  2.94714501e-01  1.59598792e+00 -8.53790432e-01 -1.04569226e+00\n",
      "  1.40167205e+00  3.01533839e+00 -2.43634870e-01  1.62433579e-02\n",
      "  1.03166661e+00  2.55958712e+00  6.29800280e-02  4.60528094e-01\n",
      " -6.65556348e-01  1.09481148e+00 -4.25375641e-02  3.56110225e-01\n",
      "  2.26104713e-01 -3.27081451e-01 -4.47691900e-01 -6.54442678e-01\n",
      "  7.59293902e-01  1.25076610e-01 -1.42709900e+00  2.88142247e-01]\n",
      "------counter :34-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.46484027 -1.48088273 -0.46105038  0.12662406  0.16228112  1.44375738\n",
      "  0.0820336   1.20563611 -4.20713062  0.48103121  1.01726829  0.21523487\n",
      "  0.8902593  -1.14593689 -0.0691895  -0.92131367 -0.91653211  3.09460934\n",
      "  0.57419037 -1.89731989 -1.34441882  0.05208912 -0.26475456  0.59442538\n",
      " -0.12396851 -0.17460705  0.12931436 -1.66843916 -1.01285855  3.28845774\n",
      " -0.15648778 -2.55348968  0.43134636 -2.16529284 -0.37814771 -1.62845354\n",
      "  0.13625387 -0.0089694   0.33835946 -4.58587157  0.35353104 -0.95370558\n",
      " -1.74762306 -1.55033798  0.04491408 -0.58521028  0.89273345 -0.69760426\n",
      "  0.94678132  0.34614582 -0.91737988 -0.28338109  0.02609352  0.20100192\n",
      " -0.25844954 -0.56720818  0.55129679  3.13035655 -0.4087036  -0.44320782\n",
      "  0.77964197 -1.30572969  2.49712701 -0.32310886  2.62627353  0.38539823\n",
      "  0.54243974 -0.34782171 -1.18220702 -0.23718324 -0.36473392  2.27343198\n",
      "  0.56253966  1.12666292 -1.8678172  -0.58757466 -0.5032982  -0.93324483\n",
      "  0.58640943  1.8253994  -1.22896238 -3.74274759  1.73028971  0.15834017\n",
      "  0.09630365  2.68924593  0.20001781 -1.9453124   0.57696748 -0.05817688\n",
      " -0.47067886  0.42729736  2.61943361  0.63795418 -0.2208126   0.71605435\n",
      " -1.70313817 -0.4465824   0.02167583  0.91359972  0.74061375 -0.36754156\n",
      "  0.23953201  0.28207421 -0.54849072 -1.18259308 -0.88855309 -0.27919958\n",
      "  3.33273434  0.20351467  0.12780677  0.01995223  0.20969537 -0.19616691\n",
      "  1.06147918  2.97195448  0.5054074  -0.05242408  1.80751275  1.30831953\n",
      " -0.29152909  1.20231087 -0.05746219 -0.82027569  0.2537775  -3.47155606\n",
      " -0.4240473   1.43106212 -0.79666134 -1.37358829 -0.07104864  0.75504936\n",
      " -0.6725684   0.18936169  0.59660084 -1.13613398 -1.30007806 -1.35430787\n",
      "  3.83187499 -1.822235    0.07654737 -0.29460685 -0.75485403  0.58476424\n",
      " -0.24229359  0.25944343 -0.69575033  0.22622018  0.45096866  0.06790345\n",
      " -0.32863601 -0.27953343  1.85304732 -1.96439698 -0.71286451  0.36174962\n",
      "  2.14302377  0.43527103 -1.5798328  -0.55337479  1.36061525 -0.35619902\n",
      "  2.40185027 -0.70471504  0.62716513  0.71531368  0.66011536  0.89705955\n",
      " -0.40201542 -0.05119698 -0.20079463  0.84135858 -0.31676921  1.74912869\n",
      "  1.06944738 -0.0911596  -0.0569791   0.63649026 -0.88287419 -1.03821881\n",
      " -0.58732998  1.81336015 -0.28018296  0.0056427   0.01853199 -2.7437478\n",
      "  0.35253834  0.07189437 -1.65926462 -0.08830985 -0.05329628  0.21777483\n",
      "  0.54142485  0.10437203 -0.50808624 -0.39335332  1.01975538  1.47714688\n",
      " -1.47434952  0.12457443]\n",
      "------counter :35-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.15056671e-02 -1.44421945e+00 -1.13488441e+00 -3.13752308e-01\n",
      "  5.98153444e-01  1.45322183e+00 -7.49743677e-01  1.17812773e+00\n",
      "  4.52337882e-01 -3.66015969e-02  1.84061784e-01  3.14569763e-01\n",
      "  4.97876959e-01 -2.13248725e-01  1.81721020e-01 -4.12609172e-01\n",
      " -1.47929532e+00  7.31627589e-02  3.00366402e-01  8.63424028e-01\n",
      "  3.38230767e-01  6.42617758e-01  2.86570239e-01 -1.00971179e-01\n",
      " -6.92270549e-01 -1.00591595e+00 -5.66461332e-01 -2.68128914e-02\n",
      " -8.55831349e-01  2.65323461e+00 -6.66367597e-01  2.17781784e+00\n",
      " -1.34644496e-01 -3.38335197e-01 -2.85464956e+00 -1.71875248e+00\n",
      " -1.08974978e+00 -8.10545227e-01 -5.93182079e-02  8.52031245e-01\n",
      "  1.59160268e+00 -2.72630641e-01 -1.25534963e+00 -1.57538039e+00\n",
      "  1.39823098e-01 -8.13332179e-01 -1.21971583e-01 -4.79637274e-01\n",
      "  1.09265226e+00 -3.11398705e-02 -1.57740104e-01  8.66051813e-02\n",
      "  1.05033555e-01  8.26129505e-01  9.32842696e-01  1.32062609e-01\n",
      "  1.74879112e+00  1.20586872e+00  1.88633714e+00  1.34867998e+00\n",
      " -4.63476624e-01 -1.33247024e+00 -3.81238640e-02 -4.63079426e-01\n",
      " -2.21438060e+00  4.50951380e-02 -4.73941917e-01 -2.75106179e-01\n",
      " -1.06427334e+00 -8.56565343e-01 -3.30502841e+00  7.08321291e-02\n",
      "  5.15303902e-01  5.77080317e-01 -1.64057538e+00 -4.80559161e-01\n",
      " -5.59782819e-01 -1.72564724e+00 -2.65698898e-01  1.16289446e+00\n",
      " -5.58698863e-01 -8.28171635e-01  8.32863561e-01 -6.79348721e-01\n",
      "  3.68921605e-02  1.44931776e+00  2.15686732e+00  5.75749139e-01\n",
      "  1.30946679e+00  8.58609587e-01 -1.25977053e+00  1.05520078e+00\n",
      "  4.45660246e+00  9.54371598e-01  4.97164941e+00  7.52237577e-01\n",
      " -1.34918093e+00 -1.79128802e+00 -6.19778804e-01  8.13431853e-01\n",
      "  1.47820365e-01 -1.76290467e+00 -3.23439232e+00 -7.81328588e-01\n",
      " -1.19296393e+00 -1.39160530e+00 -9.70693670e-01 -3.21364656e+00\n",
      "  2.06510597e+00 -3.24319315e-01 -4.79062095e-01 -2.20575925e-01\n",
      " -4.59864119e-02  5.40413862e-01  4.57456939e-01  2.56772054e+00\n",
      "  8.50396322e-02 -5.14050733e-01  1.53962921e+00 -2.47595047e+00\n",
      " -7.25266572e-01  4.97766098e-01 -6.31495253e-01 -1.60293408e+00\n",
      "  9.30158762e-02  9.47138050e-02 -3.51070492e-01  4.72992389e+00\n",
      " -9.36016270e-01 -5.03016352e-02  2.65688025e-01  4.64302810e-01\n",
      "  3.67455459e-01 -5.02573206e-01  3.74647413e-01 -2.98966106e-01\n",
      " -1.43985519e+00 -5.62941059e-01 -1.38584833e+00 -1.95916878e+00\n",
      "  1.99673154e-01 -1.02489331e-01  3.67009896e-01  2.89811497e-02\n",
      " -6.62669230e-01 -6.29744763e-02 -1.26928804e-01 -8.43471934e-03\n",
      " -4.59868694e-02  3.83706225e-01  3.71357435e-01 -6.74846141e-01\n",
      "  6.41765639e-01 -1.04056728e+00 -9.87333830e-01  4.62218229e-01\n",
      "  2.59136789e-01  2.30518759e-02 -1.82030884e+00 -3.36404654e-01\n",
      "  1.06757092e+00 -7.04814418e-01  1.24934606e+00  4.43568153e-01\n",
      "  6.76223218e-01  1.50339802e-01 -9.16173632e-02  2.96663532e-01\n",
      " -5.86061539e-01  2.45712893e+00 -4.06086293e-01  1.47829894e+00\n",
      " -8.12645698e-01  1.95864085e+00  1.99228535e+00  1.42843348e-01\n",
      "  1.33803248e+00  3.27209685e+00 -8.33069134e-01 -7.89758019e-01\n",
      " -4.95276421e-01  1.44991239e+00 -5.06891237e-01  2.80757025e-01\n",
      "  3.76387203e-01  4.04571545e-01  5.43276156e-02  5.55543895e-01\n",
      " -1.23367773e+00 -1.01293063e-01  8.94163216e-05  4.65473049e-01\n",
      "  2.19648483e-01 -2.51011162e-01 -4.89405450e-01 -7.27914959e-01\n",
      "  8.30058216e-01  8.25384960e-01 -1.58189440e+00  5.11679660e-01]\n",
      "------counter :36-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09495792 -1.46318771 -0.40941355 -0.05753987 -0.78143207  0.04617563\n",
      " -2.70412806  1.45115366 -2.30382439  0.06922709  0.65776827  1.30866209\n",
      "  0.02871014  0.91266269 -0.79779159 -0.00705213 -2.02051352 -2.61606161\n",
      "  0.42321701 -1.46383568 -1.11902789  0.91530991  0.42442663  0.65921748\n",
      " -0.55104857 -0.6594152  -0.27627414 -0.83715627 -0.21152666  2.14255534\n",
      " -0.52299722  1.37703306  0.47648499 -1.22142649  1.52152885 -1.46965148\n",
      "  1.11529231 -0.95128381  0.12416356  1.41245531  1.29802821 -0.03720313\n",
      " -1.10184283  2.4477138  -0.15955808 -0.58947083 -0.23411681 -0.78125112\n",
      " -0.64749154  0.09432316 -0.48635496 -0.4318758  -0.44606019  1.0495277\n",
      "  0.00600562 -0.41299788  0.87935546  0.59339225 -1.75167883  0.47647009\n",
      " -0.17734794 -0.85334943 -2.16649113 -0.34211971  0.23254089  0.25538145\n",
      "  0.37008253  0.05203223 -0.70048226 -0.09296606 -0.0642219   1.88667438\n",
      "  0.43170214  0.50017703 -1.06418253 -0.80478544 -0.4271607  -2.45604332\n",
      " -0.08576169  0.74649632 -0.13830096 -0.01177668  1.12497169 -0.51951722\n",
      "  0.21046272  1.15898459  1.05493816 -0.37125954  0.71153826  0.85747302\n",
      "  0.20799202  0.33196739  3.09922929  1.66358597  4.19600395  0.96089947\n",
      " -0.7660963  -0.48775338 -0.54171651  0.80902452 -2.55156192  0.5453883\n",
      "  0.36580244 -0.84155568 -0.87681007 -1.28444103  0.15166728  0.04689026\n",
      " -0.87200495 -0.03062201 -0.25671015  0.03900224 -0.1646444  -0.23322682\n",
      "  0.61844967  2.00957948 -0.21793125 -0.38254258  1.32768359 -1.04732591\n",
      " -0.04878168  0.04591534 -0.19776354 -1.50484712  1.28963288 -1.31835678\n",
      " -0.30315563  2.76816502 -0.75445613 -0.93030624 -0.1976777   0.32499348\n",
      " -0.41699102  0.00478982  0.3106054   0.46796857 -0.9843626  -1.19273962\n",
      "  0.61248675 -2.60550198  0.41400484  0.77886343 -1.56286584  0.14479418\n",
      " -0.72837703 -0.12038226  0.54692903  0.10259459 -0.19970293 -0.1046693\n",
      "  1.02791377 -0.33003306  0.58856637 -0.87923561 -0.80029006  0.46021276\n",
      "  0.45216326  0.53852841 -2.09923214 -0.43884224  1.08316243 -0.49179694\n",
      " -0.10285014  0.06230499  0.70274841  0.07189532  0.18327655  0.50016381\n",
      " -0.43391208  1.75953529  0.16394595  1.37315786  0.13092448  2.37743709\n",
      "  1.79107348  0.18859226  1.14535137  0.726785   -0.1284499  -0.34215895\n",
      "  0.23995268  0.39809843  0.80583056  0.02776185  0.81792857 -0.79148103\n",
      "  0.10178317 -0.12979682 -1.86133912 -0.48945178 -0.40568163  0.49269303\n",
      " -0.14444277  0.22193959 -0.60327149 -0.76441728  0.93125066  0.59826281\n",
      " -1.323767    0.52907961]\n",
      "------counter :37-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.85335772e-01  9.12874899e-01 -3.01868930e-01  5.45092192e-01\n",
      " -1.10660983e-01  9.33315406e-01 -9.56737157e-01  1.77607285e+00\n",
      " -8.07135509e-01  1.18661026e+00  1.07986189e+00  2.01046044e-01\n",
      "  6.02256362e-01 -4.89736274e-01 -7.94833403e-01 -7.72026309e-02\n",
      " -3.04416659e+00  7.06187748e-01  1.58494484e+00 -1.50225236e+00\n",
      " -8.70278046e-01  1.10884774e+00 -2.88024535e-01 -1.85321243e-02\n",
      " -6.43376043e-01 -2.95410804e-02 -2.38039376e-01 -7.62029534e-02\n",
      " -1.02770677e+00 -2.97007247e-02 -2.58412026e-01  1.65541660e+00\n",
      "  2.81215849e-01 -2.95796851e+00 -1.42420472e+00 -1.22509194e+00\n",
      "  4.77802653e-01 -5.43275457e-01  9.63187135e-02 -2.12740186e+00\n",
      "  9.18511282e-01  1.72899413e-01 -2.35480424e+00  2.26558394e+00\n",
      " -2.23183331e-03 -5.15526205e-01  7.68488347e-01 -1.50412258e+00\n",
      "  1.03644875e-01 -7.58242411e-01 -1.16209768e+00 -6.08780912e-01\n",
      " -9.97599027e-03  7.64578468e-01 -1.20031068e+00 -5.26039553e-01\n",
      " -2.97779636e-01  5.99069332e-01  2.56035440e-01  3.99280724e-01\n",
      " -6.07545000e-02 -4.43643669e-01 -3.49970789e+00 -3.79903565e-01\n",
      "  7.78217928e-01  3.68893236e-01  1.30102204e-01  6.26748204e-02\n",
      " -1.38567254e+00 -5.84810657e-01  2.70016266e-02  1.55057020e+00\n",
      "  3.69546049e-01 -4.21733278e-01 -1.64163431e+00 -6.97983057e-01\n",
      "  5.19766610e-01 -3.66901254e+00  2.08734646e-01  1.00349273e+00\n",
      " -2.08559400e-01 -2.03967616e-01  5.10307555e-01 -4.99567464e-02\n",
      " -2.62035354e-01  3.27241381e+00 -5.60777670e-01  3.40012392e-01\n",
      "  6.31031552e-01  5.19990939e-01  1.61017003e+00  3.90800477e-01\n",
      "  4.15731488e+00  6.24113589e-01  3.75998214e+00  3.72253050e-01\n",
      " -1.77687908e+00  3.16178307e-01 -2.05109951e-01  1.06627057e+00\n",
      " -1.50796086e+00 -3.27436185e+00 -2.49761671e+00  4.12672935e-01\n",
      " -3.50232124e-01 -7.85157129e-01 -5.53140507e-01  8.47699563e-01\n",
      "  2.35092928e+00  8.81020239e-02 -2.94812636e-01  2.83026723e-01\n",
      " -4.69436409e-03 -1.12404478e+00  6.47872153e-01  2.64101648e+00\n",
      "  1.16379721e-01  3.66055014e-01  1.74696262e+00 -1.69342683e+00\n",
      "  4.62727728e-02  4.27334052e-01 -4.47599672e-01 -1.34859748e+00\n",
      "  7.70654044e-02  3.17260077e-01 -2.07555330e-01  2.90274554e+00\n",
      " -4.79049328e-01  3.21299046e-01  2.41517072e-01  2.61249265e-02\n",
      "  6.52497397e-01  1.05466598e+00  5.49766902e-01  4.33725549e-01\n",
      " -8.69175375e-01 -1.04724833e+00 -8.51344612e-01 -2.07274606e+00\n",
      "  5.31684650e-01 -3.66195132e-01 -9.78861465e-01  7.54522422e-01\n",
      " -5.70214531e-01  1.18294899e-01  1.79025630e-01  2.16952468e-01\n",
      "  1.09726287e-01  5.01036592e-01 -6.53169013e-01 -2.33294793e-01\n",
      " -2.01084603e+00 -4.74635218e-01 -1.78966198e-01  6.62788762e-01\n",
      "  9.89688648e-01 -2.75459792e-01  5.26334293e-01 -2.55135587e-01\n",
      "  1.27676377e+00 -4.37723888e-01  1.18558836e+00 -4.00393659e-03\n",
      "  5.20443287e-01  1.03066678e-01  5.05044158e-01 -5.08344456e-01\n",
      " -9.37841838e-01 -8.06396498e-02 -1.41614026e-01 -1.62280978e-01\n",
      "  1.54152432e+00  1.63344419e+00  7.28756377e-01 -9.29820785e-02\n",
      "  1.07001878e-01  1.27586797e+00  3.99459783e-01 -4.11401089e-01\n",
      "  1.79662467e-01  2.72489690e+00  4.99938542e-02 -4.27266340e-01\n",
      "  1.35461793e+00 -2.95215750e-01  5.64118221e-02  3.32471854e-01\n",
      " -1.74411744e+00  2.24855434e-01 -1.61341548e-01  1.73580358e-01\n",
      " -1.50131878e-01 -2.12522480e-01 -1.11063712e+00 -3.29118704e-01\n",
      "  4.91551485e-01  2.72904713e-01 -1.37481040e+00  3.71854406e-01]\n",
      "------counter :38-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04131348 -0.74552115  0.22981942  0.2768037   0.35304265 -1.02714189\n",
      " -1.52965008 -2.15278174  1.29067997  0.1373447   0.92039656 -0.32218289\n",
      " -0.17066212 -0.53855691 -0.22043587 -0.70507133 -2.69381305 -2.30823144\n",
      "  0.23110434  3.50165071 -0.4431706   0.15083639 -0.66602432 -0.73126339\n",
      " -0.11176581 -0.4327332  -0.79606267 -0.59816489 -0.21509311  0.30639089\n",
      "  0.21812222  1.39603629 -0.03609073 -2.24216792 -1.14648448 -1.08673386\n",
      " -1.84999811  0.24682619  0.19600251 -2.25781003  0.1682454   0.18424678\n",
      "  0.471322    2.3581402   0.23790314 -0.31546824 -0.40805202 -0.20620279\n",
      "  0.53616505  0.79891696 -0.97145347 -0.58096015 -0.7904761   0.30949723\n",
      "  0.24419304  0.19529353  0.12739932  0.49167373 -1.41304296  0.60980947\n",
      " -0.57322491 -0.74285873  2.39293396 -0.31254062  0.49824008  0.85222948\n",
      " -0.04943956  0.38145863 -1.3159193  -0.145911   -0.12716125  1.04766697\n",
      " -0.26545821 -1.05115022 -2.15453849 -0.53680271  0.38599962 -2.08920214\n",
      "  0.55560874  0.83730223 -0.6985192  -1.182543    0.6132401   0.1951101\n",
      " -0.15924371  1.51906304  1.35894967 -0.53554381  0.60564856 -0.44740288\n",
      " -0.33734001  0.39709779  3.91714017  1.79187149 -4.35397773  0.32878742\n",
      " -1.19191884  2.39869401  0.09766035 -0.10671186 -1.44917538  6.54004877\n",
      " -3.13268741  0.14370938 -0.19943171 -0.66459251 -0.46164627  1.05712092\n",
      "  4.54769754  0.13154116  0.2264366   0.28940483  0.24413574  0.40212908\n",
      "  0.31100296 -0.3176735   0.105177    0.4215311   2.07916601  1.53278006\n",
      "  0.23699263  0.60604562 -0.61140273 -0.71905676  0.07069449 -0.42568035\n",
      "  0.37796729  1.33267715 -0.49689433 -0.24999623  0.6198849  -0.44267549\n",
      "  0.12796497 -0.08804045  0.57700281 -0.10175074  1.0029372  -0.52509759\n",
      " -1.00678016 -0.88732934  0.3877665   0.31246942  0.73434849  0.71035164\n",
      " -0.21082221 -0.28654789 -0.27994502  0.11560986  0.53851975 -0.65302612\n",
      "  0.19145875  0.02745032 -2.35513954 -1.63671073  0.2268775   0.57396588\n",
      "  1.49539578 -0.39068214 -1.1847563  -0.46466093  1.34126399  0.19988234\n",
      "  0.99561129 -0.64260954  0.07299697 -1.03596769  0.39584083  0.17754306\n",
      " -0.57675546  0.55350061 -0.04410046 -0.53933813  1.23329328 -0.98463009\n",
      "  0.77644443  0.2723828   0.97205715  1.04386982  0.79464941 -0.30180694\n",
      "  0.2509332  -0.34912619 -0.74350709  0.13304147 -0.53341076  0.93939855\n",
      " -0.23702715  0.23107457 -1.88252182  0.98849617 -0.74739407  0.4339068\n",
      "  0.11610329  0.25910539 -0.60478791 -0.1229572   1.52782799 -0.12896481\n",
      " -1.34258451 -0.17836971]\n",
      "------counter :39-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.40046103e-02 -9.53978393e-01  7.84792881e-02 -2.67215378e-01\n",
      "  3.11590190e-01 -1.26962461e+00 -8.61059412e-01  1.15985330e+00\n",
      "  1.25284442e+00  5.91534075e-01 -1.88585270e-01 -1.09687358e-01\n",
      " -6.87294158e-01 -1.22231338e+00 -5.05497763e-01 -7.78855973e-01\n",
      "  3.12361875e-01 -8.58549537e-01  3.10445544e-01  2.46098997e+00\n",
      " -8.45953301e-02 -4.47694441e-01 -4.70492865e-01 -6.40985966e-01\n",
      "  1.18211248e-01  8.03019678e-02 -7.09995683e-01 -7.36370115e-03\n",
      " -1.24435352e-01  3.44657197e-01 -1.90039806e-01  1.34659460e+00\n",
      " -4.44043330e-02 -2.13641331e+00 -7.30755092e-01 -1.26423719e+00\n",
      "  8.89826247e-01 -8.04866592e-01  4.35513044e-01 -7.19963467e-01\n",
      " -1.32912413e-01 -1.60039844e-01  6.06105234e-01 -5.41144803e-02\n",
      "  4.27179679e-01 -5.34847707e-01 -4.64534394e-01  6.10491049e-02\n",
      "  2.71384203e-01  7.69324218e-01 -3.46908549e-01 -3.26023093e-02\n",
      " -1.00394734e-01  1.75778156e-01 -6.60887420e-01  1.54035963e-01\n",
      " -1.92717525e+00 -5.48860524e-03 -7.81266611e-02  9.57582927e-01\n",
      " -6.36942947e-01 -4.71740139e-01  2.34535109e+00  4.60169069e-02\n",
      "  8.47136030e-01  1.50755211e+00  1.68578252e-01 -2.15806617e-01\n",
      " -1.65143404e+00 -7.81386488e-02 -1.70080497e-01  3.36496005e-01\n",
      " -4.50894007e-01 -9.98391459e-01 -1.54115571e+00 -2.76744949e-01\n",
      "  2.71598595e-01  8.23649576e-01  3.02843177e-01  8.24541506e-01\n",
      "  1.36705719e+00  1.71712929e-01  1.55379645e+00  9.33437128e-02\n",
      " -2.31925556e-01  1.84345481e+00  5.14724787e+00 -5.63785276e-01\n",
      " -4.39102477e-01 -1.81053228e+00 -8.76445054e-01 -4.40609113e-01\n",
      "  3.83453659e+00  1.57985331e+00 -2.99427122e+00  5.76279368e-01\n",
      " -1.66971601e+00  9.40131451e-01  4.17872575e-01 -4.50082684e-02\n",
      " -6.81857639e-01  7.92983117e+00 -3.19486381e+00 -7.06976343e-01\n",
      "  1.66505668e-01 -1.15082414e+00 -6.87532787e-01  2.18431627e-01\n",
      "  7.50380688e-01 -9.70170832e-02 -3.61935103e-01 -6.21608044e-02\n",
      "  1.11720181e-01  6.98730309e-01  1.70947569e-01  8.39625971e-01\n",
      "  7.45294226e-02  3.92976411e-01  8.24953408e-01  1.35445446e+00\n",
      " -7.84149853e-02  1.18215309e-01 -1.00860713e+00 -1.04908886e+00\n",
      " -1.37740257e-01  5.08284569e-01  3.33585738e-02  1.58949718e+00\n",
      " -3.25114938e-01 -2.15639034e-01  4.69641920e-01 -3.04948736e-01\n",
      " -3.92237015e-01  2.10077009e+00  1.72613535e-01 -2.55728608e-01\n",
      " -4.27668949e-01 -8.10521482e-02 -1.53627991e+00 -2.02069433e+00\n",
      "  5.12271396e-01 -2.21666806e-01 -6.24344439e-01  4.95869027e-01\n",
      " -2.83074955e-01 -1.80911215e-01 -4.16696902e-01  3.43588731e-01\n",
      "  6.17656576e-01 -1.36189320e+00  1.08521982e-02  1.73347006e-01\n",
      " -4.77841908e-01 -7.83805955e-01  2.42242614e-01  3.28009690e-01\n",
      "  1.13501651e+00 -9.40639008e-01 -6.04272906e-01 -1.28063198e+00\n",
      "  1.12404483e+00  3.38212175e-01 -3.68556352e-01 -5.45557153e-01\n",
      "  1.66621236e-02 -8.64765802e-01  1.06096896e-01  1.15340726e-01\n",
      " -6.09591116e-01 -8.62878892e-01  8.43523250e-02 -7.08547837e-01\n",
      "  3.92449904e-02  4.60253257e-01  5.56645634e-01  4.38011779e-01\n",
      "  4.37580438e-01  2.65061635e+00  6.51236913e-01 -6.67645939e-01\n",
      "  6.89377630e-01 -3.30556876e-01 -3.17964444e-01 -5.85535572e-01\n",
      " -3.08862272e-01  1.12343354e+00 -3.60696537e-01  3.18933488e-01\n",
      " -1.34478158e+00 -6.23137054e-01 -2.26059060e-01  1.20117879e-01\n",
      " -4.01613166e-03  6.21883681e-02 -4.66182653e-01 -1.25961744e-01\n",
      " -5.49443655e-01 -1.03096914e-01 -1.41381840e+00 -4.05888861e-01]\n",
      "------counter :40-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.81269285e-01 -1.66975214e+00  1.96977596e-01 -5.45989139e-01\n",
      " -7.28592913e-01 -9.73736012e-01  1.70671556e+00  7.42110024e-01\n",
      "  3.40421315e-01 -2.60054941e-01 -6.76082475e-01 -9.28343150e-01\n",
      " -5.02438323e-01 -1.45273327e+00 -7.20161107e-01 -6.36805828e-01\n",
      "  1.15871169e+00 -1.09895307e+00 -1.37090524e+00 -2.07949927e+00\n",
      "  1.99712831e-01 -1.44832085e+00  2.11370152e-01 -1.12323119e+00\n",
      "  4.60490299e-01 -3.95433185e-02 -2.50833174e-01 -4.27861378e-01\n",
      "  3.93371143e-01  2.67158131e-01 -6.53693466e-01  1.62316052e+00\n",
      " -9.25692549e-02  1.28591601e+00 -2.37550618e+00 -1.19538660e+00\n",
      "  1.61287625e+00 -5.14074379e-01  6.88642047e-01 -1.34069834e-02\n",
      " -7.13269181e-01  2.27993051e-01  5.23175136e-01  3.85296404e-01\n",
      "  5.48993462e-01 -4.46721988e-02  1.58418195e-01 -1.43547129e+00\n",
      "  1.21506969e+00  1.08970028e+00  1.13435775e-01 -3.05731295e-01\n",
      " -5.02168820e-01 -9.11065316e-01  9.64374449e-01  2.76855016e-01\n",
      " -1.18941389e+00  8.08312010e-02  1.25169071e-01  1.26747090e+00\n",
      " -9.31558309e-01 -1.40349438e-01 -5.61087450e+00 -1.35503557e-01\n",
      "  1.72139395e+00  1.67504875e+00  3.62435924e-01 -2.74793016e-01\n",
      " -1.45869156e+00 -2.46708902e-01  6.81022907e-02 -2.04896207e+00\n",
      "  1.30828266e-01 -7.57197017e-01 -6.87795510e-01 -7.54092330e-01\n",
      "  5.51378149e-01  1.54450115e+00 -1.03292019e-01  5.28811152e-01\n",
      "  9.84782564e-01  1.51918512e+00  1.54125940e+00  5.71287736e-01\n",
      "  8.03888579e-03  1.11335892e+00  1.35837644e+00 -1.28328331e+00\n",
      "  7.31651006e-01 -1.36999201e+00  5.18310891e-01 -1.55195760e+00\n",
      "  4.24815312e+00  2.02263617e+00 -7.24556472e-01  1.18807118e-01\n",
      " -1.54790704e+00  1.42491794e+00  1.82024409e-01 -9.20795156e-01\n",
      " -5.95330799e-01  7.61517437e+00 -3.23553207e+00 -7.95765750e-01\n",
      "  2.13390964e-01 -7.01998552e-01 -4.36414486e-01  4.50672143e-01\n",
      "  2.47342538e+00 -4.06239889e-01  3.34431205e-01  1.64982612e-01\n",
      "  2.79966321e-01  1.71657517e-01 -4.59341088e-01  1.69565121e+00\n",
      "  1.71983986e-01  1.26606475e+00 -5.03513288e-01 -9.03014882e-01\n",
      "  5.20831067e-01 -2.76597761e-01 -5.38559464e-01 -9.30742175e-01\n",
      "  5.29766033e-01  8.80484913e-01  2.01108872e+00  1.05290453e+00\n",
      " -5.26206332e-02 -1.74315179e-01  2.69337539e-01 -1.38595764e-01\n",
      " -9.33229489e-01  9.51584567e-01 -1.00771739e-02  3.11565649e-01\n",
      "  8.08188618e-02 -9.46503003e-02  1.11159997e-01 -9.51755855e-01\n",
      " -1.36517030e-01  3.36615878e-01 -1.32194990e+00  5.04438339e-01\n",
      "  6.58691006e-03 -6.78675209e-01  1.50814900e-01  2.64285195e-01\n",
      "  4.34461907e-01 -4.31411039e-01  1.26059527e-01 -3.19342741e-01\n",
      " -4.10020230e-01 -1.50722040e+00 -8.29559196e-02  2.58382257e-01\n",
      "  5.19016042e-01  7.66895459e-02 -2.62137922e+00  5.16004396e-01\n",
      "  7.67243152e-01  3.58730047e-01  6.98862729e-01 -1.57991320e-01\n",
      " -6.01481088e-01  1.26385773e+00  8.70954530e-02  5.26946803e-01\n",
      " -3.26366588e-01  1.23956613e+00 -5.10240886e-01 -9.85629265e-01\n",
      " -2.77160153e-01  3.84080933e+00  7.03726589e-01  1.47534903e-01\n",
      "  7.82752801e-01  1.05625145e+00  8.21356471e-01 -6.81968629e-01\n",
      " -1.24467849e-01 -8.96903645e-01  6.88502460e-01 -1.04519670e+00\n",
      " -7.06897255e-01  5.82464128e-01 -7.18977682e-01  6.98803966e-01\n",
      " -1.25358211e+00 -5.06753037e-01 -6.24269149e-01 -2.77097941e-01\n",
      "  6.19935116e-02  1.88035988e-01  9.75947041e-02  9.95504229e-02\n",
      "  3.87597740e-02 -1.72662190e+00 -9.67613393e-01 -1.00615031e+00]\n",
      "------counter :41-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.25212999 -0.21901362 -1.13393786 -0.46393458 -0.24864207 -2.09060625\n",
      "  1.84026023 -0.1934118   0.57475043  0.47388598 -0.38769002 -0.75162045\n",
      " -0.22892636 -1.4706353   0.04373288 -0.2617131  -2.02201895 -1.67907878\n",
      " -0.47300636  2.73660235  0.50685928 -1.10070025 -1.09613087 -1.06734068\n",
      "  0.18724491  0.30226769  0.13748726 -0.15762386 -0.09506826  0.05751355\n",
      " -0.49549551  1.99003398 -0.01190962  0.55084767 -0.34331695 -2.09026525\n",
      "  0.79646702 -0.37458332  1.32078357  0.3900199  -0.34107882 -0.27758955\n",
      "  0.59990462  0.2069243   0.35909234 -0.08883195  0.23690809 -1.78716862\n",
      " -0.55215919  0.82511724  1.10982226 -0.39657187 -0.71920846 -1.01253895\n",
      "  1.99451629  0.14103638  0.04596412  0.67823579 -0.98852739  1.34652124\n",
      " -0.81205543  0.48570584  3.51076742 -0.17341277  1.05147254  1.14553696\n",
      "  0.68872453 -0.52644013 -1.51340435 -0.22447528 -0.91829524  0.75986356\n",
      " -0.20813305  0.57073409 -1.1966543  -0.68056009  1.63932157 -0.94328174\n",
      "  0.35152062  0.65313555 -0.39029131  0.44698025  1.54386878  0.424796\n",
      "  0.10489626  1.94885619  1.81485369  0.40796482  0.8091535  -2.16671623\n",
      "  0.9792064  -1.36498423 -2.24193688  0.53897842 -3.83344517  0.11469568\n",
      " -1.13333405 -0.01134499  0.39158988 -0.37478099 -0.30952521  6.71821467\n",
      " -3.76774974 -0.07930284  0.8437039  -0.56009429 -0.78795436 -0.05348462\n",
      "  0.68646038 -0.03412997 -0.39598605  0.02062886  0.69432854 -0.06126399\n",
      "  0.98233977  1.02047006  0.42374069  1.48879926 -0.17244681  0.31804892\n",
      "  0.54187706  0.2084704   0.05831301 -0.98697795  0.10614931  0.47704823\n",
      "  1.44506543  0.47256105  0.41664678 -0.44324323  0.39510414 -0.13142225\n",
      " -0.05931182 -0.58569962  0.09941413  0.67552957 -1.37797027 -0.23838751\n",
      " -1.88594099 -1.32972977 -0.07731318  0.02448791 -0.26127718  1.45719768\n",
      "  0.27486929 -0.35133106 -0.21261847  0.38164424  0.24610669 -0.32575185\n",
      "  0.77630089 -0.08434517 -2.07103529 -1.61971674  0.36836488  0.37027941\n",
      "  0.71110185 -0.53601902 -2.57721139  0.28976412  1.51943059  0.67568729\n",
      " -0.66178479 -0.27275367 -0.61358674  0.10602903  0.67151232  0.58663031\n",
      " -0.13827939 -1.6678358   0.27710327 -1.72384032 -2.30185356  1.96011141\n",
      "  0.52746933  0.38980371  0.82468339  2.19162389  0.47392137 -0.76748282\n",
      "  0.30491118  0.5250746   1.09116924 -0.34538792  0.64086619  0.57628315\n",
      " -0.48084712  0.51048501 -1.14029705 -1.04580133 -0.63695353 -0.51044822\n",
      "  0.01986789  0.53088004  0.30629762 -0.66035406  0.35773051  0.71033049\n",
      " -1.13505911 -1.04478773]\n",
      "------counter :42-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.22355953e-01 -3.54855876e-01 -4.20335390e-01 -6.99296039e-01\n",
      "  2.56329374e-01 -1.83046447e+00 -1.24110344e+00 -2.14330590e+00\n",
      " -1.87405600e+00  4.00284826e-01 -3.00704735e-01 -7.84810738e-01\n",
      "  3.46113325e-01 -9.57251744e-01  8.95470308e-01 -6.59088245e-02\n",
      " -4.40618511e-01 -1.37830204e+00 -6.47007541e-01 -2.25102089e+00\n",
      " -1.11502485e+00 -1.17552971e+00 -1.02580349e+00 -1.29111204e+00\n",
      "  4.54479757e-01  3.70339138e-02  1.13329562e+00 -3.26514205e-01\n",
      "  5.62240794e-01 -8.57640877e-01 -3.35331814e-01  2.39147986e+00\n",
      "  3.71798546e-02 -1.65064854e-01 -1.88792405e+00 -1.85437546e+00\n",
      "  9.25787505e-01 -5.35980667e-01  9.18547211e-01 -2.02385247e-01\n",
      " -7.75738754e-01 -5.13261894e-01 -9.44859880e-01 -3.02506324e-01\n",
      "  5.89251169e-01 -3.52239158e-01 -4.93508629e-01 -1.64933093e+00\n",
      "  9.71172203e-02  1.68442135e+00  9.73997179e-01  1.46304406e-02\n",
      " -1.12874125e+00 -1.14414567e+00  2.25851651e-01 -3.81433198e-04\n",
      " -5.92458723e-01  8.34658955e-01 -1.45695235e+00  1.27748761e+00\n",
      "  2.60473157e-01  4.24405458e-01  4.02798344e+00 -1.06417508e-01\n",
      "  2.38348331e+00  1.26163829e+00  3.01596077e-01 -4.42790322e-01\n",
      " -2.04240015e+00 -2.13247518e-01  2.47407016e+00  1.08249748e+00\n",
      " -3.26337087e-01  9.53038980e-02 -2.82491580e-01 -3.48557850e-01\n",
      "  1.62440713e+00 -4.70859462e-01  2.58097893e-01  5.94030987e-01\n",
      " -1.32086188e+00  3.93535229e-01  2.24904678e-02  1.06224147e+00\n",
      "  6.96514735e-02  1.38301796e+00  6.28357168e+00 -8.89683934e-01\n",
      " -3.72765534e-01 -7.36961742e-01  7.78572489e-01 -1.59229660e+00\n",
      " -1.02900870e+00  1.66778142e+00 -6.82826717e-01  1.30179798e-02\n",
      " -1.11565621e+00  7.01768566e-01  1.17444988e+00 -9.53374051e-02\n",
      " -2.31542119e-01 -6.64580456e-01 -2.16112704e+00  3.32511190e-01\n",
      "  2.24158631e+00 -3.48927234e-01 -9.29432477e-01 -2.01380053e+00\n",
      "  2.65555392e-01  6.82738291e-02  1.57430664e-01  4.88438302e-01\n",
      "  6.93150759e-01  4.64793070e-01  4.01290864e-01  1.06977498e+00\n",
      "  6.00862945e-02  1.79685681e+00  1.46854657e+00  1.69222744e+00\n",
      "  9.72367805e-01  1.69614703e-01  4.73414412e-01 -7.17996889e-01\n",
      " -9.56707001e-01 -1.62623523e-01  1.59600139e+00  1.18238746e+00\n",
      "  4.98541672e-01 -7.03116612e-01  2.30456678e-01  1.43312220e-01\n",
      " -6.63539960e-01  5.36860930e-01  7.80149036e-03  7.60379061e-01\n",
      "  1.84019066e-02 -6.78689299e-01 -6.20255054e-01 -9.93981432e-01\n",
      " -8.95877787e-02  4.80334918e-01  8.10275639e-02  1.65690288e+00\n",
      "  3.24757181e-01 -5.22364335e-01  1.41592030e-01  8.32634663e-02\n",
      "  2.50432061e-01 -1.41484828e+00 -9.91699905e-01  8.54971700e-01\n",
      " -1.84389829e+00 -1.80148714e+00  4.29121672e-01  1.96239014e-01\n",
      "  1.19796659e+00  3.66524179e-01 -3.06373521e+00 -7.87047057e-01\n",
      "  1.47754314e+00  4.90566983e-01 -5.94534213e-01  1.78697514e-01\n",
      " -7.74797002e-02  3.57309837e-01  9.45683621e-01  1.36519815e+00\n",
      " -3.60883527e-01  8.52028017e-01 -9.62266810e-02 -1.72149602e+00\n",
      " -1.73655747e+00  2.16142536e+00  7.80686877e-01  3.37287193e-01\n",
      "  4.36273153e-01  1.43187540e+00  9.83075517e-01 -7.97461615e-01\n",
      "  6.12176600e-01  1.97414884e-01  5.92430849e-01 -2.68987611e-02\n",
      "  6.07943046e-01 -4.79385772e-01 -8.90919286e-01  5.73283842e-01\n",
      " -1.40217031e+00 -1.10442417e+00 -7.36597019e-01 -9.84544233e-01\n",
      " -1.23820736e-01 -5.70154253e-02  2.40003284e-02  2.22021071e-01\n",
      "  6.86085782e-01  1.20822151e-02 -4.58151510e-01 -9.00475931e-01]\n",
      "------counter :43-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.70102906e-01  4.86598821e-01 -5.25465051e-01 -3.73485259e-01\n",
      " -1.61590226e-02 -1.87818070e+00 -1.16170898e+00 -1.88457269e+00\n",
      "  4.96917057e-01 -1.07924527e+00 -7.59036925e-01  4.71367312e-01\n",
      "  1.58823722e-01 -1.05406962e+00  1.22783733e+00 -2.04017322e-01\n",
      "  9.55817070e-02 -3.06729380e+00 -2.54723148e-01  3.15317287e-01\n",
      "  1.91914373e+00 -1.45689684e+00 -1.67597687e+00 -1.53550323e+00\n",
      "  8.03274723e-01 -1.40222492e-01  1.41509574e+00 -9.63595362e-01\n",
      " -2.67511126e-01 -5.55077806e-01  7.36394803e-02  2.34094652e+00\n",
      " -5.49386606e-01  3.75712371e-01  1.74431327e+00 -1.22687926e+00\n",
      "  1.43880042e+00 -8.30367000e-01  1.22322067e+00 -2.25803423e-01\n",
      " -1.43539911e+00 -3.79184378e-01 -1.72119042e+00 -2.70820680e-01\n",
      "  1.14931572e+00 -2.84664370e-01 -1.04458570e-01 -3.90000252e-01\n",
      " -3.01776491e-01  1.83421546e+00  9.80679011e-01 -8.10899820e-01\n",
      " -8.96392710e-01 -7.66805853e-01  1.23040975e+00  3.50199725e-01\n",
      " -1.19446055e+00  3.39921226e-01 -6.71975654e-01  2.69574326e-01\n",
      " -1.31182978e+00  9.33915071e-01  1.81431530e+00 -6.82797564e-02\n",
      "  2.70582150e+00  1.57611351e+00 -6.63800058e-01 -9.66835030e-01\n",
      " -3.44436620e+00 -3.39822477e-01  2.20809941e+00  1.06667670e+00\n",
      " -5.83565390e-01 -1.65163094e+00 -1.29329321e+00 -9.42276233e-01\n",
      "  1.72532867e+00 -1.96658328e+00  3.64420312e-01  8.83635233e-01\n",
      " -8.60571310e-02  1.42697281e+00  1.53578501e-01 -1.06250942e-03\n",
      " -1.11692984e-01  1.97890187e+00  4.64524936e+00 -1.61446689e+00\n",
      " -6.94710895e-01 -1.84671581e+00 -7.10524969e-01 -1.05854210e+00\n",
      " -8.47149029e-01  8.71383495e-01  3.40395042e+00 -7.58536237e-01\n",
      " -1.71628976e+00  6.01386917e-01  1.06421611e+00  6.99613469e-02\n",
      " -1.11438199e-01  5.02946813e+00 -2.68969880e+00  1.39218705e-01\n",
      "  2.29165940e+00 -7.28294056e-01 -7.82427726e-01 -3.25956120e+00\n",
      "  1.42243603e+00 -9.88420388e-01 -1.65602347e-01  4.29532514e-01\n",
      "  3.58895349e-01  6.13783822e-01 -1.76729181e+00  8.83107575e-01\n",
      "  5.12421250e-01  1.02111936e+00 -2.48509681e-01  1.95583736e+00\n",
      "  9.23774051e-01  7.29750237e-01  3.60644900e-01  2.17236324e-02\n",
      "  2.86313500e-01 -8.18052650e-01 -3.35318558e-01  9.88840481e-01\n",
      " -1.56173239e-01 -1.71906856e+00  2.42973444e-01 -1.99332083e-01\n",
      " -2.63345820e-02 -6.01869286e-01  5.68071083e-01  8.66398154e-01\n",
      " -2.82150973e+00 -7.37694047e-01  1.47672380e-02  7.08736253e-02\n",
      " -1.06525250e+00 -5.40203590e-01 -1.51269755e-01  1.86613241e+00\n",
      " -1.75607406e-01 -8.46039475e-01  1.59797918e+00  8.34177094e-02\n",
      "  7.82205908e-01 -2.86978551e-02 -9.54478961e-01 -1.69935634e-02\n",
      " -1.35753879e+00 -1.23833565e+00  8.17220081e-01  5.82096228e-01\n",
      "  1.03670122e+00 -4.50480598e-01 -1.77830961e+00 -1.54902827e-01\n",
      "  5.11958002e-01  1.34796214e-01 -1.82466911e+00 -1.43456094e-01\n",
      " -2.83509863e-01  2.52736906e-01  1.23983779e+00  3.81423570e-02\n",
      "  6.29131075e-02  1.10002822e+00  2.74625847e-01 -1.84854684e+00\n",
      " -1.94027895e+00  3.92054806e+00  9.74000131e-01  1.96148401e-01\n",
      " -2.88463716e-01  2.61832476e+00  1.26173338e+00 -6.74775066e-01\n",
      "  1.60811250e-01  5.07337796e-01  9.82150605e-01 -2.11731211e-01\n",
      "  1.15609257e-01 -2.57805474e-01 -5.89307584e-01  3.82081668e-01\n",
      " -1.36360092e+00  3.38086209e-01 -8.40261333e-01  1.06011912e+00\n",
      " -1.38759470e+00  7.39212460e-01  5.18649753e-01  9.00153395e-01\n",
      "  1.05870563e+00 -1.54451092e+00 -2.37104184e-01 -1.10944687e+00]\n",
      "------counter :44-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.14979846  0.73996865  0.4408667  -0.55080444 -0.03636543 -2.07041222\n",
      " -1.35098767  0.09247736  1.9078382  -0.63089622 -0.80882518 -0.40114296\n",
      " -0.62188037 -1.03985568  0.89545575 -0.36893636  0.07752468 -2.14744196\n",
      "  0.35432073  0.77852868  0.18039386 -0.90021053 -1.16017083 -0.81362943\n",
      "  0.39222335  0.2646097   1.93782378 -0.23238916  0.88128666 -0.22460819\n",
      " -0.65322888  2.73233277  0.16781544  0.72756071 -1.31347729 -0.65436303\n",
      "  0.17846294 -1.29662026  1.82870588  0.03379041 -0.63661639 -0.56351885\n",
      " -0.87288085 -0.06857612  1.54905276 -0.24990872 -0.03230311 -1.13740423\n",
      "  0.1721416   2.05294855  1.94572977  0.26497359 -2.02824753 -1.11289904\n",
      "  0.13608567 -0.39499643 -0.35252923 -3.14923892  1.0515083   0.43689001\n",
      " -1.42204531  1.38723009 -4.50376205 -0.08793188  2.87687496  2.08135453\n",
      "  0.90626619  0.69744423 -2.23064926  0.35307595  1.68758255  0.3129687\n",
      " -0.27891529 -2.48048628  3.0696537  -0.28100104  1.08268442 -1.12596295\n",
      "  0.83038289 -0.36757221 -0.23056321  0.82121987  0.77196697  0.86322315\n",
      " -0.16465389 -0.9640238   2.03931303 -1.03452633 -1.26414544 -2.99109224\n",
      " -0.81332053 -1.2618207  -0.88539876  1.0837606  -5.93079838  0.01240741\n",
      " -1.59693722  1.19709244  1.39710285  0.70687342 -0.23440847  4.76157222\n",
      "  0.49696694 -0.17706451  1.76038974 -0.89516833 -0.78189185 -3.29398789\n",
      "  0.07519521 -0.97454467  0.52408503  0.86603634  0.2748546  -0.25189157\n",
      " -2.29050867  1.61620473  0.60301686  1.55633828  1.60161337  0.0420908\n",
      "  1.2521332   1.03218543  1.1280963  -0.41071906 -1.54748342 -1.63583672\n",
      "  0.73790264 -0.13103738  0.10239426 -0.93004596 -0.09378483  0.30684379\n",
      "  0.43484575 -0.52895993  0.70916443  0.53883088 -0.65253487 -0.43436878\n",
      " -1.63845319 -0.57098031 -0.43602622 -0.42154234 -0.81371379  2.19594003\n",
      " -0.12205118 -0.14583418  2.02423131  0.00978533  0.73592198  0.0547175\n",
      " -0.18806898 -0.31431576 -2.2668287  -0.87827988 -0.2955059   0.87039278\n",
      "  1.19066129 -2.53593257 -0.72911416 -0.14157506  0.45316996  0.83498932\n",
      " -1.10440794 -0.30821425 -0.16648933  1.28727468  1.69033789  0.12982878\n",
      "  0.29627941  1.24255356  0.30749423 -0.40687299  0.1439404   0.77483643\n",
      "  0.88583819  0.44573486  0.99785371  0.5635484   1.85474237 -0.98077118\n",
      " -2.58781126 -0.49027233  1.50102377 -0.07277404 -0.03772971 -0.1011587\n",
      " -0.47074298  0.49260793  1.17609535 -0.58558271 -0.65433753  0.30668049\n",
      " -0.02104296  0.10491813  0.27481647  1.25691814  1.34693929 -0.47898327\n",
      "  0.14733227 -0.54713533]\n",
      "------counter :45-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.14380951e+00  6.36422786e-01  1.54627609e-01 -5.04726160e-01\n",
      "  8.26866171e-02 -9.99395853e-01 -1.40909784e+00 -4.34759114e-01\n",
      "  2.88522141e+00 -8.90782920e-01 -4.15569432e-01 -7.01694142e-01\n",
      " -6.50390998e-01 -1.79613655e+00  2.39583276e-01  2.16017767e-01\n",
      " -5.38848767e-01 -3.22613133e+00 -9.11579204e-02 -8.37672779e-01\n",
      "  2.10674569e+00 -9.54826353e-01 -8.71379420e-01 -9.14709478e-01\n",
      "  6.63681629e-01  1.49892408e+00  1.33644945e+00  2.52442084e-01\n",
      "  2.24452345e-01 -2.76391500e-01 -5.23260686e-01  2.33018896e+00\n",
      "  3.44587539e-02 -8.28886016e-01  1.37339604e+00 -1.10222850e+00\n",
      "  1.57835831e+00 -5.62445017e-01  1.85555285e+00 -6.86458468e-01\n",
      " -1.63750190e+00 -4.22196285e-01 -6.88325660e-01 -9.88618132e-01\n",
      "  1.77056395e+00 -3.08913977e-01  1.31367571e-01 -6.38947755e-01\n",
      " -3.44158370e-01  1.68440796e+00  1.54502378e+00  2.18603800e-01\n",
      " -1.90046230e+00 -1.25048787e+00  8.22417743e-01 -6.44800396e-01\n",
      " -4.59936790e-01 -2.80449790e+00  9.89292445e-01  9.23647105e-01\n",
      " -1.97897929e-01  1.02264208e+00 -2.85285543e+00 -1.26544382e-01\n",
      "  3.46295959e+00  3.02302155e+00  1.77341817e-01  3.84756928e-01\n",
      " -1.95624657e+00 -1.30283399e-01  1.03945941e+00  4.60416160e-01\n",
      " -3.27807298e-01 -2.34796343e+00 -1.11583394e+00 -4.99228508e-01\n",
      "  8.59348622e-01 -6.06890320e-01 -1.04970208e+00  4.05516491e-03\n",
      "  3.57642664e-02  8.72010292e-01 -6.99240734e-01  1.28277463e+00\n",
      " -1.29094849e-01 -2.84008712e+00  2.02809171e+00  5.00861445e-01\n",
      "  5.19859541e-02 -2.12572564e+00 -2.65375004e-01 -9.48789387e-01\n",
      "  6.90388973e-01  1.34954394e+00 -4.08965970e+00  6.13057506e-01\n",
      "  3.38330437e-01  1.21846727e+00  1.55269496e+00 -5.01877468e-01\n",
      " -4.99088838e-02  3.04417331e+00 -1.22453363e+00 -5.05057886e-01\n",
      "  1.42041384e+00 -4.76319171e-02 -2.17194170e-01 -2.34031842e+00\n",
      "  2.15605234e+00 -8.38759152e-01  1.39638166e-01  6.40431445e-01\n",
      "  8.76279116e-01  4.12139021e-01 -1.66850651e+00  1.68973644e+00\n",
      "  4.19433480e-02  1.01981900e+00  1.53808837e+00  1.45387302e+00\n",
      "  1.07712126e+00 -5.32919224e-02  9.52967132e-01 -1.43205559e-02\n",
      " -1.88274578e-01  6.39337523e-01  1.26403909e+00 -1.94625444e-01\n",
      "  7.95383891e-02 -4.49365359e-01  1.88028254e-01  2.97834832e-01\n",
      " -5.45387323e-01  9.29717944e-01  4.00797778e-01  1.61684471e+00\n",
      " -4.16610542e-01 -4.25492273e-01 -2.76237571e-01 -9.56893077e-01\n",
      " -8.96200842e-01 -2.60316856e-01 -1.02256401e+00  1.53343119e+00\n",
      "  2.26931543e-01 -5.44113020e-01  1.60076543e+00 -7.48455633e-02\n",
      "  6.73836748e-01 -4.06681082e-01 -1.20658834e+00  1.01457624e+00\n",
      " -2.31727993e+00  7.95800334e-01  5.83706346e-02 -1.56297074e-02\n",
      " -1.33657823e+00  3.87065999e-01 -9.83380259e-01 -2.71599464e-01\n",
      "  8.45712250e-01  7.15397988e-01 -1.69143774e+00 -3.64991517e-01\n",
      " -6.72140720e-01  7.30773852e-01  1.74644586e+00 -1.95111355e-01\n",
      "  1.09115046e+00  8.45340051e-01  1.88727639e-01 -9.79523442e-01\n",
      " -2.78945159e+00  6.83349816e-01  6.16913059e-01  2.24525523e-01\n",
      "  1.47827481e+00 -2.35927440e+00  1.08218247e+00  4.68273309e-02\n",
      " -7.07936200e-01  1.17855583e-01  1.70709149e+00  7.55398070e-01\n",
      " -5.35339876e-01 -1.38542300e+00 -4.45407676e-01  7.69912690e-01\n",
      " -1.52014061e+00 -6.48199742e-01 -6.22012151e-01 -5.68092165e-01\n",
      "  1.20437169e-01  5.40521527e-01  8.98408300e-01  4.35508768e-01\n",
      "  1.22928198e+00 -2.54522972e+00  3.83248271e-01 -1.19439546e+00]\n",
      "------counter :46-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.30976708e+00  1.44063594e+00  1.13551294e+00  7.18338814e-02\n",
      "  2.31946765e-01  2.25237629e-01 -1.97217514e+00 -8.17117938e-02\n",
      "  2.44362786e+00 -9.32438922e-01  2.56840501e-01 -1.37364680e+00\n",
      "  2.64572607e-01 -8.76094346e-01  2.05336040e-01  5.83788327e-01\n",
      "  1.49170126e+00 -4.36175289e-01 -4.48088736e-01  9.03602588e-02\n",
      " -1.55919362e+00 -1.61239742e-01 -7.20704070e-01 -1.80028524e+00\n",
      "  1.19270576e+00 -3.04152840e-01 -1.82994730e-05 -9.15205574e-02\n",
      "  5.84498012e-02 -1.96156964e+00 -2.35170398e-01  1.68737198e+00\n",
      "  1.81044874e-01  3.67707590e-01 -3.35231105e-02 -1.63222492e+00\n",
      "  1.22692861e+00 -2.64168077e-01  1.46275370e+00  6.32509405e-01\n",
      " -7.67009453e-01 -7.32082322e-01  1.61135738e+00  3.32381412e-02\n",
      "  1.43237835e+00 -9.76883124e-01 -3.56035877e-01  1.03485044e+00\n",
      " -1.21480466e+00  6.95756288e-01  1.97829025e+00  4.05668756e-01\n",
      " -6.57286919e-01 -7.18194709e-01  1.70872363e-01 -1.09187000e+00\n",
      "  1.45958172e+00 -1.53412620e+00  9.14320493e-01  1.28325679e+00\n",
      " -5.86371578e-01 -3.45788561e-02  1.56122398e+00 -4.08447753e-01\n",
      "  2.88379792e-01  2.09310632e+00 -2.19392281e+00  1.28550914e+00\n",
      " -1.84384828e+00  5.55476145e-01  7.20618520e-01 -1.40825633e-01\n",
      "  3.27216463e-01 -1.65556642e+00 -1.22425784e+00 -5.50913392e-01\n",
      " -2.93647279e-01  1.01524809e+00 -1.96438472e+00 -4.12265023e-01\n",
      " -1.14492229e+00  9.05488567e-01 -1.56192874e+00  1.65709771e+00\n",
      "  2.07441850e-02  8.76049572e-01  7.40845201e-01 -1.26205118e+00\n",
      " -9.49273400e-01 -7.45575686e-01  1.03026603e+00 -6.93394839e-01\n",
      "  3.62752125e+00  1.72557930e+00 -3.33814336e+00  2.79888776e-01\n",
      "  6.02331216e-01  2.50377918e-01  6.01731436e-01 -8.33552053e-01\n",
      "  6.86510689e-01  4.33706231e+00 -2.07901439e+00 -1.09046218e+00\n",
      "  8.86966036e-01  1.45005636e+00  8.71972919e-01 -2.32865946e+00\n",
      " -8.44754754e-01  1.62524995e-01 -8.04372533e-01  3.57748884e-01\n",
      "  6.02884954e-01  1.50605668e+00 -7.05503778e-01 -6.89326857e-01\n",
      "  7.87555602e-01  7.16637509e-01 -5.39837384e-01 -2.26547556e+00\n",
      "  4.95690784e-01 -4.29114544e-01  6.66729834e-01  8.24248874e-01\n",
      " -7.78417592e-02 -1.76844628e+00  1.21425593e+00  2.01193321e+00\n",
      "  1.58184367e+00 -2.01987458e+00  9.54695507e-02 -2.27677888e-01\n",
      " -6.19709767e-01 -3.81910054e-01  6.05875093e-01  1.37850017e+00\n",
      " -1.82714863e+00 -1.25715793e+00 -6.38850875e-03  2.01837625e-01\n",
      " -1.18956804e+00  8.27841934e-01 -7.09520993e-01  1.52416071e+00\n",
      " -1.33669624e+00 -6.54656121e-01  1.73924852e+00 -1.61651430e-02\n",
      "  4.55607182e-01 -4.24901296e-01 -1.17896320e+00  1.51119995e+00\n",
      " -2.19386342e+00  3.18327148e-01  1.00001246e+00 -3.35317862e-01\n",
      " -8.24245707e-01 -1.42623993e+00 -9.13591764e-01  1.69190786e-03\n",
      "  5.38207667e-01  1.90276865e+00  1.29945178e+00  3.41430743e-01\n",
      " -6.26313328e-01  7.61177599e-01  1.27700952e+00 -1.15618785e+00\n",
      " -2.17123019e-01  8.25779572e-01  2.24637139e-01 -3.32421089e-01\n",
      " -2.34844616e+00  7.77262296e-01  2.71093068e-01  2.12701702e-01\n",
      "  1.68133219e+00 -1.52173784e+00  1.44673781e+00 -3.19618050e-01\n",
      " -8.92784107e-01 -4.75545063e-01  1.48685195e+00 -6.51023957e-01\n",
      " -1.34110031e-01 -6.46464645e-01 -6.53530932e-01  5.26237026e-01\n",
      " -1.78370447e+00 -1.85821489e-01 -9.39125226e-01 -3.60705555e-01\n",
      " -3.82662447e-01  1.18901424e+00  6.76489285e-01 -1.03372898e+00\n",
      "  6.45925645e-01 -8.45412997e-01 -4.27389516e-01 -7.78933523e-01]\n",
      "------counter :47-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.15325836e+00  1.23260855e+00  4.47363379e-01 -4.47535481e-01\n",
      " -1.82569364e-01  3.06408788e-02  3.99028600e+00  9.85613538e-01\n",
      "  1.63743444e+00 -8.84638663e-01 -6.38628516e-03 -1.51307813e+00\n",
      "  2.23326829e-01 -7.45815173e-01  1.47181687e-01 -9.60791625e-02\n",
      "  1.37164464e+00  8.80870070e-01  4.75074350e-01 -2.49875005e+00\n",
      "  1.35018699e+00  1.19624934e-01  4.07754997e-02 -6.28728899e-01\n",
      "  8.38467197e-01 -4.87466298e-01 -1.13858388e-01  7.65989604e-01\n",
      " -4.05731395e-01 -2.14210230e-01  9.37971013e-02  2.74877247e+00\n",
      "  3.30603706e-01 -2.49429810e-01 -1.55096083e+00 -1.14318371e+00\n",
      "  1.25610309e-01 -1.08966532e+00  1.12651535e+00 -9.19823356e-01\n",
      " -3.49946469e-01 -8.62805469e-01  3.20418089e-01  9.78918878e-01\n",
      "  1.03966314e+00 -4.17047889e-01 -1.28410327e-01  8.46129245e-01\n",
      " -9.20715275e-01  3.60025925e-01  7.13031063e-01  1.42083227e-01\n",
      "  1.76368559e+00 -1.71020256e-01  7.48848395e-01 -9.00981901e-01\n",
      "  1.08695795e+00 -6.66054707e-01 -1.73883256e+00  9.17028789e-01\n",
      " -4.01699438e-01 -2.55214296e-01  1.83109967e+00 -4.43207252e-01\n",
      " -2.95416847e-01  1.37812911e+00  1.59405199e+00  6.14161621e-01\n",
      " -2.03893863e+00 -3.45505577e-02  5.36113864e-01 -1.62093463e+00\n",
      "  2.05069796e-01 -1.01384520e+00 -8.08348274e-01 -6.96402934e-01\n",
      "  2.33101649e-01 -4.69427799e-01 -1.11401028e+00  5.20793318e-01\n",
      " -2.08473374e-01  1.62888030e+00 -1.37166542e+00  1.40883807e+00\n",
      " -3.15442060e-01 -2.99422617e+00 -1.29079998e+00 -2.25083092e+00\n",
      " -2.55722586e-01 -2.52265016e-01 -4.57110502e-01 -2.85953490e-01\n",
      " -1.27106486e-01 -8.40016174e-01 -1.00805076e+00  4.77365916e-01\n",
      "  6.94031452e-01  7.82282083e-01  7.59640926e-01 -9.76252773e-01\n",
      "  6.80859188e-01  4.99713659e+00 -1.83045926e+00 -5.98090663e-02\n",
      "  1.00871781e+00  1.06689171e+00  4.75713813e-01 -2.69964309e+00\n",
      " -1.53600346e+00  2.92595400e-01 -5.07383487e-01  1.94950222e-01\n",
      "  3.15742677e-01  3.64919448e-01  2.25638903e-01 -3.43397843e-01\n",
      "  2.80718100e-01  5.62511735e-01  7.00566961e-01 -4.16893964e+00\n",
      "  5.49957945e-01 -4.54045222e-01  4.37339596e-01  1.29940571e+00\n",
      " -4.41420440e-01 -2.36344414e+00  1.22519535e+00  8.37978303e-01\n",
      "  1.02403041e+00 -4.29815347e-01  7.70207394e-02 -5.23929264e-01\n",
      "  2.91920825e-03 -6.03402930e-01  5.80385594e-01  4.08186673e-01\n",
      " -6.00925002e-01 -2.83704281e-01  9.71313182e-01 -6.51369155e-01\n",
      " -8.71543186e-01  2.94405109e-01 -2.15076230e-01  1.49621747e+00\n",
      " -1.34912694e+00 -8.08779527e-01  1.42764599e+00 -7.29196131e-02\n",
      "  4.17656460e-01 -1.44928041e-01 -1.36459230e+00  1.49807266e+00\n",
      "  5.82705912e-01 -1.71664412e-01  7.01437714e-01 -6.68141052e-01\n",
      " -1.25408620e+00 -1.08742148e+00 -6.11309576e-01 -4.21928898e-01\n",
      "  8.90530460e-01  1.61802954e+00  6.94877236e-01  4.73108300e-01\n",
      " -5.51225709e-01  9.00315185e-01  8.23773742e-01 -2.58111132e-02\n",
      " -1.99711763e-02 -1.45497650e+00  5.72924413e-01 -5.24033869e-01\n",
      " -5.94840113e-01  2.63543840e+00  6.42947027e-01  3.76272980e-01\n",
      " -8.27040029e-01 -6.61766011e-01  1.14411121e+00 -5.43374759e-02\n",
      "  1.34460643e+00 -2.40256838e+00  7.88111354e-01 -3.99603820e-01\n",
      " -9.56735902e-02 -6.42447297e-02  1.17968851e-01  1.03631566e+00\n",
      " -1.86118411e+00 -8.16771783e-01 -5.25580317e-01 -7.01889803e-01\n",
      " -3.10974780e-01  1.21814815e+00  1.10393167e+00 -1.37880502e+00\n",
      " -1.03861633e+00 -7.35467346e-01  8.42988164e-02 -4.16313610e-01]\n",
      "------counter :48-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16130477  1.10726278 -0.54982137 -0.51034634  0.25069309 -1.91587488\n",
      " -1.38054593  1.18549188  2.65302099 -0.23374295 -0.65931744 -0.3379595\n",
      "  0.85457874 -0.50516207  0.71159653  0.32034199 -0.47487775  0.47881055\n",
      "  0.77886298 -0.68973918  1.58920295 -0.0380264   0.25861183 -0.44574514\n",
      "  0.75238345 -0.8981104   0.71354592 -1.06999318 -0.71586158 -0.22053464\n",
      "  0.36230519  2.55566508  0.40340728 -0.38703118 -2.92333437 -0.83974257\n",
      " -0.59864869 -1.30954393  0.81689014  0.79918712  0.1739107   0.12227302\n",
      " -0.37339899  0.01036619  1.12852422 -0.38305537  0.84908921  0.25868443\n",
      " -1.10213484  1.05581941  0.80145663  0.1455851   0.25597549 -0.40935315\n",
      " -0.28242049 -1.0516349   0.04760809 -0.41057772  1.93205635  0.68117707\n",
      " -0.4415187  -0.24846846  1.4824275  -1.833812   -0.06550023  1.40707367\n",
      " -1.1387974   0.77247894  0.34706042  0.46402456  0.41203247 -1.33260839\n",
      "  0.95622213 -1.85658665  0.3562104  -1.28710941  0.87953356 -1.24102088\n",
      " -0.27805106 -1.32640689 -1.84531295  2.17959346  0.21794441  1.72772331\n",
      " -0.74464368 -1.44008758 -0.28840314 -2.91181707 -0.83265965 -0.24822687\n",
      "  0.13017978 -0.72929145 -0.54747233 -0.8458197  -0.79346727  0.73379758\n",
      "  0.3192199   0.89868353  0.73741744 -0.89586166  1.24132218  4.36735962\n",
      " -2.69829023  0.23134429 -0.05524997  0.69367687  1.56879493 -2.10715532\n",
      " -1.52633393  0.21200327 -0.30093071  0.5832771   0.06741269  0.31741063\n",
      " -0.413239   -0.2566887  -0.07461636  0.43253917  1.62624517  0.10764939\n",
      "  1.34408579 -0.10833755  0.67703769  0.56900392 -0.50948756  1.99986029\n",
      " -0.08273198 -0.53053764 -0.77145703 -1.35054397  0.2176801  -0.74390855\n",
      " -0.78739808  1.18145948  0.66792782  1.57529811 -0.29343228  0.88252007\n",
      " -0.34423337 -0.68961461 -1.23420567 -1.29741612 -0.27554652  2.09431038\n",
      " -0.0739816  -1.02589074  0.02145898 -0.72831572  0.53040313  0.16757306\n",
      " -0.21368389  0.52788142 -0.90719204 -0.86037169  0.431214   -0.14142532\n",
      "  0.07469497 -1.19781288  3.48005022 -0.12843111  1.28034731 -2.51386413\n",
      " -0.99605448 -1.00759267 -0.11508242  1.50736066  1.06759164 -0.53832485\n",
      " -0.44305496 -3.11661113  0.0280036  -0.3298389  -0.06545336  0.77293514\n",
      " -0.40436055  0.69230087  0.72626409 -1.54631176  0.39537241  0.34645073\n",
      "  1.81807212 -0.29276133  1.86624661  0.05827568 -0.8922045  -0.19825374\n",
      "  0.00689951  0.73547218 -0.76501208 -1.02429852  0.06535599 -0.48730007\n",
      " -0.16961353  0.14465854  0.79893053 -1.3017403  -0.24178346  2.03767176\n",
      "  1.5542405   0.03619844]\n",
      "------counter :49-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.82341206  3.17906784  0.16180229 -0.85590207 -0.68947319 -0.79397181\n",
      " -0.39354425 -0.53220735  1.05873904 -0.38904921 -0.29771989 -0.26014903\n",
      "  0.36520497  0.06179031  0.46400705 -0.57872184 -0.29301251  1.55588009\n",
      "  0.3914231  -4.99278869 -0.86202153 -1.26149123  0.11809893 -1.08888412\n",
      " -0.14724813 -1.06322135  0.53977134 -0.90410298 -0.4645787   0.28438636\n",
      " -0.28727825  2.86037083 -0.41365406 -0.77426912 -2.03448722 -0.99730439\n",
      " -0.10650054 -0.83508467  0.34572187  0.62270664  0.42867433 -0.13951476\n",
      "  1.08070378  0.3615079   0.67758614 -1.3764696  -0.12384476  0.21270189\n",
      " -1.12482551 -0.57344316  0.32631186 -0.20067634  0.03132764 -0.17678285\n",
      " -1.18607454 -0.51723684 -0.51280094  0.19913254  0.94942511  0.3599827\n",
      "  0.1385981  -0.0112009   1.90347233 -1.46476726  0.47870266  0.12527457\n",
      " -1.37256883  0.73128881 -0.77032947  1.51617729  0.33536666  0.46004402\n",
      "  0.39898403 -1.22698791  1.99166998 -1.35610354 -0.14150428 -0.12434064\n",
      "  0.0973954   0.35230407  0.10559505  1.6074492   0.00929802 -0.59765831\n",
      " -0.82018924 -0.12713624  0.71008833 -2.36897558 -0.56254003  0.05747387\n",
      "  0.37200345 -0.35866009 -2.30171835 -0.41292568 -1.35555754  0.71635187\n",
      "  0.07609093  0.66499963  0.51195251 -0.02899208  0.88750371  4.81754558\n",
      " -0.23845053  0.31418337  1.85456776  0.0903268   0.69426351 -1.47721207\n",
      "  0.74530816  0.32222716 -0.72844329  0.35061954  0.01996513  0.16779787\n",
      "  0.25013724  0.57236048  0.23929129  0.53101788  1.21348892 -0.41171361\n",
      "  1.01068463  0.69428616  0.61800412  0.09687973  0.02439051  3.43423337\n",
      " -0.22696058 -0.12517273  0.70939212 -1.29950639 -0.52229727 -0.36584462\n",
      " -0.1468909  -0.68167413  0.72971053  0.7806524   0.29212347 -0.27616148\n",
      "  0.97550579 -1.49102348 -1.4960099  -0.86923485  1.4217873   1.2728009\n",
      " -0.45783451 -0.41806179 -0.04531541 -0.34873113  0.46476928  0.50717664\n",
      "  0.14061269  0.20911244  0.91021343 -0.88776267  0.80932418  0.10402977\n",
      " -0.21919024 -0.40304048  1.41518487  0.05256274  1.07801944  0.48945018\n",
      " -0.21860948 -0.8307308   0.10968163  1.13297963 -0.10032561 -0.58040175\n",
      " -0.85282583 -0.381052    0.19744716 -0.74328764  0.09121104 -4.35203884\n",
      "  0.48316841  0.27382477  1.51860431 -0.34276657  0.28911046 -0.41374638\n",
      "  1.19797034 -1.64782382  0.87765652 -0.08853579  0.09065188  0.38351641\n",
      " -0.00929105 -0.19494488  0.65562747 -0.95041575 -0.13342293 -0.97219158\n",
      " -1.24012131  0.96001408  0.66448437 -1.04934433 -0.11243032  1.09029433\n",
      "  0.20965377  0.29042919]\n",
      "------counter :50-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.26958641e-01 -1.06165729e+00 -4.50866691e-01 -1.08878297e+00\n",
      " -8.30356837e-01 -9.11643138e-01 -1.11934184e-01 -1.15322017e+00\n",
      "  1.22780213e+00  2.43330196e-01  1.08831104e-01 -1.30624901e-01\n",
      "  6.54180163e-01  1.84909265e-01  3.57773995e-03 -3.41201744e-01\n",
      " -1.10149606e+00 -2.10596439e+00  1.35730253e+00 -3.40065355e+00\n",
      "  9.57651337e-01 -4.15907382e-01  4.26338390e-01 -8.40390997e-01\n",
      "  4.96948200e-01 -1.02412407e+00  4.69291210e-01 -2.73509863e-01\n",
      " -3.31748916e-01  1.77657027e-01 -2.86578700e-01 -3.64648216e+00\n",
      " -1.00506728e-01 -5.87365114e-01  6.82977796e-01 -1.44787059e+00\n",
      " -6.76635909e-01 -2.09923685e+00  1.62025685e-01  9.13322004e-01\n",
      "  1.83906252e-01 -8.70724598e-01  1.78940223e+00 -1.41956274e-01\n",
      "  1.06848412e+00 -8.86670804e-01  1.95167462e-02  4.22880091e-01\n",
      " -9.66866434e-01 -2.37891332e-01 -3.62747352e-02  2.55049622e-01\n",
      "  6.67194559e-01 -6.94187098e-02 -1.20984885e+00 -1.11770325e+00\n",
      " -4.01068555e-01  1.40468218e+00  5.76975526e-01  7.90790257e-01\n",
      "  5.43331474e-01  9.14945539e-01  1.88244731e+00 -1.28728506e+00\n",
      "  2.72456116e-01  2.36521383e-01  3.05104331e-01  1.55061766e-01\n",
      " -1.44202761e+00  1.92188474e+00 -3.45940348e-01  1.70005538e+00\n",
      "  7.85089111e-01 -7.64363016e-01 -1.47659457e+00 -1.01866074e+00\n",
      " -3.29332538e-01 -5.39210860e-01  5.62089883e-01  1.00153724e+00\n",
      " -1.20433398e+00  5.42970208e-01  4.35027556e-01 -1.78237958e-02\n",
      " -8.96357431e-01 -4.06830561e+00  1.08269349e+00 -2.18056459e+00\n",
      " -7.23794244e-01  6.28927662e-01  1.73822691e-01 -1.58667282e-01\n",
      " -1.11654240e+00  2.83234090e-01 -1.27385471e+00  1.66541131e+00\n",
      "  1.22672785e-01  8.33103728e-01  1.04672026e+00 -2.03253350e+00\n",
      "  1.03313320e+00  2.68655458e+00 -7.30853084e-01  6.22558690e-01\n",
      "  1.55589705e+00  3.48882903e-02  2.08677019e-01 -1.88252272e+00\n",
      " -5.18087157e-01  1.10242376e+00 -6.91458974e-01  2.44049475e+00\n",
      "  3.73357706e+00 -3.16895955e-01 -1.52192680e+00 -3.30038255e-01\n",
      " -1.93961033e-01  6.72518748e-01  4.01622947e-01  1.26052190e-01\n",
      "  9.57182938e-01  1.37042580e+00  8.03877495e-01 -3.50509544e-01\n",
      "  2.89089217e-01 -2.40550496e+00  3.91000913e-01  3.24818928e-01\n",
      "  5.29676868e-01 -1.46617035e+00  2.25643601e-01  8.29579101e-01\n",
      "  2.51950799e-02 -8.10180558e-01  1.42336082e+00  8.30890789e-01\n",
      " -3.10114883e-02 -2.26710191e-01  1.43495887e+00 -8.92149674e-01\n",
      " -1.26854698e+00 -8.13534288e-01  2.57826485e-01  2.33056024e+00\n",
      " -5.45362162e-01  3.38829099e-01  4.80808443e-01 -2.82197884e-01\n",
      "  6.65887784e-01  7.15033778e-01  4.57288237e-01  5.35555548e-01\n",
      " -2.18239488e+00 -8.49564590e-01  8.04508623e-01  3.96171643e-01\n",
      "  3.48986432e-01 -1.05826162e+00  6.84800876e-01  1.24583213e-01\n",
      "  1.53688537e+00  2.98615867e-01 -9.17309295e-02  2.31771264e-02\n",
      "  6.48285155e-01 -5.38344928e-01  5.33906400e-01 -7.24239134e-01\n",
      " -7.59874452e-01  2.49470735e-01  5.18924541e-02  1.90239444e-02\n",
      " -3.48401829e-02  2.15694174e+00  9.88654298e-01  3.96668551e-01\n",
      "  1.64332875e+00 -1.76433940e+00 -3.30602310e-01 -3.18459517e-01\n",
      " -2.30848442e-01  2.28478413e+00  8.58050497e-01  3.59615533e-01\n",
      " -1.98793729e-01 -5.23609579e-01 -5.74478199e-02  2.61533811e-01\n",
      "  1.42851897e-02 -9.03165066e-01  4.04001088e-01 -5.75781456e-01\n",
      " -5.64702278e-01  8.52671854e-01  6.99728314e-01 -1.24949972e+00\n",
      "  5.59663912e-01 -1.26706884e+00  3.87924808e-01  8.43424285e-01]\n",
      "------counter :51-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0691137   3.93397951 -1.67851945 -1.03198852 -1.05788694 -0.01820801\n",
      "  1.78905683 -0.58070824 -0.60335338  0.25743173  0.66453022  0.3149451\n",
      "  0.46492988  0.31513967 -0.79262083 -0.4680376  -0.83253838  1.71284043\n",
      "  1.27347795  0.15296731 -0.46454332 -0.15531844  0.3031453  -0.73657594\n",
      "  0.24724382 -0.53707013  0.8170094   0.64353815  0.12773704  0.54534086\n",
      "  0.44685658 -3.50894589  0.10572716 -0.30938923 -0.6111811  -0.47579059\n",
      " -1.13446372 -0.99770865  0.52201366 -0.87622611  0.22701551  0.82345757\n",
      "  0.45891551  0.16108364  0.70330864 -1.76721454 -0.2785372  -1.70350985\n",
      " -1.19191466 -0.40135756 -0.07001202 -0.27034389  0.24282766  0.15514692\n",
      " -1.59462849 -0.80753455 -0.56861305 -0.75385077 -0.91942391  0.94945435\n",
      "  0.52714746  0.12214123  2.70812645 -1.52565881  0.77791324  0.22401841\n",
      "  0.46549131  1.42487748 -1.95477648  1.4521312  -0.29727851 -1.45407783\n",
      " -0.46768003 -0.43711488 -0.40486552 -1.32483368  0.0692817  -1.93420244\n",
      "  1.18837557  1.43505142 -1.16023709  4.80365192  1.01457087  1.80812525\n",
      " -1.00575944 -1.06675047  0.75298223 -1.97831676 -1.08555737  0.35037122\n",
      "  0.401854   -0.11717488 -2.04795483  1.51669274 -0.75430772  1.36399711\n",
      " -0.64161736  0.90591419  1.01794056 -0.16032007  0.809309    2.63480091\n",
      " -1.46751246  0.15780635  1.32098606 -0.45836081 -0.18279666 -1.85358838\n",
      " -1.23796121  0.71384487 -0.3974027   2.15546526  0.32684046 -0.12884524\n",
      "  0.354736    0.23780381  0.10838273  1.22343741  1.02750337 -0.2349552\n",
      "  0.40363383  1.43559699  0.86626923 -0.5091186   0.18670519 -1.94024556\n",
      "  0.61035671 -0.06771776  0.62083311 -0.99423953  0.17858235  1.01954114\n",
      " -0.98780353 -1.57803089  1.13958954  0.31285898 -0.04954987 -0.5148156\n",
      "  1.1470546  -0.94345158 -1.32314073 -0.48202905  0.88390367  2.36558859\n",
      " -1.79745835  0.80202737  0.43797887 -0.76209584 -1.01504551  0.56414998\n",
      "  0.72656537  0.36904253 -0.20975267 -0.84375588  0.63720348  0.04679421\n",
      "  0.1208057  -1.52472923  0.54627715  0.09094306  1.94318577  1.09285647\n",
      " -1.40887258 -0.03462734 -0.348301    0.02703163  0.88438451 -0.89869064\n",
      " -0.95344441  0.40656468  0.21707932 -0.5908723  -1.18711497 -1.82023253\n",
      "  2.09452432  0.5515347   0.39808614 -0.73635052 -0.07564756  0.19226279\n",
      " -0.30659508  0.68388711  1.1900611   0.37748802  0.23799871  0.45165816\n",
      "  0.05308018  0.42017309 -0.19768465 -0.98862832 -0.06534207 -0.84363519\n",
      " -0.69593105  0.89884984 -0.94062817 -1.13139068  0.72981922 -0.93951661\n",
      " -0.18432576  0.81432749]\n",
      "------counter :52-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22667982  1.1500769  -1.40762619 -0.59940136 -0.98720502 -0.37028912\n",
      "  0.67782916 -0.62847845  1.44077176  0.53917482  0.82485256 -0.43242427\n",
      "  0.27368465  0.52371472  0.5185165  -0.24759774 -1.21453709 -0.32354558\n",
      "  1.1098864   0.73676195 -0.08254206  0.35654625 -0.03050169 -1.58610453\n",
      "  0.62702889 -0.86692097  0.97854178  0.25880391  0.07131739  0.27049262\n",
      "  0.37067321 -3.00678856  0.02460808 -0.49596892 -0.08891477 -1.25972549\n",
      " -0.40706784 -1.48787803 -0.17635612 -1.53973079  0.53098355 -0.20182651\n",
      "  0.48289934  0.14604877  0.59318841 -1.04979397  0.09655079 -0.45460326\n",
      " -1.04257206 -0.0944839   0.01492551 -0.24147661 -0.95631329  0.59270756\n",
      " -1.56611998 -0.4371164   0.65800778 -1.42286148  0.06859246  0.96741385\n",
      "  0.1974352   0.40572999 -1.16166628 -1.23010213  0.56665703 -1.01840045\n",
      "  0.38671872  0.87938736 -1.66433352  0.50658418  0.41270135 -0.54207611\n",
      "  1.20086647 -0.55033932 -0.44813896 -1.77762568  0.74681698 -0.84513416\n",
      "  1.39292972  1.79092949 -0.26114056  0.27852083  1.36609466  0.20419658\n",
      " -0.83223591 -3.28378436  0.70913795 -2.5372152  -1.94888299  0.04677496\n",
      "  0.71812629 -0.10065009 -3.09789022  1.10256874 -1.35833435  0.77733981\n",
      " -0.29748674 -0.06399903 -0.94214311  0.24556769  0.26874511  3.24509048\n",
      " -0.6267214   0.88647038  1.05518931 -0.05138923  0.06319714 -0.83034104\n",
      " -1.46065492  1.09780827 -0.91267253  0.06468908 -0.38771705 -1.5588976\n",
      " -0.6653194  -0.24012244  0.58750859  1.07314155  0.76330378  1.46547474\n",
      "  0.64585289  1.38677076  1.39241015 -0.56800504  0.00407929 -1.12159596\n",
      "  0.49765614  0.25471647  0.04644202  0.20199974 -0.12770017  0.23781377\n",
      " -0.33696464 -0.44997498  1.09606996  0.37464341  0.02225511  0.11702355\n",
      " -0.84301495 -1.00690002 -1.36120952 -0.22133232  0.89161962  2.3382494\n",
      " -1.38314416  1.03608181  0.61945704 -0.53554987 -0.17820808  0.24271868\n",
      " -0.28734348  0.95704184  0.01244649 -0.22186518  0.13884247  0.51910524\n",
      "  0.03070769 -2.35892934 -0.49153592  0.2353998   2.16626829  2.55002047\n",
      "  0.26496157 -0.67945812  0.56435594  0.28192826  0.67187628 -0.84011185\n",
      " -0.30752437 -0.75704774  0.23397949  0.71161515  0.11999513  1.93852394\n",
      "  2.23811837  0.14372387  1.40954167 -0.03638831 -0.49323814 -0.15858409\n",
      "  0.82636744  0.97265215  1.6414963   0.37380189 -0.31251822  0.789733\n",
      "  0.48127779  0.37735914  0.22011359 -1.89706577  0.05011824 -0.84316002\n",
      "  0.25312877  1.12374275 -0.09462495 -0.84480055  0.95154761 -1.3907655\n",
      "  0.30278304  0.95533279]\n",
      "------counter :53-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.25113600e-02  4.59370857e-01 -1.48177821e-01 -1.16027877e+00\n",
      " -9.09051021e-01 -1.72446747e-01  4.13720464e-01  3.07890517e-01\n",
      "  1.98560623e+00  5.13216146e-01  7.99498856e-01 -5.79365858e-01\n",
      " -2.74265946e-03  3.70323692e-01 -1.56246451e+00 -2.13395937e-01\n",
      " -1.09862444e+00  8.04280524e-01  1.12862625e+00  1.40823167e-01\n",
      " -8.64160234e-01  1.11263862e+00 -1.57090951e-01 -1.38341539e+00\n",
      "  3.03047332e-01  1.69759936e-01  4.68383954e-01 -3.64471452e-01\n",
      " -1.36496046e+00 -2.27757880e-01  4.12700137e-01 -2.57811345e+00\n",
      "  1.76311884e-02 -4.02620947e-01 -3.44833744e+00 -9.61225167e-01\n",
      " -2.41866635e-01 -1.66015821e+00  4.18770632e-01  5.56863927e-01\n",
      "  4.17808498e-01 -6.25555247e-01 -9.61132753e-02 -5.82568405e-02\n",
      "  5.41440514e-01 -5.52701135e-01 -1.82435130e-02 -6.61070250e-02\n",
      " -1.69677102e+00 -2.75117337e-03  3.16623151e-01 -1.76851381e-01\n",
      " -5.65074774e-01 -2.43498547e-01 -1.78690995e+00 -9.79264472e-01\n",
      " -1.94891294e-01  1.39346664e+00 -9.93550178e-01  8.26593371e-01\n",
      "  2.92779521e-01  6.11759099e-02  1.31314065e+00 -1.58731442e+00\n",
      "  7.09946650e-01 -3.97907503e-01  5.19446198e-01 -6.84565044e-01\n",
      " -1.23806029e+00 -6.02350146e-01 -4.75207450e-01 -1.88576233e-01\n",
      "  4.90970179e-01 -6.65767362e-01  8.43475868e-01 -1.68944851e+00\n",
      "  6.40366946e-01 -1.27794939e+00  8.03447680e-01  1.64394576e+00\n",
      "  8.15713313e-01  1.04842471e-01  1.55438917e+00  4.15610736e-01\n",
      " -8.17764344e-01 -2.87073243e+00 -3.04703651e-01 -2.32391638e+00\n",
      " -2.50211737e+00  3.93220843e-01 -4.89613259e-01  1.62259426e-01\n",
      " -2.02495799e+00  6.32818482e-01 -1.80353338e+00  7.72429352e-01\n",
      " -7.53860954e-01  2.18587922e-01 -1.12513342e+00  6.60475231e-01\n",
      "  3.75839926e+00  2.52790425e+00  1.73575378e-01 -1.91597042e-02\n",
      " -9.93815088e-01 -2.88462000e-01 -2.62278118e-01 -5.62829182e-01\n",
      "  1.21904351e-01  1.47370498e+00 -9.92761573e-01 -3.01020609e-02\n",
      " -6.90812693e-01 -1.59695113e-01  8.18222008e-01 -1.78419441e+00\n",
      "  5.73370061e-01  1.26442921e+00  9.94682617e-01  7.42732627e-01\n",
      "  1.25476988e+00  2.43259993e+00  1.53248128e+00 -6.21538045e-01\n",
      " -8.04665340e-01 -7.24717986e-01  1.16611891e+00  2.25253045e+00\n",
      "  6.63216354e-02 -3.14098459e-01  1.13158381e-01  4.11253115e-01\n",
      " -4.06394402e-01 -1.82532337e-01  9.39121815e-01  3.91449747e-01\n",
      "  3.17502562e-02  2.20067593e-01 -1.03604458e+00 -9.71718874e-01\n",
      " -2.03031586e+00 -7.34407492e-01  4.08223948e-01  2.52340588e+00\n",
      " -2.24542198e+00  1.05152812e+00  1.12815371e+00 -4.83281623e-01\n",
      " -3.89220447e-01  3.90902746e-01  9.83719836e-02  3.82235859e-01\n",
      "  1.56130763e+00 -7.79181842e-01  2.45500649e-01  4.29639531e-01\n",
      "  3.67659885e+00 -2.06318503e+00 -6.80978888e-02  5.03444735e-01\n",
      "  2.08572608e+00  1.98196051e+00 -2.63733459e-01  2.90036356e-02\n",
      "  6.97572972e-01  5.11318721e-01  6.86958960e-01 -1.57291141e-01\n",
      " -6.16809045e-01  6.61347347e-01  1.43417595e-01  5.12487480e-01\n",
      " -3.64544287e-02  2.08421728e+00  1.92469549e+00 -1.57168906e-01\n",
      "  8.20164369e-01 -1.05211438e+00  4.85837554e-02 -2.04844168e-01\n",
      " -2.09679554e-01  6.41228737e-01  1.32719395e+00  1.02376816e-01\n",
      " -1.75585381e-01  8.90688930e-01  3.77149427e-01  2.58986973e-01\n",
      " -2.73528408e-01 -2.43554790e+00 -1.45914120e-01 -1.48167445e+00\n",
      "  1.82157847e-01  8.39352152e-01  2.73356468e-01 -1.69347076e+00\n",
      "  1.10819089e+00 -1.91981851e+00  2.89493053e-01  7.15182968e-01]\n",
      "------counter :54-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.63865291  -1.92339564  -1.23935773  -1.36574252  -1.61270119\n",
      "   0.48421726   2.63060446  -0.67057939  -1.21237344   1.28263199\n",
      "   1.59155412  -0.33299034   0.18191217   0.51827207   0.45150712\n",
      "  -2.17429804  -3.13212336   0.83626385   2.58907258  -1.88098478\n",
      "   0.40936962   1.80674022  -0.58250322  -3.12045391  -0.19561377\n",
      "  -0.07637028  -3.70737639  -0.12505163  -1.61142128   0.73439866\n",
      "  -0.25020931 -14.12275141   0.09911942   0.74355506  -5.19968152\n",
      "  -0.96382473  -0.97103022  -2.01974711   0.49756665  -0.68032369\n",
      "   0.95240624  -1.00773438  -0.53502071  -0.51711297   0.89886695\n",
      "  -0.61286195  -0.46927522  -0.17658527  -2.88681595  -1.16987967\n",
      "  -0.51617253  -0.88295262   0.50719224   1.25441585  -1.96518418\n",
      "  -1.47186636   1.07706377   1.3153254   -1.21501238  -0.34146151\n",
      "   0.65283349  -4.09723595   2.22697429  -1.61453713   0.39804798\n",
      "  -0.92042189   0.55110147  -0.9747654   -2.00440547   4.10944594\n",
      "  -2.88681345   0.58835026   1.07602917  -2.74760213  -1.40655534\n",
      "  -1.676905     0.32656849  -3.28393147   1.06819796   4.17331563\n",
      "  -0.76848921   1.16097139  10.29407809  -1.39760649  -1.53141944\n",
      "  -3.40714569   4.30685481  -3.11596856  -2.96456322   1.22390907\n",
      "  -0.20817739   0.47451951  -1.07561556   2.57540303  -3.62706681\n",
      "   1.91333008  -0.87946829   0.40906153  -6.89120423   1.96488025\n",
      "  12.64992423   6.33760577  -0.34349837   0.72394155  -2.20408404\n",
      "  -0.77273882  -2.21552897  -1.25932661   1.81155675   2.09681227\n",
      "   1.25012993   3.66287901  -0.70037657   0.62245475   2.07958967\n",
      "   2.86027547  -0.29325737  -3.45455251   1.12441068   0.75144324\n",
      "  -0.05149975   4.81831849   3.6791946   -0.41005782  -0.69395453\n",
      "   0.5506712    0.48688284   0.08211149  -2.30044815  -1.74794129\n",
      "  -0.93690936   1.45082932  -0.87383062  -1.76745812   2.58274916\n",
      "   0.16613324  -1.18993263   0.0756451   -0.3333889   -3.27524841\n",
      "  -0.7235166   -0.47499549   0.13008782  15.99986859  -3.35525709\n",
      "   2.78248759   0.74542114  -2.03118967  -1.57096765   1.18414976\n",
      "   0.54395987  -1.2804639    0.70210101  -2.71046007  -0.86901704\n",
      "   0.73081191   9.074987    -0.92886686  -1.56537587   0.11605722\n",
      "   1.99203239  -2.0880815    3.40558844  -0.42494968   1.29577155\n",
      "  -1.22498345  -0.79715395  -1.21466086   0.0332093    1.01342121\n",
      "  -0.50949668   0.41335723   0.22555664   2.95239962   5.50847465\n",
      "  -0.29848054   4.49456164  -1.16323973   0.46341723   0.11476923\n",
      "   1.99746879   2.489118     0.09727306   0.94532917   0.34170018\n",
      "   1.39286215   0.18922023  -0.06216452  -4.52977365  -2.57461515\n",
      "  -0.95004953  -2.61885422  -0.61792893   0.44427314  -2.78896274\n",
      "  -2.05095871   2.54382362  -2.40033492   1.37817245   1.74500475]\n",
      "------counter :55-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33908255 -2.73343074  5.0274254  -0.84830724  1.91983755 -0.99622849\n",
      " -0.2923974   2.58607851  2.34827731  0.43849791  0.48113844 -0.39062959\n",
      "  1.07817951  2.43400974 -2.02107927  3.647156    6.96700012 -2.48058502\n",
      " -0.67657576 -3.03274669  4.13138269 -1.11537167 -1.11083105 12.58560932\n",
      " -1.80325017  3.06654712  0.27862184 12.29798437 -1.3780326  -3.18517728\n",
      " -0.97889615 -3.50064346 -1.44726927  3.09348914 -3.58725813  0.46870636\n",
      " -1.37319909  1.66937774 -3.8318574   2.32215505 -2.13744533  2.30241391\n",
      "  3.31103152  0.07047597 -1.24320259 -0.61713493 -2.8774098   5.15049832\n",
      "  1.36214709 -1.26330174 -3.59619239  2.14710884 -2.07162181  0.25568037\n",
      " -0.97383436  1.41261286  0.20819482 -1.76664726  3.0447853  -3.07871232\n",
      "  0.1536743  -0.58943616 -0.78281699 -0.30888602 -0.46361106 -0.34998513\n",
      "  0.17523367 11.3984265   5.83097771  0.89541092 -2.15308435 -8.33037712\n",
      "  0.94067833  2.61100525  4.11237407 -2.8952579  -0.58813363 -1.74877579\n",
      " -0.68805404 -2.36157174  5.0450335  -1.84532299 -5.73031489  0.16730269\n",
      " -0.56685898 12.32878978  3.58537589 -0.62964058  0.4136085   0.29763716\n",
      " -2.33114904 -1.15265588  3.90600322 -1.06854662  3.18635356 -1.92613495\n",
      "  0.48618984 -2.12536601 -0.71587862 -1.03458481  0.56014094 -1.9987302\n",
      " -2.76652814 -6.20071936  0.47265378  1.58334216 -6.43305944 -1.73429984\n",
      " -2.89438121  0.2057389   1.7331114  -0.72442244 -0.57099646 -4.81148689\n",
      " -0.75075141  6.1730527  -2.67386498 -2.07663581  2.65658399 -0.80416472\n",
      "  1.86903845  0.01715871 -1.64721803  0.45917425  1.04651723  5.33396993\n",
      " -1.80771976 -1.57846849 -0.38395449 -1.06319911  1.17019645 -1.23774441\n",
      " -0.75365202  1.99508715  0.46877754 -0.35827392  3.91033107 -1.98925797\n",
      " -1.82669811 -3.63792636  1.12417098 -1.51625555 -1.91669171  2.3789651\n",
      "  1.12195333 -0.53732326 -2.78758913 -0.22320388  0.25595475 -2.16263122\n",
      "  0.44890391 -0.59835528  0.86011076 -4.14890586  1.69584939 -0.6229638\n",
      " -2.43254586 -2.49550766 -1.26453359 -1.51593511 -1.63049972  2.04962347\n",
      " -1.54872448 -3.53971975  5.21592621 -2.53584123  0.08781368 -3.64399845\n",
      " -1.11212263  4.418709   -0.68223568  4.13277661 -6.2079607  -0.41542592\n",
      " -0.18865734 -0.51020619 -2.12322547 -3.42282026  4.91267371 -0.49570113\n",
      " -1.05922859  0.41897167 -4.73060303  0.56333117  2.96563905 -1.78836584\n",
      "  0.11424221 -1.56735675  1.11435578 -1.72881245 -0.69741141 -1.52944177\n",
      " -3.83782126  0.03177333  0.12014315  0.71629363 -0.1247899   8.84046335\n",
      "  0.16167914 -0.52150083]\n",
      "------counter :56-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.97118107e-02  2.54217904e+00  3.10689594e-01 -5.37755936e-02\n",
      " -1.58291945e-01  5.04250911e-02 -1.16967974e+00 -3.23783427e+00\n",
      " -3.25736950e+00  2.45873219e-01  7.68701825e-01 -2.75751053e-01\n",
      " -3.52313616e-01  1.70351373e+00 -2.51199666e+00 -5.87416033e-01\n",
      "  6.45586160e+00 -2.77432993e+00 -3.32424441e-01  5.67129077e+00\n",
      " -5.28407142e-01  6.09690833e-01 -1.83131466e-02 -1.01201524e+00\n",
      "  1.13148798e-01  8.09152587e-01 -5.04720854e-01 -6.47243070e+00\n",
      "  1.97310733e-01  2.38529578e+00  6.79186946e-01 -2.87704818e+00\n",
      " -9.42631073e-01  3.91981816e-01 -3.05620758e+00 -1.62599282e-01\n",
      " -8.89892239e-01 -1.97803976e+00 -7.52108250e-01  1.24435773e+00\n",
      " -4.55738627e-02 -1.64272724e+00  1.51965947e+00  2.55576156e-01\n",
      " -4.25599994e-01 -1.36328041e-01  3.35127994e+00  4.51660726e+00\n",
      "  7.77659972e-01 -1.26982396e-02 -1.08665730e+00 -2.25714434e-01\n",
      " -1.67372950e-01  2.25187072e-01 -3.44475978e+00  2.73760926e-03\n",
      " -7.80143634e-01 -9.15137729e-01  2.18360106e+00 -2.94937490e+00\n",
      "  2.72132276e+00 -9.02878530e-01  7.83969970e-01  4.22607785e-01\n",
      " -2.51096640e+00 -1.34950994e-01 -2.95680134e-01 -7.20018741e-02\n",
      "  6.07179559e-01  1.02773294e+00 -2.69169419e+00 -6.77332593e-01\n",
      " -4.30130100e-02  1.13523104e+00  2.16661558e-01  8.88945554e-01\n",
      " -5.91168130e-01 -2.72771745e+00  1.09532230e-01  3.41967954e-01\n",
      "  3.43477319e-01 -1.32534227e+00 -4.74987913e+00 -8.16942378e-01\n",
      " -4.13078536e-01  5.68991863e+00  2.25692545e+00  2.62450220e+00\n",
      "  2.32974643e+00 -1.23706170e+00 -7.42298395e-01  3.08058758e-01\n",
      "  4.36397122e+00 -5.30405369e-01 -9.14184613e-01 -6.08873695e-01\n",
      " -9.02236722e-01  4.07261930e-01 -1.06172503e-01 -5.94026895e-01\n",
      " -1.46525038e-01 -2.09748805e+00 -3.87316877e+00 -1.09187082e+00\n",
      "  1.50232864e-01 -2.22057924e-01 -3.05829601e+00  4.50971616e+00\n",
      "  3.69728370e+00 -2.15902969e-02  4.03149153e-01 -3.52489101e-01\n",
      " -4.35049666e-01  2.73510613e+00 -1.70920278e+00  4.52303517e+00\n",
      " -3.91171848e+00 -5.05057111e-01  1.97892360e+00  7.48376806e-01\n",
      " -6.86406438e-01  1.76462380e-02 -8.93802398e-01 -4.84835951e-01\n",
      " -8.28206836e-02  2.13425276e+00 -1.60853097e+00  6.36747908e+00\n",
      "  2.88760715e-01 -5.26880792e-01 -1.43605596e-04  6.86730916e-01\n",
      "  1.83930107e+00 -3.98156215e-01 -1.41240316e+00 -4.88425421e-01\n",
      "  1.48590722e+00  5.36321827e-02 -2.98835553e-01  1.47989126e+00\n",
      "  6.58924208e-01  7.72535304e-01  6.84292049e-01 -6.02137648e-01\n",
      "  1.15208828e-01 -3.71596207e-01 -2.95081738e+00  3.49529346e-01\n",
      "  9.75199738e-01  1.19693999e-01  6.47139491e-01 -6.01044781e-01\n",
      " -7.40081516e+00  1.12040517e+00 -4.07293657e-03  1.95610973e+00\n",
      " -4.49934191e-01  1.11375739e+00  2.19233192e+00 -3.88679482e-01\n",
      " -2.56973143e-01 -8.00108889e-01  2.53903524e+00  2.35781487e+00\n",
      "  7.24946130e-01 -1.65833280e+00 -7.58521797e-02  1.22781271e+00\n",
      " -1.21649602e+00  1.34016134e+00  1.21105239e-03 -3.36353669e+00\n",
      "  1.20317219e+00  2.98374128e-01  2.60920087e-01 -5.14489262e-01\n",
      "  2.49623801e-01 -1.61199454e+00 -1.39981730e+00  2.32981762e-01\n",
      " -6.96828480e-01  3.84629434e-01 -1.53798958e+00 -3.53028020e-01\n",
      " -4.50998048e-01  3.55914863e+00 -3.14596363e-01 -4.43629044e-01\n",
      "  7.41736552e-01 -1.40725406e+00 -3.35010998e-01 -8.17236505e-01\n",
      "  6.90314929e-01 -4.77560698e-01 -3.90266577e-01  6.36690978e-01\n",
      "  8.87454585e-01  8.34501104e-01 -1.29564084e+00  3.32731060e-01]\n",
      "------counter :57-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.62056515e-01 -9.38829189e-01 -3.84881650e-01 -5.73144846e-01\n",
      "  3.64408434e-02  1.12586720e+00  8.77498176e-01  2.27847264e+00\n",
      " -4.10395014e+00  2.07047152e-01  6.99634906e-01 -1.08746629e+00\n",
      " -7.02666670e-02  2.41000579e-01 -1.09494218e-01 -1.69576998e-01\n",
      "  5.76477920e+00  1.86817483e+00 -2.39037086e-01  5.98173780e+00\n",
      " -5.28020285e-01  4.92698028e-01  2.12524097e-02  3.30453787e-01\n",
      " -5.04839715e-02 -4.86639896e-01 -8.24589647e-01 -3.80823787e+00\n",
      " -7.63494141e-01  1.06271622e+00  4.10636878e-01 -2.52585601e+00\n",
      "  7.51459439e-02  1.29050509e-01 -2.81830066e+00  4.90978266e-01\n",
      "  1.68052212e-01 -1.21323242e+00 -4.63068139e-01  8.11217631e-02\n",
      "  4.52566379e-01 -2.20747066e+00  3.58258082e-01 -2.56502218e-02\n",
      "  2.19334669e-01 -1.08666565e+00  3.20950921e-01  1.11083900e+00\n",
      " -9.39042459e-01 -4.75110079e-02 -7.54969610e-01 -1.67985972e-03\n",
      " -3.70831094e-01 -5.74608553e-03 -2.37524012e+00  3.88829832e-01\n",
      "  7.15443424e-01  1.04058943e+00  9.03515807e-01 -2.25823529e+00\n",
      "  1.84459836e+00 -4.47824650e-01  6.35451495e-01  3.65913669e-01\n",
      " -1.91331926e+00  7.56171993e-02 -1.50051908e+00 -4.87571292e-01\n",
      " -3.48177122e-01  5.51498759e-01  2.17289572e+00 -5.00732234e-01\n",
      " -3.10546742e-01  9.74696812e-01  8.95835822e-01 -1.61093649e+00\n",
      " -5.00841149e-02  3.10194183e+00  2.37513773e-01  1.99656431e-01\n",
      " -3.94255301e-01 -9.17797910e-01 -1.97681822e+00 -8.77065276e-01\n",
      " -4.15923940e-01  2.00047692e+00  3.89566699e+00 -5.42496163e-02\n",
      "  7.22177059e-02  1.99978007e+00  1.84576619e+00 -6.10390294e-01\n",
      " -3.93096450e+00 -3.77842613e-01  2.29389070e+00 -3.70539544e-01\n",
      "  3.34764108e-01  9.34540709e-02 -2.41144024e-01 -2.29322068e-01\n",
      " -1.90960159e-01 -1.51497228e+00 -2.84369530e+00 -3.18292931e+00\n",
      "  1.39213135e-01 -2.14725801e-02 -1.21682004e+00  5.05806546e+00\n",
      " -7.40099808e-01 -2.50660612e-01 -1.41440371e-01  1.68675932e-01\n",
      " -6.56383836e-01 -3.78774734e-01 -7.30614164e-01 -4.50669627e-01\n",
      " -1.29637327e+00 -6.83872500e-01  3.56798983e-01  4.62263120e-01\n",
      " -3.48978868e-01  3.78876021e-02 -1.08528660e+00 -1.64149293e-01\n",
      "  8.35820619e-01 -3.93019675e-01 -1.17657183e+00  2.09369191e+00\n",
      "  2.00875561e-01  9.08909159e-01 -2.29831464e-01  1.80364504e-01\n",
      "  5.23823027e-01  8.92115311e-01 -1.50825141e+00 -8.93401690e-01\n",
      "  8.54879239e-01  3.59092357e-01  2.53821953e+00  6.40633500e-01\n",
      " -1.85320515e-01  2.64607200e-01 -3.89535015e-01 -1.40002444e+00\n",
      "  2.55500204e-01 -1.17929694e-02 -3.66600034e-01  2.37962648e-01\n",
      "  4.43973572e-01 -3.47982402e-01  9.01655523e-02 -5.79145630e-01\n",
      "  7.46877918e+00  9.28692314e-01  1.06132996e-01  1.85876545e+00\n",
      " -6.88634199e-01 -8.55397164e-02  2.48479761e+00 -2.47711926e+00\n",
      "  1.95321088e-03 -3.82152335e-01  1.86412619e+00 -7.09269966e-02\n",
      "  3.55611754e-01 -1.41535824e+00 -1.66091429e-01  6.07297602e-01\n",
      "  1.48414926e-01  2.86090105e-01 -3.21065989e-01  2.40199034e-01\n",
      "  1.00319835e+00 -3.74827094e+00 -3.69834025e-01 -7.49242997e-01\n",
      " -2.85938328e-01 -2.25705803e+00 -6.61257416e-01  2.74179254e-01\n",
      "  3.97648263e-02  6.33516811e-01 -1.44795244e+00 -6.65265994e-02\n",
      "  6.37875147e-01 -1.82172997e+00  7.25794338e-02  1.02997179e-01\n",
      "  1.73509542e-01 -1.29041119e+00  4.08447072e-01 -5.79759212e-01\n",
      "  1.33456579e+00  1.97141380e-01  7.50270587e-02 -2.06290894e-01\n",
      "  7.45428769e-01  6.84061577e-01 -8.41463754e-01  2.26420130e-01]\n",
      "------counter :58-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.38040405e-02 -6.14377661e-01 -3.22901393e+00  6.12122380e-02\n",
      "  3.30590258e-01 -1.90388549e+00  7.76574122e-01  1.67119936e+00\n",
      " -2.88767980e+00  1.65303320e-01  7.34589374e-01  5.43808327e-01\n",
      " -1.53520234e-01  2.48192904e-01 -4.29875637e-01 -1.69226959e-04\n",
      "  8.70244276e-01  6.15693755e-01  4.35650169e-02 -1.45159245e+00\n",
      "  3.82946507e+00  6.82467436e-01  5.83327919e-01  9.88659372e-01\n",
      "  5.43791859e-02 -2.56600364e-01 -6.86367567e-01 -1.05172825e+00\n",
      "  3.33099139e-01  6.49351254e-01  4.89319087e-01 -3.25776884e+00\n",
      "  3.89053519e-01  9.81290492e-01 -1.60566725e+00  4.88820348e-01\n",
      "  8.07509507e-02 -8.48212420e-01 -4.18730095e-01 -9.19211776e-01\n",
      "  9.71343885e-02 -1.27211794e+00 -5.73232233e-02  9.80804328e-02\n",
      " -3.18504440e-01 -3.96070768e-01 -1.35322394e+00 -4.87314438e-01\n",
      "  1.85443930e-01  1.01204996e-01 -8.16422503e-01  6.47594532e-01\n",
      "  1.40073224e-02  1.30803385e-01  3.37872017e+00  1.57608112e-01\n",
      "  6.35556735e-01 -1.06548736e+00  1.48815584e+00 -1.01634165e+00\n",
      "  8.23338813e-01  5.08706263e-02 -1.03647741e+00  3.72970492e-01\n",
      " -1.25933724e+00  1.82157669e-01 -2.78095589e-01  9.77131555e-02\n",
      "  1.99717848e-01  1.98839613e-01  2.56840513e+00  2.46552779e-01\n",
      " -3.92608141e-02  1.21000712e-01  4.13761176e+00 -1.25969566e+00\n",
      "  3.08200589e-03  1.61860505e+00 -9.40671753e-02 -7.82080733e-02\n",
      "  9.11747526e-01 -5.30406770e-01 -1.75232206e+00 -4.88308048e-01\n",
      " -1.13400474e-01  2.27664932e+00  1.22297288e-01 -6.11899030e-02\n",
      " -2.38722374e-01  1.22109734e+00  1.21824020e+00  1.06406633e-01\n",
      " -3.35540720e+00 -3.39612960e-01 -1.60218842e+00 -1.00548072e-02\n",
      "  2.64872663e-01  2.74818018e-01 -1.39086046e-01 -3.31894431e-01\n",
      "  6.66239803e-03 -1.57033615e+00  2.73734191e+00 -4.54844187e-01\n",
      "  5.21260835e-01  2.85284723e-03  3.30405592e-01  3.20722305e+00\n",
      " -2.30993427e+00 -1.63325472e-01  3.35536769e-01  7.64754223e-02\n",
      " -5.42855757e-01  8.28632978e-01 -9.38777159e-01  2.92193850e-01\n",
      "  6.93096136e-01 -2.41260237e-01 -7.48455585e-02  3.07513405e-01\n",
      " -8.21665563e-02  1.92109519e-01 -1.22924306e+00  3.15900892e-02\n",
      "  1.02041987e+00 -2.02047640e+00 -7.50323924e-01  2.17257040e+00\n",
      " -2.98032003e-01  7.13073430e-01 -5.01219832e-01  5.53097477e-01\n",
      "  6.85857606e-01  7.00454629e-01 -1.14870232e+00 -5.97940394e-01\n",
      "  1.26962030e+00  3.89402492e-01 -1.00852353e+00  1.11427941e+00\n",
      "  6.43360815e-01 -8.42322281e-02  1.68535900e-01 -1.05897392e+00\n",
      "  1.25718203e-01  4.82168208e-02 -4.25603774e-02  6.18434188e-01\n",
      "  3.16939027e-01 -1.69203835e-02  6.91592179e-01 -7.03824826e-01\n",
      "  3.58800346e+00  9.51546812e-01  2.71195195e-01  8.24736835e-01\n",
      " -3.54004979e-01 -7.69936675e-01  1.54181012e+00 -2.02410798e+00\n",
      "  7.30189041e-02 -3.81189583e-01  1.33278088e+00 -9.70821932e-01\n",
      "  1.50411313e-01 -1.31843279e+00 -3.68979853e-01 -7.85648273e-01\n",
      "  1.93438455e-01  3.51745978e-01  5.89860816e-01 -4.36884505e-01\n",
      "  1.05943450e+00 -3.82051289e+00 -4.36645746e-01 -2.45419590e-01\n",
      "  3.04077738e-02 -4.02748199e-01 -1.24929458e+00 -8.84999314e-02\n",
      "  3.76033284e-01  9.70030099e-01 -1.42177185e+00  4.21616262e-01\n",
      " -2.46871456e-01 -2.36677129e+00  1.93763072e-01  5.43953264e-01\n",
      "  4.10057926e-01 -2.33435448e+00  5.45174453e-01 -5.10887821e-01\n",
      "  7.45932616e-01 -1.12968147e-01 -3.64936279e-01  4.45896492e-03\n",
      "  4.88778660e-01  7.97939831e-01 -6.30381545e-01  8.96693392e-02]\n",
      "------counter :59-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.16843086e-01 -1.08093754e-01 -1.31499208e-02 -4.57001475e-01\n",
      " -6.90489574e-01 -2.09220526e+00 -6.68879928e-02 -5.81244179e-01\n",
      " -2.63250542e+00  4.10416037e-02  4.21234084e-01 -6.74938000e-01\n",
      " -1.96123056e-01 -3.32209985e-01 -1.98548776e+00  5.49267456e-02\n",
      "  4.63643862e-01  2.77510323e+00 -4.02155814e-01  5.07840445e+00\n",
      "  2.37369599e+00  6.04462132e-02 -1.19068455e-02  6.17751096e-01\n",
      "  4.88203513e-02 -4.70529744e-01 -6.33415006e-01  1.87918569e+00\n",
      "  7.50189975e-01  6.20723229e-01  1.93847825e-02 -5.23442135e+00\n",
      "  3.16722413e-01 -1.30365254e+00 -7.25480442e-01  2.24967217e-01\n",
      " -1.31319149e-02 -2.26925462e-01 -5.53516727e-01 -4.10336741e-01\n",
      " -7.90642484e-01 -9.34439886e-01  3.23034289e-01  4.76941273e-02\n",
      " -5.93599515e-02 -9.79579000e-01  7.79187675e-01  4.65920539e-01\n",
      " -8.53675903e-01  1.27607368e-01 -6.36376148e-01  7.30504705e-01\n",
      "  2.25294432e-01  1.24038444e-01  3.00425526e+00 -1.56751731e-01\n",
      "  5.88415222e-01 -2.32997151e+00  1.80024314e+00 -9.93268590e-01\n",
      " -5.98705697e-01 -1.73774210e-01 -2.21349486e+00  1.45605168e-01\n",
      "  4.16435911e-01 -3.15169329e-02 -1.85647175e+00  4.89884584e-01\n",
      " -1.02621547e+00  4.66259801e-01  6.37766152e+00  1.71777135e+00\n",
      " -4.77594273e-01  1.04840262e-01 -2.48457935e+00 -1.39519667e+00\n",
      " -8.72935937e-02  1.01532806e+00 -2.32742352e-01 -3.24299422e-01\n",
      "  2.43892853e-01 -7.70647894e-01 -1.53640510e+00 -1.31710182e+00\n",
      " -1.69415098e-01  2.99440225e+00  1.88205536e+00  6.75561721e-01\n",
      " -6.83856677e-01 -1.52725643e+00  1.80498933e+00 -1.43004245e-02\n",
      " -8.40281714e-01  4.70764385e-01 -1.14617498e+00 -4.64251335e-03\n",
      " -6.88641405e-01  8.19016542e-01 -4.67854080e-01 -4.11043314e-01\n",
      " -1.09137894e-01  2.88869008e+00 -6.20877557e-01  9.68720117e-01\n",
      "  3.02078209e-01 -3.37290485e-02  9.82222495e-01  3.78187573e+00\n",
      " -7.17170931e-01 -5.32348596e-01 -3.13746695e-01 -2.98041252e-01\n",
      " -5.68635498e-01  1.11526207e-01 -1.63510314e+00  9.42285084e-01\n",
      "  1.95026400e-01 -9.90274513e-01  4.78825248e-01 -3.82063082e-01\n",
      " -3.35221998e-01  4.97394352e-02 -1.01228549e+00 -2.98219391e-01\n",
      "  1.08777695e+00  2.73462503e+00 -1.14439275e+00  1.09593879e+00\n",
      " -1.00331189e-01 -2.52891108e-01 -2.84326795e-01  1.27234445e-01\n",
      "  5.23515449e-01  1.60989457e+00 -7.80297466e-01 -7.13008623e-01\n",
      "  1.26815501e+00 -1.56406669e-01 -3.10201126e+00 -5.77587905e-01\n",
      " -1.73632376e-01  1.54503442e-01  8.62970241e-01 -1.56870191e+00\n",
      "  2.56347913e-01 -8.75729297e-02  8.55300538e-01  1.51816531e-01\n",
      "  2.18650137e-01  2.22337372e-01  9.23776920e-03 -8.44663083e-01\n",
      " -1.04754828e+00  9.43247897e-01  1.58377689e-02  1.43641220e+00\n",
      " -5.16753379e-01  1.33689899e-01  2.71210942e+00  7.90111623e-01\n",
      " -3.44476455e-02 -1.02387677e+00  1.91931273e+00 -5.54061235e-01\n",
      " -1.19547221e-01 -2.20620996e+00 -4.98213676e-01  9.63684483e-01\n",
      "  3.26990884e-01  4.98149319e-01  9.77333144e-01  1.84891648e-01\n",
      "  9.96428371e-01 -2.48245873e+00 -1.15599715e+00 -7.66564745e-01\n",
      " -2.90599469e-01  2.02618130e+00 -4.86212288e-01 -2.70798373e-01\n",
      "  1.66188143e+00  1.43689859e+00 -1.37197480e+00  2.45006186e-01\n",
      " -4.49414380e-01 -7.31640273e-01 -1.85760810e-02  4.68192112e-01\n",
      "  6.47243875e-01 -2.40312569e+00  5.36073143e-01 -1.64429555e-01\n",
      " -1.43566214e+00 -8.61569105e-02 -4.36491682e-01 -4.22079456e-02\n",
      "  6.78138871e-01  5.92918091e-01 -1.12559993e+00 -4.93146832e-01]\n",
      "------counter :60-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.17567014e-01 -9.10255449e-01 -1.03135017e-01 -6.47718028e-01\n",
      "  1.56656078e-01  6.35705766e-01  8.68234679e-01 -9.92373774e-01\n",
      " -3.90265878e+00  1.13915838e-01  3.14989970e-01 -1.47286519e-01\n",
      "  1.14504124e-01  3.72343316e-01 -1.54787719e+00  6.43739471e-01\n",
      "  2.78653811e+00 -1.88157219e+00 -5.24361038e-01 -5.35536860e-01\n",
      "  2.71914352e+00  1.05543377e-01 -6.00929410e-03  7.89863043e-01\n",
      "  2.25241588e-01  5.89829937e-01 -8.02565366e-01 -9.52937730e-01\n",
      "  1.25901153e+00  7.36321892e-01  5.15464572e-01 -4.28969919e+00\n",
      "  1.79837899e-01  6.39127423e-01  8.95886808e-01  5.46911599e-01\n",
      " -7.70680862e-01 -2.15251494e-01 -9.78816859e-01  1.95719232e+00\n",
      "  7.32267944e-01 -7.22439466e-01 -3.96976891e+00  5.16140087e-01\n",
      "  6.87725594e-01 -5.16672175e-01 -6.17795899e-01  6.56117432e-01\n",
      "  1.52077723e-01  1.05130748e-01 -5.01775209e-01  1.44669927e-01\n",
      " -1.09375541e+00  5.50429959e-02  1.60488900e+00  8.95234778e-02\n",
      "  3.70454726e-01  5.68959947e+00  1.16818246e+00 -1.31102761e+00\n",
      " -1.81573428e-01 -1.31567651e+00 -3.17507256e+00  2.51896510e-01\n",
      " -1.18446393e+00 -7.65049340e-01 -1.54004857e+00 -1.31138314e+00\n",
      "  7.41076374e-02  4.62252654e-01  4.81545778e+00  1.21159634e+00\n",
      " -7.36739940e-02  3.78894679e-01  1.56177128e-01 -2.50238088e-01\n",
      "  5.36806607e-02  1.30085322e+00  6.26419258e-02 -2.75916693e-01\n",
      "  8.70426023e-01 -1.47444173e-01 -1.02090993e+00 -1.25940598e+00\n",
      " -3.84961256e-01  1.67561480e+00 -2.80631919e-01  1.73939741e+00\n",
      " -5.32690276e-02 -2.41158145e+00  1.43708649e+00 -4.35970824e-01\n",
      "  7.50274279e+00  7.79343086e-01 -1.27166634e+00 -1.38953875e-01\n",
      " -5.06051128e-01  1.48638487e+00 -4.75214502e-01  3.39697122e-02\n",
      " -2.90077453e-01  1.54725335e+00 -1.54987186e+00  9.69099149e-01\n",
      "  1.75147202e-01 -8.98190406e-02  8.10660650e-01  3.64277673e+00\n",
      " -1.29855831e+00 -8.81832632e-01  4.40223880e-01 -2.22521428e+00\n",
      " -6.87651152e-01  2.91282898e-01 -1.14281419e+00  4.82928572e-01\n",
      " -5.16619731e-02 -3.05186410e-01 -8.69401208e-01 -9.06617580e-02\n",
      " -4.54282816e-02  5.12874947e-02 -7.70886407e-01 -3.94966820e-01\n",
      "  4.60560491e-01  2.82528380e+00 -1.03416871e+00  1.76115811e-01\n",
      "  6.87230258e-02  3.42265910e-01 -1.09842809e-01  7.14018795e-02\n",
      "  5.24756755e-01  1.99105805e+00 -2.38403167e-01 -9.19889396e-01\n",
      "  7.98748960e-01  2.63138516e-01 -1.66298245e+00 -8.47289231e-02\n",
      " -1.10961972e-01 -4.27513068e-01  2.35116462e-01 -1.71941800e+00\n",
      "  8.97640010e-01 -2.40173074e-01  4.48830951e-01  6.09345663e-01\n",
      "  3.96774357e-01  3.39706506e-01  3.62943992e-01 -4.63274817e-01\n",
      " -8.91220971e-02  1.36781020e+00  8.97127056e-02  2.07072098e-01\n",
      " -3.11957449e-01 -1.50191796e+00  3.24247970e-01 -1.53242996e-01\n",
      "  1.87098596e-02 -2.20590870e+00 -1.74279055e+00 -3.72002164e-01\n",
      " -1.67768270e-01 -1.37690057e+00  7.61121530e-02  1.00501970e+00\n",
      " -3.36567545e-01  4.40855746e-01  2.20961450e-01 -3.96794758e-01\n",
      "  1.26745899e+00 -3.73174385e-01 -6.71847627e-01 -9.41114568e-01\n",
      " -2.03114781e-01  1.39376002e+00 -8.55932925e-01  4.17215621e-01\n",
      " -3.42339117e-01  1.80002895e+00 -1.32473598e+00 -2.78636564e-01\n",
      "  6.88965049e-01 -1.06232782e+00  1.27407702e-01  3.90415504e-01\n",
      " -7.05500439e-01 -2.06317162e+00  4.36130576e-01 -1.51235353e-01\n",
      " -2.66814856e-01  4.08376113e-02 -2.38494340e-01  2.40270864e-01\n",
      " -2.07607169e-01  1.04025211e-01 -1.14290865e+00  3.97574225e-01]\n",
      "------counter :61-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.34277586e-01  2.19759289e-02  3.64495015e-01 -5.55393071e-01\n",
      "  9.37682433e-02  4.25603579e-02 -7.48422844e-02 -1.07227536e+00\n",
      " -3.44153175e-01  1.16574779e-01  8.58089282e-04 -2.20821270e-01\n",
      " -1.94095870e-02  2.01657769e-01 -4.53904395e-01  4.10415746e-01\n",
      "  4.52980867e+00 -1.59725886e+00 -4.12971084e-01 -4.44389437e-02\n",
      "  2.53909854e+00  3.05807288e-01  6.08214605e-01  7.19124417e-01\n",
      "  1.99445366e-01  2.88129427e-01 -9.06080339e-01 -9.99958038e-01\n",
      "  1.03448668e-01  9.13765537e-01  2.43986290e-01 -3.74224519e+00\n",
      "  2.48928566e-01  7.72872588e-01  1.09591434e+00  8.62813156e-02\n",
      " -2.56994461e-02  7.05357465e-02 -1.00135151e+00 -1.42099335e+00\n",
      "  7.43526584e-01 -7.18090828e-01 -5.71623273e-01  5.03472774e-01\n",
      " -2.25197110e-01  1.36879495e-01 -4.27610424e-01  1.26575431e-01\n",
      "  2.67893034e-01 -5.25687728e-02 -7.60605566e-01  8.93755568e-02\n",
      " -1.23396417e+00 -5.78332781e-02  2.46146664e+00 -5.91243307e-02\n",
      "  7.85569610e-02  4.47732854e+00  7.10025631e-02 -1.60295058e+00\n",
      " -1.02542029e-01 -7.98933245e-01  7.09109917e-01  2.25633699e-01\n",
      " -4.09111373e-01  1.05103071e-01 -1.28195473e-01  2.39953768e-02\n",
      " -1.73146050e-01  7.56976081e-01  4.41336049e+00  7.76515006e-01\n",
      " -9.22934333e-02  2.81401434e-01 -1.15504136e+00 -4.27797427e-01\n",
      " -1.06031976e-01  2.84200318e-01 -2.84372214e-01 -5.03373436e-01\n",
      "  1.14410433e-01 -7.84334297e-01 -9.49309639e-01 -8.66070609e-01\n",
      "  7.11356405e-02  4.65833781e+00  1.63424284e+00 -6.95974418e-02\n",
      "  5.25719785e-01 -1.30709975e+00 -4.53336052e-02 -8.44277337e-01\n",
      " -6.15271556e+00  1.03869888e-01 -1.01191976e+00 -1.80310581e-01\n",
      " -3.53759791e-01 -7.91679248e-01 -3.96023565e-02 -1.45685097e-01\n",
      " -4.87806222e-01  2.01499931e+00  1.42253121e+00 -9.94992281e-01\n",
      "  5.76716394e-01 -2.22495645e-01  1.04251194e+00  2.75131128e+00\n",
      " -1.09026264e+00 -3.26427852e-01  2.06214250e-01 -9.28363393e-01\n",
      " -6.34832029e-01 -2.05017671e-01  1.43530072e+00  4.34338555e-01\n",
      "  1.66922953e-01 -6.40383599e-01  2.27786595e+00  4.21928162e-01\n",
      " -3.16987274e-01  2.38362675e-01 -8.23591176e-01 -2.23152992e-01\n",
      "  4.25288352e-01  1.55846557e+00 -1.28665409e+00  1.43328698e+00\n",
      " -8.87924803e-02  3.81762732e-01 -2.79718377e-01 -2.12915999e-01\n",
      " -2.27592840e-01 -9.92636864e-01 -4.87994507e-01 -7.58542906e-01\n",
      "  8.10899741e-01  9.08044114e-01 -2.10442694e+00 -3.74398287e-01\n",
      "  1.64963974e-01  3.18883561e-01 -1.38301977e+00 -1.54448637e+00\n",
      "  3.71658966e-01 -2.04741828e-01  3.24762206e+00  4.84413733e-01\n",
      "  2.82545676e-01 -6.94022251e-02  1.71656553e-01 -5.13727491e-01\n",
      "  8.77103372e-01  1.37954341e+00  1.57419393e-01 -8.87852831e-03\n",
      " -8.64873208e-01 -7.68662461e-01 -2.31216412e+00 -6.67229708e-02\n",
      " -2.53511682e-01 -1.87674912e+00 -1.95786670e-01 -4.67029542e-01\n",
      "  2.99330584e-02 -1.27167271e+00 -1.44284812e-01 -7.59502695e-02\n",
      "  4.33967543e-01  4.82371520e-01  1.89081778e-01  7.94520962e-01\n",
      "  1.01140218e+00  1.69690230e+00 -8.26071270e-01 -5.94749654e-01\n",
      "  6.62355423e-03 -6.59906507e-01  2.01042834e-01  2.21039120e-02\n",
      " -1.18106389e-01  1.01559996e-01 -1.66191908e+00 -3.83484655e-01\n",
      "  2.08417357e-01 -6.41075837e-01 -8.53202453e-02  4.11126545e-01\n",
      "  1.77015113e-01 -2.03760910e+00  5.13352684e-01 -3.27722173e-01\n",
      " -1.42891947e-01 -1.45035810e-01  2.40822182e-01  1.85754446e-01\n",
      "  5.37184829e-01  5.64731651e-01 -1.24384257e+00 -3.32672682e-01]\n",
      "------counter :62-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.62167776e-01  1.05954202e-01  1.88462761e+00 -7.11935984e-01\n",
      " -3.86812616e-02 -3.12236357e-01  3.75557600e-02 -1.45621030e+00\n",
      " -2.88965225e+00  2.15955812e-02  3.44781363e-01 -5.87345847e-01\n",
      " -5.30513766e-02  7.25693817e-02  4.89953242e-01  2.57017694e-01\n",
      "  2.42261213e+00 -4.18756390e-01 -3.26777289e-01  2.22334725e+00\n",
      "  2.29941765e+00  2.45393749e-01  1.73192777e-01  4.21630688e-01\n",
      " -3.45459431e-01  1.08180560e+00  5.20873078e-01  1.16715729e+00\n",
      "  1.57319286e-01  1.82559482e-01  2.99426489e-01 -3.85075701e+00\n",
      " -1.50510760e-01  1.47484602e+00 -8.36776717e-01 -1.02942472e-01\n",
      " -3.10929282e-01  2.22290005e-02 -3.53453766e-01 -1.20054865e+00\n",
      "  1.07747254e-01 -6.49819523e-01 -1.34985130e+00  4.60131882e-01\n",
      "  1.43439012e-01 -3.91658814e-01  1.36496714e+00  8.23339328e-01\n",
      "  7.23254597e-01  3.72183159e-02  2.29416218e-02  6.18025813e-01\n",
      " -2.99021112e-01  3.40905511e-01 -1.70007935e+00 -1.54956573e-01\n",
      " -6.56023282e-01 -4.63565486e+00  1.56274001e+00 -6.74893757e-01\n",
      "  4.24331446e-01 -7.35530775e-01 -3.38762484e+00  2.12770225e-01\n",
      "  2.39732547e+00  6.58540227e-01 -7.32129737e-01 -1.23626859e+00\n",
      "  1.28866125e-02  1.18492261e+00  4.23106460e+00 -1.34957522e+00\n",
      " -1.82169194e-01 -3.97051113e-01  7.36618397e-02 -9.52268238e-01\n",
      "  2.26118833e-01  9.06794468e-02  5.98001543e-02 -4.03671086e-01\n",
      "  4.95519264e-02 -6.13562773e-01 -5.62453166e-02 -5.30174286e-01\n",
      "  1.66919252e-04 -1.50149236e+00  4.95707433e-01 -2.51263853e-01\n",
      " -2.96877653e-01 -1.63965679e+00  4.73011553e-01  1.98382042e-01\n",
      "  2.57441741e+00  4.77955711e-01 -1.75060324e+00 -1.77213731e-01\n",
      " -1.83789980e-01 -6.77778544e-01 -4.15419916e-01  1.62822494e-01\n",
      " -1.96748155e-01  1.79587608e+00  3.52407551e+00 -1.12051990e+00\n",
      "  5.95924153e-01 -2.94295453e-01  3.34368561e-01  2.96460787e+00\n",
      " -8.47570560e-01  3.46612775e-01 -6.59476501e-02 -7.87837730e-01\n",
      " -2.04002647e-01 -2.97772092e-01 -3.82715888e-01 -6.26612979e-01\n",
      "  2.81511152e-01 -7.55486024e-01  1.57834269e+00  1.26896882e+00\n",
      " -1.16834462e-01  1.66111151e-01 -4.64980442e-01 -1.40257100e-02\n",
      " -2.72665047e-01  1.47853854e+00 -7.95406187e-01  7.66453359e-01\n",
      "  2.18154912e-01  2.97359457e-01  9.00497927e-02 -2.84494247e-02\n",
      "  4.30466448e-01  5.24871156e-01 -2.45692208e-01 -3.84516146e-01\n",
      "  1.19117750e+00  1.32425899e-01 -1.01323406e+00 -5.21312765e-01\n",
      " -7.71292816e-02  7.35508905e-01  1.76482260e+00 -1.09308615e+00\n",
      "  6.91471393e-01 -4.70498083e-02 -7.17120805e-01  2.56567232e-01\n",
      "  1.39576563e+00  3.04503454e-01 -4.07429791e-01  1.59648414e-02\n",
      " -1.13187139e-01  1.24942202e+00  2.76610233e-01  4.71849117e-02\n",
      " -2.69038510e-01  1.46814001e+00 -5.09165969e-01 -3.92607272e-01\n",
      "  1.06572720e-01 -1.79126591e+00 -4.82397560e-01 -2.94709854e-01\n",
      "  1.58876838e-01 -9.89657070e-01  4.02389012e-01  5.33135571e-01\n",
      "  7.16121692e-01  1.47195148e+00  1.83173573e-01  8.30441338e-01\n",
      "  1.18637069e+00 -3.60234071e+00 -5.61364713e-01 -6.22872025e-01\n",
      " -4.94934164e-01 -1.22069626e+00  5.48602424e-02  3.52290864e-01\n",
      " -1.15119581e+00 -1.61772331e+00 -1.27197274e+00 -8.03199933e-02\n",
      "  6.86816997e-01  1.52104557e+00  6.97374507e-02 -1.30617004e-01\n",
      " -5.99192614e-01 -1.63420041e+00  2.11678699e-01  5.10526003e-02\n",
      "  1.14817019e+00 -4.26479959e-02 -7.01776857e-01  1.39384161e-01\n",
      "  7.35450884e-01 -1.45725844e-01 -6.40386038e-01 -2.61450065e-01]\n",
      "------counter :63-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.08539436e-01 -2.49291203e-01  1.67593246e+00 -5.44148840e-01\n",
      "  1.01512976e-01 -7.66893125e-01  6.58745850e-02  9.45821173e-01\n",
      "  5.83167675e-01  5.19773327e-01  7.01940067e-01  1.65493536e+00\n",
      " -3.28416048e-02  2.07496825e-01 -4.08706029e-02 -2.60780762e-01\n",
      " -2.91877081e-01  2.06135748e+00 -3.97165802e-01 -1.88261781e+00\n",
      "  3.03973210e+00  1.06007983e-01  2.39729096e-01  1.02869725e-01\n",
      "  2.67796227e-01  5.63857148e-01  2.04063109e+00 -5.65083878e-01\n",
      "  4.42710331e-01  6.26303793e-01  4.04883874e-01 -3.76068985e-01\n",
      "  4.70897644e-02  1.59030768e+00 -1.46508367e+00  2.57940491e-01\n",
      " -1.48618038e-01  1.98799709e-01 -1.90267501e-01 -1.79513611e+00\n",
      "  3.98216562e-01 -5.69316185e-01 -1.34885503e+00  6.05673526e-01\n",
      "  4.06784638e-02 -6.74562341e-01  1.10900544e+00  1.97133171e+00\n",
      "  4.76595772e-02  1.69266051e-01 -8.68398730e-03  1.96002528e-01\n",
      "  8.63520220e-01  4.13556633e-01 -1.14194141e+00 -4.94356057e-02\n",
      "  7.45409866e-01 -2.93694400e+00 -4.95707575e-01 -7.01992604e-01\n",
      " -6.80822325e-02  1.03506479e-01 -4.74826266e+00  2.37855669e-01\n",
      "  1.77669457e+00  5.96709649e-01 -6.86267992e-01 -1.35328275e-01\n",
      " -5.53761527e-02  1.22802811e+00  4.22700116e+00  2.05055389e-01\n",
      " -4.87650423e-01 -1.55778164e-01 -9.52076842e-01 -2.24305710e-02\n",
      "  6.96938400e-02 -3.69118656e-01 -2.33413361e-01 -9.65771535e-02\n",
      " -9.28914550e-01 -3.81417014e-01  5.01508894e-02 -4.16845427e-01\n",
      "  2.61260274e-01 -1.47831732e+00  2.99374146e-01 -2.48257143e-02\n",
      " -1.34456440e-01 -5.39112239e-01 -3.87246360e-02 -1.94691877e-01\n",
      " -6.38529275e+00 -5.88999199e-01 -9.71380144e-01  2.95609481e-01\n",
      "  8.45149953e-02 -4.24478682e-01 -4.56342987e-01 -7.03866199e-02\n",
      " -1.08411006e-01  2.55732117e+00  4.61262476e+00 -1.87755593e+00\n",
      "  7.34066004e-01  6.13747460e-03  3.13300943e-01 -2.01287222e+00\n",
      " -2.35782530e-02  6.94833199e-01  3.22166695e-01  6.93512003e-01\n",
      "  4.22904312e-01 -7.38224613e-02 -8.03319006e-01 -1.47910038e-02\n",
      " -3.62854646e-01 -4.71585166e-01 -1.58283426e+00  1.72382312e+00\n",
      "  2.23780074e-02  3.34156849e-01 -7.15217911e-01  3.37098349e-01\n",
      " -3.56580474e-01 -1.65697925e+00 -4.86368941e-01  5.79206121e-01\n",
      "  4.21028125e-01  3.98088554e-01  3.00666080e-01 -1.40420030e-01\n",
      "  1.11367352e+00  7.38181016e-01 -1.29016985e-01 -2.54268415e-01\n",
      "  1.80358852e+00 -1.20361335e-01 -1.25555536e+00 -5.90023478e-01\n",
      "  2.66511643e-01  2.02257624e-01  5.49100920e-01 -6.18565632e-01\n",
      "  5.93278018e-01  2.03924490e-01  2.34820830e-01  6.73435723e-01\n",
      "  3.38108118e-01 -3.41807005e-01  5.80373858e-01  3.49053554e-01\n",
      " -1.62746317e+00  1.55546724e+00  2.74566457e-01  1.46024940e+00\n",
      " -4.03945416e-01  2.78567113e-01 -2.53373736e-01 -4.06963330e-02\n",
      " -2.90806185e-01 -8.67039400e-01  1.00151976e+00 -6.73235696e-01\n",
      "  2.47163323e-01 -5.92620124e-01  6.38033167e-01  2.73354838e-01\n",
      "  1.10988628e+00  2.21952348e-01  3.60445385e-01  1.14902518e+00\n",
      "  1.17206251e+00 -5.85499140e-01 -3.82126558e-01 -3.32276020e-01\n",
      " -3.64776634e-01 -1.38457556e+00  1.65256408e-01  1.32556556e-01\n",
      " -1.76574289e+00 -3.00074292e+00 -1.13155072e+00  1.35359569e-01\n",
      "  1.49071312e-01 -1.78955602e+00  2.12006824e-01 -1.36342337e-01\n",
      " -2.07050663e-01 -1.40751455e+00 -1.67018203e-01  5.15553867e-01\n",
      "  7.66513469e-01  9.26868214e-02 -3.33417188e-01  1.63094379e-01\n",
      "  6.42978964e-01  2.00468675e-01 -1.58749647e-01 -1.16605343e-01]\n",
      "------counter :64-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.38093001e-01  1.26543388e-01 -1.36278245e+00 -5.20761690e-01\n",
      "  6.72891491e-01 -9.02386084e-01 -8.38931088e-01  5.38102974e-01\n",
      " -1.65488466e+00  1.08336075e-01  6.52690033e-01  4.33031200e-01\n",
      " -8.06522580e-02  5.55610524e-01 -9.78976520e-01  5.27059995e-01\n",
      " -2.66349366e+00  4.89078646e-01 -3.99979930e-01 -1.98063094e+00\n",
      "  1.90704010e+00  2.46062783e-01 -1.01162281e-01  3.81656846e-01\n",
      "  7.55735618e-02  5.54411016e-02  1.16084115e+00 -2.05071218e+00\n",
      "  6.04029361e-01 -6.55339123e-01  6.62660571e-02 -1.34476114e+00\n",
      "  5.08345715e-02  1.70130445e+00  2.24337943e+00  1.54464079e-01\n",
      "  2.86325909e-01  4.79926855e-01 -3.43177801e-01 -2.46866755e-01\n",
      " -7.93849519e-02 -1.03965755e+00 -1.40957633e+00  4.20143259e-01\n",
      "  2.91760560e-02 -7.25113370e-01  1.81160866e+00  1.36593815e+00\n",
      "  9.06820655e-01  3.85208757e-01 -2.48647200e-01  5.45382163e-01\n",
      "  3.75352091e-01  4.70402568e-01 -3.28592162e+00  1.83814519e-01\n",
      "  6.06909319e-01 -2.38796944e+00  2.52983135e-01 -4.77305259e-01\n",
      "  9.18659040e-01 -7.62737911e-01 -2.63673187e+00  1.47864131e-01\n",
      " -1.73888924e+00  3.00710532e-01 -1.39703892e-01 -8.74957634e-01\n",
      "  2.32466260e-01  1.45701154e+00  1.52497578e+00  3.05453119e-02\n",
      " -2.65911721e-01 -1.89619226e-01 -6.74538559e-01  2.18139657e-01\n",
      "  5.35954764e-03  1.38627106e+00  1.71812427e+00  2.16787552e-01\n",
      "  9.35234770e-01 -2.54383120e-01 -6.94725539e-02 -4.58469606e-01\n",
      "  1.29383179e-01 -3.26372068e+00  8.83367929e-01 -2.68044035e-01\n",
      " -5.70836184e-02 -2.86875030e-01  1.13166474e+00 -1.44356397e-01\n",
      " -2.40604419e+00 -1.69639272e+00 -1.63525565e+00  1.16231846e-02\n",
      "  5.08050039e-01 -5.73144017e-01 -7.83744941e-01 -1.05754485e-01\n",
      " -3.45468711e-01  2.46969083e+00  2.51705219e+00 -1.70021051e+00\n",
      "  9.77642687e-01  5.85314883e-02  4.81636078e-01  3.56544278e+00\n",
      " -4.76750059e-01  6.24368588e-01  4.07250503e-01  3.27685501e-01\n",
      "  1.36968686e-01 -3.64350798e-02  1.52723556e+00 -7.14519654e-01\n",
      "  4.27710835e-01  2.62146142e-01 -2.72151751e+00  1.43063175e+00\n",
      " -7.30887252e-02  1.94718590e-01 -3.52592999e-01  1.27566006e-01\n",
      " -3.59526051e-01 -1.49392567e+00 -4.65245071e-01  1.43405412e+00\n",
      "  4.12440044e-01  1.19893161e+00  1.17808103e-01 -1.24743318e-01\n",
      "  4.35188310e-02  1.14476463e+00 -3.16874487e-01 -3.85554667e-01\n",
      "  1.40221503e+00  1.31967711e-01  2.45768025e-01 -2.29715658e-02\n",
      " -4.39877968e-02  6.07328613e-01 -1.21639436e-01 -9.53733711e-02\n",
      "  5.67988749e-01  7.69806608e-02  1.21958579e+00  8.02677818e-01\n",
      "  1.64486152e-01 -2.37289942e-01  1.24007930e+00  2.37448453e-01\n",
      " -6.14341736e-01  1.05431575e+00  1.68219683e-01 -2.52613061e-01\n",
      " -2.45728691e+00  5.32028009e-02 -2.66611419e-01  1.90336171e-01\n",
      " -1.21334606e-03  3.41625002e-02 -1.71289856e+00 -6.24927499e-01\n",
      "  7.73829810e-03 -8.44263208e-01  3.94956204e-01  1.54475564e+00\n",
      "  6.53374792e-01  2.15734622e-01  4.77894834e-01  5.48887878e-01\n",
      "  1.61339819e+00 -1.85955146e+00  6.94357719e-01 -7.10540214e-01\n",
      " -5.85649523e-01 -1.07941228e+00  1.89424259e-01  2.70280652e-01\n",
      " -5.48007456e-01  9.04684628e-01 -1.20230338e+00 -7.43728589e-02\n",
      " -6.45984548e-01  4.61996401e-01  2.11344400e-01  2.07306274e-01\n",
      "  4.61981961e-01 -2.19990495e+00  6.65190618e-03  1.87828686e-01\n",
      "  5.01057127e-01  2.08303765e-01 -3.33578256e-01  3.42307050e-03\n",
      "  9.18842600e-01 -3.73246915e-01 -3.69198410e-01  1.75181882e-01]\n",
      "------counter :65-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.14859516e-01  2.60785783e-01 -7.60874921e-01 -5.83411185e-01\n",
      " -1.87947579e-01  1.18478269e+00 -6.40567148e-01  3.71184141e-01\n",
      " -3.42923549e-01  6.42742203e-01  8.18883587e-01 -8.69226631e-02\n",
      " -5.56742743e-01 -2.40194666e-01 -1.15329749e+00  1.27108466e+00\n",
      "  2.15820725e-01 -1.43553840e+00 -4.64587926e-01  2.03795632e+00\n",
      " -3.32740416e+00  2.90311025e-01 -6.43983215e-01  9.95334534e-02\n",
      " -1.23228475e-01  7.57043519e-01  2.80835862e-01 -2.14974496e+00\n",
      "  1.13642017e-01  2.55912003e-01  2.88184462e-02 -1.91641785e+00\n",
      " -4.22369892e-02  3.07320584e+00  2.05438706e+00 -2.40259415e-01\n",
      " -3.70723053e-01 -2.67149785e-01 -3.81643631e-01 -1.16217965e+00\n",
      "  1.37304292e-01 -2.21030278e+00 -2.48922743e+00  1.75636134e-02\n",
      " -4.02786931e-01 -1.26601892e+00 -3.49115877e-01  1.16638881e+00\n",
      " -5.64469157e-03  1.84133111e-01 -1.03123075e-01  4.62884235e-01\n",
      "  1.28127480e-01  3.71918377e-01  2.33215364e+00 -1.95775771e-01\n",
      "  8.99187213e-01  4.08486028e+00  1.07242338e-01 -5.31434731e-01\n",
      " -6.78790862e-02 -1.05415418e+00 -1.19253904e+00  4.83282765e-02\n",
      "  7.66045577e-01 -1.47148676e-01 -2.13858674e-01 -7.65142932e-01\n",
      " -6.96539123e-01  1.86947372e+00  1.12576929e+00  7.14646529e-01\n",
      " -1.71333331e+00 -2.57999343e-01 -1.09723444e+00 -7.85529453e-01\n",
      " -2.52366930e-01  8.31981680e-01  1.70712247e+00 -1.18355009e-01\n",
      "  1.45146601e+00 -1.22579687e+00  2.94295616e-03 -6.43968942e-01\n",
      " -3.21044565e-01  4.37729839e+00  2.57733039e+00  1.29583431e-01\n",
      " -1.32364477e-01 -1.09136827e+00  4.55182875e-01 -3.43757611e-01\n",
      " -2.73476666e+00 -7.04374446e-01 -7.12073912e-01 -2.96771659e-01\n",
      " -3.86889785e-01 -8.05290458e-01 -9.13645008e-01 -1.55083620e-02\n",
      " -3.91584220e-01  2.57219635e+00 -1.19168479e+00  1.33732800e-01\n",
      "  8.10035119e-01 -5.07651947e-01  9.49823676e-02  4.84498957e+00\n",
      " -2.79127277e+00  3.51968957e-01 -2.66877353e-01  2.05185591e-01\n",
      " -2.59189116e-01 -1.40746637e+00  2.66305819e+00 -7.26760086e-01\n",
      "  2.30242190e-01 -1.38360338e+00  8.92645670e-01  1.20569147e+00\n",
      " -4.75260301e-01  2.55250827e-01 -5.72943481e-01 -4.69900430e-02\n",
      " -2.46814240e-01 -1.45300673e+00 -1.73461926e-01  7.47490287e-01\n",
      "  7.01066023e-01  9.55118513e-01 -1.81009947e-01 -3.38369662e-02\n",
      "  1.70109223e-01  1.60534889e+00 -1.26339766e+00  8.37189357e-02\n",
      "  1.32842761e+00 -1.68780869e-01  2.14940135e+00  6.07438725e-01\n",
      " -1.58733654e-01 -1.31633940e-01 -5.16151223e-01  6.46541910e-02\n",
      "  2.59640391e-01  1.18778233e-01  1.14634146e+00 -5.30181671e-02\n",
      "  1.94797610e-01 -2.72736241e-01 -7.33143311e-01 -2.96835895e-01\n",
      " -1.78319509e+00  1.13643331e+00 -1.77468734e-01 -3.60831896e-01\n",
      " -1.81579099e+00 -9.31989580e-01 -3.50406452e-01  1.98485257e-01\n",
      "  8.94578571e-02  1.02867598e+00 -1.11607184e+00  6.21110681e-01\n",
      "  2.00097287e-01 -2.43274721e-01  3.55184633e-01  1.63074054e+00\n",
      "  6.60858943e-01 -1.53761155e+00 -3.41333256e-01  1.33380885e+00\n",
      "  1.01734121e+00 -9.64530600e-01  4.26758228e-01 -6.59924265e-01\n",
      " -9.73444628e-01 -3.44386989e+00 -3.34771383e-01 -4.98091837e-02\n",
      "  1.18132414e+00  1.77992514e+00 -9.83394942e-01 -5.91425837e-01\n",
      " -7.73287346e-01  1.61465874e-01 -1.85425788e-01  9.07201351e-03\n",
      "  1.37439301e+00 -9.43269251e-01 -8.33927304e-01  8.18546672e-01\n",
      " -3.56523842e-01 -2.08571039e-02  5.70044231e-01 -2.68876257e-01\n",
      "  4.37971963e-01  2.08177695e-01 -7.95509110e-01  3.08868451e-01]\n",
      "------counter :66-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.41222391e-01  7.38910111e-01 -1.06753079e-01 -5.54797218e-01\n",
      "  6.80132475e-01 -6.33077941e-01 -5.81466027e-01  1.06240057e+00\n",
      "  1.24996582e+00  6.51665448e-01  7.05194097e-01 -4.41180788e-03\n",
      " -3.01652912e-01  4.48747614e-01 -5.36345240e-02  1.09094348e+00\n",
      " -1.01432297e+00 -1.97832835e+00 -6.52515800e-01 -3.17301944e+00\n",
      " -8.87073235e-01 -2.90528690e-01 -3.32989686e-01 -4.32306095e-01\n",
      " -2.68986451e-01  6.84047061e-01 -2.86698642e-01  5.85447005e-01\n",
      "  1.81198435e-01  9.95606847e-01  4.61251336e-01 -1.67043811e+00\n",
      " -8.18940775e-02  7.77122110e-01  2.15759804e+00  9.22687769e-03\n",
      "  2.21345919e-01  3.76870529e-01 -2.72126932e-01 -1.02777935e+00\n",
      " -5.04822302e-01 -1.44619282e+00  3.49090253e+00  7.78991240e-01\n",
      " -5.07603737e-01 -1.01223724e+00  2.33455915e-01  1.34548839e+00\n",
      "  4.89199018e-01  4.16294314e-01  7.40891201e-03  1.59037451e-01\n",
      "  5.64913900e-01  3.45305137e-01  4.86118597e+00  3.96716085e-02\n",
      " -8.33339791e-03  1.70933313e+00 -1.13891554e+00 -1.16145311e+00\n",
      " -5.89163902e-01 -9.36557930e-01  1.62807607e+00  2.38007320e-01\n",
      " -1.45077220e+00  2.56464034e-02 -2.81119271e-01 -1.08029699e+00\n",
      " -3.09242409e-01  1.23904894e+00  1.87396212e+00 -3.64772069e-01\n",
      " -6.80232275e-01 -2.58004016e-02 -1.56840495e+00 -1.50988494e+00\n",
      "  1.12050968e-01  3.97381826e-01  1.11837151e+00 -5.45788819e-01\n",
      "  1.22459189e+00 -2.53679797e-01  1.44447268e-01 -7.83697472e-01\n",
      "  1.33350647e-01 -4.10209895e-01  1.12863256e+00  1.37072922e+00\n",
      "  4.31109966e-01  7.91500079e-01 -6.00905097e-01 -5.87956961e-01\n",
      " -1.78090511e+00 -1.58486007e-01 -1.22905992e+00 -4.17891021e-01\n",
      " -5.10732947e-01  2.35995520e-01 -4.52227103e-01 -9.10337378e-02\n",
      " -1.63039078e-01  2.60329434e+00 -1.62219134e+00  7.71987554e-01\n",
      "  8.26418334e-01 -1.49781859e-01 -2.93480415e-02  4.63433312e+00\n",
      " -7.98374987e-01  2.31286811e-01  2.13011752e-01 -1.95907436e-01\n",
      " -8.10965850e-01 -9.59626317e-01  3.12075751e+00 -5.20783977e-01\n",
      "  6.15973810e-01 -1.13698255e+00 -1.23184340e+00 -2.55258982e+00\n",
      " -5.85341327e-01  1.21335044e-01 -5.36098262e-01  8.44090426e-02\n",
      " -4.05216507e-01 -1.43044883e+00 -3.90604771e-01 -2.35593497e-01\n",
      "  8.33505610e-01  1.10053711e+00 -2.29988333e-01  2.02846770e-01\n",
      "  1.85353172e-01  8.91222119e-01 -2.96111827e-01 -1.93475983e-01\n",
      "  1.08694645e+00 -1.68685835e-01 -3.87738137e+00  5.02386608e-01\n",
      "  7.98239386e-01  2.49339246e-01 -3.16080720e-01 -2.61578682e-01\n",
      "  6.56995367e-01 -1.91538393e-01 -5.01577697e-01 -1.84234146e-01\n",
      " -3.04882089e-02  6.50351202e-02 -2.88334611e-01 -1.99748734e-01\n",
      " -5.66066175e-01  4.21522928e-01 -3.89223587e-01  1.25536008e+00\n",
      " -1.27446957e+00 -1.85572027e+00 -4.80979256e-01  7.95978330e-01\n",
      "  1.39735441e-01  8.12958832e-01 -7.59528961e-01  1.09506056e+00\n",
      " -8.63037045e-02 -1.90941545e-01  3.37245313e-01  7.45993620e-01\n",
      "  8.65442149e-01  2.37337118e+00 -4.91356568e-01  1.29585928e-01\n",
      "  8.97619716e-01 -5.99372808e-01  4.10680195e-01 -2.81647161e-01\n",
      " -1.17129433e+00 -2.70457471e+00 -4.86522128e-02  6.02447637e-01\n",
      "  1.73225270e-01 -5.34965670e-01 -8.73285807e-01 -2.15619102e-01\n",
      " -1.27250759e+00  1.27099976e+00 -1.92282053e-03 -1.56565498e-01\n",
      "  8.51068136e-01 -1.81925639e+00 -3.66664027e-01  6.93219382e-01\n",
      " -6.59945889e-02  1.53234039e-01  6.22084963e-01  1.01324516e-01\n",
      "  6.72969944e-01 -3.01671284e-01 -9.11030217e-01  4.29873538e-01]\n",
      "------counter :67-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.13146621e-01 -1.02285280e+00 -1.77170608e+00 -9.28123339e-01\n",
      " -3.70620880e-02 -3.45311233e-01  9.08838976e-02 -1.30865261e+00\n",
      "  2.08510490e-01  5.87604849e-01  6.12317901e-01  3.36633394e-01\n",
      " -3.42402474e-01  3.67818563e-01  6.95280749e-01 -3.05647530e-01\n",
      " -3.43199428e-01  8.68346006e-01 -7.97498335e-01 -2.68917972e+00\n",
      " -1.32624768e+00 -4.05004984e-01 -5.02466279e-01 -3.46517464e-01\n",
      " -5.22735962e-01  6.73321682e-01  2.06561277e-01 -1.07791142e+00\n",
      "  4.80189732e-01 -1.37727079e+00  3.65895008e-01 -1.44322997e+00\n",
      " -1.11932223e-01  9.16940694e-01 -9.35931617e-01  4.61032851e-01\n",
      " -2.82813384e-01  4.52188587e-01 -1.29029548e-01  5.02312856e-01\n",
      " -5.86322089e-01 -9.44765700e-01  2.36844334e+00  7.38472844e-01\n",
      " -3.87593274e-01 -4.18768390e-01  1.21878712e+00  3.95669372e-01\n",
      " -1.00395593e+00  3.94913236e-01 -5.60931565e-02  3.12954862e-02\n",
      " -2.06723762e-01  5.19150593e-01  5.13576858e+00 -2.18283355e-02\n",
      "  1.81313227e-01  4.07563986e-01 -1.72375131e+00 -5.33129084e-01\n",
      " -3.06057227e-01 -6.49319239e-01 -1.91449787e+00  2.36573405e-01\n",
      "  6.80415104e-01  2.14090275e-01 -2.72271638e-01 -4.36415178e-01\n",
      " -3.95272638e-01  9.03539334e-01  2.16087030e+00  2.53935855e-01\n",
      " -1.09973864e+00 -3.59583528e-02 -2.24365384e+00 -8.22308883e-02\n",
      "  1.94939489e-01  8.90127471e-01  5.90939346e-01 -1.03742056e+00\n",
      " -2.82616209e+00 -1.50318907e-02  9.51590508e-02 -7.36732946e-01\n",
      "  2.72236494e-01  5.93655701e+00 -1.37994938e+00 -8.94893559e-01\n",
      "  8.78573970e-01  1.05929778e+00  3.55824019e-01 -8.99764450e-01\n",
      " -4.11095222e+00  1.67886160e-02 -1.21006020e+00 -4.64291422e-01\n",
      " -5.66580527e-01  7.42538598e-01 -6.62297640e-01  1.79717429e-01\n",
      "  2.33860756e-02  2.10626075e+00 -1.14102231e+00  5.93194815e-01\n",
      "  8.14195838e-01 -2.48325583e-01  1.09371828e-01  3.63569563e+00\n",
      "  1.44199437e-01 -4.46350936e-01  2.72375819e-01 -1.83234615e-01\n",
      " -1.09978527e-01 -8.17896910e-01  2.04050929e+00 -5.90145685e-01\n",
      "  1.51085811e-01 -9.21730663e-01 -6.93054273e-01 -4.29210394e-01\n",
      " -5.81086065e-01 -1.68302762e-01 -3.25818153e-01  1.90565459e-01\n",
      " -3.89969576e-01 -1.52555338e+00 -1.56856939e-01 -6.96552208e-01\n",
      "  9.31833594e-01  3.58976057e-01  1.35839449e-01  2.26891239e-03\n",
      "  4.51759772e-01  3.53548797e-01 -4.95118426e-01  1.36758127e-01\n",
      "  1.13732072e+00 -8.56701309e-01  1.06012831e+00  2.46190735e-01\n",
      "  4.14609832e-01  5.03498036e-01 -1.15364869e+00 -5.06382279e-02\n",
      "  3.28777337e-01 -1.69351264e-01 -1.11426771e-01 -5.35311604e-01\n",
      "  3.40815944e-02  1.09543398e+00 -3.32533748e-01 -2.32281216e-01\n",
      "  1.16415762e+00  6.57641154e-01 -4.85526275e-01  8.52120053e-01\n",
      " -1.29454501e+00  3.11189667e+00  4.46487858e-01  1.03301691e+00\n",
      "  1.69828152e-01 -1.48608195e+00 -8.19173585e-01 -1.65427614e-01\n",
      " -1.00754761e-03  6.87223948e-02  4.55886634e-01  1.05976974e+00\n",
      "  1.17343990e+00  9.92361043e-01  1.76081816e-01  3.84409933e-01\n",
      "  8.16507663e-01  7.01928962e-01  8.09749840e-02 -1.33555679e-01\n",
      " -7.73525046e-01 -5.23628575e-01 -9.16907903e-01  9.06335794e-01\n",
      "  4.48044884e-01 -5.71030948e-01 -4.51002097e-01  3.48994891e-02\n",
      " -3.86056426e-01  1.08869502e+00  1.64164672e-01  2.60226379e-01\n",
      "  7.21080019e-01 -1.47606189e+00 -3.98532667e-01  1.07697620e+00\n",
      "  1.21699702e-01 -5.53790018e-01  1.53697555e-01  1.33018568e-01\n",
      "  8.06479843e-01 -6.05790087e-02 -1.04032673e+00 -2.50832516e-01]\n",
      "------counter :68-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.42194325e-01 -3.35607120e-01 -1.13377849e+00 -1.82908159e-01\n",
      " -1.12728384e-01 -1.39387304e+00 -4.36035349e-01  8.64543357e-02\n",
      "  8.90345329e-01  1.09214039e-01  2.76063922e-01  5.18537263e-02\n",
      " -1.02296269e+00  1.36717446e-01 -9.04381890e-01  4.56197590e-01\n",
      "  1.27717365e+00  1.08703965e+00 -4.56682394e-01 -3.01891573e+00\n",
      "  8.76143168e-01  4.74561833e-01 -2.87174038e-01 -3.29967915e-01\n",
      "  4.97375435e-02  5.43070940e-01  2.26731773e-01  2.16678143e+00\n",
      "  8.01698395e-01 -1.54717305e+00 -1.68886290e-01 -1.52494231e+00\n",
      "  7.47764793e-02  1.74463775e+00  6.16253594e-01 -7.46638648e-02\n",
      "  1.57046234e-01  9.85627049e-01 -2.30302946e-03  5.06714175e-01\n",
      "  2.68339764e-02 -1.02928897e+00 -1.25874762e+00  4.45437590e-01\n",
      " -1.99746923e-01 -9.74556141e-01  5.44809615e-01  6.12555307e-01\n",
      " -5.19842563e-01  2.68144438e-01  8.22508885e-02  7.63945850e-01\n",
      " -1.59467093e-01  5.71361528e-01  1.49280271e+00  1.30811037e-01\n",
      " -4.05032967e-01 -1.41285072e-02 -2.09701283e+00 -3.72811554e-01\n",
      " -2.08897182e-01 -1.05838467e+00  2.03536701e+00  5.19872821e-01\n",
      "  5.47746480e-01  1.62645925e-01 -8.57224987e-01  3.14788362e-01\n",
      " -4.97440229e-01  1.43142559e+00  1.45789960e+00  2.17520047e-01\n",
      " -5.87195541e-01  1.33656672e+00 -1.51877968e+00 -4.47610757e-01\n",
      " -7.10033154e-01 -1.63651040e-01  5.49309337e-01 -1.12199443e+00\n",
      " -5.88289890e-01 -2.87628030e-01  4.15410622e-01 -2.73862251e-01\n",
      "  2.04797258e-01  5.14289893e+00  1.06588298e-01 -2.52847352e-01\n",
      "  1.11634692e+00 -1.53930518e+00  3.41965344e-01 -5.50616169e-02\n",
      " -2.13714637e+00 -5.84139580e-01 -6.22365014e-01 -4.53029480e-01\n",
      " -8.05642743e-01 -6.27899687e-01 -3.49658693e-01  7.93904641e-01\n",
      " -8.81197269e-02  1.96642629e+00 -1.17113893e+00  1.75505847e-02\n",
      "  9.63783928e-01 -1.81117249e-02  2.45017832e-02 -9.97387883e-01\n",
      " -9.39339411e-02  2.95685678e-01  3.47688698e-01 -4.68216383e-01\n",
      "  7.49031923e-02 -1.54838406e+00 -4.62035935e-01 -2.24801596e-02\n",
      "  2.73281432e-01 -6.34320555e-01 -3.93506841e-01  2.45128926e-01\n",
      " -3.63868101e-01  1.59248942e-01  3.10717820e-01  1.66332766e-01\n",
      " -4.31501021e-01 -1.53781167e+00 -1.53946619e-01  1.32489386e+00\n",
      "  6.05437032e-01 -1.63331181e-01  2.24139058e-01 -8.69846328e-03\n",
      "  3.57475495e-01  1.07439195e+00 -2.00465768e-01  6.79729806e-01\n",
      " -3.96225974e+00 -1.83224517e-01  2.29728891e-01  6.24056961e-01\n",
      "  3.61789596e-01 -4.52987510e-03 -9.71679659e-01  1.17630697e-01\n",
      "  3.86760151e-01  3.19593203e-02 -8.14064780e-01 -6.12755948e-01\n",
      "  7.95174275e-03  4.61984804e-03  3.31490369e-01  1.23746782e-01\n",
      " -1.48554685e+00  1.14172094e+00 -5.18708395e-01 -2.62342058e-01\n",
      " -1.02968288e+00  2.00435089e+00 -1.78939578e-01  8.90911868e-01\n",
      " -2.11527248e-01 -1.15198779e+00 -1.53116385e+00 -2.69823328e-01\n",
      "  3.93225358e-01 -2.61979991e-01  5.95172925e-01  1.39878613e+00\n",
      "  1.39333552e+00  1.48007874e+00  2.64606255e-01  3.26036433e-01\n",
      "  7.28379436e-01  1.87451232e+00 -1.28100163e+00  1.17500799e-01\n",
      " -1.11010384e+00  7.18969992e-02  1.19293421e+00  4.44353281e-01\n",
      "  5.12974163e-01  4.07955045e-02 -3.98529845e-01  2.07290362e-01\n",
      "  7.60351244e-01  8.20764904e-01  1.26940514e-01 -1.00035331e+00\n",
      "  3.01668348e-03 -1.11844099e+00 -1.18679029e-01  9.68545887e-01\n",
      " -1.16395595e+00 -4.91360388e-02 -1.68471947e-01  2.14180768e-01\n",
      "  6.12298201e-01 -2.15028134e-02 -9.88282573e-01 -1.49413305e-01]\n",
      "------counter :69-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.72135284e-01 -6.86209301e-01 -5.59762580e-01 -2.84604738e-01\n",
      "  4.07135518e-01 -7.88699842e-01  1.25670071e+00  2.97556736e+00\n",
      " -9.98560645e-01  4.92740960e-01  3.13802912e-01 -4.14642543e-01\n",
      " -1.54741509e-01  5.46801313e-01 -8.18376058e-01  2.22138837e-01\n",
      "  2.37796691e+00 -9.37002407e-01 -6.55516846e-01 -4.83181947e+00\n",
      "  3.19339160e-01  4.19956337e-01 -2.79248084e-01 -3.69377933e-01\n",
      " -1.74866744e-01 -2.49090194e-01  4.27130677e-01  1.15698771e+00\n",
      " -1.79815702e-01 -1.60282792e+00  3.78621177e-01 -1.43675146e+00\n",
      "  6.31746936e-02  1.52778202e+00  3.00349810e-01  1.73712884e-01\n",
      " -4.83215354e-02 -4.87926396e-02  2.09318875e-02  5.11161936e-01\n",
      " -1.21185462e-01 -8.85304027e-01  3.13767051e+00  8.01634345e-01\n",
      " -3.02473231e-01 -1.32146098e+00 -9.08475097e-01  6.92236952e-01\n",
      " -6.44534089e-01  5.34065747e-01  5.04058240e-01  1.02125579e+00\n",
      " -6.30998653e-02  2.77635666e-01 -1.29288385e+00 -4.43016818e-01\n",
      " -1.13810307e+00  2.15693879e+00 -8.82129800e-01 -4.02943617e-01\n",
      " -2.30732333e-01 -1.31660974e+00 -2.09686855e+00  4.97574824e-01\n",
      " -5.53649781e-01  3.41645510e-01 -2.67257347e-02 -5.80112454e-01\n",
      " -5.99739325e-02  1.44518139e+00 -1.52973324e-01  8.26637201e-02\n",
      " -4.11672759e-01  6.74232930e-01 -1.11292195e+00 -4.09108547e-02\n",
      " -2.85699022e-01 -7.23260771e-01  2.91592948e-01  6.50472373e-01\n",
      " -6.59720244e-01 -6.58009649e-02  7.99587755e-01 -1.04368286e+00\n",
      "  4.47323970e-01 -4.47688743e-02  7.63972374e-01 -6.59466053e-02\n",
      " -1.40362735e-01 -1.30810449e-01  8.21373677e-01  2.17479479e-01\n",
      " -7.78063276e-01  3.26277121e-01 -1.12165870e+00 -1.89102504e-01\n",
      " -5.88965326e-01 -3.61579176e-01 -1.64381963e-01 -5.86577940e-01\n",
      "  8.34885184e-01  1.75980491e+00 -2.36440446e+00 -3.85655138e-01\n",
      "  1.11937837e+00 -1.18935560e-01  3.53364292e-02  8.52107102e-01\n",
      " -1.72608341e+00  6.20236598e-01  4.73878828e-01 -5.35453534e-01\n",
      "  2.32123874e-01 -2.07365636e+00 -7.68690282e-01 -5.54932639e-02\n",
      "  7.62681328e-02  1.13975487e+00 -4.73745904e-01 -2.28887805e+00\n",
      " -2.87650713e-01  7.28274582e-01 -5.05502446e-01  3.39357222e-01\n",
      " -4.05068774e-01  1.29507242e-01  3.29706321e-01 -7.52913160e-01\n",
      "  7.17189151e-01  1.15946656e+00  4.13660005e-01  2.04405983e-01\n",
      "  6.73451299e-02 -1.24608053e+00 -1.72117667e-02  3.25426635e-02\n",
      " -9.41597783e-01 -1.40033852e-01  6.99537774e+00 -4.34739563e-01\n",
      " -1.90464196e-01  3.85258766e-01  8.80609345e-01  1.29668751e+00\n",
      "  5.67344338e-02 -5.47420841e-02 -4.59713891e-01 -5.66257147e-01\n",
      "  2.72702148e-01 -2.10286564e-01 -2.20864655e-01  6.41041137e-01\n",
      " -4.32300676e+00  3.49194171e-01 -4.19979309e-01  1.30733143e+00\n",
      " -7.58876597e-01  1.51992160e+00  5.46659972e-01 -1.63618689e-01\n",
      "  1.23337116e-01 -8.09746158e-01 -9.35937050e-01  4.45376366e-01\n",
      "  5.89093244e-01 -6.78565826e-03  8.11595386e-01  1.85544169e+00\n",
      "  1.53099465e+00  1.39680048e+00  2.22990068e-01  7.33418832e-02\n",
      "  1.00191736e+00  3.15452122e+00 -3.77301637e-01  1.11674178e-01\n",
      " -7.73013247e-01  6.37451949e-01 -9.03140006e-01  5.95314984e-01\n",
      "  9.23492811e-02 -5.90298356e-01 -2.12669817e-01  4.54751092e-01\n",
      " -2.96712082e-01  7.75169342e-01  2.07053907e-01 -5.35090061e-01\n",
      " -7.87683206e-02 -3.23756145e+00 -5.29862400e-01  1.04161327e+00\n",
      " -1.25026287e+00  1.22463920e-01  1.80810773e-02  3.18516462e-01\n",
      "  6.20501969e-01 -4.82952503e-01 -1.04999086e+00 -1.48242736e-01]\n",
      "------counter :70-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.95816642e-01 -7.04406621e-01  1.04786240e+00 -1.31534176e+00\n",
      "  2.72290514e-01 -6.84451036e-01  1.19238274e+00 -2.05944658e+00\n",
      " -4.89176768e-01 -9.05413542e-02  4.59585475e-01 -7.46898365e-01\n",
      " -6.56915866e-01  2.28702207e-01 -1.80638529e+00  2.81821221e-01\n",
      "  3.15250744e-01 -2.30696745e+00 -7.20554271e-01 -1.18429748e+00\n",
      "  4.94341410e-01 -2.45408569e-01 -1.11457503e+00  7.61979241e-01\n",
      " -2.66944934e-01  5.21159901e-01  7.11189481e-01 -1.25574973e+00\n",
      " -3.53735664e-01 -6.06176670e-01 -1.74905055e-01 -1.30867844e+00\n",
      " -4.91663847e-02  1.23262681e+00  1.26710005e+00 -2.04128542e-01\n",
      "  3.76088413e-01  8.18290336e-01  3.55258496e-01 -5.90491978e-01\n",
      " -3.54655150e-01 -6.50025451e-01 -1.44526780e+00  3.21287485e-01\n",
      " -3.11477981e-02 -8.59072328e-01  1.86102563e-03  1.16218537e+00\n",
      " -4.03860792e-01  7.12724900e-01  1.73115543e-01  1.67409130e+00\n",
      "  7.90486139e-02 -6.21302283e-04 -1.10071827e-01 -5.48675945e-01\n",
      " -3.79435755e-01  1.74445488e+00 -1.37763913e+00  3.98197758e-01\n",
      "  4.07572372e-01 -9.89535332e-01  1.26623655e+00 -1.65395010e-01\n",
      " -1.09203385e+00  1.33436464e-01 -3.27906697e-01 -2.03732561e-01\n",
      " -6.55155055e-02  1.45775898e+00  2.86781637e-01  1.49896882e+00\n",
      " -4.56370658e-01  4.29390778e-01  1.02643492e-01 -2.11792567e-02\n",
      " -3.62074670e-01 -1.04906161e+00  2.99882694e-01  6.88549585e-01\n",
      " -7.33444488e-02  3.19277427e-01  8.23895341e-01 -4.73203735e-01\n",
      "  2.16459532e-02  6.81750355e+00  1.15505443e+00  5.76536304e-01\n",
      "  7.39911387e-01 -4.05369477e-01  1.03822842e-01 -4.14314400e-01\n",
      " -9.03872030e-01  2.76955963e-01 -6.17908997e-01 -3.73980650e-01\n",
      " -5.96817281e-01  1.84422927e-01 -5.59483777e-01 -5.52690546e-01\n",
      "  1.65125002e+00  5.08158673e-01  6.39719144e-02  2.83081280e-01\n",
      "  1.32045723e+00 -8.36182286e-02  9.01231045e-01  5.02876283e-01\n",
      "  1.85756754e+00  3.88067805e-01 -3.11353585e-01 -2.02233689e-01\n",
      "  7.34188742e-01 -1.10540240e+00  3.04915982e-01 -1.62229207e+00\n",
      "  1.36545162e-01  1.22627168e+00  1.48960085e+00 -7.61365282e-01\n",
      " -3.07924054e-01  5.62263085e-01  3.25310623e-01  1.74980709e-01\n",
      "  2.82382296e-01  1.15192411e+00  4.45099355e-01 -5.43454206e-01\n",
      "  6.92977919e-01  4.05059010e-01  3.23730460e-02  1.31149278e-01\n",
      " -5.33539606e-01  5.53366719e-01  7.93611289e-02 -7.01668536e-02\n",
      " -5.11218079e-01  5.31458288e-01 -2.94335224e+00  1.81063831e-01\n",
      "  2.63133819e-01  1.64508037e-01  1.07236009e+00  1.58479538e+00\n",
      "  1.08080264e-01 -9.45024541e-02  2.12609531e+00 -7.15823369e-01\n",
      "  3.93798581e-01  3.63845314e-01  8.19907836e-01 -2.24463596e-02\n",
      " -1.71007123e+00  5.47669101e-01 -2.13589366e-01 -8.07820859e-01\n",
      " -2.39028955e-02 -1.07850876e+00  6.58509803e-01  3.91890381e-01\n",
      "  3.56483294e-01 -2.44054134e+00 -3.18370284e-01 -4.94166821e-01\n",
      "  6.12229773e-01  1.88793934e-01  5.35979075e-01  1.06266002e+00\n",
      "  1.72762960e+00 -1.78516739e+00  5.50045618e-01  4.62831354e-01\n",
      "  8.47640583e-01 -4.25163565e-01 -3.99876979e-01 -7.22992649e-02\n",
      " -1.89827280e+00 -5.04427982e+00 -1.39752177e+00  3.33231956e-01\n",
      "  5.14738322e-01  5.10168191e-01 -5.92290272e-02 -5.61707594e-01\n",
      " -3.14703455e-01 -1.78147787e+00  3.93288869e-02 -4.66553887e-01\n",
      "  9.80191481e-01 -2.42219010e+00 -2.38350522e-01  7.07441777e-01\n",
      " -8.87633831e-01  2.17146029e-01  9.13162520e-02  3.44052797e-01\n",
      "  6.44129445e-01  5.23299180e-02 -1.11848214e+00 -3.90694609e-01]\n",
      "------counter :71-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34838441 -0.57501205  0.92371977 -0.93819874  0.30099207 -0.46795727\n",
      "  1.18980453 -0.28931436  0.80895909  0.26917992  0.24845038  0.03439256\n",
      " -0.06937926  0.03272038 -0.75525434 -0.08039719  1.65254952 -1.01513357\n",
      " -0.49765357 -0.41115456  1.20221124  0.31752947 -0.53395633 -0.36918984\n",
      " -0.41574084 -0.21908779  0.40698571  0.87375559 -0.70256118 -0.77681561\n",
      "  0.19359769 -0.9193968  -0.09718676 -1.18786785  0.48556892 -0.19298133\n",
      " -0.32802312 -0.41447226  0.16881316 -0.08285456 -0.37006107 -0.3825327\n",
      " -1.0016077  -0.03422252 -0.48645808 -0.80739584  0.28323246  1.09048671\n",
      "  1.79147771  0.21629416  0.22922715  0.52256244  0.13222959 -0.05843861\n",
      " -0.13293301 -0.7842175  -0.0637468   1.84373059  0.18789454  0.69670524\n",
      "  1.03267485 -0.74057841  0.71577949 -0.06990366  0.03588078  0.1638516\n",
      " -0.53421043 -0.34984056 -0.42198984  1.60015175 -1.7476677   1.30272134\n",
      " -0.35997795  0.08678975 -0.41210343 -0.4135457  -0.34076834  0.30891981\n",
      "  0.41202006  0.14871803  0.7977916  -0.45121919  0.71180261 -0.51282892\n",
      "  0.37293637 -1.75069813  0.97984985 -0.36929536 -0.12686818  0.5181481\n",
      "  1.47570888 -0.08763576 -0.25798319  0.1699318  -0.59787927 -0.04259176\n",
      " -0.63361282 -2.97271627 -0.42573608 -0.60670344  1.7009612   0.02247328\n",
      "  1.08047074 -0.1172631   0.44735833 -0.47148127  0.5428866  -0.09341296\n",
      " -0.15556679  0.2683133  -0.3535459  -0.29209622  0.26568916 -1.05654413\n",
      "  2.07167846 -0.49478076  0.48310423  1.06953121 -0.83934116 -1.77917247\n",
      " -0.18948579 -0.00832113 -0.27198408  0.08835578  0.22139209  0.04781411\n",
      "  0.54068825  2.36534853  0.81332668  0.6583044  -0.06785179 -0.52547833\n",
      " -0.08377707  0.03541415 -0.18758965  0.03442815 -0.27783139  0.72999817\n",
      " -2.33490183 -0.43232878  0.37064299  0.38208122 -0.06659299  1.49700313\n",
      " -0.05846027  0.52021168 -0.30253971 -1.11587362  0.5580564  -0.05108516\n",
      "  0.29341332 -0.35596244 -0.28975118  0.16339682 -0.23744499 -0.07429768\n",
      " -0.20326446  0.48545277 -0.88541835  0.33750522  0.02267062 -1.09362769\n",
      " -0.29518033 -0.02880428  0.14969187  0.32236238  0.32851025  0.97284013\n",
      "  0.6977054   1.74853061  0.17227326  0.21817744  1.05686495 -1.63067236\n",
      "  0.05264162  0.10750209 -0.26789484  2.3910334  -1.25263358  0.22368749\n",
      " -0.02201659 -0.14055038 -0.16315162 -0.23306104  0.99597595 -1.68642144\n",
      " -0.2287556  -0.90005144  1.17978852 -3.68352443 -0.43881234  0.95637555\n",
      "  0.12570171 -0.40540871 -0.09859877  0.22813713  0.49309264 -0.68623005\n",
      " -1.39496     0.18736333]\n",
      "------counter :72-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0192333  -0.59503498  0.03355303 -1.1435778   0.1969195   1.08690003\n",
      "  1.01859083  3.00808284 -0.50668996 -0.33046624  0.31210974  2.00901115\n",
      " -0.37788674  0.22811353  0.49867369 -0.06312523 -1.38929394  0.11849336\n",
      " -0.63712172 -1.44115794  1.75935098 -0.63921945 -0.69862636 -0.19706979\n",
      " -0.63016638  0.73255201  0.97849259 -0.75332836 -0.52540842  0.51462151\n",
      " -0.06010833 -1.03518892 -0.09882378  1.24101    -1.17108607 -0.22212811\n",
      "  0.87865007 -1.08381732 -0.07130206 -0.33666798 -0.09087345 -0.59994861\n",
      " -1.20745095  0.78526158 -0.31402834 -0.40978836  1.29940976  0.98408417\n",
      " -0.19019497  0.55934871 -0.63103441  0.69671904 -0.92389418 -0.01666399\n",
      " -0.16226614 -0.61490895  0.82267206  1.79449134 -1.04805953  0.76362517\n",
      "  0.53851031 -0.65911063  3.70666382 -0.13217974  2.97610452 -0.17637897\n",
      " -0.21869131 -0.87546449 -0.00922794  0.67163084 -1.99442587  2.9376162\n",
      " -0.20129493 -0.47502302 -0.42613861 -0.08811165 -0.52151347  0.55628912\n",
      "  0.67862745  1.84987113  1.82790816 -0.62507733  0.73750554 -0.63171721\n",
      "  0.02818769  2.3716151   1.41415903 -1.78766131  0.6627735  -0.60673407\n",
      "  1.15666502 -0.96029569  6.169741   -0.42518086 -0.53374677 -0.3957977\n",
      "  0.22575875 -2.58640199 -0.56051379 -0.56243159  1.66828943 -0.34105155\n",
      " -0.74645653  1.66219249  0.05082205 -0.48778276  0.62252771  0.32226454\n",
      "  1.34688591 -0.41964354 -0.12022452 -0.79496992 -0.16945488 -1.22321852\n",
      "  0.87239864  1.44883974  0.01123352 -0.31069481  0.87916033 -0.13959988\n",
      " -0.54200206 -0.0616717  -0.83098428  0.08246858  0.00891455  0.82690537\n",
      "  0.19126153 -0.5263505   0.43257128  0.38387523 -0.50154791 -0.20957459\n",
      "  0.67580147 -0.8371614  -0.41299665  0.33797321  1.55107911 -0.10031709\n",
      " -2.37111124 -0.78715422  0.45025336  0.02273847  0.42792242  1.12022312\n",
      " -0.72918192 -0.1694047  -0.41586323 -0.859713    0.40360001 -0.31163736\n",
      "  0.25653253 -0.65147107  1.25742201 -0.94245    -0.54828356 -0.64037272\n",
      " -0.60887337 -0.87545932 -4.59396995 -0.21775285  0.26849532 -0.92854474\n",
      " -1.48687905  0.89532164  0.40533474  0.03501172  0.21740206 -0.42954767\n",
      "  0.48926832  0.3549932  -0.38029027  0.13030081  0.88058408  0.03009994\n",
      "  0.24318549  0.17999817 -0.72038152 -3.01860724 -0.19542591  0.69737282\n",
      " -0.97195358  1.75824191 -0.23168161 -0.07994996  0.23755418 -2.27360803\n",
      " -0.43055679 -0.22106518  0.91025728 -3.2735348  -0.6498893   0.52368666\n",
      "  0.07746377  0.06224122 -0.27280486 -0.15059497  0.44107243 -0.37941593\n",
      " -1.39840778 -0.34057206]\n",
      "------counter :73-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.43466364 -0.32995759  0.13576873 -0.1239513  -0.08442066 -0.2111726\n",
      "  1.03787671 -2.00853416  0.06794535  0.53623698  0.0955249  -0.5875754\n",
      " -0.60585781  0.34735263 -1.23192258  0.49928264 -1.76608091 -0.97309198\n",
      "  0.33939084 -0.47172884 -0.95641337  0.12878675 -0.42182995 -0.6786499\n",
      " -0.39997925  1.1167358  -0.69880627 -0.49571099  0.10046054 -2.42628588\n",
      "  0.61253166 -0.77537936 -0.66704392 -0.01709836 -1.88071965  0.63223788\n",
      " -0.02274317 -0.69835077  0.01602639 -0.47598622 -0.38894987 -0.7961591\n",
      " -0.5317941   0.55235822 -0.21743097 -1.58644107 -0.29998448  1.05587956\n",
      " -0.05010767  0.08194731  0.09342032  0.76394803 -0.20865359 -0.73635963\n",
      "  0.35968961 -0.29327667  1.16996116 -1.54471997 -0.5850473   0.43665639\n",
      " -0.03212449 -1.02056891  0.69232347  0.64748944  4.33359599  0.08246235\n",
      " -0.50260689 -0.58349239 -0.16397103 -0.92232075 -1.67908545  1.04873436\n",
      " -0.12570351  0.82225858  1.44621137 -0.60114925 -0.20911961 -0.46741384\n",
      " -0.54090263  1.02100631  1.63419147  0.71195276  0.59772345  0.38693176\n",
      " -0.26008858  3.05940685  1.13539488 -1.11434407  0.616336   -1.36409019\n",
      "  0.8883772   0.22126245  4.27071557 -0.05024304  0.17833839 -0.44774766\n",
      " -0.19957347 -0.33989614  0.13627746  0.08781008  1.67949605  1.83590706\n",
      " -1.25280308  1.27015525 -1.04327636  0.70393319 -0.34197301  0.00689091\n",
      " -1.29019081 -0.48975956 -0.11174265  0.17755192  0.20597784 -0.31495848\n",
      "  1.30455426 -0.6934364  -0.04970451  0.27445478  1.83110003 -0.71117117\n",
      " -0.52287162  0.64009856 -0.42571996 -0.82667716  0.65206218  1.45634906\n",
      "  0.06625987 -0.47601606 -0.73866843 -0.57115765 -0.17312286  0.5679219\n",
      "  1.38561833 -0.3149372   1.08824137  0.3429407   0.25625265  0.11166301\n",
      " -1.04827512  1.10234296  0.33169819  0.41786997  0.26091429  1.2670831\n",
      " -0.01586667  0.13421992 -0.16943801 -1.01028211  0.55084613 -0.37565561\n",
      "  0.18785603  0.31656915  0.52706833 -1.3301783  -0.65747995 -0.02139411\n",
      " -0.81020031  1.08941237 -0.59042273 -1.22572348 -0.44973147  0.04690119\n",
      " -1.01872857 -1.04022808  0.17952491  0.20245947  0.3654538   1.22336089\n",
      "  0.92780537  0.64056584 -0.15819741 -0.0147378   1.30569334  1.5280052\n",
      "  1.23739826 -0.37593454 -1.21254648 -3.0780819  -0.03512823  0.79515306\n",
      "  0.1195965   1.71245722 -0.84194125  0.6559516   0.30211546 -0.91563187\n",
      "  0.1466327  -0.5677695   1.03867195 -3.15827621 -0.04792871  0.63483282\n",
      " -1.52079742  0.01153071  0.14062414  0.31085834  0.6624861  -0.60774549\n",
      " -0.05266463 -0.42371309]\n",
      "------counter :74-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17389749  0.09597263 -0.49928376 -0.41571645  0.02350167  0.8352732\n",
      "  0.2667201  -0.61199447 -0.83139752  0.83690511  0.4092944  -0.51300692\n",
      " -0.56954654  0.24935171  0.36659083 -0.20041336  2.46662885  0.08220962\n",
      " -0.04736762 -2.50676055 -0.16173451 -0.99938327  0.42252934  0.55502057\n",
      " -0.48578404 -0.30992474 -0.50244471  1.30510191  0.31332655 -1.13496689\n",
      "  0.2100886   2.3997638   0.24811846 -0.6842204  -1.421241   -0.11023447\n",
      " -0.08827223 -0.21647746 -0.39238775 -0.94813665  0.15498917 -1.26021988\n",
      "  1.63379196  0.43836432 -0.55516356 -1.41612545  2.01627835  0.19686478\n",
      "  0.36162622  0.01274587 -0.36062607  0.55224752  1.0536666  -0.32150588\n",
      "  0.53605297 -0.38449809  0.26224834 -2.20980967  2.17320748 -0.26231972\n",
      " -0.82033842 -1.32231314  1.66612195  0.16989386  4.27413654 -0.93364135\n",
      " -0.16965679 -0.71018825  0.08350896 -1.22757949 -0.67964753  2.55425762\n",
      "  0.22932212  0.36179586  1.35474871 -0.26810015 -0.69664644 -0.11857356\n",
      " -1.0971839   0.31234618  0.03756294 -0.2084633   0.32967649  0.16767282\n",
      "  0.19031263  5.4146304   1.6973584  -0.14647819  0.84637585 -0.56349316\n",
      "  0.09104632  0.51542394  2.37290744  0.10909727  1.06498448 -0.6426116\n",
      " -0.47827154  0.61939049 -0.18743561 -0.73250152  1.40114126  1.28043677\n",
      "  1.98190443  0.39446224 -0.66713887  0.37849159 -0.27619975 -3.18004502\n",
      "  0.13306666 -0.51506157  0.55645114 -0.45104915 -0.04329037 -0.3265225\n",
      "  1.25449328 -0.28717484  0.28588581 -1.37951253 -3.05452361 -1.85526499\n",
      " -0.52530949  0.71619247  0.21010766  0.33068708 -0.07967699  1.21566886\n",
      "  0.323055   -0.78337171  0.67322696 -1.39464995  0.12435361  0.30317065\n",
      " -0.38931353 -1.33738892 -0.20371086  0.5901267  -0.05725034  0.49941403\n",
      " -3.66877003 -5.52058969 -0.37249361  0.52373996  0.25160397  1.68680059\n",
      "  0.38490702 -0.23401227 -0.39180294 -0.8020125   0.00899758 -0.18389964\n",
      "  0.19871257 -0.8053301  -0.1088582  -2.92087223 -0.94344116 -1.244668\n",
      " -0.17370353 -0.53342841  2.28952344 -0.28739771  0.12685438 -0.44096918\n",
      " -0.84288696 -0.18276211  0.5520537   0.23123329  0.11611515  1.66334092\n",
      "  1.03540818  1.37882276 -1.68945397 -0.83168956  1.37992491  0.19110676\n",
      "  1.45775884 -0.08629465 -0.46501451  1.10801221 -0.60931481  0.38547676\n",
      "  0.67392649  1.18851635 -0.52776233  0.84375179 -0.61817358  0.22326184\n",
      " -0.67268665 -0.93708327  0.5677803  -3.0159831   0.2290767  -0.30088845\n",
      " -0.42256673  0.19516956  0.22071095  1.18967207 -1.0346643   2.1933046\n",
      " -0.85505254  0.04001465]\n",
      "------counter :75-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.04266481e-01  1.02024978e+00  1.45811084e+00 -6.40164509e-01\n",
      "  6.87356989e-01 -2.06541377e-01 -1.60398470e+00  5.03824620e-01\n",
      "  1.79135507e+00  7.69752280e-01  1.03252155e-01  2.74637492e-01\n",
      "  1.39137855e-01  2.33329755e-01 -7.44593136e-01  1.57708999e+00\n",
      "  3.26154734e+00 -8.62507795e-01 -9.13029216e-02 -3.04624362e+00\n",
      "  1.30633585e+00  8.37447280e-02  5.22018841e-01 -1.64053570e-01\n",
      "  7.54895457e-03  4.40119026e-01 -5.74281515e-01 -5.62139120e-01\n",
      "  2.68561553e-01  4.41244432e-01  2.20662772e-02 -3.40920084e+00\n",
      " -3.47201696e-02 -2.61312703e-01 -1.00189187e+00  1.77325899e-01\n",
      " -1.57747139e-01 -4.56365211e-02 -3.25084664e-01 -7.51770457e-01\n",
      "  6.74447111e-01 -8.71100583e-01  5.19712021e-01  6.75133177e-01\n",
      " -3.02520457e-01 -1.13112643e+00  1.84069511e-01  9.80969889e-01\n",
      "  1.11368521e-01  9.85614344e-02 -6.54548300e-01 -9.14473113e-01\n",
      "  5.85651279e-01 -4.27358314e-01 -2.70002773e+00 -2.52693661e-01\n",
      " -1.78382043e-01 -1.63795457e+00 -5.43330625e-01 -2.92503527e-01\n",
      " -7.23974896e-01  4.76458157e-02  3.31130755e-01  1.97708281e-01\n",
      " -9.63710349e-01 -7.65858902e-01 -8.18158580e-02  7.36763549e-02\n",
      " -2.32966897e-01  1.14536072e-02 -1.32107312e+00  3.93299380e-01\n",
      "  1.26456404e-04  4.75823117e-01  7.74656250e-01  6.96111485e-01\n",
      " -3.63452850e-01 -3.58527899e-01 -7.69723814e-01  1.54083920e-01\n",
      " -5.28493230e-01 -1.26281768e-01  2.96724197e-01  1.07683959e+00\n",
      "  3.56496774e-01  1.95217027e+00  2.82314161e+00 -1.68734487e+00\n",
      "  3.44631429e-01  3.10665604e-01 -1.02603231e-01 -1.57083820e-01\n",
      "  1.22080076e+00  6.30887578e-02  1.32454656e+00 -8.38673429e-02\n",
      " -2.86031158e-01  4.39936535e-01 -1.23407050e-01 -7.86989951e-01\n",
      "  3.95531835e+00  1.69042371e+00  4.44863190e+00 -5.08379912e-01\n",
      " -6.93180663e-01  1.90093287e-01 -1.07531022e+00  1.74371957e+00\n",
      " -3.36285269e+00 -2.56763818e-01  4.51286706e-01 -6.06683165e-01\n",
      " -4.17554801e-02 -8.20146047e-01  1.84006130e+00  2.15449119e+00\n",
      " -1.38772013e-01 -7.49385326e-01  4.83494415e-01 -1.34411492e+00\n",
      " -4.64474918e-01  5.15659645e-01  1.40989777e-01  2.09643104e-01\n",
      " -3.52603101e-02 -8.15252621e-02  3.09472878e-01  5.80522558e-01\n",
      "  6.69602483e-01 -4.62609931e-01  3.15652734e-02  1.34099356e-01\n",
      " -2.46795735e-01 -1.79040002e-01  9.61619871e-02  7.17181593e-01\n",
      " -6.55507402e-01 -4.64717363e-01 -2.01468952e+00 -4.93298134e-01\n",
      " -1.21967698e-01  5.47161808e-02  3.56785322e-02  1.08252845e+00\n",
      " -1.62110241e-01 -2.77419354e-01 -1.28440965e+00 -7.37776393e-01\n",
      "  4.51986077e-03 -6.89377623e-01  5.52611723e-01 -6.05094576e-01\n",
      "  7.06977970e-01 -1.33191238e+00 -5.90396914e-01 -3.73904790e-01\n",
      " -1.65874017e-01 -1.03745552e-01  2.31715711e+00  2.36842845e-01\n",
      " -2.46142477e-01 -7.04431638e-01  3.03949291e-01  1.44486947e+00\n",
      "  3.38823396e-01 -1.89843924e-01  1.38483595e-01 -1.61726029e+00\n",
      "  1.04768450e+00  1.04475479e-01 -7.07746650e-01  2.03031664e-01\n",
      "  1.35938043e+00 -8.40718590e-01 -5.76235952e-01 -9.30838971e-02\n",
      " -4.24648230e-01  2.53737996e+00 -4.07807455e-01  3.13972954e-01\n",
      "  1.93845896e-01  5.52779199e-01 -2.24593405e-01  9.64636099e-02\n",
      " -1.95673837e-01 -3.55011156e+00 -3.50148520e-01  3.06657082e-01\n",
      "  1.16212333e+00 -3.97516773e+00  6.25210241e-01 -2.90389161e-01\n",
      " -3.00417652e-01  1.82313420e-01  3.87370902e-01  4.29770243e-01\n",
      " -4.28625066e-01  2.32031005e+00 -1.04733715e+00 -4.19321990e-01]\n",
      "------counter :76-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44479405  0.14118355  0.72696346 -1.33632096 -0.38544672 -0.16961282\n",
      "  0.74031975  0.99773702 -0.82704344  0.18223973  0.1835999   0.49873657\n",
      " -0.56233813  0.74481649  1.6665518   0.06907013 -2.36212184  0.3805379\n",
      "  0.1449854   1.5228146   0.9069629  -0.1518768   0.22938467 -0.65720142\n",
      " -0.30897937  0.70052517 -0.04941177  2.23651124  0.12764535 -0.06367495\n",
      " -0.41554224 -2.9148237   0.05968184  1.16031958 -1.56405468 -0.11650184\n",
      " -0.20286889  0.07126324 -0.39500201 -0.23750697  0.15156001 -1.0918552\n",
      " -1.98410945  0.86769639 -0.51311414 -1.42678338  0.28150861  1.19235499\n",
      " -1.0184586   0.32106693 -0.18303111 -1.16056376  0.68820886 -0.11880221\n",
      " -0.3057964  -0.42812148 -0.20114261 -3.77199056  0.67333391  0.12745042\n",
      " -0.44149119 -0.14965732 -0.23786629  0.09721517  0.51431704 -0.7373316\n",
      " -0.10945537  0.02580235 -0.20683811  0.54642593 -0.77580903  0.32063489\n",
      "  0.52050456  0.662996    1.3204563  -0.36487971 -0.25047015  1.23724117\n",
      " -0.38380497  0.32700755  0.72833022 -0.05211613  0.54686835  0.11449784\n",
      " -0.2130306   2.16094046 -0.30718711 -0.51891659 -0.0651939   0.06541892\n",
      "  0.18240426  0.3062722   0.29286043  0.63542196  0.6031028  -0.29188251\n",
      " -0.32835786  0.25867358 -0.21075589 -0.16574935  3.41622197 -0.02429708\n",
      "  2.45645714  0.82335091 -0.63047279 -0.03526339 -0.73303664 -1.64012608\n",
      "  0.47331175 -0.23401942  0.19082904 -0.80403557  0.0908441  -0.75715909\n",
      "  1.78955329 -0.37947283  0.05680021 -0.1633787   1.12997856 -1.70026758\n",
      " -0.48254002  0.54394019  0.2262282   0.05352335  0.75394697  0.99395696\n",
      " -0.0409218   0.26419231  0.95474131 -0.61260218 -0.33996034 -0.03206064\n",
      "  0.02147497 -1.4443221   0.07251858  0.46653742 -0.7700093   0.2980534\n",
      " -0.17879615  0.02432514 -0.91320658 -0.25586496 -0.03971982  1.24453719\n",
      "  0.19525007  0.06598014 -0.82691793  0.13896145 -0.18482746 -1.55636886\n",
      "  0.54594192  0.61994949 -0.96263665 -0.38308657  0.09438863 -0.81863478\n",
      "  1.89500458  0.69156156  3.17572195  0.0781306  -0.306449   -0.83354758\n",
      " -0.4721045  -0.35111956  0.23739551 -0.09233898  0.15506438  1.90608254\n",
      "  0.91224576 -1.43444615 -1.23741565  0.12712452  0.61191173  0.34563706\n",
      "  0.64280079 -0.38011781 -0.68974618 -3.34408384  0.12213798  0.34668068\n",
      "  0.12272618  0.25326921 -0.17751814 -0.17591155  0.63377602  0.02525769\n",
      " -0.19320297 -0.60862456  0.46506849 -2.15429885  1.01425469  0.07129942\n",
      " -0.02855109  0.24854955  0.48656045  0.32624106 -0.38520572  0.18032426\n",
      " -0.95014792 -0.40452325]\n",
      "------counter :77-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.14021016e-01  3.36113487e-02  8.40856001e-01 -1.08877248e+00\n",
      "  4.09194680e-02  3.81888526e-01  1.93634608e+00  4.16222087e-01\n",
      " -1.02538782e+00  1.28766415e-01  4.89282797e-01 -4.68791025e-02\n",
      " -8.70849293e-01 -8.47537723e-02  1.43929070e+00  5.34645211e-01\n",
      "  6.20918662e-01 -8.62849386e-01  9.67809166e-01 -4.27360926e-01\n",
      "  5.85942471e-01 -5.18277372e-01 -1.30709947e-01 -1.73320401e+00\n",
      " -1.30635628e+00  4.44212753e-01  3.38420020e-01 -3.28933274e-01\n",
      " -2.41468237e-01  2.47106106e-01  5.82196592e-02 -3.00279790e+00\n",
      " -3.57591212e-01  2.46298447e+00 -5.50693181e-01  1.37979695e-02\n",
      " -2.91971948e-01  1.32800306e-01 -3.18077144e-01  8.30392595e-02\n",
      "  1.00016957e-01 -1.02803920e+00 -4.26474178e-01  1.13877818e+00\n",
      " -1.07899253e-01 -1.14547894e+00  7.06145584e-01  1.24122095e+00\n",
      "  1.10778990e-01  3.74257246e-01 -1.62064862e-01  2.87754471e-02\n",
      "  5.02664459e-01 -6.84265585e-03 -1.02407238e+00 -9.96966727e-01\n",
      "  4.47835826e-01  1.23940093e+00  6.31224742e-01  3.98641035e-01\n",
      " -1.13359352e+00  4.76173477e-02 -1.05848440e+00  8.58366102e-01\n",
      "  4.44211993e-01 -8.46173436e-02 -2.35482259e-01 -9.54530590e-01\n",
      " -8.22833451e-01  1.48267126e-01 -1.44926777e+00  4.65798666e-01\n",
      "  4.14940843e-01  8.29101658e-01 -1.51473082e-01 -9.69965331e-01\n",
      "  1.35744199e-01  1.01744980e+00 -3.75052880e-02  6.94068228e-01\n",
      "  1.51457382e+00  9.93654321e-02  9.64808337e-01 -1.96043181e-01\n",
      " -2.10265407e-01  3.20268890e+00  2.89642837e+00 -2.87600035e-01\n",
      "  2.50730047e-01 -2.09985191e+00  9.98372396e-01  6.59677857e-01\n",
      " -2.45512422e+00 -1.65892767e+00 -1.83121544e-01 -5.28094980e-01\n",
      " -8.77691245e-01 -6.14754456e-01  1.91026544e-01  8.98302157e-01\n",
      "  3.12728528e+00 -5.49070023e-01 -2.38907066e+00 -2.75476147e-01\n",
      "  5.58356278e-01  1.54433854e-02 -8.93212742e-01  7.66100110e-01\n",
      "  2.34107675e+00  5.53923003e-02 -4.44574404e-01 -5.00064125e-01\n",
      "  5.01949731e-01 -8.79899208e-01  6.17198711e-01  1.64872965e+00\n",
      "  1.51891928e-02  4.29027827e-01 -4.85235876e-01 -1.68169271e+00\n",
      " -8.38975143e-02  8.81245350e-01  7.10615444e-01 -6.60163880e-01\n",
      "  1.48097505e+00  4.12945496e-01  5.56992159e-01  3.07390810e-01\n",
      "  1.09100790e+00 -1.27056985e-01 -5.14495696e-01 -1.99083956e-01\n",
      "  7.28124197e-01 -1.05516958e-01  2.53491448e-01  8.65159872e-01\n",
      "  3.52879939e-01 -1.07048243e-01 -1.93419843e+00 -3.28973575e-01\n",
      " -5.03486665e-02  2.56980218e-01 -2.38347281e-01  1.56006642e+00\n",
      " -5.71056453e-02 -2.35386446e-01 -1.42202852e-01  4.14975350e-02\n",
      "  2.80682385e-01 -1.17444072e+00  5.02010737e-01  8.81872397e-01\n",
      " -1.41666445e+00  6.35642267e-01 -2.64253134e-01 -1.10944114e+00\n",
      "  1.33551879e+00  1.41972825e+00  3.27065828e+00  3.43166314e-01\n",
      " -3.60130297e-01 -7.94126070e-01 -7.37743247e-01 -5.65606779e-01\n",
      "  3.63505175e-01  4.94901598e-01  1.95044991e-01  1.76418557e+00\n",
      "  1.33368534e+00 -7.36347444e-01 -1.11933551e+00 -7.31694993e-02\n",
      " -7.51856616e-01 -2.07389874e+00  6.28375722e-01 -2.58672248e-01\n",
      " -2.06262815e+00 -1.14813889e+00 -2.29757253e-03 -2.40802460e-01\n",
      "  6.83459635e-02 -2.17399782e+00 -5.11491829e-01 -4.10693981e-01\n",
      "  3.88475978e-01 -2.19234186e-01 -1.28415965e-01 -9.20158928e-01\n",
      "  8.02664816e-01 -2.47421978e+00 -1.85262814e-01 -3.57175086e-01\n",
      "  4.23007258e-01  4.18337742e-01 -4.28693557e-02  4.74381855e-01\n",
      " -1.21913471e-01 -5.85967624e-01 -8.97478744e-01 -1.39097341e-01]\n",
      "------counter :78-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41815184  1.04563565  1.81246269 -0.96829406 -0.02936686 -0.75737476\n",
      "  1.09899601  0.31299481 -1.22318592 -0.62268607  0.76941456  0.55886862\n",
      " -0.75008635  0.71020426  3.06804644  0.33423638  0.71517129 -1.32417483\n",
      "  0.39751979  2.85952773  1.4061334  -0.89918101  0.20932364 -1.40275201\n",
      " -1.41119324 -1.18127504  0.2619781  -0.42331009  0.03980522  1.24827243\n",
      " -0.22993176 -2.9512191  -0.32912103  1.91299187 -1.14573486  0.33051352\n",
      " -0.29973373  1.02155891 -0.47078778  0.0722175   0.154626   -1.16935312\n",
      " -2.32291117  1.15472875 -0.16550865 -1.60212169 -0.50835696  1.01602059\n",
      " -0.57049427  0.52069918  0.05500716  0.2232653   0.32226016  0.10278537\n",
      "  0.81607215 -1.20841146  0.59386227 -1.90300343 -0.99902339  0.34591967\n",
      " -0.91524465 -0.39293388 -0.99023664  1.03918867 -1.08865375 -0.15696232\n",
      " -0.50976664 -0.72681125 -1.45202027  0.34224655  1.05166555  0.74149909\n",
      " -0.19246033  0.91089754 -0.02889913  0.00897313 -0.10520131  0.0419598\n",
      " -0.52673689  0.64394591  4.16492183  0.45555679  0.88211741 -0.00841775\n",
      " -0.09223871  3.99438809  2.07295931 -0.75780671  0.46288864 -0.17501218\n",
      " -0.08707178  0.43015544 -2.84242462  0.2787742   0.19034454 -0.43087383\n",
      " -0.5694574  -3.32094179  0.42485595 -0.37475083  2.20867561  0.37562375\n",
      " -1.47916663  0.26487344 -0.36124057  0.20021718 -0.86964913  1.34641381\n",
      " -1.65395166  0.19501683 -0.50615393 -0.33197163  0.39219607 -2.08924859\n",
      "  0.65289488 -0.58999292 -0.01305758  0.2040102   0.78902343  0.63876827\n",
      " -0.1904621   0.61900562  1.4702584  -0.43212693  1.58187792 -1.02543526\n",
      "  0.89097227 -1.53633793  1.45141199  0.57763899 -0.87572307 -0.37102072\n",
      "  0.0238774   0.11049782  0.28467718  1.21803226  1.03875115 -0.26188657\n",
      " -0.31726971 -0.83401774 -0.50973151 -0.09919104  0.53837562  2.09118593\n",
      " -0.29864452 -0.27628717 -1.24527025 -0.14887607  0.02602969 -0.01236857\n",
      "  0.13002734  0.67841229  0.24679751 -0.22387962 -0.53837924 -0.2364492\n",
      "  1.73900092  1.17706412  1.48763523  0.41880608  0.56101995 -1.35699198\n",
      " -2.1479604  -1.35144007  0.43145759  0.80069912  0.28812096  1.07080972\n",
      "  1.22765885 -0.97351303 -0.57446738 -1.08811613  0.54177315 -0.80640672\n",
      "  0.45159768 -0.24452871 -1.93205753 -0.95892101 -0.61292188 -0.14456965\n",
      "  0.45057083  0.1618199   0.16478085 -0.51571966 -0.81949041  0.99567804\n",
      "  0.01507552 -0.88892414  1.96983882 -1.92317284 -0.74783808  0.54511325\n",
      " -0.52459952  0.03077138  0.27265966  0.42384864  0.11090802 -0.65739591\n",
      " -0.72484702  0.14263009]\n",
      "------counter :79-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.88229901e-01  1.24863228e+00  3.79643540e+00 -1.43312410e+00\n",
      "  4.05291300e-01  6.78954311e-02 -1.68357611e+00  4.85560268e-01\n",
      " -7.56998567e-01  8.37863729e-02  2.03075253e-01  1.23238330e+00\n",
      " -4.53605956e-01  1.68731114e-01  1.80731126e+00  1.08503140e+00\n",
      " -1.94698185e+00  1.16200422e+00  3.52388830e-01  2.79126754e+00\n",
      "  1.14373318e+00 -2.11270584e+00  1.13985713e-01 -1.44694575e-01\n",
      " -3.36755061e-01  9.31255444e-01  7.10607486e-02 -6.85912162e-01\n",
      " -4.41920327e-01  6.56395992e-02 -9.78794234e-02 -3.91277019e+00\n",
      " -4.21688160e-01  1.14594762e+00  2.15951905e+00  9.63832932e-02\n",
      "  7.03006516e-02 -4.94808247e-01 -1.28692025e+00 -2.36687643e-01\n",
      " -1.32173004e-01 -2.15408589e+00 -2.03474118e+00  9.12891842e-01\n",
      " -8.17628876e-01 -1.37362462e+00 -1.12898677e+00  1.30946332e+00\n",
      " -7.64241736e-02  1.09217357e-01 -1.06225831e-01  1.59224124e+00\n",
      "  4.72501466e-02 -2.32156826e-01 -5.67808573e-02 -9.93104257e-01\n",
      "  7.42697143e-01  1.88180277e-01 -6.80050241e-01  4.15416874e-01\n",
      " -1.29022467e-01 -9.79294144e-01  3.56346515e+00 -1.49674137e-01\n",
      " -4.38083269e-01 -1.03353042e+00 -2.40121947e-01  1.88504147e-01\n",
      " -1.55397329e+00 -8.08810485e-01  6.78437062e-01  1.22606499e+00\n",
      " -1.17348584e-01  7.04298243e-01 -8.90175394e-01  1.64840769e-02\n",
      " -1.53349728e+00  1.06029600e-01 -8.63566423e-01  6.45998876e-01\n",
      "  4.79670184e+00  8.92434109e-02  4.52262492e+00  3.07834414e-01\n",
      "  1.90095587e-01  2.85160050e+00  1.62102271e+00 -5.20673813e-01\n",
      "  7.84120349e-01 -5.53376876e-01 -5.64768384e-01 -1.52906960e-01\n",
      " -2.34064344e+00 -1.41146149e-01  2.43068607e+00 -4.03869444e-01\n",
      " -2.14783836e-01 -5.17916374e-01 -4.94759232e-01  3.12106508e-02\n",
      "  2.18023726e+00  1.05658758e+00  6.74881397e-01  4.51256131e-04\n",
      " -5.78037113e-01  1.70685660e-01 -8.61226392e-01  2.91083477e+00\n",
      " -3.37856573e+00 -4.01174531e-01  1.91735247e-01 -1.57810560e+00\n",
      "  3.26340979e-01 -1.71005111e+00  5.00693818e-01  6.68804630e-01\n",
      "  1.70808134e-03 -1.85139769e-02  1.73736238e+00  3.34979181e-01\n",
      " -1.25984575e+00  1.61124141e-01  1.03748199e+00 -2.59511295e-01\n",
      "  5.52890095e-01 -1.94662822e+00  3.64722276e-01  1.93390373e+00\n",
      "  1.12549958e+00 -5.53033801e-01 -6.48259091e-01  1.83127987e-01\n",
      "  1.48116761e+00 -5.38310067e-01  7.95955713e-01  1.24262478e+00\n",
      " -1.23354964e-01 -5.35056164e-01 -2.87312837e+00  1.95927927e-01\n",
      " -7.97026517e-01  4.05350705e-03  8.64360848e-01  1.65845065e+00\n",
      "  4.70150336e-02 -9.92936077e-01  9.87629083e-01 -6.53717478e-01\n",
      " -3.19679918e-01  5.06182952e-01  8.76067709e-01  9.35185231e-02\n",
      " -1.91293883e+00 -6.58070192e-01 -1.92858480e-01  7.23761877e-01\n",
      "  9.51745103e-01  3.80891608e-01  1.81907373e+00  1.24910501e-01\n",
      " -2.63327198e-01 -1.99489043e+00  4.44353306e-01 -5.40865659e-01\n",
      "  4.02232583e-01 -1.50485102e-01  3.26264561e-01 -7.28471189e-01\n",
      "  3.49629118e-01 -3.76843888e-01 -1.29690465e+00 -6.73709395e-01\n",
      "  8.30445219e-01 -2.53869509e+00  1.57028924e-01  2.03525336e-01\n",
      " -1.68353034e+00 -4.79203646e+00  4.11251373e-01  1.15132854e-01\n",
      " -3.79526359e-01  5.59221434e-01  5.93041633e-02  4.84275088e-01\n",
      " -5.41159797e-01 -3.11131348e-01 -1.87520807e-01 -1.26192473e+00\n",
      "  6.35184071e-01 -1.71418814e+00  7.25983363e-01 -4.56243368e-01\n",
      "  5.13812173e-01  7.07243849e-01  4.13545931e-01  3.81789931e-01\n",
      " -1.00365098e+00 -5.78319499e-01 -1.23379121e+00 -1.86583978e-01]\n",
      "------counter :80-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41308961  1.32658646  1.41251329 -1.18269061 -0.0968758  -0.85684609\n",
      "  0.24719814 -0.65152604 -1.10913447 -1.02233152  0.48642807  0.59715809\n",
      " -0.4148536   0.92257685 -0.07115126  0.33174803  0.16136976 -1.57717798\n",
      " -0.12786086  4.30200982  0.47209967 -1.78705846  0.69434305  0.08919305\n",
      " -1.19925067  0.05094253  0.41551151 -0.98171047 -1.06622335  2.70733968\n",
      " -0.21015285 -3.83936172 -0.6642119   2.83453872  0.88456719 -0.11634015\n",
      " -0.41503642  0.0653028  -0.82862187 -0.16202152 -0.94500657 -0.85113291\n",
      "  3.84244051  1.11844781 -0.15337934 -1.50445959  1.09755709  1.16530394\n",
      " -0.43321918 -0.03355147 -0.19653466  0.83706755  0.23577062 -0.33122275\n",
      "  2.25906687 -1.69654406  0.83601163 -1.02297994  0.7269486  -0.29516007\n",
      "  0.36439876 -0.60935369  3.45559136  0.49699603 -2.06932836 -0.70649749\n",
      " -0.24030653 -1.62304921 -0.27575348  0.32118063  1.85632948  2.24619547\n",
      "  0.38569919  0.37916373 -1.62229001 -0.41737755 -0.7548409   0.39297925\n",
      " -0.63939515  0.31580281 -0.05727617  0.03177484  3.23781686  1.07700383\n",
      "  0.42628489  4.52999975  1.81436576 -0.96593081  0.14421195 -1.16507282\n",
      "  0.39095581  0.01438665 -6.151021    0.21199568  2.86736518 -0.33824076\n",
      " -1.4888484   0.14027159 -0.77316223  0.09183715  2.97340912 -3.23936282\n",
      "  0.05652939  1.82171516 -0.01161482  0.26286257 -0.44360379  0.52556162\n",
      " -0.96532182 -0.24801119  0.08525429 -0.65393121  0.13785764 -1.15438687\n",
      "  0.31702699 -0.33178721 -0.28118565 -0.00973058 -1.88853508  1.72577425\n",
      " -1.2117533   0.709063    1.05241882  0.6254687   0.38396564  1.29718586\n",
      "  0.23960843 -0.77570923  1.14617184 -1.33716034 -1.01933597  0.39476135\n",
      "  0.82458571  0.7106855   0.90066964  1.36685586 -0.61580815  0.12546413\n",
      " -0.89029238 -0.20101427 -0.06610861  0.23686165  0.07599547  2.09376345\n",
      " -0.27248904 -1.07336923  2.47235348 -0.90403036 -0.09602015 -0.09346495\n",
      "  0.6134753   0.55495817  2.26368956 -1.01944181 -0.26433725  0.28373367\n",
      "  0.89122588 -0.32038241  1.8385574  -1.67460028  0.13261039 -1.24670468\n",
      " -0.79736138 -0.69048712  0.44624502  0.71516513  0.58189783  0.43072981\n",
      "  0.46433566 -0.5831454  -1.39897835 -2.3063842  -1.36525649 -0.07788931\n",
      " -0.84065976  0.02260126 -2.25871403  0.64103303 -0.90506623  0.4674667\n",
      "  0.58460858 -2.07501499  0.34036023  0.17806471 -0.48639735 -0.60287909\n",
      " -0.22917204 -1.60133479  1.46268519 -3.24191453 -0.37004691 -0.3814226\n",
      " -1.30766285 -0.11330105  0.31796056  0.68950943 -0.53586875 -0.544409\n",
      " -0.46775267 -0.15035638]\n",
      "------counter :81-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.69318010e-01  6.37850412e-01  1.96796729e+00 -1.30712231e+00\n",
      "  6.21959546e-01 -4.32907053e-02  9.91261158e-01  9.70039762e-01\n",
      " -8.74529092e-01 -5.60527849e-01  5.36002648e-01  1.56691478e+00\n",
      " -6.20047533e-01  4.76851319e-01 -5.72736582e-02 -8.54045310e-01\n",
      "  2.67808696e+00 -1.40012389e+00 -1.85558754e-01  5.64305469e+00\n",
      "  9.16863472e-02 -1.74329356e+00  7.87641934e-01 -8.56660448e-01\n",
      " -1.07702358e+00 -1.08461859e+00 -2.21482873e-02 -2.35690896e+00\n",
      "  8.59676911e-01 -1.36542624e+00 -5.01128974e-01 -4.01611049e+00\n",
      " -4.62054371e-01  6.89004336e-01 -2.73830981e+00 -4.91347697e-01\n",
      " -3.46432349e-01  3.39238775e-01 -6.43339037e-01 -5.69504040e-01\n",
      " -9.03569440e-01 -2.84382305e+00  3.59350138e+00  4.40884872e-01\n",
      " -2.04132871e+00 -9.25506006e-01  9.22416133e-01  1.22433606e+00\n",
      "  1.02058191e-01 -8.39545056e-02  1.31454490e-01  1.13972913e+00\n",
      " -4.90539803e-03 -4.01585699e-01  1.71824119e+00 -1.97838632e+00\n",
      " -3.26473291e-01 -7.66100379e-01 -6.60147680e-01  6.41881289e-01\n",
      " -2.81373762e-01 -8.02595828e-01 -1.57686538e+00 -2.22248782e-01\n",
      " -2.04553881e+00 -2.17761945e-02 -4.23343474e-01 -3.39760068e-01\n",
      " -5.10606738e-01  6.06198779e-01  3.21938621e-01  3.33336422e-01\n",
      "  4.15382268e-01  2.52941000e-01 -1.99340107e-01 -2.24899361e-01\n",
      " -8.54972555e-01  9.96675192e-01 -6.93245496e-01  5.75614609e-03\n",
      "  1.40149714e+00 -6.79191571e-01  2.10946612e+00  1.12977395e+00\n",
      "  1.52772785e-01  3.00102238e+00  1.69011751e+00 -1.18160816e+00\n",
      "  2.96130539e-01 -4.79656720e-01  2.32918179e-01  7.19390055e-01\n",
      "  8.57608134e-01  9.60274197e-02  2.07901419e+00 -1.01908790e-01\n",
      " -2.44628043e-01 -4.53493283e-01  7.35065708e-01  3.05220013e-01\n",
      "  2.33022284e+00  5.60454882e-01  7.53523515e-01  1.28658509e+00\n",
      " -1.23697462e-01  9.32279743e-01 -6.37843978e-01  4.78054279e-01\n",
      " -7.10023130e-01 -2.77328724e-01  1.86945355e-01 -7.06395977e-01\n",
      "  1.60293169e-01 -1.93352161e+00  2.81869890e+00  1.10624176e+00\n",
      " -1.41968256e-04 -4.91753500e-02  1.44940424e+00  1.20540193e+00\n",
      " -5.12329186e-01  6.14319059e-01  6.48813551e-01  2.11338826e-01\n",
      " -5.17834470e-02  4.45121360e-03  3.63156205e-01 -6.96419375e-01\n",
      "  1.01019964e+00 -8.58923147e-01 -1.01401177e+00 -3.91169965e-01\n",
      " -1.88831403e-01  2.19224761e-01  7.51724287e-01  1.30058374e+00\n",
      " -1.79113043e-01 -4.24280765e-01 -1.87394060e+00 -1.56196400e-01\n",
      "  2.38361471e-01  5.45103389e-01  1.55506332e+00  1.40061968e+00\n",
      "  6.72343299e-02 -6.73648148e-01  6.23907016e-01 -1.12584753e+00\n",
      " -4.87374481e-01 -5.50896438e-01  7.38832894e-01  7.40394393e-02\n",
      " -1.69984190e+00  2.15175831e-01 -4.74796316e-01 -7.50672255e-01\n",
      "  4.29265824e-01  2.08707883e+00  2.70497369e+00 -5.55865949e-01\n",
      " -1.66515718e-02 -1.55083342e+00 -5.75550257e-01 -1.30134457e-01\n",
      "  4.81527902e-01  4.54465928e-01  6.20325912e-02  7.76166444e-01\n",
      " -5.80016510e-02  1.15183506e+00 -1.61855094e+00  2.89921764e-01\n",
      " -1.13486794e-01 -1.82359563e+00  8.44727917e-02  7.35366295e-02\n",
      " -2.19501755e+00 -2.73873195e+00  1.63735885e+00 -5.44166908e-02\n",
      "  2.10722179e-01 -1.76649275e+00  5.29811132e-01  1.08862192e+00\n",
      "  2.53339023e-01  7.39325309e-01 -3.48770714e-01 -1.35208533e+00\n",
      "  5.29351694e-01 -2.25363538e+00  6.29618404e-01 -1.44598986e-01\n",
      " -1.74101266e+00 -6.79860577e-02  7.40873964e-01  6.90898912e-01\n",
      " -6.49436965e-01 -7.92936645e-01 -1.52430375e+00 -6.61677144e-02]\n",
      "------counter :82-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92057099  1.4711619   1.53537399 -1.43660615  1.65898644 -0.17353481\n",
      " -1.71962738 -3.88669832  2.35859997 -0.59230813  0.26999096  1.10239401\n",
      " -0.2742326   0.74761294  1.52358891 -0.1017486   2.60254459  2.0270129\n",
      " -0.10080697 -2.62661852 -0.13154425 -1.12877771 -0.02763416  1.54411766\n",
      " -0.65248571  0.07026411 -0.30138449  1.44316765 -0.19211292  2.39298878\n",
      " -0.10637164 -4.00766012  0.06205379  2.03533564 -2.81152338 -1.02022183\n",
      " -0.62119276 -0.05481461 -0.62226628 -0.69347209  0.59521408 -2.35324206\n",
      "  1.5022581   0.86655717  0.32411948 -1.36270777  2.06002555  1.03639975\n",
      "  1.41533922 -0.05032406  0.43189356  0.76740806  0.19691383 -0.45828486\n",
      "  0.59091257 -1.10827942 -2.89148757 -2.56139378 -4.31428078 -0.2171464\n",
      "  3.45318959 -0.1096746   1.85735825  1.13447499 -1.63860363 -0.95650102\n",
      "  1.19068472  2.65933717 -2.07944571  0.1695486   0.24623547 -0.55375806\n",
      " -0.1077546   2.07670973  0.10946284  0.01275431 -0.60730155  0.11777859\n",
      " -0.34447277  0.18849501  1.71426687 -0.34486722 -0.25925328  1.35686084\n",
      "  0.35822093 -3.39198467  0.82055945 -0.89333532 -1.15556166  0.12687929\n",
      " -0.12749084  0.09541457 -9.51029155 -0.55193291  3.4684786   0.29701439\n",
      "  0.08273209  1.01763177  0.82255436  1.5279682   0.80369313  0.05123519\n",
      " -1.62627162  1.49825472 -0.78204893  0.58818089 -1.06563879  1.78661601\n",
      "  0.07769949 -0.18780081 -0.09206422 -0.46671332  0.13135293 -1.30708594\n",
      "  0.59621123  1.18162006 -0.67232149  0.93592521  2.61586776  1.32915705\n",
      "  0.22619565  1.54885473  0.63443102 -0.11237887  1.26954354  4.66148106\n",
      "  0.3155828  -0.6323962   0.50992129  0.21448844 -1.11145135 -1.10067863\n",
      " -0.93851445  0.73679667  0.68117352 -0.34182187 -0.70295465 -0.43440913\n",
      " -1.03640185  0.94276798 -0.1157199  -0.48929778  2.27476113  2.03471085\n",
      " -0.30020335 -0.68487752  0.77456459 -0.64254215 -0.09191823 -1.45782874\n",
      "  0.39037359  1.07528237 -4.16801618 -0.40903013  0.1035146  -1.94321518\n",
      "  1.29567185 -0.56615717  1.51037748 -1.85286128  0.32822881 -1.39127982\n",
      " -3.9862767  -1.29200801 -0.35443056  0.31087506  0.57749694 -0.36957776\n",
      "  0.25743793  1.25380404 -0.05301087  0.18399319  1.71610684 -0.07175788\n",
      " -1.49990237 -0.01133274 -1.37359166 -1.60276687  1.67994601  0.79789111\n",
      "  1.54404163 -1.52683019  0.39874582  0.32257779  1.0231334   0.08497316\n",
      " -0.29208727 -1.14389756  0.5320609  -2.34727105  1.18989129 -0.04234203\n",
      "  2.38492974  0.37828974  0.87789829  0.5815653  -0.18349214 -2.0561406\n",
      " -0.32076287  0.64792909]\n",
      "------counter :83-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37936134  1.29054831 -1.70873781  1.37541173  1.46438938 -0.1594687\n",
      "  1.91888993  2.27996377  2.28507904 -1.69332846  1.70029254 -0.67278997\n",
      "  0.25634085  0.7805207  -2.26790461 -0.10708854 -0.35730787 -0.50123488\n",
      " -0.82117227  5.20586757 -1.44599199 -0.62116928  1.9301629   1.44001508\n",
      " -1.47785047  0.17443268  0.49679519  0.84994016 -0.70245759 -1.01569342\n",
      "  0.06905556 -4.30035602 -0.29907083 -1.8759369   5.3567128  -0.12228495\n",
      "  1.27280442  0.43712254 -1.25927501 -0.84458457  2.75716472 -2.90616873\n",
      "  0.24791129 -0.33833604 -0.41111032  0.32188779 -0.61932676 -1.61249523\n",
      "  1.31943423 -1.72307052  0.9554072   1.55419219 -0.31221098 -0.62364358\n",
      "  0.68822905  0.56813207  1.00699776 -2.77746373  2.19883441 -0.14117774\n",
      " -0.07314484  0.22105164  3.11325843 -0.90104486 -2.63597957 -0.18085304\n",
      " -2.11368715  0.46524216  0.61598795  2.18727983 -3.07924417 -1.18140913\n",
      " -0.10112691  1.14923635  1.15395886 -0.09951112  1.76767769  0.79646766\n",
      "  0.56918428 -2.56115923  0.52640397 -1.18744842 -0.57448083 -0.52127568\n",
      "  1.36680425 -5.34755686 -1.49632204 -3.41787708 -3.12892114 -1.7395094\n",
      "  0.74970589 -0.30037802  5.94676923  1.98749023  1.14799559 -0.21148136\n",
      "  1.37729526 -0.84406942  1.50604343  0.40898406  0.24542943  0.29041326\n",
      " -2.62595766 -2.66022139  0.22324493  0.27626403 -0.2189093  -4.40348409\n",
      "  1.77204061 -0.42540146  0.46284903  0.12949289 -1.06284831 -1.93850236\n",
      " -2.59134198 -4.78620524  0.9245592  -0.01140291 -0.46676155  1.93123591\n",
      "  1.45604426  0.10927692  0.93176848 -0.18876232  0.52296638 -1.85103563\n",
      "  0.81607866 -2.9841731  -1.92747232 -0.73537144 -0.66719984 -0.45822877\n",
      "  1.66680599  2.95216892 -0.16593333  0.43567826 -1.85728703 -0.09017501\n",
      " -1.74520866  0.47349232  1.05041569  1.40534433 -0.35595168  3.38041933\n",
      " -0.36580622 -1.63222196  1.80706623 -1.58875629  0.16895273 -0.50209693\n",
      " -0.7181837   1.92325129 -3.32389247 -2.83756402 -0.45347094 -2.69404261\n",
      "  1.57947124  5.12835456 -3.0038472  -0.81104723  0.89286126 -1.2825911\n",
      "  0.46805999  0.19753238  0.40811644 -0.71675423  0.10910609  2.28593642\n",
      "  0.49285135  5.16052904  0.86725025 -2.25993447 -2.87376692  0.84276195\n",
      " -2.06457868  0.579796   -0.29282105  4.85856787 -0.12042829 -1.93349145\n",
      " -2.02884999 -0.42323954 -1.6137498   1.48995474  1.68360058  0.75843848\n",
      " -0.24503417 -1.48738052 -0.51908235  9.42764414  1.49982344  0.30177657\n",
      " -1.26859037  1.3446014   0.92674498  0.72736712  1.89804947 -0.04555121\n",
      " -1.22556203 -0.19910696]\n",
      "------counter :84-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.14324031e-01 -5.41640171e-01 -7.49434695e-01  1.92481613e+00\n",
      " -5.86554367e-01  1.67089379e+00 -2.28297796e-01  1.87518683e+00\n",
      "  2.61238177e+00 -1.98065334e+00  1.41977467e+00 -8.67377718e-01\n",
      " -4.38187979e-01  1.33542401e+00 -5.68749350e-01 -4.35898199e-01\n",
      " -1.82097849e+00 -8.76073526e-01 -3.39894310e-01 -2.76545167e+00\n",
      "  2.80708053e+00 -6.29632703e-01  2.62214606e-01  2.78854145e-02\n",
      " -8.80412780e-01  1.37409233e+00  8.29070456e-01  2.34857679e+00\n",
      " -2.55979533e-01  6.52368537e-01 -4.19416767e-03 -4.56464647e+00\n",
      " -6.21521389e-01  2.59645097e+00  1.52865160e+00 -3.86301620e-01\n",
      "  1.12629424e+00 -1.86614531e+00  7.27675910e-01 -1.10543236e-01\n",
      "  1.50332509e+00 -5.33995429e-01 -1.91402975e+00 -3.94129749e+00\n",
      " -2.53773835e-02  9.31654826e-01  8.44322738e-01  1.54844596e+00\n",
      " -1.16582329e+00 -5.22112839e-01  5.67955053e-01 -1.30068553e+00\n",
      "  7.07771968e-01 -6.17545826e-01 -2.76027723e+00 -8.90185015e-02\n",
      "  6.52183421e-01 -7.76339639e+00 -2.72051480e+00 -3.81013339e+00\n",
      " -1.63278358e+00  1.34950761e+00 -1.11358410e+00  5.80661974e-01\n",
      " -2.10244263e+00 -4.29652158e-01 -5.44480563e-01  4.30030431e-01\n",
      "  3.60036566e-01  4.72503835e+00 -1.75528754e+00  3.18433315e+00\n",
      " -9.73056771e-01  2.10729676e+00  3.83411508e+00  9.30097066e-01\n",
      "  1.16820511e-01  1.07164447e+00 -1.01911235e+00  1.00428599e+00\n",
      "  4.50683901e-01 -1.08396468e+00  4.68083920e-01  6.10817620e-01\n",
      " -6.59265625e-01 -4.42284445e+00 -1.05187240e+00  4.65586567e-01\n",
      " -9.87809659e-01 -1.14222384e+01 -1.99447629e+00 -4.13624709e-01\n",
      " -4.65348982e-01  1.50956047e+00  6.81223561e+00 -9.53273431e-01\n",
      "  1.30624501e+00 -1.75646308e+00  4.58364503e-01  3.49931412e-01\n",
      " -5.46638244e-01  1.19348096e+01 -4.74538384e+00  1.04954831e+00\n",
      "  1.55179485e-01  2.37063735e-01 -1.75825645e+00 -2.34582677e+00\n",
      " -5.79568253e-01  9.32137791e-01  1.47944161e+00 -4.56415871e-01\n",
      "  1.96197674e+00  3.01032182e-01  4.19522763e-01 -7.86632349e+00\n",
      " -9.00057126e-01  3.14932103e+00 -2.64182903e-01  1.11018785e+00\n",
      "  7.97006351e-01  4.33138762e-01  1.21021421e+00  1.21158768e-01\n",
      "  1.31645359e+00  1.80891072e+00  9.18889569e-01  4.28586453e+00\n",
      " -1.22913313e+00 -2.13167332e-01 -6.14691704e-02 -5.29191460e-01\n",
      "  9.06624359e-02 -1.42003734e+00  1.21605450e-01 -1.81522854e-01\n",
      "  1.60159176e-01  1.06701459e+00 -2.24298390e+00  1.95786851e+00\n",
      "  1.25331050e-01 -4.00309286e-01  6.65343664e-01  3.36239641e+00\n",
      " -1.36596131e+00  6.50287698e-01 -4.69009239e+00  2.93558911e-01\n",
      "  6.91360432e-01 -8.37685329e-01  6.31327753e-01 -1.37140585e-01\n",
      "  5.43862449e+00  7.88857543e-01 -2.81989798e-02  1.12798862e+00\n",
      " -1.49494472e+00  8.79907057e-01  1.55568534e+00 -1.28906295e+00\n",
      "  1.66601550e+00 -2.65187535e+00 -1.17712381e+00  4.66695237e-01\n",
      " -1.21608112e+00 -9.01819430e-01  2.53929937e+00 -1.48622684e+00\n",
      "  1.31690126e+00  1.48944650e+00  4.46352311e-01 -4.27015984e-01\n",
      " -1.50950829e+00  1.80518542e+00 -3.96206734e-01  8.45244696e-01\n",
      "  1.26513135e+00 -4.19986867e+00  4.27253841e-02  2.59239307e+00\n",
      " -6.26156562e-01 -2.82811561e+00 -1.08134879e-01 -1.33733555e+00\n",
      " -2.02432596e+00  1.39128826e+00  5.97152314e-01 -3.00752251e+00\n",
      " -6.09116402e-01  8.67611161e+00 -2.91493730e-01  1.16325936e-01\n",
      " -1.39370427e+00  5.03301863e-01  2.10330832e+00  5.54584157e-01\n",
      " -1.91587429e-01  1.91888466e-01  5.13358139e-01 -4.06965546e-01]\n",
      "------counter :85-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.65038779e-01 -9.04157700e-01  6.96484399e-01  1.54723240e-02\n",
      "  5.54944264e-01 -9.34421645e-01 -4.41133407e+00  3.65109004e+00\n",
      "  1.65558719e+00  3.92507679e-01  1.06377277e+00 -7.74046352e-01\n",
      " -6.92282052e-01  1.26277828e+00  2.79969843e+00 -1.56708232e+00\n",
      "  2.19195511e-01  1.52267304e+00  1.09416234e+00  9.15751060e+00\n",
      "  3.22508390e+00 -4.00130827e-01  8.82937124e-01  1.30612023e+00\n",
      " -6.88738509e-01 -6.12925268e-02 -6.72963294e-01 -3.03416593e+00\n",
      " -1.33281318e-01  6.79268964e-01  3.37127075e-01 -8.81366245e+00\n",
      "  9.56930904e-01  2.90693008e-01 -2.88270970e+00 -1.68189927e+00\n",
      "  2.21614541e+00 -6.55421374e-01  5.09033073e-01 -8.16403313e-01\n",
      "  2.02648073e-01 -6.16505493e-01  1.37864315e+00 -3.92564188e+00\n",
      "  5.27202316e+00 -1.09490100e-01  1.03247653e+00  8.51793936e+00\n",
      "  1.68802179e+00  2.36650269e-01 -1.27082978e-01 -5.55469542e-01\n",
      "  1.45892924e+00  3.89093513e-01 -1.57551818e+00 -1.29863374e+00\n",
      " -4.36129038e-01 -1.02113495e+01  2.59679863e+00 -6.25644679e-01\n",
      " -2.88293383e+00  1.36133300e+00 -3.62498523e+00 -2.11644113e-01\n",
      " -5.30060973e+00  9.35989715e-01 -1.35273999e+00  2.14726362e+00\n",
      "  6.43487169e-01  3.24016646e+00 -4.61285317e+00 -1.46469381e+00\n",
      " -1.24510592e-01  1.66799538e+00 -8.04498143e-01 -6.47381928e-02\n",
      "  7.51867610e-01  6.15668896e-01 -1.08254056e+00 -9.95086595e-02\n",
      "  1.48134693e+00  1.83606430e-02 -1.27694331e+00  3.15033464e+00\n",
      "  1.54660392e+00 -7.61997081e+00  2.50338667e+00  2.52457058e+00\n",
      "  1.87891595e+00  2.02185507e+00  1.29731219e-01  1.65958424e+00\n",
      "  8.83374372e+00 -6.93718688e-01  1.23198259e+00  4.20601992e-01\n",
      " -3.50286568e-01  5.47945419e-01  9.43478914e-01 -9.48508136e-01\n",
      " -1.30160589e+00  5.86906385e+00 -3.94693709e+00 -6.43585203e-01\n",
      " -1.26853459e+00 -1.78226622e-01 -1.03268481e+00 -4.52653149e+00\n",
      " -3.85907480e+00 -7.25638467e-01  1.27667609e+00 -7.31238419e-01\n",
      "  1.31139622e+00  8.00698597e-01  3.08371866e+00 -3.98849320e+00\n",
      "  1.14107782e+00  6.71474597e-01 -1.50314406e+00  4.90271870e+00\n",
      "  7.23764735e-01 -7.07422745e-01 -3.81622119e-01  1.58903138e+00\n",
      "  1.58119450e+00 -3.48878118e+00 -7.43726809e-02  1.60698624e+00\n",
      " -1.58198941e+00 -1.98669632e+00 -4.94169181e-01  2.25056538e-01\n",
      "  1.73436458e+00  8.37282365e-01  1.22788597e+00  2.15306736e-01\n",
      "  6.47850483e-01  1.14639236e+00 -1.60045424e+00 -3.26811498e+00\n",
      " -2.89899025e-03  3.35347001e-01 -9.95826105e-01  3.75881856e+00\n",
      "  1.38286541e+00  3.88649526e-01  2.70066917e+00 -1.60573004e+00\n",
      " -1.12026992e+00 -1.31815940e+00  1.72346374e-01  8.67963452e-01\n",
      "  2.02307713e+00 -1.31709322e+00 -3.33017936e-01  1.41390375e+00\n",
      " -2.21380589e+00  4.28348252e-02  1.61726271e+00 -9.00866634e-01\n",
      "  1.29439285e+00 -2.11485818e+00  3.48240935e+00 -1.13901891e+00\n",
      " -1.03880874e+00 -1.20490182e+00  6.50460662e-01  8.84317038e-01\n",
      "  2.26342491e+00 -2.32001634e+00 -1.57091521e+00 -9.03839097e-01\n",
      "  1.90412062e-01  7.54940077e-01 -1.35766749e+00 -5.33922746e-01\n",
      " -7.16130341e-03  4.50697147e-01 -7.77163485e-02  1.25078389e+00\n",
      " -3.77796822e+00 -2.99449363e+00 -2.17496258e-01 -1.01070758e+00\n",
      " -1.15364285e+00 -3.66641302e-01 -1.46414283e+00  5.53964503e-01\n",
      "  7.33874619e-02  6.97701662e-01 -5.70725821e-01 -7.75964608e-01\n",
      " -4.43494752e+00  1.25656850e+00 -1.02892204e+00 -4.95744524e-01\n",
      "  6.52240416e-01 -1.60140145e-01  1.41077927e+00  9.22716537e-01]\n",
      "------counter :86-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.16393029  -0.73495294  -0.92595655   0.58893592   0.50233559\n",
      "   0.18021882  -3.30763835  -3.84738757   0.12986518   0.88170124\n",
      "   0.65588047   0.6164361    0.64349433   0.9422379    0.89208946\n",
      "   1.45237865   1.75262125   1.19167976  -0.02853292  -0.76297794\n",
      "   0.91249653  -0.09319829   0.18888245  -0.20158106   0.41091231\n",
      "   0.81871437   0.65163399  -0.48767023  -0.66774798  -0.03951795\n",
      "  -0.19520447  -3.86044869   0.01656278   1.26092143  -0.79944413\n",
      "   0.04133891  -0.26594663  -0.09115292   0.50360216  -1.06417648\n",
      "   0.73458921  -1.14455869  -2.20115519  -0.04878817  -0.53676324\n",
      "   0.60691554  -1.21195049   0.13630508   0.85838278   1.38746478\n",
      "   0.54515697  -0.82193017  -0.64302417   0.90997605   0.22502149\n",
      "  -0.4509615   -0.69156584   4.14995307  -3.13293577   0.569206\n",
      "   0.07917044   0.74140716  -2.20760403  -0.03625895  -3.10963807\n",
      "  -0.10715142   0.12290794   0.04549141  -0.09551098   1.97414221\n",
      "  -1.06856173   1.57896778   0.806412     0.41496731   1.7747334\n",
      "   1.42402011  -0.27777622   0.97710617  -0.4203112    0.16751544\n",
      "   0.92296765  -0.2311866   -1.76507182   0.8663523    1.33551944\n",
      " -10.07404501   0.5323282   -0.48340206   0.7525396    1.97942809\n",
      "   0.19705397   0.59307963   3.82603154   0.40742646  -0.86776696\n",
      "   0.53705271   0.21129655  -1.68737493   0.2558913   -0.30862174\n",
      "   0.04633102   3.56058935  -9.39712767  -0.13403067   0.45135907\n",
      "   0.72399585   0.133388    -1.8242974    0.69175136   0.4537244\n",
      "   0.6808508   -0.55784523   1.2872275   -0.77317549  -2.02654805\n",
      "  -0.87353723   0.56559426   0.25733744   0.81851611   3.68356649\n",
      "   0.58254821  -0.04642816   0.34901105   0.49433145   0.35630368\n",
      "  -3.72837863   0.93278173  -0.41268323   0.26116257  -2.80526694\n",
      "  -0.04283023  -0.34333259  -0.62225056  -1.93986942  -0.46667478\n",
      "   0.37880908  -0.45160912  -0.99046475  -1.95622944  -2.48134324\n",
      "   0.44388156   0.85392539   1.40532109   3.04644804   0.44973583\n",
      "   0.5447014    1.0413688   -0.46519666   0.02299773   0.09251295\n",
      "   0.54471713   1.12696458   0.85412175  -0.01312995  -0.93905186\n",
      "   0.50590589  -3.40323818  -0.1236181    2.64726747  -1.35350167\n",
      "   0.58060993  -1.5385001   -0.73477829   0.93978173   0.71366798\n",
      "  -0.67725919   0.71646268   1.53003389   1.00220936   2.37406909\n",
      "  -0.48104308   0.30687349   1.06069753   3.04831833  -0.38506206\n",
      "   0.1867817   -0.08493451  -0.08275038  -0.08939892   1.14933524\n",
      "  -0.9539539    0.01517987   0.31766997   0.58246592   0.86500123\n",
      "  -0.26263037  -0.28841441  -0.46891462  -0.90463053  -1.64807333\n",
      "   0.86676351   0.50085317   0.51222553   0.77225051   0.91682696\n",
      "   0.23267058   0.02842696   0.3871678   -0.834257     0.99052898]\n",
      "------counter :87-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.90000022e-01 -7.78143187e-01 -3.74254650e-01 -2.28519534e-01\n",
      " -1.07444725e-02 -4.10925401e-01 -2.25914855e+00 -3.85617277e-01\n",
      " -1.59180404e+00 -1.65782434e+00  2.44326911e-01  5.20912538e-01\n",
      "  6.30986048e-03  1.67972926e+00  4.02527338e-02  5.11729784e-01\n",
      " -2.74414259e+00 -1.33083235e+00 -3.19808195e-01  2.59681980e+00\n",
      "  4.81737144e-01 -3.56911729e-01  2.22296694e-01  2.35461620e-01\n",
      " -4.55354247e-01  4.48016638e-01 -1.50229311e-01 -4.32039609e-01\n",
      " -1.06399443e-01 -2.35209376e+00 -5.05508563e-01 -6.42318613e+00\n",
      "  2.12357326e-01 -1.68168908e+00 -1.84736034e+00 -1.06269855e-01\n",
      "  1.79058929e-01 -8.01978236e-01  4.38386634e-01 -1.16439567e+00\n",
      "  1.13171570e+00 -1.47229034e+00  3.22735826e+00 -1.05868382e-01\n",
      " -7.62937137e-01 -2.71559478e-01  2.00842946e+00  4.82364033e-01\n",
      "  1.79778742e-01  2.92261750e-01  6.82292746e-01  6.81401806e-03\n",
      "  2.83028482e-01  7.72857092e-01  9.12430038e-01 -5.62980570e-01\n",
      "  1.62105457e+00 -3.02356415e+00 -2.50488213e+00  3.94256463e-01\n",
      " -5.38401424e-01 -6.37092425e-01 -5.84823018e+00  3.32611197e-01\n",
      "  2.44807339e+00 -1.76946753e-02  5.26248561e-02 -7.09537032e-01\n",
      " -1.19844340e-01  5.11953587e-01 -4.61357312e-01  4.40874095e-01\n",
      "  3.18277146e-01 -2.35870566e-01  1.16744326e+00  1.15512034e-01\n",
      "  5.44593520e-02  6.42248327e-01 -3.78788970e-01 -2.97467078e-01\n",
      "  1.75516879e+00 -6.80048914e-01 -4.74873014e-01  9.72435359e-01\n",
      "  6.10532597e-01  3.91614059e+00 -2.13368596e+00  2.22471675e+00\n",
      " -6.18598472e-02 -1.02807510e-01 -5.02529567e-03  2.30754414e+00\n",
      "  3.67621895e+00  3.44116824e-01 -3.55100113e+00  5.65971980e-01\n",
      "  8.69570699e-02  1.00332425e+00  1.54028875e+00  3.49304479e-01\n",
      "  3.91504170e-01  7.32323676e-01 -1.32046540e+00 -3.87908592e-01\n",
      " -2.18325758e-01  3.09629585e-01  3.10292683e-01  1.72117206e+00\n",
      " -9.22305676e-01  5.16174905e-03  8.68726982e-01  1.42825383e+00\n",
      "  8.43070359e-01 -8.84758975e-01  2.59300073e+00  2.53019633e+00\n",
      " -1.85366399e-01 -5.47313307e-01  6.16246034e-01 -1.41129689e+00\n",
      "  5.52596573e-01 -5.03213144e-02  2.18531792e-01  9.60094407e-01\n",
      "  1.49930269e+00 -8.82908347e+00  2.37256354e-01 -6.16948664e-01\n",
      "  9.16373589e-02  9.78315744e-02 -7.03070412e-01 -1.80644206e-01\n",
      " -2.26624308e+00 -2.17275700e-01 -4.50855470e-01  1.04399399e+00\n",
      "  6.40193767e-01  3.49731656e-01  3.03966583e-01  5.14559374e-01\n",
      "  1.33809493e-01  1.34504739e-01  1.37183318e+00  2.36556283e+00\n",
      "  1.69851772e-01  3.28432582e-01  6.66879957e-01  2.92832910e-01\n",
      " -3.89570278e-01 -9.82305125e-02  1.31346843e-01  9.47118031e-01\n",
      "  8.42458755e-01  9.90260535e-02 -1.04202900e+00 -3.74338910e-01\n",
      " -2.03943005e+00 -3.46176963e-01  2.04574908e-01  2.39099855e-02\n",
      "  6.90928166e-01  4.57422042e-01  6.54026748e-01 -1.80162547e-02\n",
      "  5.43899307e-01 -3.86537391e-01  2.36013355e-01  1.43079817e+00\n",
      "  1.12666263e+00 -1.57148481e+00 -4.43264867e-01 -1.42700912e+00\n",
      "  9.93166833e-01  1.14941827e+00  1.07822436e+00  5.96538547e-02\n",
      " -4.82361634e-01 -1.09026016e+00 -3.94860579e-02  8.46264524e-01\n",
      "  1.29373497e+00 -4.61900207e-01 -2.21947828e-01  1.59975045e-01\n",
      "  7.72097581e-01  2.29289794e+00 -8.30084631e-02 -4.45203658e-01\n",
      "  7.82815644e-01 -2.34280739e+00  1.28482301e-01 -3.26840215e-01\n",
      " -1.62072305e+00  6.32995757e-01  1.34092063e+00 -1.67321050e-01\n",
      "  1.04834420e+00 -8.89173263e-01 -1.10411613e+00  8.87275339e-01]\n",
      "------counter :88-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.43273272e-03  1.25430905e+00 -2.47426686e+00 -1.91165070e-01\n",
      " -3.41093576e-01 -7.88034739e-01  3.27518579e-01 -1.19301929e+00\n",
      "  1.83680468e+00  1.09794499e+00  1.03857506e+00 -2.00134650e-01\n",
      " -2.08254856e-01  1.19386260e+00  1.37292163e+00 -8.04870828e-01\n",
      "  6.54654090e-01 -6.89063544e-01 -4.37589570e-02  4.81916602e+00\n",
      "  1.13766403e+00  1.75571469e-01  1.16675017e-01  5.24684677e-01\n",
      " -6.75157814e-01  3.59805699e-01 -5.68470502e-01  5.08154681e-01\n",
      " -9.39196121e-01 -2.42142351e+00 -4.33449298e-01 -5.80170449e+00\n",
      "  7.13005386e-02 -4.76281675e-01 -1.60256460e+00 -1.24123660e-01\n",
      " -5.35264743e-01 -5.98324229e-03  5.40679130e-02 -8.13010125e-01\n",
      "  3.86843399e-01 -1.65067191e+00  1.68596503e+00  4.15539523e-01\n",
      " -9.06661443e-01 -3.65458199e-01  5.92063023e-01 -5.73067926e-01\n",
      "  3.70720703e-01  8.30937040e-02  6.11753723e-01  7.74816531e-02\n",
      "  5.24136949e-01  2.20592794e-01 -1.71829474e+00 -6.80263859e-01\n",
      "  7.03968480e-01  2.38002255e+00 -1.63023480e+00 -6.48367754e-01\n",
      " -3.48701604e-01 -1.35876153e+00 -4.37182264e+00 -1.67455399e-01\n",
      "  1.88104850e+00 -1.46566147e-01  5.15832990e-01 -8.31974569e-01\n",
      "  2.65287999e-01  1.32278367e-01  2.85278252e+00  3.28288072e+00\n",
      "  3.95594441e-02 -1.98412561e-01  5.37156650e-01 -3.43983823e-02\n",
      "  7.30353477e-02 -1.81676419e+00 -4.61171310e-01 -4.94484990e-01\n",
      "  2.11610811e+00 -6.62888211e-01  6.31977942e-01  4.10548003e-01\n",
      "  7.54937285e-01  1.13587222e+00  6.92794357e-01 -1.96295772e-02\n",
      "  8.77736303e-01 -1.22361362e+00  1.29505537e+00  1.17363667e+00\n",
      "  3.73330562e+00  4.82349408e-01  1.36625783e+00  2.43267412e-01\n",
      " -2.89365489e-02  9.00145874e-01  7.98749025e-01  6.28715875e-01\n",
      "  4.95882762e-01  2.96804591e-01 -2.19774328e+00 -1.93506128e-01\n",
      " -3.72502099e-01  1.06878091e-01  7.08404792e-03  7.28716470e-01\n",
      "  5.36173861e+00 -3.55495320e-01  1.27619301e-01  6.99748079e-01\n",
      "  2.17581066e-01 -8.75205355e-01  2.64683159e+00  2.31648292e+00\n",
      " -4.65872792e-01 -1.03909067e+00 -2.85883601e+00 -1.23670127e+00\n",
      "  5.00018857e-01 -5.14768027e-02 -4.62926624e-01  4.66019225e-01\n",
      "  1.22932898e+00  8.05189896e-02 -2.24768940e-01 -3.78569999e+00\n",
      "  1.78507146e-01 -2.61822481e-01 -8.93621740e-01  1.73417384e-01\n",
      " -2.92493952e-01  6.66508201e-01 -8.92340544e-01  5.74068133e-01\n",
      "  2.36983399e-01  4.68397593e-01 -8.34706244e-01 -2.78641854e+00\n",
      " -1.88455959e-01  2.26418842e-01  2.09698637e-01  2.09503381e+00\n",
      " -1.63314192e-01  5.71895740e-01  2.36311078e+00  4.70352441e-02\n",
      " -3.97968773e-01 -1.21914941e-01  2.57535725e-01  5.31218129e-01\n",
      "  8.05016270e-01  3.37749242e-01 -1.23884833e+00 -3.51748504e-01\n",
      " -1.87322677e+00 -8.89947564e-01  3.68472130e-01  1.01096120e-01\n",
      "  2.41995587e-01 -4.69155439e-01 -8.26033023e-01 -1.26802895e+00\n",
      "  3.14787276e-01  9.29510009e-01 -4.05786452e-01  1.13848156e+00\n",
      "  6.03645096e-01 -3.06205900e+00 -6.50947958e-01  4.03040658e-01\n",
      "  7.72578078e-01 -2.25686765e+00  7.04513450e-01 -3.33573173e-01\n",
      " -1.09475956e+00 -1.75619254e+00 -2.54542805e-01  2.65033314e-01\n",
      "  2.72954306e+00 -2.44440497e-01 -3.49344832e-01 -3.24896900e-01\n",
      "  8.85771045e-03  1.51170823e+00 -4.57933008e-01 -9.53362879e-01\n",
      "  1.44839086e-01 -3.00153318e+00 -1.09081568e+00 -4.13246191e-01\n",
      " -2.58162691e+00  5.13607161e-01  8.33529640e-01 -3.96004117e-02\n",
      "  3.29691162e-01  2.50019267e-01 -1.09670968e+00  1.30445880e+00]\n",
      "------counter :89-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41294379 -0.15958325  0.38209554 -0.08180894  0.48138585  0.72124172\n",
      "  4.50720278 -1.26087835  1.41936025  2.69908258  1.12457895  0.13126366\n",
      " -0.37830433  1.26455778  0.77722762  0.11970664  3.40105358 -1.80400413\n",
      " -0.01304872  1.33933255 -1.33677994 -0.16488168  0.09853907  1.27703783\n",
      " -0.28405512 -1.25829188 -1.66629304 -0.42399987 -0.81267157 -1.92526675\n",
      " -0.15867057 -6.36893719  0.45933091 -0.1451701  -1.30514003 -0.45843666\n",
      " -0.19585466  0.02380579 -0.08045943  0.57759878  0.64460148 -1.67065822\n",
      " -4.59018115 -2.2171951  -0.58955948 -0.47712001 -1.49750375 -0.32996441\n",
      " -0.04121982  0.01383725 -0.42101555  0.16922196  1.36180565  0.59351203\n",
      "  2.23252444 -0.66389416  2.09812031  0.69375886 -1.97019215  0.3861196\n",
      " -0.52017807 -1.72237299 -5.72544547 -0.33251841  0.26699572 -0.09770404\n",
      " -1.07021581 -0.42796702 -0.2218382  -1.42130249  2.81624682  4.35309516\n",
      "  0.39666257 -0.07461995 -0.11287916  0.3195311  -0.19801257 -0.4715769\n",
      " -0.98388028 -0.73812781 -3.91635484  0.18466698  1.61261471 -0.06062631\n",
      "  0.18140038 -2.5732737   2.47112755 -0.00939348  0.03137216  2.34211389\n",
      "  0.64951651  1.84610263  4.03936595  0.6021062  -0.07747431  0.25046243\n",
      "  0.15140491  0.19469368  0.41845728  0.73877123  0.31048488 -3.307275\n",
      "  0.39069017 -1.02667093 -0.06646424  0.12277827 -0.3334187   2.33368831\n",
      " -1.91597825 -0.35853549  0.52387276  0.73190303  0.24736645 -0.98897457\n",
      "  2.62963079 -1.97025076  0.65723857 -2.15585394  0.82200295 -3.87218364\n",
      "  0.15532999 -0.29182767 -0.46818497  0.07583799  0.65408168  0.45357425\n",
      " -0.36797287 -1.03461826  0.53743978  0.16921406 -1.06636145  1.18996193\n",
      " -0.99051139 -0.9254806  -1.13093982  0.54938534  1.12733511  0.25327441\n",
      " -0.68424348 -2.27473404  0.21206032  0.0539519   0.23467348  1.04080359\n",
      " -0.13485639  0.30910488  1.50136209  0.16614014 -0.11197543 -0.05709807\n",
      "  0.27015423  0.09286807  1.98251316  0.50928328 -0.84916461 -0.24272908\n",
      "  0.53767997 -0.87483362  3.01542261  0.7668374   0.15230999  1.840525\n",
      " -0.35945304  0.10477986  0.59517473  1.021937   -0.99831828  2.33017721\n",
      "  0.45152144  2.10782181 -0.42452578 -1.36110249  0.47270882  1.38875714\n",
      "  0.60266726 -0.48889175 -0.66163548 -2.40316826  0.27531402  0.17800631\n",
      "  1.75610697  2.97926216 -1.1840837  -0.58344021 -0.04877613  1.41536797\n",
      " -0.62296857 -0.49279258  0.18521625 -1.51745714  0.77407339 -0.97248273\n",
      " -1.38205103  0.21103446  0.14271961  0.07931627  0.70116037 -0.00810884\n",
      " -1.51962843  1.19125209]\n",
      "------counter :90-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03387    -2.63688635  1.15700859  0.04483902  0.38913195  0.08509335\n",
      "  1.34951178  2.19604513  1.4762419   1.67065696  1.34858648 -0.29144245\n",
      " -0.15812781  0.87377907  0.91891752 -0.10863576  2.672555    1.1442453\n",
      "  0.07780643  0.23703943 -0.00816821 -0.07243041  0.12397516  0.46363936\n",
      " -0.29692531 -0.06772429 -0.91637645 -0.66160061 -1.17864011 -1.96524332\n",
      " -0.14674167 -2.76563232  0.16079298  1.22757677 -1.27448638 -0.14479845\n",
      "  0.66106189 -0.1698263  -0.00605035  0.20629775  1.13983317 -1.76182211\n",
      " -4.68924825  0.14623836 -0.94648245 -0.35831587  0.19023501 -0.08890165\n",
      " -0.72235142 -0.4409458  -0.25278905  0.40297716  0.99005709  0.70554966\n",
      " -0.02199563 -0.48202532  0.85481656  0.81114973  0.07333897  0.88573608\n",
      " -0.82646815 -1.11618476 -3.68621205 -0.47186978  0.75948151 -0.02114487\n",
      " -1.53120999 -0.53778177 -0.48951004 -0.76700353 -4.83876672  2.62441672\n",
      "  0.39796449  0.0764891   2.30980293 -0.15521309  0.10889919 -0.13952131\n",
      " -0.58514542 -0.22745857 -4.18216429 -0.23772635  1.57081318  0.20513976\n",
      "  0.24618698 -1.28568479  1.67334865 -0.13411864 -0.12159644 -0.26896741\n",
      " -0.7830937   1.25972022  4.51491153 -0.90407577  0.39831222  0.1808715\n",
      " -0.72929253  0.27850075  1.82060524  0.15132157  0.26310223 -2.65315475\n",
      " -1.59630036 -0.31635436 -0.39270692  0.09470781 -0.39942556  2.06718846\n",
      "  4.0122862  -0.29036882  0.16170502  0.40530254  0.43839468 -1.08925039\n",
      "  2.48384472 -0.8696318  -0.1964987  -1.55710964  3.4803275  -2.023153\n",
      "  0.15559728 -0.30918909  0.15642131  0.10075169  1.86674723  1.14327482\n",
      " -0.10748832 -0.87771268  0.45473584  1.19250928 -0.73028826  0.21565988\n",
      " -0.43591326 -0.80299064 -0.84961139  1.002218    0.89497681  0.46099655\n",
      "  0.26366849 -2.51334049  0.11878259  0.01415933  0.85902226  1.43016197\n",
      " -0.21485781  0.33374274  0.23965487 -0.92570587 -0.00502475 -0.24302886\n",
      "  0.45295948  0.54688825  1.33189284  0.20394044 -0.83192076 -0.15642958\n",
      " -0.29405778 -0.81130743 -1.34526826  0.42079375  0.17078226  0.82870739\n",
      " -0.93166315 -0.0398811   0.38075022  0.85488924  0.11584896  2.2303728\n",
      " -0.04459657 -0.18750634 -0.3465951   0.53031077 -0.12289438 -2.31297794\n",
      "  0.15813598 -0.38840513 -0.64117785 -0.67437513 -0.45994194  0.53146575\n",
      "  1.56601542 -1.35973364 -0.99937355  0.45746892  0.17920368  1.73182126\n",
      " -0.56260143 -0.82380461 -0.32478049 -1.23126504  1.02110268  0.0218302\n",
      " -0.80892203  0.44643445 -0.25519838  0.01766999  0.67245236 -0.06019158\n",
      " -1.38697424  0.99870692]\n",
      "------counter :91-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.09172770e-02 -1.43154955e+00 -1.98087720e+00  2.67010085e-01\n",
      "  2.55202457e-01 -1.81683649e-01  2.26226418e+00 -1.96541700e+00\n",
      " -1.32567434e-02  2.02067736e-01  2.43128764e-01 -9.30380215e-01\n",
      "  2.69055817e-01  1.00624517e+00 -8.63061152e-01 -5.07259356e-01\n",
      "  3.41201286e-01  4.63541858e-01 -9.44663373e-02  2.58133287e-01\n",
      "  8.51454676e-01 -1.46843340e-01 -1.36778888e-01  8.02831814e-01\n",
      " -2.54750847e-01  1.95586919e-02 -7.90168652e-01 -1.39295363e+00\n",
      " -3.02557412e-01  9.57280709e-01  4.63282374e-01 -2.92438327e+00\n",
      "  1.05393306e-01  7.42273110e-02 -9.53426561e-01 -4.61649303e-01\n",
      "  8.21223634e-01  1.37613009e-03  8.05669289e-02 -1.68683433e+00\n",
      "  7.64254444e-01 -1.27520844e+00 -3.03859741e+00  2.22920798e-01\n",
      " -4.14849678e-01 -6.03785102e-01 -6.83251182e-01 -4.47465849e-02\n",
      "  5.23105030e-01  1.33963423e-01 -1.34930445e-01 -5.03784268e-01\n",
      "  7.09630653e-01  1.00569452e+00  1.61904114e+00 -9.13674238e-01\n",
      "  1.33638754e+00 -3.09240967e+00 -1.91210929e+00  5.95148401e-01\n",
      "  3.51333087e-01 -8.25705040e-01 -3.65045364e+00 -8.02840286e-01\n",
      "  1.13916184e+00 -3.15514106e-02  8.56049967e-02  2.04368818e+00\n",
      " -3.41403224e-01  5.46939732e-01 -5.81898425e+00  3.03428891e+00\n",
      " -3.20742627e-02  7.12469580e-02  3.16218029e+00  2.96922175e-01\n",
      "  1.92903338e-01 -1.80829394e+00 -6.88881989e-01 -2.48617825e-01\n",
      "  2.89404023e+00 -2.12023543e-01  4.16624541e+00  3.31767701e-01\n",
      "  7.55954377e-02  6.65019552e+00 -5.41342652e-01  1.41114218e+00\n",
      " -1.39689163e+00 -4.63663756e-01 -2.37148987e+00  8.18370548e-01\n",
      "  2.49963403e+00  8.57983780e-01  2.60201176e+00  8.20042305e-02\n",
      " -2.45227955e-01 -2.05861867e-01  1.40967342e+00  1.21370272e+00\n",
      " -1.22995565e-01 -2.22835332e+00 -4.36781101e+00 -2.04819196e+00\n",
      " -1.02823093e+00 -7.43201972e-02 -3.10735065e-01  2.67801332e-01\n",
      "  2.96050960e+00 -4.19333809e-01  1.42261998e-01 -1.42344507e-01\n",
      "  3.24275808e-01 -1.22051075e+00  7.54301063e-01 -1.63984635e+00\n",
      " -3.79363693e-01 -8.56380132e-01  3.28788388e+00 -2.25980885e+00\n",
      "  1.47065493e-01 -1.97431171e-01 -4.64503137e-01  2.05495365e-01\n",
      "  1.67881936e+00 -5.94982463e+00 -3.47159462e-01  3.01839566e-01\n",
      "  1.56432999e-01  5.20350952e-01 -7.65892475e-01  1.07478320e+00\n",
      " -4.15263039e-01  1.48729080e+00 -7.63258593e-01  5.27950142e-01\n",
      "  6.53581575e-01  3.11408992e-01  7.40225069e-01 -1.49074194e+00\n",
      "  6.47124820e-02  3.40751446e-01  5.66341916e-01  1.60731551e+00\n",
      " -4.39252800e-02  1.56584663e-01  3.20145644e+00  3.18902233e-01\n",
      " -2.43693835e-01 -3.72971252e-01  1.27387578e-02  5.52668362e-01\n",
      "  6.86258289e-02  1.62358636e-01 -2.30661900e-01 -1.29940763e-01\n",
      "  4.16270519e-01 -2.89028232e-01  1.14316503e+00  7.00257061e-01\n",
      "  4.06538303e-01  5.41075072e-01 -7.12413989e-01  1.11259679e-01\n",
      "  5.06128635e-01  2.68964681e-01 -2.73162103e-01  3.73894826e-01\n",
      " -1.83525706e-01  2.15948227e+00 -5.46993036e-01 -1.85824070e-01\n",
      " -2.40864511e-01 -2.63887707e+00  3.26210465e-01 -1.69825736e-01\n",
      " -1.76117336e-01 -1.10630830e+00 -2.82493911e-01  5.16701396e-01\n",
      "  1.12480338e+00  1.23278113e+00 -1.54584162e-01 -1.58505428e-01\n",
      " -7.66358055e-01  3.33553161e+00 -5.88275095e-01 -3.82288414e-01\n",
      " -1.23910834e-01 -6.15057584e-01  6.94038415e-01 -3.54354142e-02\n",
      " -1.60269497e+00  1.64961526e-01 -4.99476001e-01 -1.27282994e-01\n",
      "  5.07385372e-01  2.08745938e-01 -9.92887310e-01  8.12794571e-01]\n",
      "------counter :92-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.61114495e-01 -5.44249786e-01 -1.25174795e+00  5.25816057e-01\n",
      "  1.39042007e-01 -4.02163085e-01  1.02868651e+00 -1.62114161e+00\n",
      "  2.55329458e+00  1.37916208e-01  5.00389645e-01 -6.62100891e-01\n",
      " -4.12112124e-01  3.64877649e-01  1.11913690e+00  2.98295099e-01\n",
      "  2.09397810e+00  8.81309288e-02 -2.69646052e-02 -6.43923482e-01\n",
      "  6.24450286e-01 -4.80285517e-02  1.07461360e-01  1.56199968e+00\n",
      " -1.49237886e-01 -1.53847106e-01 -8.20959042e-01 -7.67457136e-01\n",
      " -5.05594503e-01  1.05828242e+00  1.32053840e-01 -2.78766368e+00\n",
      "  6.19755764e-02 -8.81065306e-01 -1.44327171e+00 -3.08480660e-01\n",
      "  1.37647880e-01 -1.19776616e+00  5.72710738e-02 -1.22985739e+00\n",
      "  8.76842706e-01 -5.96376439e-01 -2.22846527e+00  5.48138096e-01\n",
      " -5.08130290e-01 -2.77494775e-01 -6.62036284e-01 -4.39632148e-01\n",
      "  5.93748565e-01 -1.13868016e-01 -3.96109662e-02 -4.38839006e-01\n",
      "  6.07898086e-01  2.95027490e-01  1.73137534e+00 -9.27793961e-02\n",
      "  6.36108211e-01 -1.20227545e+00  7.71966983e-01  8.85860536e-01\n",
      " -1.13648211e+00 -7.93542105e-01 -2.81679249e+00 -6.40869938e-01\n",
      " -1.39185490e-02 -1.05237750e-01 -7.23753651e-01  8.45493163e-01\n",
      " -9.20136111e-01  7.14316871e-01 -3.11699570e+00  1.32572175e+00\n",
      " -9.28438769e-02 -1.53410754e-01  3.27303098e+00  1.10265841e+00\n",
      "  1.27734807e-01 -2.06582176e-01 -2.87253973e-01 -8.85950598e-02\n",
      "  3.24798167e+00 -6.78901128e-02  2.85322269e+00  3.80502087e-01\n",
      "  5.69154882e-01  5.68663685e-01 -6.21086022e-01 -6.71394491e-02\n",
      "  6.15944554e-01  1.60108191e-01  4.82303504e-01  7.08036143e-01\n",
      " -1.88871734e-01  3.94068608e-01  2.19235283e+00  4.03822073e-01\n",
      "  3.80022990e-02  3.59060272e-01  7.52417125e-01  1.07987567e+00\n",
      " -7.86993552e-02 -3.66201992e+00  9.52318136e-01 -1.98655566e-01\n",
      " -9.65066041e-01  2.57326983e-01 -3.07574050e-01  4.23744320e-01\n",
      " -1.24581880e+00 -8.61114495e-01  3.26767246e-01 -1.18664291e+00\n",
      "  7.11007599e-01 -2.97867513e-01  1.58029400e+00  4.90280052e-01\n",
      "  1.33911601e-01 -2.40150506e-01  1.26724338e+00 -2.01685646e+00\n",
      "  1.48118825e-01 -3.87541040e-01  4.89292485e-01  6.81687850e-01\n",
      "  3.91107012e-01 -4.95038865e+00 -5.32318562e-02 -1.00829485e+00\n",
      "  2.08004483e-01  4.14815119e-01 -5.14369238e-01 -6.42237585e-01\n",
      "  5.57764311e-02  1.01934418e-01 -6.17454463e-01  2.89956916e-01\n",
      "  1.13875761e-01  5.43302495e-01 -1.20532336e+00 -2.42974392e+00\n",
      "  1.99787424e-01  1.52422519e-01  1.44375826e-01  1.98407739e+00\n",
      "  8.37197110e-02 -1.44616793e-01  3.60757070e+00 -8.72366806e-01\n",
      " -2.91284706e-01 -1.26282571e-01  1.97232789e-01  7.75718744e-01\n",
      "  4.84854200e-01 -3.63380339e-01 -2.29002158e-01 -2.25920434e-02\n",
      "  1.65807285e+00  5.35563119e-01 -2.01823352e-01 -4.37891582e-02\n",
      "  4.79935572e-01  8.30497411e-03 -2.79914368e-01  4.35363189e-01\n",
      "  5.34511643e-01  1.32624492e-01  1.51674969e-01  1.44436608e+00\n",
      "  7.44554166e-01  2.31152043e+00 -1.39475149e-01  6.75765170e-02\n",
      " -2.82569868e-02 -1.07007170e+00 -7.41679909e-01 -8.04088098e-05\n",
      "  3.11249327e-01 -2.27878710e+00 -3.19182278e-01  9.29828210e-01\n",
      " -7.54282166e-01  1.86090228e+00 -1.55917128e-01 -7.00946713e-02\n",
      "  4.77525964e-01 -4.70611047e-01 -2.28375301e-01 -3.62454457e-01\n",
      " -2.25415194e+00 -1.65313312e+00  4.64736798e-01  4.38661443e-02\n",
      " -7.74696102e-01  4.59787394e-01 -1.18640663e+00 -5.54183869e-02\n",
      "  5.12292379e-01  9.74584009e-01 -8.59912690e-01  2.52378438e-02]\n",
      "------counter :93-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.33163325e-01 -2.18248580e+00  1.87454993e+00  6.96710768e-01\n",
      " -2.67281737e-02 -3.43078369e-01  5.99298574e-01 -5.57117011e-01\n",
      " -6.36042512e-02 -1.62899312e-01  7.66606832e-01 -1.87779568e-01\n",
      "  3.10802023e-01 -6.86061214e-02  1.46706626e+00 -1.71841046e-01\n",
      "  2.28093556e+00  1.47394189e+00  5.53522844e-02 -1.30106249e+00\n",
      "  6.12459595e-01 -2.27899853e-01 -5.02130472e-01 -3.30783762e-01\n",
      "  1.63607354e-01  7.38146875e-02  4.30444683e-01 -2.42037422e-01\n",
      " -9.68996495e-02  1.41991185e+00 -2.67030486e-02 -2.76676048e+00\n",
      "  2.11580862e-01 -2.05354041e-01 -1.56136812e+00 -1.04783447e-01\n",
      " -3.90551969e-01 -6.52410462e-01  1.67475603e-01 -1.89868429e+00\n",
      " -1.05705527e+00 -6.47412923e-01 -7.62758771e-01  2.98429273e-01\n",
      " -5.64845300e-01 -6.17701958e-02 -6.83392854e-01  7.14869649e-01\n",
      "  5.71853916e-01 -1.29764463e-01  6.43504309e-02 -6.21111980e-01\n",
      " -1.05272311e+00 -3.31524879e-01  8.87215593e-01 -2.25142470e-01\n",
      "  3.25352081e-01 -1.22413254e+00 -4.28846388e-02  6.16847440e-01\n",
      "  3.97247104e-01 -7.31430512e-01 -1.88387720e+00 -2.46706651e-01\n",
      "  1.77663602e+00 -1.39500959e-01 -4.68402067e-02  2.74966575e-01\n",
      " -4.19914611e-01  1.91083729e+00 -1.94534775e+00  2.01944337e+00\n",
      "  5.61385909e-02  5.45431092e-01  3.08567393e-01 -6.44747761e-02\n",
      "  3.43171306e-01 -6.08555583e-01 -1.20825502e-01  8.73844194e-02\n",
      "  2.65115237e+00 -3.58984350e-03  2.40719121e+00  5.83846727e-02\n",
      "  7.97754182e-01  4.87009579e+00 -1.05716760e+00 -4.84548351e-01\n",
      "  2.93182315e-01 -1.40356185e-01  5.67367717e-01 -1.15820306e-01\n",
      " -2.55949063e+00 -6.23632542e-01  2.38829402e+00  3.38718058e-01\n",
      "  4.72647026e-01  9.46137996e-01 -4.40412002e-02 -5.92753502e-01\n",
      "  1.59490826e-01  1.56118477e+00 -2.72360701e-01 -2.15109696e-01\n",
      " -2.50041408e-01  7.68541737e-02 -2.59945758e-02  1.92377449e-01\n",
      " -5.97684591e-01 -2.02560785e-01  5.69683645e-01 -8.54419217e-01\n",
      "  1.02342757e+00 -1.12624323e+00  1.97827255e+00 -5.30339676e-01\n",
      " -1.56217181e-01  2.46905217e-01  2.64259228e+00 -1.85260253e+00\n",
      "  3.60483052e-01  8.74111322e-02  3.53003377e-01  6.82035598e-01\n",
      "  1.10405092e-01 -3.73110485e+00 -8.28831228e-03 -4.44317244e-01\n",
      " -2.96455684e-01 -7.54072225e-01 -4.26635660e-01  1.69035155e-01\n",
      "  2.52502091e-01 -5.65191853e-01 -1.43014979e+00  3.49323123e-01\n",
      "  5.23525970e-01  6.20203478e-02 -1.52197167e+00 -2.80620233e+00\n",
      "  4.14970544e-01  5.79863301e-01  1.91600251e-01  2.14507763e+00\n",
      "  1.31236492e-01  5.37738666e-01  5.77356671e-01 -5.15321720e-01\n",
      " -2.29095991e-02 -5.27114416e-01  3.64296431e-01  8.32307052e-01\n",
      " -1.76044381e+00 -7.96955144e-01 -6.37560222e-01  6.24216002e-01\n",
      "  1.12026511e+00  6.29058747e-01 -2.80478958e+00 -6.42292771e-01\n",
      "  5.77201071e-01  4.00472554e-01 -1.14707496e-02  8.53245365e-01\n",
      "  3.68723833e-01 -4.25217987e-01  5.03896290e-01  1.99857579e+00\n",
      "  1.70677828e-01 -2.01924688e-02 -6.10681417e-01 -1.59785736e-01\n",
      " -3.36278802e-02  6.71334488e-01 -5.61221640e-01  4.87658443e-01\n",
      "  7.85328097e-01 -3.10534899e-01 -7.86344561e-02  5.07175766e-01\n",
      "  5.18746183e-01  1.20006427e+00  2.44042495e-01  1.32058376e-01\n",
      "  4.11000102e-01  1.88471390e+00  2.14879031e-01 -5.35840094e-01\n",
      " -6.69418647e-01 -4.86365787e+00 -2.02952220e-01  1.55485852e-01\n",
      " -1.54173543e+00 -9.51950936e-02 -1.05654968e+00 -8.51214722e-02\n",
      " -3.69151725e-01  4.19515549e-01 -9.35047117e-01  1.31971566e-01]\n",
      "------counter :94-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.63561521e-02 -3.49303913e-01  6.32140108e-01  7.05787059e-01\n",
      " -2.67408938e-01 -1.84592353e-01 -2.01582403e+00 -1.90741115e+00\n",
      " -1.85812984e-01  1.94556022e-02  9.18374763e-01 -1.48492973e-01\n",
      "  6.36126611e-01 -1.43157077e-01  1.06725177e+00  1.15349685e-02\n",
      " -7.61789352e-01  8.10293324e-01  8.22123057e-02  2.22907249e+00\n",
      "  5.10403141e-01  4.47701504e-01  4.84904077e-01  3.43515740e-02\n",
      "  5.60346087e-01  4.25007162e-01  1.29195769e-01 -2.28591558e-01\n",
      " -4.18315817e-01  6.00868334e-01 -3.43660579e-01 -5.17475794e+00\n",
      "  2.42792382e-01  4.94361678e-01 -1.41360903e-01 -2.05477011e-02\n",
      "  5.36019246e-01  9.27857776e-02  1.24332516e-01 -1.55874922e+00\n",
      "  4.52789080e-01 -3.10995481e-01 -1.68519039e+00 -4.13202370e-01\n",
      " -8.33869861e-02 -1.23006371e-01  2.83492497e-01  7.69332180e-01\n",
      "  6.09593040e-01 -1.02837410e-01  5.26929398e-01 -3.80927925e-01\n",
      " -1.33132687e+00 -4.29194985e-01 -8.13073494e-01  1.78861357e-01\n",
      " -6.32372478e-01  9.55953701e-01 -1.25343897e+00 -5.48187060e-01\n",
      "  2.93798801e-01 -8.83915174e-01 -1.05678026e+00  3.82015152e-01\n",
      "  1.19899189e+00 -2.10800010e-01  4.93443562e-01  4.78946341e-01\n",
      "  6.01377596e-01  6.00759142e-01 -2.00554495e+00  1.20492550e+00\n",
      "  2.93464945e-01  3.02216768e-01  1.61863652e+00  6.94661475e-01\n",
      " -1.94992430e-01 -5.75035701e-01 -3.57790523e-01 -3.89778780e-01\n",
      "  1.23864562e+00  6.01117519e-01  9.95337063e-01  8.31990160e-01\n",
      "  6.30364149e-01 -1.28674122e+00  1.79236547e-01  3.66654044e-01\n",
      " -6.10825290e-01 -1.17349607e-01  7.55651346e-02 -2.41831476e-01\n",
      " -5.67771376e+00  2.33986939e-01  1.25844224e+00 -5.14365804e-01\n",
      "  1.11527052e-01  7.30039841e-01 -2.99546042e-01 -6.74401765e-01\n",
      "  2.24774884e-03 -1.60278139e-01  7.38192338e-01  9.59904920e-01\n",
      "  6.15179234e-01  7.39583414e-01  2.25041651e-01  1.15020109e+00\n",
      "  2.82298655e-01 -1.15303847e-01  7.15779474e-01  9.40158540e-01\n",
      "  7.47119088e-01 -1.52824975e+00  1.65731826e+00  6.89351057e-01\n",
      "  3.87811519e-01 -1.53769138e-01  9.49245539e-01 -2.89080614e+00\n",
      "  2.75675382e-01 -7.29116427e-02  1.66616182e-01  5.43414059e-01\n",
      "  8.27035977e-01 -1.51668530e+00 -8.35819084e-03 -2.13923947e+00\n",
      "  1.04979851e-01 -2.03685558e-01 -1.36033972e-01 -1.36423704e-01\n",
      "  4.14020631e-01 -1.93307089e-01 -1.25673907e+00  2.59010348e-01\n",
      "  6.42249877e-01 -7.32421319e-01 -1.01123477e+00 -2.55026795e+00\n",
      "  5.31860264e-01  4.23696586e-01  3.45378081e-02  1.92764005e+00\n",
      "  5.19165489e-01  5.98774735e-01  3.13803931e-01 -5.59639918e-01\n",
      "  9.54934093e-03 -1.54545418e-02 -9.06890186e-02  3.94856349e-01\n",
      " -8.54699508e-01  3.35949806e-01 -6.14785892e-01  3.66830701e-01\n",
      "  2.18067477e-01  4.13516450e-01 -4.62925057e-01 -6.99993593e-01\n",
      "  6.21560534e-01  3.03208660e-01  2.79710589e-01  4.68672859e-01\n",
      "  4.21706382e-01 -4.90502893e-01  4.51990505e-01 -2.30692343e-01\n",
      "  2.34162725e-01 -6.50826760e-01 -1.65239120e-01 -5.08305644e-01\n",
      "  5.42799279e-01 -1.53139743e+00  6.78972453e-02  4.86817389e-01\n",
      "  7.83791810e-01  9.66854423e-01  1.86335657e-01  3.83469552e-01\n",
      "  5.09445792e-01 -1.21530613e-01  2.65851743e-02  1.03128004e-01\n",
      "  6.24248810e-01  1.17034396e+00  1.16685554e-01 -2.83241003e-01\n",
      "  3.43797037e-01 -3.68375650e-01 -1.07357208e-01  1.90159303e-01\n",
      " -2.85846360e-01 -1.33969803e-01 -6.28392230e-01  4.57760304e-02\n",
      " -5.16044024e-01  4.89990612e-01 -2.48715664e-01  5.76790322e-01]\n",
      "------counter :95-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08267032  0.68421748  0.63574794  1.06433938 -0.31124098 -0.55164365\n",
      " -1.34097471  1.54801033 -0.79325787  0.94360711  0.23144882 -0.02606483\n",
      "  0.45501965  0.4316848   0.73976008  0.10954453  0.45667428 -1.39335403\n",
      "  0.15155517  0.92735907  1.19375687  0.64029198  0.48125967 -0.82159132\n",
      "  0.83560127 -0.11200898 -0.62327798 -0.0206358   0.21220541 -0.09962996\n",
      " -0.66172611 -4.36799616  0.11358336  0.17839526 -1.00433748  0.7608394\n",
      " -0.01829158  0.41469056 -1.29381606 -1.11799374  0.55623858 -0.35297494\n",
      " -1.06260099 -1.68514779  0.08767714 -0.19436234  0.60011311  0.66282531\n",
      " -0.51081054  0.20955003 -0.6712222  -1.43573671 -0.54784282 -0.71168143\n",
      " -1.30839982  0.47991934 -0.22220416  1.1879957  -1.34776672 -1.34344354\n",
      "  1.06323735 -1.52558301 -1.47223338  1.00331496 -1.24251394  0.07979456\n",
      "  0.17809666  0.31016798  0.24503932  0.45241571 -0.6138861   3.16584846\n",
      "  0.01427089  0.47226001  4.27114038 -0.61972452 -0.27720659  0.05000386\n",
      " -0.181527   -0.60017349 -0.05591162  0.29466899  0.09107068  0.16495825\n",
      "  0.01779417  0.87004511 -0.2484074  -0.42438044 -0.3517446  -1.2677203\n",
      " -0.44779407 -0.64505444 -0.61201387  1.15114352 -0.35254209 -0.15823845\n",
      "  0.33657588  0.46128054 -1.0493111  -0.93064983 -0.19649229  2.77500612\n",
      " -0.90338251 -0.52737067  0.99633865  0.52756807  0.5065502   0.00506215\n",
      "  3.08118503 -0.15295825  0.32029719 -0.56790621  0.24705671  0.28363773\n",
      "  0.99898738 -2.24978442  0.63379848 -0.11868182 -0.25622643 -2.71154348\n",
      "  0.07136061 -0.34994986  0.37551931 -0.91262149  0.78896182  0.62054058\n",
      "  0.16470055 -0.82580063  0.07965201 -0.3035361   0.27641105 -0.15216529\n",
      "  0.09834441 -0.05634138 -2.05564078 -0.454598    1.11501725 -0.73147958\n",
      "  0.79777022 -2.04219835  0.62665168  0.75945934 -0.49625795  1.62402598\n",
      "  0.60212332  0.60798365 -0.94315468  0.19871946 -0.18264887  0.09637009\n",
      " -0.57002805 -0.37182699  0.08701868 -1.36239188 -0.00763365  1.42011823\n",
      "  1.89324536  1.01014081  1.72315155 -0.23993069  0.02982399  1.44584789\n",
      "  1.18049868  0.11519484  0.79075425 -1.48016402  0.81623401  0.31563811\n",
      " -0.11716488 -0.92698678 -0.28757389 -0.8858306   2.34315094 -2.10827978\n",
      "  0.20504662  0.4562802   0.72449071  1.62780431  0.34780297 -0.61701256\n",
      "  1.91883211 -2.97737339  0.57779604  0.93622515  0.04918827  1.01874645\n",
      "  0.27585069  0.43900389 -0.17486893 -0.74693221  0.3838347  -0.34101774\n",
      " -0.95823303 -0.83129471  0.00590412  0.16984679 -1.59637634  0.5418704\n",
      "  0.14073945 -1.05323721]\n",
      "------counter :96-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.05004911e-01  1.14983286e+00 -8.46384050e-02 -4.08725078e-01\n",
      " -5.88724528e-01 -7.57703498e-01 -1.36133811e+00 -8.75740785e-01\n",
      " -3.08933554e+00  1.79640036e+00  5.53552495e-02 -2.21382898e+00\n",
      " -1.14820607e-01  8.61404519e-01  6.72342580e-01  3.95531347e-01\n",
      "  1.92285503e+00  1.44982306e+00  5.78889266e-01 -4.55794150e-01\n",
      " -1.98675381e-01 -7.83128568e-01  3.87307953e-01 -4.72653484e-01\n",
      "  8.06822759e-01 -1.15793782e-01 -1.55176512e+00 -7.87070872e-01\n",
      " -9.26106835e-02 -8.86899639e-02 -1.30724399e+00 -4.32629619e+00\n",
      "  4.21955862e-01  4.78672010e-01  2.81502762e+00  1.03556045e+00\n",
      "  1.33995252e-01 -2.32983329e-01 -9.02000045e-01 -6.06999299e-01\n",
      "  5.24448148e-01 -4.35990058e-02  3.66401426e+00 -1.72700570e+00\n",
      " -1.42853126e-01 -4.17067942e-01  7.38522547e-01  1.12321402e+00\n",
      " -2.84226282e-02 -1.71008345e-01 -7.68410756e-01 -1.47736981e+00\n",
      "  8.80611801e-03 -6.09163796e-01  1.44152384e+00  6.79433770e-01\n",
      " -1.07766091e+00  3.03557765e-02  9.06354090e-01 -1.35736377e+00\n",
      "  3.27258104e-01 -2.15328715e+00 -6.68236917e-01  1.05047204e+00\n",
      "  1.65298357e+00 -7.67420352e-01  1.90473624e+00  5.18321624e-01\n",
      " -2.09732089e-01  2.49189028e-01 -5.08579059e-01  6.42035302e-02\n",
      "  3.46931202e-01 -4.57195407e-02  1.86764434e+00 -1.09082143e+00\n",
      " -4.39041874e-01 -7.79322343e-01  1.79059300e+00 -9.66884404e-01\n",
      " -3.57456408e+00  1.09002009e-01 -5.91886819e-01 -4.36986766e-01\n",
      " -2.27170033e-01 -5.82824929e+00  2.98060820e+00 -5.08288424e-01\n",
      " -6.69931467e-01 -4.89888688e-01  1.47690835e-02 -1.48150541e+00\n",
      "  1.25790805e+00  1.08489978e+00  6.94378595e-01 -2.83681463e-01\n",
      "  8.55868525e-01  1.08939283e+00 -1.40807414e+00 -3.76015817e-01\n",
      " -3.64225771e-01  9.26087054e-01  7.15038602e-01  7.61385974e-01\n",
      "  3.15095310e-01  2.23812484e-01  5.80404491e-01  8.47851099e-01\n",
      "  1.01986082e+00 -5.24144715e-01 -8.40704711e-02 -2.94540614e-01\n",
      "  1.91424488e-01 -1.38071795e+00 -1.25059588e-01 -8.95963824e-01\n",
      "  5.13450210e-01 -7.91053503e-01  1.98414086e-01 -4.81778561e+00\n",
      " -1.32687361e-01 -2.62521080e-01  5.50903563e-05 -5.35169673e-01\n",
      "  5.61319859e-02 -3.29560431e-01 -4.60782290e-02 -2.04616268e+00\n",
      "  8.48494054e-02  1.82945135e+00  3.24619317e-01  5.52650819e-02\n",
      " -8.40535778e-01  4.62513353e-01 -2.01209024e+00 -9.03664470e-01\n",
      "  6.18630421e-01 -6.96081794e-01  1.10681826e+00 -1.31807818e+00\n",
      "  3.18030494e-01  4.59882291e-01  2.85571289e-01  1.07203710e+00\n",
      "  6.08398685e-01  4.73973353e-01 -3.08897852e-01  1.14903932e+00\n",
      " -5.05082067e-01 -7.04484446e-01 -9.02447353e-01 -3.34271993e-01\n",
      " -1.63954503e-01 -8.87190503e-01 -2.73555610e-01  9.62250686e-01\n",
      "  2.85668236e+00  1.83048439e+00  7.95822739e-01 -1.16856441e+00\n",
      "  2.55636071e-02  1.88211959e+00  1.48883463e+00  1.60277733e-01\n",
      "  5.41228596e-01 -1.32877976e+00  1.46166065e-01 -7.00335783e-01\n",
      " -6.35880213e-01  1.35957348e+00  4.90573210e-01 -5.44318620e-01\n",
      "  1.90178883e+00 -1.60228352e+00  1.31681611e-01  3.03678542e-01\n",
      "  5.22097116e-01  2.91292883e+00  3.85486852e-01 -7.38684895e-01\n",
      "  1.42453488e+00  6.90094812e-01  4.30380683e-01  3.15871184e-01\n",
      "  5.04428613e-01 -7.50718302e-01 -1.43763330e-01  9.55710759e-01\n",
      "  5.85761293e-02  6.11225600e+00  6.41846370e-01 -1.36131900e-01\n",
      " -8.07738707e-02 -9.26262122e-01 -3.30211044e-01 -5.59353190e-01\n",
      " -1.49100089e+00  5.92554125e-01 -1.07550020e-01 -1.49773538e+00]\n",
      "------counter :97-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.38162133e-01  4.08739883e-01  2.14316089e-01  7.72165849e-01\n",
      " -6.40488853e-01 -5.92545559e-01 -2.90324425e+00  1.19448505e+00\n",
      " -1.29265950e+00  3.40392656e-01  7.67456817e-01 -8.45141857e-01\n",
      "  1.11332644e-01  2.99502071e-01  8.35076460e-01 -1.59011792e-01\n",
      "  2.21142325e+00  9.08629969e-01  1.91638955e+00 -2.18612385e+00\n",
      " -1.70085114e-01 -4.93528374e-01  7.17181387e-01 -1.28847032e+00\n",
      "  7.47549439e-01 -8.34474672e-01 -1.46297002e+00 -4.26600800e-01\n",
      " -6.13351747e-01  1.95879686e-01 -1.71128087e+00 -4.95590504e+00\n",
      "  2.92704884e-01 -5.35031733e-01  5.48340017e-01  1.31994200e+00\n",
      " -3.62493441e-01 -3.64162648e-02 -5.86646695e-01  1.73260447e-01\n",
      "  2.65211340e-01 -1.39325707e+00  2.11104369e+00  1.16417481e+00\n",
      "  1.55316275e-01 -2.30582554e-01  1.12907679e+00  1.66902935e+00\n",
      " -4.84722503e-02  3.27789883e-02 -5.94257353e-01 -9.96899442e-01\n",
      " -3.40537100e-01 -1.06149324e+00  1.15481301e+00  6.59169780e-01\n",
      "  2.79591215e-01  1.43469263e+00  5.99236429e-01 -1.34079015e+00\n",
      "  9.60113788e-02 -2.06517469e+00  2.39890422e-01  1.06416713e+00\n",
      " -3.41224514e+00 -5.73268083e-01  6.84958524e-01  6.64330052e-01\n",
      "  1.23891271e-01  7.24179037e-01 -1.80981777e+00  2.71141673e-01\n",
      "  7.07430440e-01 -3.17684325e-02  2.17996849e+00 -1.43348072e-01\n",
      " -1.34025811e-01 -3.39776022e-01 -3.34341470e-01 -6.89215254e-01\n",
      " -3.14817403e+00 -9.97614287e-02 -1.52061987e-01 -6.33124378e-01\n",
      "  1.00383777e-01 -5.10010241e+00 -4.50844270e-01 -9.24846672e-01\n",
      " -7.44020286e-01  1.85770949e-01 -7.25749490e-01 -1.23652756e+00\n",
      " -1.48576747e-01  7.33843326e-01  1.77219264e+00 -1.30634083e-01\n",
      "  1.03121825e+00  1.11313855e+00 -7.79472596e-01 -2.74951308e-01\n",
      " -4.09647457e-01  3.14334171e+00 -1.22879187e+00  7.57152028e-01\n",
      "  5.90467320e-01 -2.17279158e-01  7.19076487e-01 -1.53422092e+00\n",
      " -1.65435236e+00 -2.57676109e-01 -4.26185407e-02 -1.11865028e+00\n",
      "  4.54725614e-01 -2.17983929e-01  2.18799626e+00  5.21119005e-01\n",
      " -1.99258575e-01 -3.25072834e-01  1.10352378e+00 -4.21289572e+00\n",
      "  6.50451261e-03  1.96748485e-01 -3.52169670e-01 -6.18266640e-01\n",
      "  9.55081293e-01 -1.54077081e+00  1.49286299e+00 -7.96454073e-01\n",
      "  3.40788275e-01  2.90028144e-01  7.17099560e-02  3.68286332e-01\n",
      " -3.25974015e-02 -3.90614965e-01  8.04121605e-01 -4.29090449e-01\n",
      "  4.31562494e-01 -1.12826195e+00  3.03081770e+00 -8.26808291e-01\n",
      "  3.66715104e-01  6.62930395e-01 -3.09271759e-01  1.40170332e+00\n",
      "  6.48884769e-01  9.84726380e-01  9.29785507e-02  5.95823265e-01\n",
      " -2.64505009e-01 -2.19857366e-01 -8.06084431e-01 -1.28124992e-01\n",
      " -2.35693294e+00 -5.78523731e-01  1.32423407e-01  1.20238240e+00\n",
      "  1.88097201e+00  1.12580723e+00 -1.44128457e+00 -3.31061940e-01\n",
      " -2.03028836e-01  2.68587600e+00  8.60939261e-01 -1.04771517e-01\n",
      " -2.19630645e-01 -1.41232596e+00  2.56461164e-01  2.56196764e-01\n",
      " -4.42561388e-01  2.36113544e-01  1.00513486e+00 -3.39393357e-02\n",
      "  1.02335608e+00 -1.36828026e+00 -3.16753826e-01  3.09482759e-01\n",
      "  6.48232546e-01  2.21056319e+00  3.11748862e-01 -6.98059674e-02\n",
      "  2.06574791e+00  7.82233031e-01 -1.48230785e-01  1.29323210e+00\n",
      "  3.44668247e-01 -8.68597210e-01  3.19938357e-02  1.51506118e+00\n",
      " -3.33400174e-01  6.95388442e+00  2.10534724e-01  2.37941122e-01\n",
      " -8.66276638e-01 -2.01678711e-01 -4.41704761e-01 -4.19948988e-01\n",
      " -1.11583787e+00  9.10137977e-01 -6.89611540e-01 -1.86027983e+00]\n",
      "------counter :98-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33057713 -1.97867079 -0.42785657  0.72508808 -0.65022823 -1.33455876\n",
      " -2.04505359 -1.48393062 -0.28245383 -0.02783429  1.04476063 -0.90073234\n",
      "  0.66110222 -0.21394545 -0.22942626 -0.13491723  1.99215499  0.8632533\n",
      "  1.26289155  1.81056951 -0.04734778  0.4146769  -0.72687543 -0.56683611\n",
      "  0.76353618  0.03402423 -1.10240679 -1.61364548 -0.05556789  1.59523613\n",
      " -1.08409069 -4.82509616 -0.06629276  0.07452122  0.46259507  0.99109108\n",
      " -0.3619072  -0.20886342 -0.26204316 -0.34899615  0.83600535 -0.40595418\n",
      "  0.51445214 -1.40024553  0.42591993 -0.08310693  1.69593307  1.25706358\n",
      " -0.46401027  0.08474159  1.19910552 -0.84240416 -0.69882382 -1.1597633\n",
      "  0.8629776   0.48617577 -1.74710015  0.41025247  1.23778604 -1.33615822\n",
      "  1.33656584 -0.91030369  0.41732469  1.14646488 -1.39342345 -0.46355584\n",
      "  0.45933952  0.78677409  0.59621535  1.24703309 -1.48053345  0.63870467\n",
      "  0.5993825   0.97115823  3.34993059 -0.71578629 -0.22835359 -1.07150112\n",
      " -0.03593633 -1.16634513  0.56370557 -0.08738823 -0.1164974  -1.35906955\n",
      "  0.23021759 -7.05634976  1.17326602  0.67495244 -0.15996904 -0.8354947\n",
      " -0.09046316 -0.53755273 -1.16530207  1.01095631  0.6068807  -0.75237728\n",
      "  0.95156745  1.17281127 -0.41172467  0.12194697 -0.46447553  1.6629599\n",
      " -1.05196375  0.81636872  1.2956399   0.28981223  0.65538075 -0.32385059\n",
      " -0.05875444 -0.15830601  0.33607309 -0.72045804 -0.02678038 -0.67690371\n",
      "  1.16581171 -1.56827366  0.32732874  2.29408629  0.88543212 -1.83356794\n",
      " -0.15913307 -0.0525428   0.23944466 -0.57382324 -0.20009721 -1.95447364\n",
      "  0.67780305  0.75598974  0.25691445 -0.1607657   0.70109389  0.0671181\n",
      "  0.55970097  0.00868824  0.23780326 -0.3835714   0.56891468 -1.13502084\n",
      " -1.65077328 -1.5460765   0.48220213  0.70925631 -0.34980725  1.52900993\n",
      "  0.72000931  0.74840065  0.99124973  0.49847732 -0.13638424 -0.07137706\n",
      " -0.46131025  0.04504931 -1.62031982  1.22723109  0.56284472  0.89457664\n",
      "  0.59378808  1.51361969 -0.4473808  -0.07969341 -0.24643438  2.09588198\n",
      "  0.64954503  0.16620396  0.92049131 -1.25670235  0.35525426 -0.70800826\n",
      " -0.62069695 -0.00908943  0.54882056 -0.8063519   0.59798812 -2.19967271\n",
      " -0.25092063  0.18742115  1.21990901 -1.55931165  0.68146388 -0.2657959\n",
      "  0.60542238 -1.00481645  0.09349632  0.88646204  1.22385021 -0.77117999\n",
      "  1.4577888   1.52934694 -1.09794849  2.72998982  0.04138583 -0.47934557\n",
      " -0.38333769  0.0304762   0.67878883  0.20165125 -0.71199055  0.63332135\n",
      " -0.83167544 -1.72049381]\n",
      "------counter :99-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34044762  0.95255001  0.33260694  0.87945232 -0.35119017  0.01502161\n",
      " -1.06656124 -1.02465642 -1.898741    0.94552254  1.17537379 -0.80532116\n",
      "  0.44353412 -0.4273278   0.30162538  0.24227738  2.02560438  0.03695427\n",
      "  0.64795388  3.13645406 -0.01099827  0.77327631 -0.05482461 -1.24155384\n",
      "  0.40183105 -0.60735002 -0.59164172 -1.88194319 -0.18684126  1.05434996\n",
      " -0.61365234 -4.95695808  0.05781816 -0.48274116 -0.23338851  0.52008482\n",
      " -0.75765647  0.00623416 -1.0523568  -1.45424756  0.71297217 -0.87072161\n",
      "  1.50426199 -1.92529246  0.72720168 -0.32471844  0.48556878  0.7321441\n",
      " -0.53163857  0.0315782   0.58131051  1.27344585 -0.55710431 -1.84588475\n",
      "  2.2024945   0.50573185 -0.38235104 -0.38468947  0.85594432 -1.30670801\n",
      "  0.2058377  -0.04313077  0.27597257  0.04457109 -0.80389473  0.19390669\n",
      " -0.36224112  0.39651957  0.56792693 -0.50775601 -0.38072394  0.63379909\n",
      " -0.22154661  1.61959533  5.4469307  -0.40923256 -0.25045943 -1.72352898\n",
      " -0.45727559 -0.84466422 -0.74115858 -0.38019537  0.01434514 -0.89629989\n",
      "  0.08085381 -4.1009734   0.13614759 -1.41991683 -1.30476275 -0.88827792\n",
      " -0.97814689 -2.31119174 -0.5793525  -1.21132725  0.69408267 -0.28557417\n",
      "  1.08850618  0.8004744  -0.10012629  2.40086852 -0.20681849  3.15071447\n",
      " -1.39383658  1.32113009  1.42219043  0.29863125  0.70310863 -0.26498168\n",
      "  2.08924074  0.05778761  0.05895931 -0.49232301 -0.13526035  1.12377662\n",
      " -1.48259208 -1.14282538 -0.26325345  1.45925186  1.10952164 -3.67678998\n",
      "  0.12981543 -0.04231325  0.45902568 -1.46841023 -0.14822711 -0.8742481\n",
      "  0.87362617 -0.97559548  0.3904521  -0.74911206  0.80454544 -0.21938386\n",
      "  0.28992896  0.83156638 -0.01070889 -0.12425662 -0.40728289 -1.01747007\n",
      " -1.87351162 -0.99773248  0.28392636  0.27065167  0.64848828  1.75535621\n",
      "  0.70489501  1.24793355  0.18709411  0.13289258  0.10875565  0.16732295\n",
      " -0.23292259 -0.27287648 -2.03915637  1.34300072  0.53141136  0.76197679\n",
      " -0.22782117  1.17248501  0.02700061 -0.49169735 -0.02872697  0.49606927\n",
      "  0.03980214 -1.00906041  0.45378225 -1.04891736  0.92689311 -0.45892717\n",
      "  0.4246862   0.70413066 -0.09073586 -1.00402377  0.97180826 -0.58935557\n",
      " -0.05949456  0.24158955  1.08155573  2.84071523 -0.00927218 -0.38676538\n",
      " -0.65483812 -0.90107025  0.91112208  0.6696041   0.58222974 -0.41308655\n",
      "  0.89980957  1.21002194 -1.09448044  1.41871123  0.62631887  0.14573147\n",
      "  0.64580847 -0.36182687  1.24089424 -0.11079878 -0.33141046  0.6721558\n",
      " -0.73296498 -2.07388711]\n",
      "------counter :100-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.33318653e-02  1.65472078e+00 -2.77049963e+00  5.62863776e-01\n",
      " -3.08252941e-01 -5.51288285e-01 -3.09036594e+00 -3.04111390e+00\n",
      "  3.25082915e+00  1.80524978e+00  2.85132034e-01 -7.64455454e-01\n",
      "  7.12210213e-01 -9.94659429e-01  1.33623399e+00  2.01853089e-01\n",
      " -1.03395803e+00 -7.98191428e-02  1.13509983e+00  3.11328810e+00\n",
      "  5.50825059e-01  5.92298434e-01 -1.36481596e+00 -8.46276330e-01\n",
      "  4.00401211e-01  2.22781300e-01 -1.82496231e+00 -4.67322286e-01\n",
      "  2.73944438e-01  1.49791980e+00 -6.40839798e-01 -4.38313168e+00\n",
      "  1.15914306e+00 -1.07823105e+00 -4.21751839e-01  3.22895957e-01\n",
      "  2.33206613e-01 -1.05714649e-01 -9.86069150e-01 -2.19849482e+00\n",
      "  3.89425028e-02 -5.04933890e-01  2.31718710e+00 -1.25506819e+00\n",
      " -4.87604244e-01  2.50456070e-02  1.09149815e+00  3.03332258e-01\n",
      "  2.50474038e-01 -1.69252186e-01 -3.47362550e-01 -1.09594180e+00\n",
      " -9.41332321e-02 -1.46985670e+00  1.03745796e+00  3.42896106e-01\n",
      "  1.15127897e+00 -3.65372026e-01  1.03000200e+00 -1.72591633e+00\n",
      "  5.72677782e-01  5.77111616e+00  1.25186255e+00  1.17612040e+00\n",
      " -2.46142167e+00  6.33755063e-02 -1.93538184e-01  1.15836608e+00\n",
      "  9.63144586e-01  1.24953446e+00 -3.70968072e-01 -3.66312088e-01\n",
      " -5.20714561e-01  1.07195140e+00 -8.01435286e-01 -1.35581068e+00\n",
      " -6.41153680e-01  3.17959771e-01 -1.92769873e-01 -9.93014730e-01\n",
      "  9.59969074e-01 -8.67586462e-01 -3.44953986e-01 -1.94627937e+00\n",
      "  4.12908960e-01 -4.08595360e+00 -9.03455196e-01 -1.46785096e+00\n",
      "  3.81251392e-02 -1.42029020e+00  3.07158684e-01 -3.43650551e-01\n",
      " -1.23211316e-01 -5.72688578e-02  9.75639026e-01 -6.34719944e-01\n",
      "  2.40321252e-01  1.97767251e+00 -9.88584432e-01  2.56734859e+00\n",
      " -8.96580552e-01  2.27307080e+00  1.31426382e+00  1.07654507e-01\n",
      "  6.65509343e-01 -3.31404751e-01  1.32514135e-01  1.58246256e-01\n",
      " -1.90399709e+00 -2.81159681e-01  3.89585885e-01 -2.02142179e-01\n",
      "  3.22961918e-01  1.17254566e+00  7.43073037e-01 -3.14131599e+00\n",
      "  3.75442760e-02  1.04159591e+00  1.00302021e+00 -3.53580123e+00\n",
      "  8.33756915e-01 -6.31122359e-01  2.36161038e-01 -9.94724675e-01\n",
      "  9.80393002e-01  4.03730666e+00  2.41987918e-01  1.17876539e+00\n",
      "  3.62702256e-02  2.08516493e-01  1.25181129e+00 -3.86580852e-01\n",
      " -1.93608439e-01  1.07189933e+00 -1.15776873e+00 -4.93621772e-01\n",
      "  8.46469931e-01 -4.98598857e-01  1.15694509e+00 -1.20100147e+00\n",
      " -3.11237548e-02  9.20491952e-01 -4.59142775e-01  1.34651762e+00\n",
      "  8.86898862e-01  6.89073085e-01 -4.79557842e-01  9.37299222e-01\n",
      " -2.80510524e-01 -5.50495868e-01 -5.11344398e-01 -3.72640705e-01\n",
      " -2.18751037e+00  1.02402090e+00  5.14131261e-01  6.99271496e-01\n",
      " -1.61908852e+00  1.59321369e+00 -4.73485214e-01  1.00709205e+00\n",
      " -6.70725903e-02  1.06719342e+00  8.06074741e-01 -9.86062499e-01\n",
      "  7.01327874e-01 -1.39489206e+00  3.71930605e-01 -1.78214772e+00\n",
      " -2.93136276e-01  8.23892474e-01 -9.20561178e-02 -1.36933834e+00\n",
      "  1.35064022e+00  5.98764866e-01  6.27709210e-01  9.11735297e-01\n",
      "  8.38274002e-01 -4.36479352e-01  5.66939275e-01 -6.44260101e-01\n",
      "  2.04879406e-01 -1.06349660e+00  5.75645900e-01  3.98001524e-02\n",
      " -2.12673888e-03 -1.04450737e+00  6.69643009e-01  1.17921035e+00\n",
      " -2.14897989e+00  1.33398379e+00  5.23480156e-01  7.41804111e-01\n",
      "  1.34684719e-01 -1.19638315e+00  8.68310321e-01 -5.40870368e-01\n",
      " -8.27137714e-01  1.21242745e+00 -2.37406979e-01 -2.78673569e+00]\n",
      "------counter :101-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.81730657e-01  1.07940674e+00 -2.03239322e+00  7.90602223e-01\n",
      " -9.68254509e-01 -1.02369008e-01  2.05208342e-01 -1.31882042e+00\n",
      "  2.78616877e-01  9.55839344e-01  1.11547513e+00 -4.35386678e-01\n",
      "  2.32100545e-01 -9.03897042e-01  1.08851247e+00  5.20684620e-01\n",
      " -7.32861274e-01  1.22656976e+00 -2.05048902e-01 -2.69011048e+00\n",
      "  1.08677081e-01 -6.97775356e-01 -4.02040570e-01 -8.10887062e-02\n",
      " -5.65403759e-01 -6.80016579e-01  1.68488648e-01  1.22834891e-01\n",
      "  1.39684877e+00  8.50730709e-02 -5.64535343e-01 -4.11175121e+00\n",
      "  8.45757584e-01 -4.78055263e-01 -5.45165404e-01 -1.28812805e-01\n",
      "  9.72248765e-01 -1.59492653e-01 -1.46669768e+00  4.22627414e-02\n",
      "  1.41244853e-02 -1.11658138e+00  2.69310406e+00 -1.16691992e+00\n",
      "  2.70112783e-01 -2.27842691e-01  3.14927633e-01  9.77617457e-01\n",
      " -6.95927639e-02 -3.28848005e-01 -1.05294878e+00 -1.17597016e+00\n",
      " -5.24642764e-01 -1.06728106e+00  1.60449022e-01  5.68935131e-01\n",
      "  1.25600235e+00  2.36793909e+00 -3.21639489e-01 -5.68781822e-01\n",
      "  4.12740257e-01  4.10868343e+00  1.95393114e+00  1.14070534e+00\n",
      " -1.83816294e+00 -4.64743622e-01 -5.60781652e-01  4.46626915e-01\n",
      "  4.08322554e-01  5.20213413e-01 -1.04879563e-01  1.55138466e+00\n",
      " -3.77512666e-01  6.60523930e-01  1.55021598e+00 -4.20226323e-03\n",
      " -8.10883534e-01 -2.55988876e-02 -3.44138068e-01  1.29697341e+00\n",
      "  9.04991795e-01 -5.51913500e-01 -1.98072200e+00 -1.50292991e+00\n",
      " -3.83099990e-01 -2.57208035e-01 -8.97631618e-01 -1.24197451e+00\n",
      " -2.38747294e-01 -1.47282162e+00 -3.38946311e-01  7.30688720e-01\n",
      " -2.71147826e+00  7.01122367e-01  2.09537098e+00 -5.00576329e-01\n",
      "  5.11376821e-01  8.09242083e-01 -9.46156657e-01  7.66421499e-01\n",
      " -3.14484050e-01  3.70249338e+00 -4.69876253e-01  7.80374255e-01\n",
      "  7.63438184e-01  4.88193933e-01  1.39251656e+00 -1.71203116e+00\n",
      " -2.05798230e+00 -1.11811150e+00 -8.12631261e-02  1.44461759e-01\n",
      " -2.35768741e-01  8.34465950e-01 -9.94677892e-02  1.26415972e+00\n",
      " -2.53091572e-01  8.52495642e-01 -1.00238880e-01 -1.32086376e+00\n",
      "  7.13316049e-01 -7.66764232e-01 -3.45963656e-01 -5.94876210e-01\n",
      "  5.92346361e-01 -3.91022130e-01  1.09280107e+00 -1.79489791e+00\n",
      "  8.03237240e-01  6.31635390e-01  9.13027278e-01  2.68611423e-02\n",
      "  1.01859180e+00  4.67666164e-01 -1.74182474e+00  2.28632040e-01\n",
      "  6.28907575e-01 -1.54477290e+00  9.08954794e-01 -4.96252810e-02\n",
      "  6.10888342e-02  7.69317937e-01 -8.42214863e-01  1.30425330e+00\n",
      "  2.24747581e-01  2.90262218e-01 -3.05391036e-01  9.17211027e-01\n",
      " -3.74389884e-01  2.08742277e-01 -7.19751003e-01 -1.06271157e+00\n",
      " -2.85499224e-01  6.27016946e-01  5.91426227e-01  7.56123417e-01\n",
      "  1.59236907e+00  1.24339923e+00 -8.10311533e-01 -5.85184451e-01\n",
      " -5.79203281e-01  7.07505230e-01  3.68507803e-01 -4.46248927e-01\n",
      "  4.69083712e-01 -1.80042292e+00  2.27266616e-02 -8.97371283e-03\n",
      " -1.27968218e-01  2.09471735e-01  4.41599879e-01 -3.53058994e-02\n",
      " -6.15033107e-01  8.96211568e-01  1.09744817e-01 -2.98138853e-01\n",
      "  3.86155613e-01 -7.25950213e-01  1.00796065e+00  1.55353704e-02\n",
      "  1.31453627e-01 -2.58750863e-01  5.98647295e-01 -6.15594800e-02\n",
      "  4.78839084e-01 -8.70405017e-01  4.25313386e-03  9.79922413e-01\n",
      "  3.63525422e-01  9.81291756e-01 -1.78398199e-01 -3.93264617e-02\n",
      " -1.34416211e+00 -1.22681213e+00  1.19430706e+00 -5.34797539e-01\n",
      " -1.54347132e+00  7.61876681e-01 -1.88769742e-03 -1.98804750e+00]\n",
      "------counter :102-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.85582883e-01 -9.31640720e-01 -1.53498869e+00  6.47641669e-01\n",
      " -3.95127970e-01 -3.11587857e-01 -1.12472214e+00 -1.00824661e+00\n",
      "  1.74942080e+00  4.79641078e-01  8.42578571e-01  5.45286246e-01\n",
      "  1.68547411e-01 -4.55758774e-01 -6.93817525e-02 -6.37496389e-02\n",
      " -8.65058436e-01 -2.51239902e-01 -4.08627083e-01  1.19296913e-03\n",
      " -2.49473143e-01 -1.89181862e-01  1.17201424e-01  8.25267079e-02\n",
      "  6.58003147e-02 -7.51042192e-01 -3.62882130e-02 -1.19781140e+00\n",
      "  6.00149876e-01  5.62745519e-01 -3.98441489e-01 -3.72046740e+00\n",
      "  3.83896432e-01 -8.99710692e-01 -4.50683576e-01  4.25505226e-01\n",
      "  3.69221142e-01 -2.16470975e-01 -6.71788979e-01  1.27579305e+00\n",
      " -1.91301281e-03 -7.03125063e-01 -6.77628499e-01 -6.73210013e-01\n",
      "  7.48770852e-01 -1.81407001e-01  1.36561157e-01  9.30657990e-01\n",
      " -3.01824114e-01 -6.14859511e-02 -1.58208397e+00 -9.35035387e-01\n",
      "  9.32002884e-02 -5.09087023e-01 -1.67660311e+00  4.89487966e-01\n",
      "  1.42977231e+00  4.17876635e-01  1.11653188e+00 -1.29800552e+00\n",
      " -3.04426827e-01  2.19047126e+00  1.35508538e+00  3.41912879e-01\n",
      "  2.82659406e-01  2.50910762e-01  9.41138144e-02  2.74828800e-01\n",
      "  2.54789465e-01  1.80279051e+00  1.36854579e-02  1.86272715e+00\n",
      " -1.34644936e-01  1.38182586e+00 -1.17626810e+00 -6.98375767e-01\n",
      "  2.29187290e-01 -4.27614489e-01 -2.80183111e-01  9.84048794e-01\n",
      " -1.78715125e+00 -4.46536604e-01 -1.88350702e+00 -1.16694508e+00\n",
      " -5.87767448e-02 -5.87266294e+00 -4.55909241e-02 -1.27219578e+00\n",
      " -5.27314096e-01 -9.28877580e-01  9.47752239e-01 -1.38687894e-01\n",
      " -1.39315498e+00  1.47051126e+00 -6.66132577e-01 -4.21371688e-01\n",
      "  7.89184993e-01  9.10329115e-01 -1.51141575e+00  1.13313403e+00\n",
      " -5.05031458e-01  2.29809453e+00  1.46739428e+00  7.58357796e-01\n",
      "  4.67260529e-01  6.48871346e-01  3.44072423e-01 -1.36140770e+00\n",
      " -1.17477879e-01 -6.31054046e-01 -2.77371980e-01 -1.77737705e+00\n",
      "  9.07758699e-02  3.91021730e-01  5.41912673e-01 -1.99295909e+00\n",
      "  5.02734181e-01  6.21625872e-01  9.99733226e-02  1.60555427e-01\n",
      "  4.81669363e-01 -1.67426060e-01  3.84050385e-02 -1.85289010e-01\n",
      "  8.78659000e-02  1.70330894e+00  8.59344506e-01 -8.95642738e-02\n",
      "  7.07275968e-01  2.51724038e-01  6.77415582e-01  2.30996238e-01\n",
      "  2.77053564e-01  2.79643752e-01 -1.84298155e+00  2.70106338e-01\n",
      "  9.32479042e-01 -8.47136367e-01  5.83812919e-02  5.04555769e-01\n",
      "  8.50044775e-02  4.24473181e-01  2.53372202e-01  1.72152642e+00\n",
      "  8.17364411e-02  2.12705706e-01 -1.49359746e-01  1.72233392e+00\n",
      " -3.86233080e-01  1.25800391e-01 -9.85509973e-01 -6.59179649e-01\n",
      " -1.63298891e+00 -1.29486154e+00  1.43644952e+00  3.24562632e-01\n",
      "  1.72608945e+00  6.58176676e-01 -3.75943696e-01 -2.93665880e-01\n",
      " -4.65718303e-01  2.88898488e-01  7.17400523e-01  4.79870773e-01\n",
      "  9.27996298e-01 -1.02415642e+00  1.00110948e+00  6.12536316e-01\n",
      " -1.63571384e-01  6.58440317e-01  5.43962328e-02 -4.13485798e-01\n",
      " -3.92074082e-01 -6.37744781e-01  4.82335580e-01 -5.98193493e-01\n",
      "  3.61012537e-02  1.10565014e+00  5.09404846e-01 -5.30034110e-01\n",
      " -6.52005531e-03  5.74501954e-01  3.07581510e-02 -5.84880179e-02\n",
      " -9.89278139e-02 -1.93801224e-01  9.67416863e-01  6.16728982e-01\n",
      "  1.33433884e+00  3.46459868e-01  1.69455409e-01  3.82121856e-01\n",
      " -8.89856506e-02 -4.53752931e-01  8.79549822e-01 -1.82614501e-02\n",
      " -9.60513894e-01  5.14480156e-01  4.82600835e-01 -8.11417534e-01]\n",
      "------counter :103-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41288329 -0.8871515  -0.21122287  0.37457451  0.41307727 -0.19154284\n",
      " -0.24682131 -0.91349719  0.7196658  -0.90154873 -0.26445067 -1.61134492\n",
      "  0.14653404 -1.33314387  0.00349667  0.09508308 -0.31958335  0.82747112\n",
      " -0.42481473 -2.3848722  -0.54049404 -0.0151319   0.80220567 -0.21834841\n",
      "  0.43701487 -0.80625335  0.13946048 -0.66546966 -0.09116592  1.20801505\n",
      " -0.36016773 -3.06337993 -0.04704817  1.37712108 -0.16377494  0.04606873\n",
      " -0.07091701  0.13694257 -0.53110588  0.17145614  0.97078185 -0.03542667\n",
      "  0.02547954 -0.33878393  0.24684758  0.15039657  0.65339643  0.64302698\n",
      "  0.15185514  0.06484982 -1.29761239 -0.47358635  0.25060803 -0.45198828\n",
      "  0.25038331  0.46293015 -2.04222884  1.78182179  0.61800752 -2.58015406\n",
      "  0.76246333 -0.28662065  0.23558589  0.54591912 -0.57606264 -0.02658178\n",
      "  0.87740185  0.79949781 -0.04644954  1.32001977 -1.02600926 -0.3102645\n",
      "  0.13644414  0.75378714  1.94982884  0.45210543  0.01812023  0.60627958\n",
      "  0.09054434 -1.79307907 -0.41125404  0.63239736 -0.79967701 -0.19332999\n",
      "  0.67349668 -3.13219004 -0.70898737 -0.83157634  0.3627429  -0.18876267\n",
      "  0.57472509 -1.16194773  1.53009109  0.91614673  2.27366166  0.26050503\n",
      " -0.32547918  0.19556574 -0.29221946  0.86531959 -0.25010095 -0.34464827\n",
      " -0.46568569  0.85798388 -0.06771365  0.00430871 -0.2225037  -1.84560777\n",
      " -0.08737375  0.46613646 -0.190833   -2.54557509  0.73431231  0.48897333\n",
      " -1.59722373 -2.08155061  0.18173755  0.60322421 -0.27485535  0.44047914\n",
      "  0.37069693 -0.12025468  1.1228325  -0.20222801 -0.36596463 -2.12890111\n",
      "  0.7562151   0.06896508  0.13712318  0.26393202  0.60685033  0.28170301\n",
      "  0.81205831 -0.86606069 -0.77695813 -0.64768845 -0.28515315 -0.1711055\n",
      "  0.06652121  2.59949966  0.11634756  0.76599605  0.02291702  1.9468897\n",
      "  0.57233323  0.60335855  0.79889686  0.85196675 -0.07460493  0.74560743\n",
      " -0.36860111 -0.12763859 -2.15769155 -1.83934802  1.55826965  0.50653069\n",
      "  2.22897498  0.9837433  -0.68652289 -0.02984446  0.10246928 -1.3663677\n",
      "  0.07199759 -0.13708538  0.38278595 -0.98093933  0.25651068 -1.83522678\n",
      " -0.01441312  0.49507232 -0.04068186  0.57742921  1.21350949  1.15479195\n",
      "  0.51452376 -0.19360681  0.29049464 -1.47130185 -0.28821207 -0.01189149\n",
      "  0.14796834  1.45997977  0.45758487  0.77183745  0.50819786 -0.60670909\n",
      "  1.07777238  0.37248377 -0.64087864  2.20818079  0.20789842 -0.02918457\n",
      " -0.37458948 -0.05451646  0.68605338  0.00373329 -1.07043286  0.16209527\n",
      "  0.88820593 -1.4592676 ]\n",
      "------counter :104-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.33391686e-01 -9.95709719e-01 -1.86138522e+00 -8.85875042e-02\n",
      " -6.65486377e-02 -5.11769251e-02 -1.05644126e+00 -2.02165212e-01\n",
      "  4.54812435e-01  6.57055836e-01  9.21240161e-01 -1.79437725e+00\n",
      " -1.00151763e-01 -1.83741394e-01 -6.33722545e-02 -2.87414354e-01\n",
      "  4.34038708e-01  1.39439985e-01 -2.14808413e-01 -6.07987746e-01\n",
      "  6.92457069e-02 -1.96559225e-01  8.06776670e-01  6.66998107e-01\n",
      "  3.19099595e-01 -1.10779080e+00 -3.15011525e-01 -6.91975591e-01\n",
      " -3.62229354e-01 -5.29574595e-02 -6.17443513e-02 -3.23360901e+00\n",
      "  3.05136671e-01 -3.31012788e-01 -6.43203127e-01 -3.71767621e-01\n",
      "  7.35426234e-01 -9.21430030e-02  3.00736592e-01  6.76075592e-01\n",
      "  1.27363590e+00  6.59376421e-01 -2.13136049e+00  5.45876757e-01\n",
      " -2.70321409e-01  5.40798965e-01 -9.02135280e-01  2.60232805e-01\n",
      " -1.78483649e-01  2.25905493e-01  5.24331611e-01 -4.73654881e-01\n",
      " -5.91889588e-01  1.32605490e+00 -1.33340576e+00  3.80815855e-01\n",
      " -3.03128921e-01 -1.08420828e+00 -6.48136545e-01 -6.99463773e-01\n",
      " -5.53055427e-01 -3.58287610e-01  8.12710337e-01  1.67472498e-01\n",
      "  1.04840544e+00 -2.96347373e-01 -1.60193309e+00  2.23691621e-01\n",
      "  2.04268516e-01  1.25771181e+00 -8.88970311e-01  1.83022456e+00\n",
      " -2.27098425e-03  3.91711626e-01  1.04809700e+00 -8.18943876e-02\n",
      " -9.64508772e-02  2.53211834e-01 -4.23747677e-01  6.27003743e-01\n",
      "  1.85889596e-01  1.91396082e-01 -6.22458298e-01  5.88394825e-01\n",
      "  5.70955946e-01 -3.27093606e+00 -6.56897908e-01  6.81572777e-01\n",
      "  3.27910622e-02 -8.22488837e-02  9.29433622e-02 -4.98702424e-01\n",
      "  4.30672752e-01 -2.34286044e-02  2.03786029e+00  7.38886287e-01\n",
      "  3.31244142e-01 -1.07018138e+00 -9.47971651e-01  9.45165627e-01\n",
      " -9.72924348e-01  1.31597074e+00  1.81594152e-01  5.03528397e-01\n",
      "  4.50302604e-01  1.69321027e-01 -3.55399961e-01 -9.31866771e-01\n",
      " -3.10123956e-01  1.23669985e-01 -8.56497860e-03 -1.39645536e+00\n",
      "  1.00507404e+00  1.03525290e-01  4.98709609e-01 -1.71760544e+00\n",
      "  4.46010467e-01  1.96097020e+00 -1.04899068e+00 -6.95153175e-01\n",
      "  7.70333222e-01  1.45524408e-01  7.14708620e-01  4.94334903e-01\n",
      " -1.67650748e-01  1.44557589e+00  1.18924880e+00 -1.02900267e-03\n",
      " -1.26165982e-01 -6.94435214e-01  5.32727305e-01 -4.84483409e-02\n",
      "  1.19539148e-01  1.59327429e-03 -1.73134115e-01 -4.64356605e-01\n",
      " -1.36160080e+00 -9.65694499e-02  1.00273481e-01 -5.69910589e-01\n",
      "  6.40044072e-01  9.82858969e-01  3.23367842e-02  1.50502206e+00\n",
      " -1.06630112e-01  1.98615510e-01  2.43814273e-01  6.01294054e-02\n",
      "  5.40206698e-03  3.68773491e-01 -4.17090771e-01  6.47616732e-01\n",
      " -8.61410522e-01 -1.73441098e+00  4.34330392e-01 -2.23841698e-01\n",
      "  1.36754307e+00  8.15250899e-01 -2.50044692e-02  6.72782167e-03\n",
      "  3.26473437e-01  1.19715310e+00  1.71069945e-01 -9.37350302e-01\n",
      "  7.88427555e-01 -8.35163275e-01  1.01559745e-01  1.11939063e+00\n",
      "  5.37394327e-01  5.25653828e-01  3.75747736e-02  4.99101518e-01\n",
      "  9.55289001e-01 -1.56105913e+00  1.67995472e-01 -2.08829567e-01\n",
      "  2.16844494e-01 -1.34287541e+00  2.00524693e-01 -1.18670694e-01\n",
      " -2.19759065e-01 -4.91690755e-01  1.46670774e-01  4.40658149e-01\n",
      "  7.52378178e-01  4.27356877e-01  8.24685516e-02 -5.96844268e-01\n",
      "  9.27505877e-02 -1.62617981e-01 -2.70437641e-01  2.68827919e-01\n",
      " -2.41660053e-01  4.01108216e-02  6.74524546e-02 -1.35886634e-01\n",
      "  1.01597310e+00 -8.24624468e-02 -1.65669591e-01 -1.03291549e-01]\n",
      "------counter :105-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.56445473e-01 -4.30873078e-01 -7.16141572e-01 -2.70754617e-01\n",
      " -6.59057387e-01 -1.52971073e-02 -2.00671466e-01  4.13296980e-02\n",
      " -1.10524315e+00  4.38793522e-01  1.01155550e-01 -6.74585923e-01\n",
      "  1.05287755e-01  7.37161828e-01  6.76825081e-01 -4.90732294e-01\n",
      "  4.15398495e-01  4.78734433e-01 -1.52269680e-01 -2.48166743e+00\n",
      "  1.42998843e-01 -4.44773454e-01  7.49534283e-01  8.03753649e-01\n",
      "  1.47085132e-01 -1.31603316e+00 -2.80211223e-01 -6.08150315e-01\n",
      " -6.71995613e-01 -9.30054360e-01 -1.14818704e-01 -2.55490662e+00\n",
      " -4.55112598e-01 -1.88522521e-01 -4.58111669e-01 -7.54250726e-01\n",
      "  3.42154690e-01 -2.12273656e-01 -6.90395819e-04  4.10081751e-01\n",
      "  4.89801724e-01  2.47238080e-01 -8.86373243e-01 -4.90732697e-01\n",
      " -8.58999198e-01  8.51510118e-01  1.90524159e-01 -1.12276531e+00\n",
      "  1.56730323e-01  9.04867323e-01  5.69106077e-01  2.51195365e-01\n",
      "  5.50940762e-01  1.05054231e+00  1.48668596e+00 -5.50189532e-01\n",
      " -2.20137439e-01 -5.86045582e-01 -7.12507076e-01  7.75191272e-03\n",
      " -7.59818011e-01  1.97179447e-01 -2.26883705e+00 -4.22928289e-01\n",
      "  4.54808644e-01 -1.66934779e-01 -1.60962480e+00 -1.63303897e-01\n",
      " -4.25959087e-01  1.49173144e+00  2.82835210e-01  1.86524341e+00\n",
      " -1.98813116e-01  5.44061200e-01  2.67992709e+00 -4.23432562e-02\n",
      " -8.36814394e-01  2.81647256e-01 -2.48243246e-01  6.30794852e-01\n",
      "  2.87291515e-01  3.18650290e-01 -4.47292745e-01  7.60039412e-01\n",
      "  5.51195419e-01  2.82168311e+00 -7.79389701e-01  2.41781430e-02\n",
      "  2.88518123e-01  6.16823168e-01  3.19555725e-01 -3.01932789e-01\n",
      "  1.39606802e+00 -1.83346904e-01  2.09271913e+00  5.84437882e-01\n",
      "  1.20752368e-01 -1.08793460e+00 -1.27340372e+00  7.69539088e-01\n",
      " -5.46491089e-01  1.58344656e+00  1.01535296e+00 -1.17664318e+00\n",
      "  9.53576190e-02  3.71668202e-01 -2.26132981e-01  5.19327376e-01\n",
      "  9.47953654e-01 -1.41441443e-01 -2.47654706e-01 -1.12111926e+00\n",
      "  8.86332105e-01 -7.68919661e-01  6.59583836e-01  1.85194216e+00\n",
      " -1.00713793e-01  1.27823461e+00  1.17062144e+00  1.68897924e-01\n",
      "  8.87489006e-01  2.57982339e-02  1.09298998e+00  2.10113943e-01\n",
      " -2.26920490e-01  2.61087463e+00  1.26993779e+00 -8.03373340e-01\n",
      "  2.79193253e-01 -4.51541442e-01  4.92286218e-01 -4.21925633e-03\n",
      " -1.42745274e+00 -2.69325640e-01 -1.95288586e-01 -2.90878867e-01\n",
      " -3.24383332e+00 -1.81851958e-01 -2.69072920e-01 -9.22875919e-01\n",
      "  1.89282623e-01  5.64741674e-01  2.07387654e-01  2.25485071e+00\n",
      "  4.92995502e-02 -2.59774658e-01  5.33920314e-02 -5.54237943e-01\n",
      " -5.90850203e-02 -4.00826389e-01 -2.87482875e-01  6.84236620e-01\n",
      " -2.03614920e-01 -1.19996884e+00 -1.84009117e-01 -5.62093442e-01\n",
      "  2.37151405e+00  9.99046431e-01  1.61382274e-01  1.09391790e-01\n",
      "  2.26841444e-01  6.25375388e-01 -1.19498350e+00 -8.76438028e-01\n",
      "  4.23863392e-01 -5.98655887e-01  9.50466429e-02  6.53896436e-01\n",
      "  9.98231144e-02 -9.15895970e-01 -8.49808465e-02 -4.79789208e-01\n",
      "  4.23584959e-01 -2.54359092e-02  2.13651910e-01 -6.23797449e-01\n",
      " -1.89686288e+00 -7.28798087e-01 -5.18187831e-01 -4.18635804e-01\n",
      "  1.83852842e+00  3.09380999e-01  4.54752020e-01  4.58130069e-01\n",
      " -5.27804059e-01  5.22787678e-01 -5.83983435e-01 -5.62475971e-01\n",
      "  2.30916172e-01 -4.67677763e-01 -5.92701813e-01  1.86216573e-01\n",
      " -7.35213298e-01  3.01502591e-01 -9.87255027e-01 -6.39178165e-03\n",
      " -6.30501926e-02 -6.88406194e-01 -6.36151615e-01 -7.37253450e-01]\n",
      "------counter :106-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.48456011e-02 -3.57649700e-01 -1.98901478e-01 -1.15042669e-01\n",
      "  8.76540412e-02 -7.36712330e-02 -8.31736976e-01 -5.00308074e-02\n",
      " -4.16697218e-01  4.66713969e-01  9.09381843e-01  5.62830074e-01\n",
      "  1.27841477e-01  5.68027846e-02  2.51557162e-01 -2.63546375e-01\n",
      " -1.43728303e+00  5.63774421e-02 -2.58238339e-01 -1.12563060e+00\n",
      "  6.93159905e-01 -4.81249608e-01  7.65191490e-01  8.98552892e-01\n",
      "  5.10546272e-02  1.05286714e-01 -5.17200155e-02 -6.33477659e-01\n",
      " -9.31277471e-01 -5.60680753e-01 -1.67300006e-01 -2.59805949e+00\n",
      " -3.51921393e-01  3.67609878e-01  1.37744827e-02 -8.42220007e-01\n",
      "  1.57675717e-01 -3.23555483e-01  2.49798675e-01  4.76625524e-01\n",
      " -4.23723581e-01  3.07291112e-01 -1.57119518e+00 -1.93933734e-01\n",
      " -7.40137877e-01  8.19641898e-01 -8.89334249e-01  3.45191204e-01\n",
      " -5.13909915e-01  7.43897134e-01  3.56390455e-01 -5.14954106e-01\n",
      " -1.15306931e-01  9.86066010e-01  9.27253554e-01 -5.32043384e-01\n",
      " -2.30733734e-03  5.53225158e-01 -1.09337356e+00  3.27310315e-01\n",
      "  1.10383567e-01  6.35963828e-01 -8.86629519e-01 -4.30770059e-01\n",
      "  2.45774766e-02  1.82621977e-01 -1.67920387e+00 -3.34276480e-01\n",
      " -5.30929194e-01  1.20741475e+00  5.07495570e-01  1.51217486e+00\n",
      " -2.70371003e-02  3.96017836e-01  4.42047571e-01  1.21585131e-01\n",
      " -4.53999897e-01  2.17197458e-01 -5.73355928e-01 -1.06300099e+00\n",
      "  3.27751526e-01  2.45377376e-01  1.34308208e-01  6.88134319e-01\n",
      "  6.01675319e-01  4.14262836e+00 -7.78504911e-01 -1.44770334e-01\n",
      "  3.19123309e-01  5.02164675e-02  4.27267673e-01 -1.90234985e-01\n",
      " -1.58437930e+00 -4.54961096e-02 -1.35271321e+00  3.56657879e-01\n",
      "  5.74363045e-02 -1.10114141e+00 -1.34453975e+00  1.61426939e+00\n",
      " -4.00601523e-01  2.57861582e+00 -2.17528780e-01 -2.81011633e-01\n",
      " -4.69378976e-01  3.77475544e-01 -4.38102624e-01 -1.03005453e-01\n",
      "  6.52093387e-01  5.45775589e-02 -2.94669606e-01 -8.01890857e-01\n",
      "  1.07595892e+00 -8.24359502e-02  3.57478814e-01 -1.07598885e+00\n",
      " -2.77580941e-02  9.42601520e-01  5.23301611e-01 -1.37157352e+00\n",
      "  6.88941162e-01  5.37409629e-01 -1.10844990e+00  5.12732551e-01\n",
      " -5.35483045e-02  1.58370258e-01  1.34554936e+00 -2.71530811e-01\n",
      " -3.45008858e-01 -4.44267513e-01  3.35424354e-01 -2.10302161e-01\n",
      " -1.64545997e+00  1.06986971e+00  1.23732680e-01  2.18675938e-01\n",
      "  1.65272953e-01 -2.18388358e-01 -1.03484671e+00 -2.53367560e-01\n",
      "  1.50583146e-01  5.29874220e-01  5.05174133e-01  2.16203302e+00\n",
      "  1.62941230e-01 -3.30377030e-01  2.19316713e+00 -2.01725475e-01\n",
      " -4.87682630e-02  5.55707508e-01 -2.68956202e-01  5.99764337e-01\n",
      " -4.87351612e-01 -8.27978163e-01 -2.10936171e-01 -7.34008707e-01\n",
      "  3.64381894e+00  1.05855049e+00  2.79534725e-01  9.16248882e-01\n",
      "  2.37402586e-01  1.40212323e+00 -4.60166422e-01 -1.39744305e+00\n",
      " -1.91115867e-01 -4.01811629e-01  3.03869475e-01  4.35465130e-01\n",
      "  3.72621472e-01 -1.03978795e+00  4.85524988e-02  7.55638642e-02\n",
      "  5.15795961e-01  1.21861596e+00 -8.35601610e-03 -6.71221509e-01\n",
      " -9.62306345e-01 -1.35455037e-01 -6.40427116e-01 -9.09179582e-02\n",
      "  6.31793325e-02  1.06368805e+00 -7.94785763e-02  1.69991676e-02\n",
      " -1.03847291e+00  1.14636319e-01 -6.71681205e-01 -2.58475924e-03\n",
      "  4.46746865e-01 -1.01353880e+00  4.45115636e-01 -2.24162570e-02\n",
      " -2.28575534e-01  1.06215496e-01 -4.70259915e-01 -1.19075081e-01\n",
      "  2.23495225e-02 -7.49410871e-01 -1.25077213e+00 -3.50161620e-01]\n",
      "------counter :107-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.13202955e-01  1.36588425e-01  1.88397317e-01  9.59890801e-02\n",
      "  3.63415184e-01 -1.66602709e-01 -1.00691329e+00  2.42679519e-01\n",
      " -4.77950078e-01  2.94601559e-01  8.80857528e-01 -4.84277356e-01\n",
      "  3.69067567e-02  2.54232704e-01 -5.16493225e-03 -3.13337984e-01\n",
      " -1.22475489e+00  9.55658164e-03 -2.23161111e-01  1.46086107e+00\n",
      " -9.77719744e-01 -3.80438498e-01  5.99414517e-01  6.58962046e-01\n",
      " -1.71150456e-01 -1.58001161e-01  1.68126582e-01 -3.72072752e-03\n",
      " -9.36934805e-01 -4.41568047e-01 -3.13979531e-01 -2.58140095e+00\n",
      " -4.26194445e-01  1.12005587e-01 -9.96170439e-01 -7.75648501e-01\n",
      "  2.35046132e-01 -1.24154167e-01 -1.47656584e-01  5.97417741e-02\n",
      "  8.71617998e-02  3.05172308e-01 -9.86982210e-01  4.32932852e-01\n",
      " -4.77123787e-01  8.71070615e-01 -8.21574805e-01 -2.28575068e-01\n",
      " -4.28134392e-01  1.69527367e-01 -9.97701606e-02  2.99178832e-01\n",
      "  8.35021577e-01  1.06773314e+00  2.16965070e-01 -1.33406565e-01\n",
      "  4.23074318e-01  3.21375064e-02 -1.56196688e-01  8.38567787e-02\n",
      " -5.94407845e-01 -1.14057443e+00 -8.07841599e-01 -5.17509153e-01\n",
      " -2.48888244e+00  7.87538469e-01 -9.51625218e-01 -4.45874685e-01\n",
      " -1.33236093e-01  9.32547301e-01 -3.92610531e-01  1.51559197e+00\n",
      " -5.96096117e-01  8.97697330e-02  3.76942485e-01 -3.76363147e-02\n",
      " -4.24108858e-01  1.40158933e-01 -9.64636977e-01  8.08126876e-01\n",
      "  1.01758080e+00  2.42293294e-01 -2.86442795e-01  7.99023810e-01\n",
      "  6.99684051e-01  3.51694449e+00  7.30674243e-01  9.01071294e-02\n",
      " -1.05469938e-01 -4.12205314e-01  4.04322044e-01  7.19736026e-02\n",
      " -6.66329792e-01  5.42390994e-01  1.10934210e+00  4.17603148e-01\n",
      "  4.95672354e-01 -8.08240998e-01  1.20036259e+00  1.53653943e+00\n",
      "  1.85960693e-01  1.92643810e+00  5.37968638e-01 -1.13704313e+00\n",
      " -2.32606504e-01  1.04644089e-01 -4.91936866e-01 -1.40627227e+00\n",
      " -7.10582612e-01  4.77757251e-01 -1.88646009e-01 -4.30299827e-01\n",
      "  1.05395997e+00 -8.31418994e-01 -1.12615499e-01  7.26703945e-01\n",
      " -5.71327157e-02 -1.18155875e+00 -5.16772578e-01 -1.44653539e+00\n",
      "  4.83836320e-01  1.05910252e-01 -6.86948137e-01  5.82063994e-01\n",
      " -1.74918540e-01 -3.80238435e+00  1.39431362e+00 -1.09196010e-01\n",
      " -8.36689172e-02 -2.76775977e-01  5.77464608e-01 -1.50955311e-01\n",
      " -1.57088585e+00  9.73218272e-01 -1.33015458e-01  1.88511719e-01\n",
      "  2.75152160e-01 -3.38966064e-01 -8.54902275e-01 -6.69795154e-01\n",
      " -1.02319894e-01  4.22381390e-01 -4.62462497e-02  2.30082154e+00\n",
      "  1.18991541e-01  4.63130043e-01  6.40084833e-01 -4.22063831e-01\n",
      "  2.13597973e-01  3.29095542e-01 -3.45594522e-01  2.92388308e-01\n",
      " -7.13839730e-01 -1.13297150e+00 -3.17507153e-01 -6.32774582e-01\n",
      "  3.05236026e+00  1.83127033e+00  1.94098284e-01  4.54537568e-01\n",
      "  2.56242055e-01  9.42101606e-01 -2.58281396e-01 -8.83839104e-01\n",
      "  1.79869992e-01  7.18883658e-01 -2.20684777e-01  6.48487835e-01\n",
      "  1.35239233e-01  1.98579062e-01 -2.21131944e-01  6.63638574e-01\n",
      "  1.59546285e+00 -3.37949299e-01 -4.48750970e-02 -6.65770966e-01\n",
      " -5.55781772e-01  8.85003649e-01 -1.15052453e+00  3.56047079e-01\n",
      "  1.01327841e-01  5.88238642e-01  3.43304924e-01  3.67452625e-01\n",
      " -1.28477465e+00  6.59368089e-01 -4.58865853e-01  2.31939017e-01\n",
      "  3.14861012e-01 -1.26223174e+00 -2.69922113e-01  5.07469941e-02\n",
      "  3.82451258e-01  1.18659864e-01 -2.28901534e-01  2.51277069e-01\n",
      " -1.42264753e-01 -7.07488781e-01 -1.82120960e-01 -5.28498392e-01]\n",
      "------counter :108-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0768445  -0.17744418 -0.15980243  0.23556775  0.20745933 -0.19668605\n",
      " -0.51387045 -0.0846637  -1.89930948 -0.54581536  1.59079837 -1.0443981\n",
      "  0.23785329  0.73601214  0.95745476 -0.06433063 -0.75791875 -0.56392497\n",
      " -0.26190213 -1.51166509 -0.26044212 -0.50284114 -0.31254874  0.6655437\n",
      " -0.14290394 -0.22947761  0.05639509 -0.79415346 -0.73563814 -1.96698884\n",
      " -0.27314233 -0.66437127 -0.38657702  0.20245234 -1.65521883 -0.46744954\n",
      "  0.18093869 -0.28724278  0.43141492  1.02157896 -0.46546777  0.14380322\n",
      "  0.21449371 -0.2298078  -0.89475519  0.66950875  0.75625165 -0.34584491\n",
      " -0.01424768  0.24090452  0.16551328  0.11705621 -0.17861393  1.32271187\n",
      "  0.9017916  -0.11224095  1.24689928 -0.5266969  -0.0568445  -0.50014277\n",
      " -0.34959507 -1.04015883  0.21625619 -0.51358361  3.9000309   0.21819588\n",
      " -1.03846621 -0.61961986 -0.18362618  0.9020498  -0.44925061  1.37080535\n",
      " -0.24985697 -0.07549422 -0.05584704 -0.12749079 -0.33755937  0.557017\n",
      " -0.45159098  0.84277199  0.11513411  0.08069854 -1.03591522  0.22945981\n",
      "  0.77369137 -6.1353894   0.26071057 -0.74559246  0.59961156 -0.1898703\n",
      "  0.30100407  1.76376138 -1.73671195  0.32763644  1.28678384  0.56394032\n",
      "  0.13043458 -1.19662623 -0.59953233  1.25789893  0.2294835   1.58843721\n",
      "  0.54694522 -0.62495289 -0.148287    0.38401685 -0.45391058 -1.90424949\n",
      " -0.59574711  0.88131232 -0.21615293 -0.67398164  1.03212181  0.1702253\n",
      "  1.06898383 -1.14790548 -0.11183227 -1.36384294 -0.80430041 -1.17410897\n",
      "  0.48410829  0.07903952 -0.28071068  0.71388991  0.15128065  2.64472202\n",
      "  1.42449555 -0.21231928  0.22221895 -0.54382951  0.45763559 -0.16473437\n",
      " -1.06357137  0.53285582 -0.36464884  0.07348685  0.19804413 -0.41908042\n",
      " -0.97579917 -0.90833933  0.03410845  0.28079722  0.4337082   2.15280625\n",
      "  0.14586349 -0.14646147 -0.05522947 -0.37829969  0.03479211 -0.56449534\n",
      " -0.29021297  0.37672974 -0.19644059 -0.64876401 -0.30578237 -0.08429489\n",
      "  2.38336917  1.55632033  1.17933336  0.37489873  0.28707576  1.15173254\n",
      " -0.13045698 -0.9225087  -0.08687066  0.71578052 -0.35137397  2.05923958\n",
      "  1.04321288  0.09442133  0.12554564  0.56954692  1.44972231  1.10612421\n",
      "  0.04267351 -0.81050221 -0.80150242 -0.28623988 -0.97720288  0.27465603\n",
      " -0.52236851  0.06728135  0.08734316 -0.12252397  0.87401397  0.70465197\n",
      " -0.37447434  0.04221469  0.49591114 -0.14315965 -0.16963147 -0.26444689\n",
      " -0.23296162  0.02867061  0.086455    0.12559558 -0.0940178  -0.58477666\n",
      " -0.28396302 -0.44660532]\n",
      "------counter :109-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.65916290e-01  2.01907402e-01 -1.35247836e-01 -2.06419456e-01\n",
      "  3.57596217e-01  9.89318583e-01 -7.14287175e-02 -2.73313238e-02\n",
      " -3.94643260e+00  6.79046270e-01  4.12002858e+00 -1.46877608e+00\n",
      " -3.28147516e-01  1.69320371e+00  1.11908645e+00 -1.76217443e-01\n",
      " -2.27262625e+00 -3.29211851e-01 -2.44379476e+00 -2.36385327e+00\n",
      " -3.49879584e-01 -2.02918120e+00  1.39785319e+00  1.89550094e+00\n",
      " -4.81034147e-01 -2.38381034e+00  3.95765187e+00 -1.67218510e+00\n",
      " -7.18806686e-01 -1.48736498e+00  2.16999098e-01 -1.02207393e+01\n",
      " -9.27152325e-01 -1.11557927e+00 -4.05465861e+00 -1.02720018e+00\n",
      "  7.86910335e-01 -5.95000479e-01  4.01456602e-01  1.75455856e+00\n",
      " -4.56654047e-01  4.10806399e-01 -2.57127137e+00  5.32971115e-01\n",
      " -1.21137641e+00  1.08800851e+00  2.96772562e-03 -1.06362603e+00\n",
      "  8.19987735e-01  1.21836581e+00  4.28119304e-01  2.02792842e-01\n",
      "  8.79690234e-01  2.51156982e+00 -1.30368577e+00 -4.23248922e-01\n",
      "  3.02596690e-01 -2.30907299e-02  3.06849367e-01 -6.27587128e-01\n",
      " -5.17406185e-01 -5.78258114e+00  2.26489369e+00 -7.84611371e-01\n",
      "  3.08991111e+00  1.63088503e+00 -2.30949849e+00 -6.65477843e-01\n",
      " -9.08884548e-01 -4.43153062e+00  1.95629535e+00  1.59371186e+00\n",
      " -8.33447111e-01 -3.40002088e+00 -1.88552317e-01 -2.26488061e-01\n",
      " -9.18971987e-01  1.17487811e-02  2.87597196e+00  6.34953890e-01\n",
      " -5.42462240e-01  7.15285798e-01  6.68942501e+00  6.91637829e-01\n",
      "  1.26075483e+00 -3.21787243e+00 -1.76375979e+00 -3.65526645e-01\n",
      "  9.52231155e-01  1.28112696e-01  1.89710191e+00  1.53531444e+00\n",
      " -3.84253576e+00  3.39077612e-01  2.58504253e-01  7.78887348e-01\n",
      " -6.37583630e-01 -9.20757573e-01  2.49186599e+00  3.67184630e+00\n",
      "  5.35881836e+00  1.67637833e+00 -2.23281832e+00  2.96990845e-01\n",
      "  5.28374135e-01  2.12446826e-01 -6.94108075e-01 -3.33373267e+00\n",
      " -1.20431489e-02  1.36504175e+00 -3.12738391e-01 -4.40330656e+00\n",
      "  9.17444949e-01 -4.93134420e-01  3.09571521e+00  1.41656893e-01\n",
      " -3.65912471e-02 -5.75357836e+00  1.20776341e+00 -9.67560580e-01\n",
      "  5.10450147e-02 -1.85854240e+00 -4.02002293e+00  1.05539426e+00\n",
      " -5.37427175e-01  8.66991879e-01  2.34285256e+00 -1.76687576e+00\n",
      "  8.77769226e-01  2.47635649e-01  7.05658221e-01  7.34006000e-02\n",
      " -1.14345127e+00 -1.19261054e+00  1.41895741e+00  1.16828843e+00\n",
      " -4.15791303e-01 -9.45035293e-01 -1.45651056e+00 -2.41807956e+00\n",
      " -1.51342302e-01  2.87447602e-01  4.29941534e-01  1.34044912e+01\n",
      "  5.32619884e-01 -2.07459581e+00  1.88366947e+00 -9.42458093e-01\n",
      "  2.47574504e-01  1.32680672e+00 -5.10623835e-01  4.64357244e-01\n",
      " -8.10930859e-01 -2.72890179e+00 -2.82249161e+00 -1.00428426e-01\n",
      "  9.90437779e+00  2.13555599e+00  4.78394525e-01  2.87900263e-01\n",
      "  2.70900357e-01  5.07884374e+00 -1.03544842e+00 -1.72970444e+00\n",
      "  6.21339760e-01  2.22594348e+00 -1.75705229e+00  5.23427378e-01\n",
      "  8.71272996e-01  5.75028270e-01 -6.09064926e-01  1.07016386e+00\n",
      "  2.99027860e+00  1.32833775e+00  2.80745427e+00 -1.06073905e+00\n",
      " -1.61854683e+00  4.04295369e-02 -1.39797568e+00  3.52808487e-02\n",
      "  2.44931792e-01  1.53278447e+00 -1.07802244e+00  1.33069998e-01\n",
      "  1.02302572e-01  9.73108826e-01 -8.43016048e-01  1.32085413e-01\n",
      "  1.33405295e+00 -1.69897021e+00 -7.44302155e-01 -2.12482385e-01\n",
      "  1.46512788e+00 -1.48648875e-01 -2.23272949e+00  5.67425850e-01\n",
      "  6.27336602e-01 -1.42924578e+00 -2.13612571e+00 -2.14470051e-01]\n",
      "------counter :110-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.62038781  1.55538664  2.01190505 -0.40017815 -1.5061809  -1.65940413\n",
      "  1.45313491 -3.94382539 -1.5467212   0.0153359  -0.70882978 -6.23521599\n",
      " -1.21468644  2.76574241  1.95714126  0.38990419  0.97115267  0.41443427\n",
      "  0.69133526  0.97393549 -0.88698048  1.332282   -0.36724022  6.27486096\n",
      " -0.35598261  1.46468208  1.4319323   2.7346675  -0.04348149 -2.44434543\n",
      "  0.05162845  0.12745755  1.59139733  5.12427046 -0.1322324   1.00826228\n",
      " -0.94586236  0.96758799 -0.16547567  1.89748055  1.32485668 -1.26887037\n",
      " -1.81467283  0.31501137  0.27464098 -0.66186765 -2.32203581  1.29274038\n",
      "  3.28200982  0.02089125 -0.12225517 -3.10332055  0.94671647  0.24319438\n",
      "  1.6625962   1.3398441  -3.99363104  0.45510542  0.95112347  0.41120313\n",
      "  0.78916301  1.61483358 -6.61324052 -0.34959098 -0.29097873 -0.32837434\n",
      "  1.37273484  2.23838719  0.64613238  0.0910227   2.88968872  2.44334383\n",
      "  2.27883722  0.1689242   2.15666941  4.69840142  1.43360224 -0.76812082\n",
      " -1.22055916 -1.2350934   0.7925993  -0.34443483 -2.17884578  0.49109818\n",
      " -0.6094151  -2.93752715 -1.09858027  5.5574989   0.50207286  5.75990101\n",
      " -1.9331045  -0.70587824  4.35887188 -2.38314959 -2.41866305 -0.78087458\n",
      "  0.29574212 -0.60421427 -0.0526029  -0.11793183  2.31262808 -0.75948815\n",
      "  2.04805527  7.23080824 -0.77402434  0.18967953  0.28954204 -1.53539029\n",
      "  2.85760102  0.06345119 -1.85613843  0.2586402  -0.2571751  -0.08274623\n",
      "  0.75182821 -2.39274986  0.99794817 -0.19458162 -0.91044987 -1.53862728\n",
      " -0.6877852   1.22547865  0.85859616 -0.23556999 -3.05394294  0.06674669\n",
      " -1.41008226 -7.65104817  0.67710513 -0.34387406  0.97040529  0.75070132\n",
      " -0.95207994  1.65042321  1.3213706   0.26246129  0.07993489  2.02496581\n",
      "  2.57872013  0.93356871  1.89113798  0.10948138 -2.93494647 -6.88026079\n",
      "  1.20527999  0.58502198 -0.13335229  0.29625044 -0.57155601 -0.85964354\n",
      " -0.63368473  0.44698809 -2.90848201  1.26169301  0.4602551  -0.40024539\n",
      "  1.06489766 -2.0385386   1.20642059  1.95421242 -0.56416313  0.08629625\n",
      "  0.41289143 -0.94228921 -1.61674213 -0.39174268  0.33167121  0.88727095\n",
      " -0.11325229 -1.78371129 -0.08763947  2.96418465 -0.82539774  1.20212929\n",
      " -0.88898086 -0.23168976 -0.38264486 -5.37394185 -4.96666264 -0.42376016\n",
      " -3.26619146 -4.36044236 -0.97226499  0.64803328 -1.43144593 -5.29563192\n",
      "  0.13437274 -3.12755362  1.41997354  0.21401778  4.37845063 -1.09465535\n",
      " -0.52184876 -1.31492637  0.37049584 -1.25576111  0.58030282  0.8003329\n",
      " -0.29637379  1.34294325]\n",
      "------counter :111-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.61773805e-01 -3.56050861e-01 -1.51055415e+00 -3.15237423e-01\n",
      "  2.58989572e-01  1.38196941e+00  3.68931938e+00  3.36327283e-01\n",
      " -1.00555213e+00  1.92978447e-01 -2.72933637e-01  8.71054189e-01\n",
      " -3.24498407e-01  2.58806154e-01  1.11929126e+00 -3.07512748e-01\n",
      " -7.13869461e-01  2.07202647e-01  3.29445418e-01  1.80193604e+00\n",
      " -3.61762946e-01  1.12524132e+00 -3.34619933e-01 -2.42473131e+00\n",
      " -4.96342019e-01  6.02692664e-01 -9.73237504e-02  1.27919115e+00\n",
      " -1.39496449e+00 -1.97687984e+00 -1.50832973e-02 -1.10818277e+00\n",
      "  7.15826840e-01  3.85496410e-01  1.58838007e+00  3.88677418e-01\n",
      "  7.37553672e-02  1.90085616e-01  3.35366294e-01  9.12332590e-01\n",
      " -1.69770065e-01 -4.28802190e-01 -6.87728537e+00  2.06583619e+00\n",
      "  7.12723833e-01 -6.98598048e-01 -4.59701239e-02  1.46530312e+00\n",
      "  1.82493674e+00  1.69426479e-01  5.62352479e-01  2.55989628e-01\n",
      "  3.19849991e-02  4.41156789e-01  4.14591767e-01  1.62776759e-02\n",
      "  1.57418733e+00  1.53519339e+00  9.88713980e-01  4.62901598e-01\n",
      " -8.30390515e-01  1.84561207e-01  2.08986465e+00  4.40572664e-01\n",
      "  1.24337022e+00 -5.05523252e-01  1.60272568e+00  4.76575940e-01\n",
      "  3.30516430e-01 -1.55189672e+00 -1.14611008e+00 -4.26290967e-01\n",
      "  3.75193734e-01  1.01389471e+00 -4.70494120e+00 -2.49122749e+00\n",
      "  4.37643204e-01 -1.67910521e+00 -1.34440926e+00 -1.21184922e+00\n",
      " -1.48026902e+00 -1.02454938e-01 -1.79324454e+00 -1.63121069e-01\n",
      " -2.85161464e-01 -1.91519192e+00 -7.36542467e-01 -5.28774450e-01\n",
      " -1.86707229e+00  2.06649530e+00 -2.31123256e+00  9.39391839e-01\n",
      " -3.74559644e-01 -1.20954839e+00  3.82174609e-02 -6.09799530e-01\n",
      " -3.43449218e-01 -5.47140126e-02 -6.73179101e-03 -9.19109086e-01\n",
      " -1.07969525e-01 -1.10193024e+00 -3.11692876e-01  3.23481261e+00\n",
      " -5.30588275e-01  1.36871669e-01  1.28586374e-01 -2.90385482e-02\n",
      "  4.04282584e+00 -5.97148931e-02 -6.29643284e-01  6.79476366e-01\n",
      " -7.48718394e-02  3.54403094e-01  1.32269848e+00 -1.95118482e-01\n",
      "  7.68210015e-01 -8.61488116e-01 -4.51800736e-01  1.50010377e+00\n",
      "  5.50564086e-01  1.06360921e-01  7.50139224e-01 -1.66373579e-01\n",
      "  1.12712697e+00  2.78775439e+00 -2.23886027e-01  3.89796120e-01\n",
      "  4.29510340e-01 -6.49382242e-01 -1.29450084e-01 -3.55297551e-01\n",
      "  1.91303962e+00  7.13278553e-01  1.28511911e+00 -3.38564019e-01\n",
      "  1.48708041e+00  2.25798136e+00  1.73815683e+00 -7.54163303e-01\n",
      "  1.36809688e-01  5.67672220e-01  1.40557661e+00 -3.63714252e+00\n",
      " -2.84356579e-01 -4.51730384e-02  2.01499509e-01 -7.45466770e-01\n",
      " -7.15219608e-02 -3.22023421e-01 -1.17166468e+00 -9.03417164e-03\n",
      " -8.26989491e-01 -8.20156363e-01 -4.61611208e-01 -4.56536490e-01\n",
      "  9.79144673e-02  3.77303136e-01  8.24662770e-01  9.78565109e-01\n",
      "  1.60877878e-01 -3.24974427e-01 -1.06282472e+00 -1.91408136e-01\n",
      "  1.59556624e-01  2.61190292e-01  1.21366202e-01 -1.15850160e+00\n",
      " -5.37978696e-01  2.12676509e-01 -6.81301675e-02 -7.02344616e-01\n",
      " -6.66445802e-02  4.77300678e-01 -1.04243838e+00 -4.55709166e-01\n",
      "  1.93726858e-01 -4.31296784e-01 -5.34649902e-01 -6.86053749e-01\n",
      " -2.86161163e+00 -1.95147625e-01 -1.10638825e+00  2.14221878e-01\n",
      "  6.51881719e-01  5.17146969e+00 -1.67108820e-02 -6.11752219e-01\n",
      " -9.67614843e-02 -1.47515605e-01  1.34754423e+00 -9.63879976e-02\n",
      " -5.86664702e-01 -6.83596019e-01 -5.21270641e-01 -3.86113841e-01\n",
      " -3.43496269e-03  8.61955389e-01 -7.81786079e-01 -2.60865938e-01]\n",
      "------counter :112-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30002446 -1.28402343 -0.92539674 -0.17453877  0.23159865  1.14361072\n",
      " -0.2746263   0.06655909 -0.41192511  0.40444513 -0.18148183 -0.2524361\n",
      "  0.45785419 -0.18209731 -0.08388992  0.01840631 -0.6389785   0.15012\n",
      "  0.40584354  3.34795828 -1.20497354  0.59634076 -0.24714769 -1.46408356\n",
      "  0.0941443   0.78193121  0.16300639  0.49084028 -0.127472   -1.86730874\n",
      "  0.29084132 -1.54198537  0.59390994  0.10105618  1.00320909  0.01344349\n",
      "  0.09177805  0.98118773  0.01078177  0.61222292 -0.08874328 -0.73800265\n",
      " -2.01275381 -0.33192413  0.13303277 -0.67999659 -1.52070342  0.39124687\n",
      "  0.58673125  0.12389416 -0.03055539  2.01334034 -0.2974141   0.57767774\n",
      "  0.13844094 -0.1056087   0.42776372 -0.33310424 -0.66674398  0.77197725\n",
      " -0.55808536 -0.42890124  2.45584678  0.09679762  3.53795826 -0.42628712\n",
      "  0.86778497  0.8134949   0.1879229  -1.53525906  3.94432112 -0.30016072\n",
      "  0.20408066  0.70570023  5.07496862  0.01709625  0.43638262 -0.43840621\n",
      " -0.80364881 -0.94809908  0.20125101 -0.42750574 -2.11530832 -0.26418903\n",
      " -0.578837   -3.89857336 -2.47337508 -0.66530558 -0.47266218 -1.14223423\n",
      "  0.34622728  0.76663072 -0.44735853 -0.25115468  0.83805366 -0.61358264\n",
      "  0.12193361  0.36350088  0.59195337 -0.11080223  0.67219689 -0.48540784\n",
      "  2.46171968  2.4836081  -0.14389808  0.01601576 -0.35821274 -0.38360684\n",
      "  0.03031319 -0.05324293 -0.17687464 -0.66822886  0.27088359 -1.18366035\n",
      "  0.33325948 -0.10527111  0.30165947 -0.73126638 -3.2944467  -1.29206737\n",
      "  0.6729322   0.26012252  0.51370177 -0.18785141  1.63946508  3.37854447\n",
      " -0.09134532  1.16435936  0.50253907  0.56117201  0.14639394  0.59547422\n",
      "  0.86080627  0.01478894  1.2520717  -0.03757629  1.04526769  0.85963504\n",
      " -0.52614973  0.04444797  0.06260615  0.12075707  1.10540897 -2.55122298\n",
      "  0.08416628 -0.18021456  0.12338552 -1.33657106  0.56213037 -0.68105197\n",
      " -0.88240172  0.20772222 -0.11645811 -0.62488403 -0.09401555 -2.63851553\n",
      "  0.47259822 -0.97683625  0.03142666  1.36533962 -0.00990408 -0.38254079\n",
      "  0.84071915 -0.08801689 -0.42177713  0.35386562  0.23477091 -0.04806228\n",
      " -0.12767681 -0.60395543  0.24927331  0.91532045 -0.74506016 -0.38734772\n",
      " -1.32924191 -0.57420265  0.16445717  0.41555437  0.15134145 -0.78917671\n",
      " -2.42080492 -0.24137313 -0.61033211 -0.0490371  -0.90653232  0.64833559\n",
      " -0.19850467 -0.38269262  1.1879618  -0.21298591 -0.25844372 -0.39829186\n",
      " -0.42167432 -0.43561949  0.0191458   0.49477706  0.40395018  0.24978364\n",
      " -0.62712883  0.00606196]\n",
      "------counter :113-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.05060236e-02 -1.18402715e+00 -1.32527162e+00 -4.14700762e-01\n",
      " -9.74949484e-02  1.27356419e+00 -9.58461131e-02  6.33149244e-01\n",
      "  1.84576919e-01  1.98119176e-01 -1.40090654e-01  3.48182193e-01\n",
      "  4.39988548e-01 -1.61391981e-01 -2.26644624e+00  2.55948772e-01\n",
      " -5.60810195e-02  9.20412109e-01  4.61042291e-01  3.11159309e+00\n",
      " -2.19486237e+00  4.38536209e-01  1.06587363e-01  7.27537468e-01\n",
      "  4.48154071e-02  3.48808271e-01 -1.66765054e-01  7.97272780e-01\n",
      " -4.22380622e-02  7.95442211e-01  5.06572285e-01 -1.50681390e+00\n",
      "  5.38754322e-01  2.30105076e-01  6.28054804e-02  3.03103706e-01\n",
      "  3.75556759e-02  5.85747829e-01  5.91583372e-01  2.70100222e-01\n",
      " -4.29028508e-01 -6.83485226e-01 -1.30132604e+00 -5.72864980e-01\n",
      "  2.64054185e-04 -6.21579644e-01  1.97900546e+00  5.34022166e-01\n",
      " -2.90951458e+00  1.85339455e-03  8.26147951e-01  9.99429933e-01\n",
      " -1.75704330e-01  7.81599159e-01  1.58377589e-01  3.98856721e-01\n",
      "  9.82654213e-01 -1.80440768e+00 -1.39994944e+00  9.11364093e-01\n",
      " -5.22997837e-01 -1.29584633e+00 -2.10465810e-01  2.04248824e-01\n",
      "  3.54720324e+00 -4.25676992e-01 -1.06490006e+00  1.03736068e+00\n",
      "  6.75011826e-01 -2.28461155e+00  2.98543084e+00 -1.43159753e+00\n",
      "  2.46148878e-01  7.24815440e-01  1.61547080e+00 -7.73155034e-01\n",
      "  4.35886175e-01  1.05287134e+00 -8.17630621e-01 -1.09369003e+00\n",
      " -7.49463458e-01 -2.53269293e-01 -1.34328686e+00 -2.61538427e-01\n",
      " -9.81660429e-01 -3.77498279e+00 -8.37003064e-01  1.47310502e+00\n",
      " -7.45085624e-01  5.18623265e-02  3.30524174e-01  5.68832324e-01\n",
      " -6.48237014e-01 -1.16829372e-01 -9.05277784e-01 -4.97410573e-01\n",
      " -5.60455313e-02 -3.42581488e-01  5.41743660e-01  1.44772435e-01\n",
      "  1.55250295e-01 -9.63086072e-01 -2.00504767e+00  1.81404495e+00\n",
      " -4.51797415e-02 -9.22602119e-02  2.95366723e-01  1.99354716e-01\n",
      "  2.03762509e+00 -4.45496472e-02  2.52915645e-01 -8.08697732e-01\n",
      "  1.47327649e-01 -6.01569945e-01  4.79055805e-01  3.47186971e-01\n",
      " -8.70922628e-01 -7.36271461e-01  1.85237363e+00 -8.49052735e-01\n",
      "  4.68729679e-01  8.82895991e-02  4.71592373e-01  2.99508076e-02\n",
      "  1.45546419e+00  2.53619552e+00  7.46840321e-02 -5.39617922e-01\n",
      "  4.90517322e-01 -3.18942852e-01  3.97462794e-02  5.56656403e-01\n",
      "  2.42956283e-01  3.92088212e-01  5.13665538e-01  3.13284457e-01\n",
      " -4.27226410e-01  5.14872763e-01  7.24733084e-01 -4.02521228e-01\n",
      "  2.40409926e-01  4.54946254e-01  1.05438432e+00 -2.17247768e+00\n",
      "  2.44655238e-02  1.69931298e-02  1.30936779e-01 -8.15580194e-01\n",
      "  7.92600925e-01  2.40743851e-01 -1.86942658e-01 -1.11096491e-01\n",
      " -9.65486542e-01 -5.77543475e-01 -3.16229347e-03 -1.37119641e+00\n",
      " -1.78974508e-01 -1.26730314e+00 -1.55220534e-02  5.92066925e-01\n",
      "  2.88695196e-01 -6.89785261e-02 -8.40010866e-01  1.07860355e-01\n",
      " -1.36912349e+00  2.90817055e-01  2.95640463e-02  4.74226838e-01\n",
      " -1.53375084e-01 -1.09158664e+00  1.35286932e-01  7.48508467e-01\n",
      " -2.87074184e-01  6.35660746e-01 -1.24689083e+00 -6.62894486e-01\n",
      "  2.92254772e-01  6.04509403e-01 -3.71670982e-01 -6.17838276e-01\n",
      " -8.81046210e-01  6.75092717e-01 -7.20636574e-01  4.38084402e-01\n",
      " -6.30674005e-01  1.90226670e+00 -1.26553892e-01 -5.56246970e-01\n",
      "  1.05255900e+00  9.16162859e-02  6.28611837e-01  3.06754805e-01\n",
      " -1.72809930e-02 -9.13781971e-02  1.86909823e-01  6.65078140e-01\n",
      "  4.28413582e-01 -9.02533376e-02 -4.97930069e-01  3.20301476e-01]\n",
      "------counter :114-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03987683 -0.89424883 -1.0703077  -0.22773864  0.25293452  1.35317305\n",
      "  1.22683398  0.48027874 -0.25435763  0.97457958 -0.02588229  0.38766638\n",
      "  0.0473794   0.0716389  -1.00512032  0.51427206  2.0009341   0.36064721\n",
      "  0.34038655  3.51827709 -1.59366298  0.69492158  0.18602378  0.59025907\n",
      "  0.00928568 -0.04178817 -0.73707467  0.63208529 -0.18755679  0.88199556\n",
      "  0.30947022 -1.4286653   0.85840951  0.45880129  0.04128584 -0.04077274\n",
      " -0.37220871 -0.02927888  0.3262008   0.52568065  0.33162125 -1.02615572\n",
      " -2.05930883 -0.08506534 -0.04753995 -0.3841243   0.45700237 -0.85319268\n",
      "  0.93234658  0.1795716   0.23632196  1.73172503 -0.03411867  0.52417392\n",
      "  0.47566513  0.6288596   0.33875099 -0.44238736  0.57998658  0.87480735\n",
      " -0.63614041 -1.23947736  0.02808804  0.10673549  3.54416699 -0.34394104\n",
      " -0.0315141   0.25890629  0.40891162 -2.27499883  0.5362748  -0.76757749\n",
      "  0.0428724   0.74160954  1.71883265 -0.43318635  0.29654231  0.24935383\n",
      " -0.39991103 -0.8812515  -0.91649371  0.50465434 -1.30666898  0.24454018\n",
      " -1.04668416 -2.35672897  0.20843234 -1.36718983 -1.09092408  0.36899402\n",
      "  0.74141805 -0.07490208 -4.60690436 -0.17512009 -1.10236898 -0.66456631\n",
      " -0.09601929 -0.26209758  0.41395213  0.04014071 -0.20073433 -0.44944266\n",
      " -0.19802537 -0.06247954  0.04524015 -0.03793391  0.57589292 -1.59877136\n",
      "  2.38308836 -0.08071052 -0.32576088 -0.06940745  0.388325   -0.60817792\n",
      "  0.14030362  0.4630579  -0.41412806 -0.69941342  0.21635866  0.15591411\n",
      " -0.03072958  0.49425703 -0.29142533 -0.05617236 -1.04790495 -4.29468394\n",
      " -0.65313954  1.75587359  1.20450173  0.22643715  0.17633322  0.76911869\n",
      "  0.61265473 -0.10476089  0.43105096  0.49898833  0.03987446  0.78723669\n",
      "  0.61754981  0.08112012  0.04501052 -0.22764446  0.52292328 -2.27656575\n",
      "  0.19795297  0.72535925 -0.31101003 -0.9052744   0.96049099 -0.288793\n",
      " -0.1277706   0.09852135  0.66405277 -0.56163667  0.43393646 -2.13129388\n",
      "  0.10246887 -0.61594596  0.21471203  0.67846749  0.13010447  0.21270414\n",
      "  0.35272437 -0.57235197 -0.34522788  0.41190191  0.14882135  0.45296047\n",
      " -0.1432019   0.37355499 -0.05136418  1.48116397 -0.30205847  2.33304048\n",
      " -0.38099328 -0.52118802  0.41922808 -1.68632678  0.2467218  -0.90984894\n",
      " -1.07254164 -1.75980189 -0.53150006  0.29543042  0.50178722  1.25595873\n",
      "  0.20548416 -0.66168871  1.21564993 -0.31674684  0.17285695  0.08604934\n",
      "  0.38417    -0.12726869  0.37325055  0.31058008  0.31616527  0.14234909\n",
      " -0.25070356 -0.06076049]\n",
      "------counter :115-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16640386 -1.11459971 -1.19788757 -0.30504462 -0.03618813  0.8016458\n",
      "  0.77745474 -0.65801457  0.04235301  0.6615049  -0.13027867 -0.64487376\n",
      "  0.19096654 -0.2654276  -0.90399446  0.09836894  2.06525835  0.62824178\n",
      "  0.19886013  3.60815442 -1.32181422  0.78914777  0.04541317  0.81205732\n",
      "  0.20184589 -0.7011132  -1.07176978  0.51060033  0.52233606  0.973157\n",
      "  0.28484106  1.71702542  0.74045771 -0.18415466 -0.56403875  0.03995547\n",
      " -0.21895403  0.33138793  0.45450722  0.78061014  0.02601335 -1.38170302\n",
      " -1.45299639  0.15346964  0.20628133 -0.66284805  0.82524593 -0.65159442\n",
      "  0.88833754 -0.10648031  0.17217028  1.05799344 -0.25135806  0.11350708\n",
      " -1.65392019  0.16159418  1.33301467 -0.92599943 -0.28972179  0.78397038\n",
      "  0.46526538 -1.0098814  -1.21274891  0.13178163  2.73932264 -0.32567104\n",
      "  1.10842588  0.05230489  0.46166137 -2.18775835 -0.72729832 -1.258361\n",
      "  0.12268355  0.52051693  0.82189273  0.05676121  0.13662792  0.30391975\n",
      " -0.13269474 -1.60189501 -0.40341807  0.24757638 -1.38845813 -0.07479438\n",
      " -1.1970866  -3.24597059  0.50712119 -0.58092649  0.09467856  0.19739178\n",
      "  0.51822568  0.61175304 -4.44282737 -0.92840228 -1.00534151 -0.3125294\n",
      "  0.00501681  0.15607847  0.38842727 -0.78759065  0.23906019 -0.56909202\n",
      "  0.53480779 -0.83350699 -0.0389069  -0.17463737  0.29993355  3.19207789\n",
      " -4.43089952  0.02649345 -0.13896292 -0.53411795  0.26901913 -0.47664638\n",
      " -0.28188166 -0.79452363  0.22587305 -0.81180625  1.18851949  0.03861511\n",
      " -0.06384749  0.40271841 -0.15347813  0.06473897  1.11875101 -1.21905609\n",
      " -0.16744085  1.82725785  0.69074791 -0.40139151  0.09692527  1.30355141\n",
      "  0.50917773 -0.00652268  0.49689946  0.56508048  0.19634516  0.38879253\n",
      "  0.37631944  0.0520098   0.19499177  0.60209117 -1.03243485  0.86432703\n",
      "  0.31439446  0.28385676 -0.32106096 -0.80944702  0.71248761 -0.41134766\n",
      " -0.40601331 -0.31281968  1.19830605 -0.51158733  0.42364695 -0.38211699\n",
      " -0.81851384 -0.13023784 -0.54441713  1.16810702 -0.05025159 -0.52823033\n",
      "  0.4564678  -0.63799506 -0.319639    0.3076219   0.18917546  0.60090855\n",
      " -0.18048363  1.04430474 -0.22631716  0.72697524 -0.32093815  3.05595937\n",
      "  0.07485928 -0.67393832  0.26072163  2.29717733  0.17247895 -0.80679884\n",
      "  1.67612274 -1.29302552 -0.61968671  0.07453804  0.24613716 -1.2318881\n",
      " -0.15520858 -0.732705    0.8750265  -0.08606109  0.01876866  0.05315\n",
      "  0.14476336 -0.48999784  0.11891338  0.47077984  0.25278607  0.12201596\n",
      " -0.70860495 -0.22743944]\n",
      "------counter :116-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.65915295e-01 -5.94609231e-01 -1.85703252e+00 -2.26277918e-01\n",
      "  3.30718936e-01  8.22261922e-01  9.03336118e-01 -1.45061192e+00\n",
      " -4.07974215e-01  7.58726020e-01  2.73059258e-03 -4.91712785e-01\n",
      "  2.92692085e-02 -5.69172715e-01 -8.74832203e-01  6.95624592e-02\n",
      "  2.11291572e+00  1.17196178e-01 -1.09616167e-01  2.52911817e+00\n",
      " -1.13375650e+00  4.14436244e-01 -6.37057554e-02  3.68285635e-01\n",
      "  1.68000251e-01 -3.38836823e-02 -1.01118972e+00  1.45976886e+00\n",
      "  1.89224823e-01 -1.82094809e-01 -7.54032837e-02  1.12761926e+00\n",
      "  6.48727399e-01 -1.89213349e+00 -9.25834689e-01  2.68073507e-02\n",
      " -4.79215302e-01  2.39436960e-01  6.04088155e-01  7.08973270e-01\n",
      " -8.49693698e-02 -6.76258898e-01  2.79191900e+00  8.09650946e-01\n",
      "  1.14810000e+00 -8.00681707e-01  3.64142293e-01 -7.63808840e-01\n",
      " -7.63707125e-01 -7.68750825e-02 -8.70100974e-01  1.28226854e+00\n",
      " -5.06614157e-01  6.83762428e-01  8.74565947e-01  1.41928074e-01\n",
      "  5.48255526e-01  7.91105363e-01  4.48487671e-01  7.34834766e-01\n",
      "  5.29822575e-01 -5.12710264e-01  1.86569200e+00  3.57654109e-03\n",
      "  6.09469119e-01 -8.33336168e-01  1.05596695e+00  8.04385117e-01\n",
      "  4.58594250e-01 -2.32699049e+00 -9.90723225e-01 -1.55800074e+00\n",
      "  1.61943799e-01  5.68016717e-01  1.60779558e+00  3.76843228e-01\n",
      "  5.74675220e-02  5.02344089e-01 -5.69221055e-01 -1.15693225e+00\n",
      "  4.52988069e-01  2.61716681e-01 -1.40227697e+00 -6.31328406e-01\n",
      " -5.11006941e-01 -2.92222779e+00  3.24160398e-01  1.90342089e+00\n",
      " -1.18619083e+00  1.59282195e-01 -1.50421304e-01 -8.25786492e-01\n",
      "  1.76104466e+00 -8.50030981e-01 -1.31566430e+00 -4.98219433e-01\n",
      " -1.23683230e-01  1.91083316e-01 -3.65966157e-03 -4.60119371e-01\n",
      "  8.17762390e-03 -5.35902995e+00 -1.89511419e+00 -1.48731914e+00\n",
      " -2.46099179e-01 -2.77817164e-01  5.70647842e-01  5.19457302e-01\n",
      "  3.47607589e+00 -1.35493921e-01 -3.17553342e-01 -5.77042573e-01\n",
      " -4.38203484e-02  1.58653387e+00 -8.81077910e-01 -9.43726622e-01\n",
      "  6.20781852e-01 -5.08939435e-01 -9.13244811e-01  9.18589894e-02\n",
      " -2.20271210e-01  1.78625713e-01 -3.74561557e-01 -1.04844820e-02\n",
      "  1.27542034e-01  1.88094810e+00 -4.97343044e-01  7.55929754e-01\n",
      "  3.15401472e-01 -4.12164371e-01 -1.84279533e-01  1.15952068e+00\n",
      "  8.91854668e-01 -1.74174617e-02  1.67096852e-01  3.19108097e-01\n",
      " -2.08731134e-01  3.70182944e-01 -1.45237626e+00 -1.10836472e+00\n",
      " -1.12006699e-01  1.07203344e-01 -8.30364147e-01  1.85674084e-01\n",
      "  3.10212729e-01  3.90396461e-01  2.03709701e-01  1.93451766e-01\n",
      "  5.00014324e-01 -3.29893577e-02 -4.75080936e-01 -2.57631453e-01\n",
      "  1.37904943e+00 -5.47512171e-01 -5.52378224e-01  6.75148293e-02\n",
      " -5.42096484e-01  8.16678895e-02 -1.07041000e+00  8.41278056e-01\n",
      "  2.10880700e-02 -5.99628373e-01  4.25914871e-01 -6.08148254e-01\n",
      "  5.32476930e-01  2.53645248e-01 -5.73921059e-02  6.30783960e-01\n",
      " -2.60707678e-01 -1.14661641e+00  1.94302334e-01  8.45318013e-01\n",
      " -8.19267112e-01  2.45380413e+00 -1.30269074e-01 -6.81344889e-01\n",
      "  8.27940255e-02  3.93439656e+00  2.83097041e-01 -4.36486689e-01\n",
      "  7.74066029e-01 -1.53696308e+00 -8.54055028e-01 -1.92657133e-01\n",
      " -7.67546350e-01  1.71086248e+00  1.05887764e-01 -9.16983469e-01\n",
      "  5.24093396e-01 -3.35176531e-01 -2.30607322e-01 -1.27400413e-01\n",
      "  5.88182173e-02 -5.37260834e-01  1.26286613e-01  2.50088269e-01\n",
      "  1.31080718e-01  1.22553913e+00 -7.79690217e-01 -3.42636827e-01]\n",
      "------counter :117-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.62683830e-01 -3.36880051e-01  1.91286397e+00  1.64724234e-01\n",
      " -1.17414105e-01  1.59430237e+00  1.31717285e+00 -1.53093191e+00\n",
      " -6.35586078e-02  5.84466122e-01 -3.93687042e-01 -8.75490004e-01\n",
      "  4.71871343e-01 -2.07008716e-01 -6.72145862e-01  8.73321119e-01\n",
      " -3.02295637e-01 -8.58665133e-02  8.72636251e-02  5.22911546e+00\n",
      " -6.63039668e-01  3.78304864e-01  1.31475134e-02  3.37684352e-01\n",
      " -1.30751776e-01  9.86068697e-01  2.18029580e-01  3.09141242e-02\n",
      "  3.57832890e-01 -5.66074464e-01 -3.61048160e-02  1.06470865e+00\n",
      "  3.38700535e-01 -1.37209183e+00 -7.74900769e-01 -2.60335043e-01\n",
      " -1.92867754e-01  4.14009805e-01  4.45287532e-01  8.44156261e-01\n",
      " -2.18397374e-01 -9.22466669e-01 -4.09924496e-01  1.17666554e+00\n",
      " -6.84812762e-01 -2.59189204e-01  8.13293792e-01 -2.31045122e-01\n",
      "  1.41601795e+00 -1.39969097e-01 -3.18372060e-01  9.37781040e-01\n",
      "  2.03518924e-01  6.59831921e-01  2.33892340e-01  1.03143620e-02\n",
      " -2.89537785e-01  7.10085837e-01 -1.80714981e+00  7.75851387e-01\n",
      "  2.77926911e-01 -4.50899856e-01 -9.81598947e-01  2.48733572e-01\n",
      "  1.48874171e+00 -5.25781215e-01 -2.98827409e-01 -9.00637544e-01\n",
      "  6.77990847e-02 -2.01526237e+00 -8.59793726e-01 -1.02803280e+00\n",
      "  6.06404178e-02 -3.50273605e-01  5.27873564e-01  1.24631687e+00\n",
      " -6.83101236e-01  1.23382637e-01 -7.75254634e-01 -1.03136408e+00\n",
      "  5.05959791e-01 -6.20085515e-02 -1.75637383e+00 -1.78779212e-01\n",
      " -8.12366007e-01 -9.01229910e-01 -5.24868385e-01  2.34261425e-01\n",
      " -5.72987129e-01  9.79005603e-01  2.93393175e-01  2.21334467e-01\n",
      "  5.79009818e-01 -8.11823158e-01 -2.12714354e+00 -5.76097576e-02\n",
      " -2.66995267e-01  2.18257951e-01 -1.16183926e+00 -4.22582946e-01\n",
      " -7.17559570e-01 -1.11718155e+00 -1.08193639e+00  6.35653194e-01\n",
      " -4.28119397e-01 -1.64691790e-01 -4.46319756e-01  1.64620958e+00\n",
      "  3.56198220e+00 -8.80839700e-02 -1.28061605e-01 -9.65713897e-01\n",
      "  1.86543056e-01  8.37424696e-01 -7.39982706e-01 -1.26978350e+00\n",
      "  4.83832097e-04 -5.80212352e-01  5.10553128e-01  3.55918354e-01\n",
      " -7.38301943e-03  4.51589936e-01  1.83951391e-04  2.27453209e-01\n",
      "  3.16245034e-01  1.14798018e+00 -9.61007909e-03  6.97659246e-01\n",
      " -1.04650059e-02 -4.67112365e-01 -3.68654004e-01  9.76944034e-01\n",
      "  4.03162292e-01 -2.14122783e-01  7.90142075e-01  4.28396898e-01\n",
      " -1.16194571e+00  9.18461363e-02 -1.22336449e+00  1.41797481e+00\n",
      "  1.41524009e-01 -8.92476960e-02 -1.79834442e+00  8.18049050e-02\n",
      "  1.75627684e-01  1.69776140e-01 -4.79682620e-02 -4.28915320e-01\n",
      "  1.14564873e-01 -1.04911430e-01 -1.39023522e-01 -2.75742891e-01\n",
      " -1.18881559e+00 -6.62472731e-01 -2.36913707e-01  9.22274515e-01\n",
      " -5.82542532e-01 -4.26662281e-01 -1.02605429e+00  7.00886159e-01\n",
      " -1.46888222e-01 -8.55775216e-01  8.67012730e-01 -6.31523791e-01\n",
      "  2.12320315e-01  2.33142293e-01  1.38054944e-01  5.99986121e-01\n",
      "  1.08191624e-01 -2.01869059e+00  1.11480812e-01  1.11856982e+00\n",
      "  5.21991035e-01  2.03443873e+00 -5.04070092e-01 -5.12282378e-01\n",
      "  4.63458231e-02  3.82151096e+00  3.89496516e-02 -3.15174201e-01\n",
      "  1.29972794e+00 -2.80804081e-01 -6.24133255e-01  2.39508779e-01\n",
      "  1.86265904e-01 -9.41647499e-01  7.58643915e-02 -5.25954320e-01\n",
      "  6.42833915e-01 -4.37966591e-03 -7.44197662e-01  3.79604568e-01\n",
      "  1.10013430e-01 -3.17711101e-01 -1.78282909e-01  6.33862455e-02\n",
      "  7.61439899e-03  4.48168417e-02 -5.63165281e-01 -4.21245352e-01]\n",
      "------counter :118-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.91541150e-01 -5.91941582e-01  3.72755803e-01  6.50399455e-02\n",
      "  1.32933167e-01  1.41944920e+00  1.15168589e+00 -1.12880541e+00\n",
      " -1.18329495e+00  2.79323503e-01 -9.44340209e-02  4.82850291e-01\n",
      "  3.06905478e-01 -4.83942986e-01 -8.83892968e-01  8.78774165e-01\n",
      "  2.89810183e+00 -5.71632303e-01  2.57985139e-01  9.65163810e-02\n",
      " -1.03932311e+00  5.56753735e-01 -7.74643890e-02  6.73708596e-01\n",
      " -5.84805923e-02 -1.00499431e-01  5.86854910e-01  5.17632547e-01\n",
      " -2.96590803e-01 -1.21803655e+00  2.44452281e-03 -4.00397204e+00\n",
      "  7.10878263e-01  1.12610124e+00 -7.57243794e-01 -1.72730406e-01\n",
      " -3.98119770e-01  3.29920872e-01  4.51708419e-01  7.63208252e-01\n",
      " -2.18895355e-01 -6.33762106e-01  3.77266605e+00  9.77956241e-01\n",
      "  4.92412207e-01 -2.24151585e-01  3.45553813e-01 -7.27173729e-01\n",
      "  7.23084994e-01  8.58671505e-02  4.17264306e-01  2.36631427e-01\n",
      "  1.76956795e+00  5.81604127e-01 -9.12139720e-01  1.07276523e-01\n",
      "  8.48604003e-01  1.78003297e+00  5.46766872e-01  8.58600100e-01\n",
      " -6.49486564e-01 -4.12259972e-01 -1.59027214e+00  1.79167599e-01\n",
      "  1.73554000e+00 -3.69008937e-01  4.18848124e-01  6.74543041e-01\n",
      "  4.19914452e-01 -1.78574337e+00  6.22268586e-01 -5.56213397e-01\n",
      "  5.56166099e-01 -1.39694642e-01  4.31739652e-01  1.15221896e+00\n",
      " -1.38085117e-01 -3.58459208e-01 -6.01660920e-01 -5.57481044e-01\n",
      "  3.19619588e-01 -1.09057449e-01 -1.17728638e+00 -8.02343920e-02\n",
      " -1.03791509e+00 -2.45166049e+00 -5.67696545e-01 -5.14057686e-01\n",
      " -8.47639300e-01  6.44176563e-01  3.50570934e-01  1.78841765e-01\n",
      "  8.79584517e-01 -4.97304218e-01 -2.14555265e+00  9.00212910e-02\n",
      " -2.37133849e-01  1.04630319e-01 -2.10096319e-01  5.32300465e-01\n",
      " -6.51334179e-01 -1.08929903e+00 -1.58853280e+00 -1.45973221e+00\n",
      " -2.75962476e-01 -5.63917059e-02  3.39756146e-01  1.47359229e+00\n",
      " -2.51146756e+00  8.31873322e-02 -4.22339164e-02 -7.18322297e-01\n",
      "  4.48333271e-01  8.77492015e-01 -5.35144348e-01 -7.76960538e-01\n",
      "  2.70060665e-01 -5.72495297e-01  1.39610361e+00 -4.20386770e-01\n",
      "  2.79486947e-01  1.11628775e+00  4.84008299e-01  2.10165242e-01\n",
      "  1.55854543e-01  1.43840058e+00 -2.23418569e-02  1.23243308e-01\n",
      "  3.81588794e-01 -2.65160730e+00 -2.66223224e-01  7.33995618e-01\n",
      "  4.91823245e-02 -5.16176490e-01  7.47295285e-01  4.60906268e-01\n",
      " -6.97033590e-01  6.41220907e-01 -2.53875942e-01  6.01368977e-01\n",
      "  7.77921140e-02  1.71364540e-01 -9.66734896e-01  2.37202698e-01\n",
      " -9.59095154e-02 -5.61324198e-02 -1.07850007e-01  6.19711359e-02\n",
      "  1.79475428e-01 -3.08670356e-01 -5.95537978e-01  1.83172646e-01\n",
      "  9.15456862e-01 -6.26760916e-01  2.43998325e-01 -4.25343119e-01\n",
      "  1.58520929e+00  1.82653758e-01 -3.39755470e+00  1.17083957e+00\n",
      "  2.44611053e-01 -3.66270051e-01  1.23895242e-02  3.40885222e-01\n",
      " -5.33898362e-01  1.60942082e-01  4.54079540e-02 -9.20596492e-02\n",
      "  2.28296573e-01 -1.60155670e+00 -8.54002848e-02  5.32736749e-01\n",
      " -3.04642490e-01  2.51779830e+00 -8.29024947e-01 -2.52580779e-01\n",
      " -1.23458133e-02  4.44043910e+00 -4.62808998e-03 -5.70158760e-01\n",
      " -7.08679835e-01 -1.05108085e+00 -4.92228293e-02  1.60775751e-01\n",
      "  6.80069871e-01 -1.76734614e+00  2.75416790e-01 -6.82186300e-01\n",
      "  7.36237266e-01 -1.53117227e-02  7.19346030e-01 -2.09526591e-01\n",
      " -2.87381035e-01 -5.53074253e-02 -3.52078317e-01  1.59020915e-01\n",
      " -5.05541613e-01  1.56860757e-01 -3.75919499e-01 -1.27241361e-01]\n",
      "------counter :119-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.36954650e-02 -4.31679500e-01  2.13033660e+00 -1.00670016e-01\n",
      "  4.63863623e-01  1.09109851e+00  1.39248014e+00  1.11186271e+00\n",
      " -1.28768889e+00  2.94256819e-01 -1.37734643e-01 -2.71975092e-01\n",
      "  2.40928375e-01  3.55956681e-01 -1.86948394e-01  5.39195492e-01\n",
      "  2.79029632e+00 -2.73177296e-01  6.51443994e-01  2.78006602e+00\n",
      " -3.26532295e-01  5.60456868e-01 -7.43445439e-03  8.66462266e-02\n",
      " -2.05781856e-01  4.02265208e-01  5.62083426e-01  3.76378991e-01\n",
      " -6.74061164e-01 -7.12491464e-01 -5.84534334e-02  1.48967520e+00\n",
      "  4.49934539e-01  1.83291986e+00 -1.43304395e+00 -3.08205512e-01\n",
      "  1.52328364e-01  2.65267315e-01  5.13828278e-01  6.94064418e-01\n",
      " -1.48786042e+00 -4.78815045e-01  2.54661105e+00  8.70546782e-01\n",
      "  2.29776697e-01 -2.20073901e-01 -3.05726242e-03 -4.62862728e-01\n",
      " -2.71689967e+00  1.86789631e-01  6.35287773e-01  2.81003146e-02\n",
      "  9.98061504e-02  7.28013046e-01  8.66727120e-01  2.17991481e-01\n",
      "  2.49845114e-01  1.09108163e+00 -5.71033577e-01  8.85719835e-01\n",
      " -8.85009783e-02 -1.29789273e+00 -1.26357142e+00  5.56643484e-02\n",
      "  7.57297179e-01  2.78145419e-02  7.13914805e-01  2.89332214e-01\n",
      "  1.50154116e-01 -1.78847550e+00 -3.21826711e-02 -3.58036629e-01\n",
      "  5.66825912e-01  1.72560725e-01  2.19562702e-01  1.45186837e-01\n",
      "  3.36787862e-01  1.98754794e-01 -4.95577709e-01 -3.26710812e-01\n",
      "  4.09246874e-01 -7.25250557e-01  6.34632572e-01 -6.02096578e-02\n",
      " -7.78223343e-01 -2.07166436e+00 -8.08483439e-01 -7.38997808e-01\n",
      " -5.58667096e-01 -6.06239092e-01  3.80929582e-01 -1.04478483e+00\n",
      " -1.00282344e+00 -4.11909056e-01 -3.11098003e+00  5.30432443e-02\n",
      "  2.08749986e-01  8.30870669e-01  7.50319625e-02 -2.04669309e-01\n",
      " -3.82714663e-01 -1.22361922e+00 -9.17185632e-01  1.01402532e+00\n",
      " -3.23739812e-01  2.28101810e-01  1.56957972e-01 -1.63448977e+00\n",
      "  1.79067005e+00  1.21446910e-01 -1.79060409e-01 -5.03265161e-01\n",
      "  5.36134098e-01  3.55577864e-01  6.44235935e-01  1.48552256e+00\n",
      " -1.07756196e+00 -1.90050219e-01 -2.47002078e+00 -1.97236740e-01\n",
      "  3.64155691e-01  9.18219496e-01  8.02544866e-01  3.96855929e-01\n",
      " -9.71842067e-02  1.38782229e+00  2.02553528e-01  9.80436650e-01\n",
      "  3.49505604e-01 -2.47320644e-02 -4.27464090e-02  6.07238040e-01\n",
      "  6.69518667e-02 -3.25267955e-01  8.10924893e-01  4.71036770e-01\n",
      "  2.00852046e-01  2.43325654e-01 -1.01017458e+00 -1.07825744e+00\n",
      "  2.21332369e-01 -1.61101782e-01 -1.40272830e+00  6.13918303e-01\n",
      "  2.01668556e-01 -7.40280182e-02 -1.22927647e-01 -2.13490289e-01\n",
      "  3.23135292e-01 -9.29582760e-01 -2.71850162e-01  3.95582858e-01\n",
      "  6.74291451e-01 -6.47300753e-01  4.20512766e-01  2.38344937e-02\n",
      "  2.63741308e-01 -4.99340097e-01 -2.37193381e+00  6.46514847e-02\n",
      "  3.99463294e-01 -5.71971997e-01 -1.96694510e+00  6.98581954e-02\n",
      "  3.05672156e-01  3.63315109e-01  1.70366225e-01  2.72781137e-01\n",
      "  2.84993393e-01 -2.03023160e+00  4.91985224e-03  5.88815514e-01\n",
      " -7.61633496e-01 -2.04618166e-01 -3.58963499e-01  3.32134369e-02\n",
      "  5.62375271e-02  1.75795587e+00 -1.12921019e-01 -4.19565359e-01\n",
      " -6.63492506e-01 -8.23979086e-01 -1.10192371e-01  1.60928231e-01\n",
      "  4.52286427e-01 -2.17653898e+00  2.80315485e-01 -3.72248261e-01\n",
      "  6.86347347e-01  3.16941606e-01  9.10352347e-01 -3.17298311e-01\n",
      " -6.12706259e-01  4.26630008e-01 -4.96125564e-01 -4.24649700e-02\n",
      " -2.48182637e-01 -1.04552643e-01  1.38867602e-01 -2.25459002e-01]\n",
      "------counter :120-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.07799191e+00 -4.82002989e-01  1.40687389e+00  8.24648584e-02\n",
      "  1.47392945e-01  9.21036652e-01  4.08104677e-01  9.63030359e-01\n",
      " -8.73664658e-01  3.43044754e-01 -1.41286794e-01 -4.05856015e-01\n",
      " -1.91515930e-01  3.21164483e-01 -1.53005154e+00 -6.54832776e-03\n",
      "  1.05251756e+00 -9.78188737e-01  5.04260282e-01  2.47635437e+00\n",
      " -5.92764729e-01  6.65851972e-01  2.23610562e-02 -4.67041677e-01\n",
      " -4.64046507e-01 -2.42474929e-01 -7.16495809e-02 -4.13798519e-01\n",
      "  1.14833201e-01  3.62566605e-01 -9.15068228e-02  9.49771998e-01\n",
      " -1.72231598e-01  8.68310794e-01 -4.21224763e-01 -2.08753352e-01\n",
      " -2.58735617e-01  2.50792752e-01  4.21643400e-01 -1.14770080e-01\n",
      " -8.49877573e-01 -2.16849906e+00  3.46341463e+00 -6.37241375e-02\n",
      "  1.76368873e-02 -7.08356248e-01  3.32332293e-01  7.15569245e-02\n",
      "  4.85870064e-01 -1.26780537e-01  7.52467600e-01  9.06634621e-02\n",
      "  6.23057488e-01  6.65246418e-01  6.66450728e-01 -1.91445275e-01\n",
      "  5.47681927e-01  6.31111931e-01 -9.98350047e-01  8.27759684e-01\n",
      " -9.23825849e-02 -3.19884164e-01 -1.16288488e+00  3.21989816e-01\n",
      "  4.32486110e+00 -2.46464624e-01  9.39801148e-01 -2.52621813e-01\n",
      "  4.41654842e-01 -1.08832750e+00 -3.44329670e-01  1.53139074e+00\n",
      " -1.90819457e-02 -1.81103145e-01  8.23934185e-01 -2.54426853e+00\n",
      "  1.80196105e-01 -1.67829590e+00 -1.04524270e+00 -5.68557037e-01\n",
      "  5.01774974e-01 -1.57496464e-01 -3.23840202e-01 -1.09791180e-01\n",
      " -6.49737933e-01 -2.42331734e+00  5.25889564e-01  6.25856236e-01\n",
      " -8.30610644e-03  3.74441580e-01 -6.76533586e-01 -5.85700099e-01\n",
      " -1.88561569e+00 -6.53350822e-01  2.87760066e-01  1.86496059e-01\n",
      " -3.08992467e-01  9.25493037e-01  6.24689980e-02  2.11497768e-01\n",
      " -1.08173578e-01  2.39241736e+00 -7.27557211e-01  1.20640391e-01\n",
      " -5.70896331e-01  3.79221685e-02  3.91374762e-01 -2.97396356e-01\n",
      "  4.52385081e-01 -4.53875396e-01 -2.42474965e-01 -8.49438742e-01\n",
      "  1.82184941e-01 -3.91424787e-01 -4.92339430e-01  3.70728636e+00\n",
      "  6.50203893e-01  2.03578046e-01 -1.59069589e+00 -5.57316219e+00\n",
      "  3.73117046e-01  6.83575899e-01 -2.22444239e-01  8.41142116e-01\n",
      "  1.31618790e+00  4.87763246e-01  2.51292971e-01  1.24100640e+00\n",
      "  4.27359154e-01 -3.78992461e-01 -1.63906016e-01  3.41400847e-01\n",
      " -4.90115223e-01 -5.16601294e-01  3.75795510e-01  4.42092214e-02\n",
      " -4.83462218e-02  4.29026900e-02 -1.61518094e+00  1.57772318e-02\n",
      " -3.43982398e-01 -5.99791502e-01 -5.33111347e-01  6.76414228e-01\n",
      " -1.84643709e-01  5.69555863e-01  1.17523212e+00  1.24852785e-01\n",
      " -2.50789377e-01 -1.49159592e-01  1.82585527e-02  1.21408550e-01\n",
      "  1.49180245e+00 -1.04423315e+00  4.90777242e-01  1.01622506e-01\n",
      "  4.94518457e-01 -3.29621619e-01 -9.19402989e-01 -1.10298762e-02\n",
      "  1.80879875e-01  8.78080111e-02 -1.52051641e+00 -5.80562167e-01\n",
      "  3.65550923e-01 -4.34057731e-01  4.20407020e-02  5.17684609e-01\n",
      "  8.34869968e-02 -1.73604926e+00 -1.11327462e-01 -1.93914300e-01\n",
      " -2.14205590e-01 -9.45505566e-01 -1.78701038e-01 -5.95187924e-01\n",
      " -2.15641171e-01  2.80216709e+00 -3.64091721e-01 -4.54811966e-03\n",
      " -9.71064983e-01  1.44675458e+00  1.13346097e-01  3.45816503e-02\n",
      "  3.39615470e-01 -1.58968366e+00  1.30710812e-01  1.51355313e-01\n",
      "  9.81287019e-01 -8.00455681e-02  4.36125861e-01 -4.27988126e-01\n",
      "  8.03476577e-01  5.10229772e-01 -5.69670430e-01 -1.89874031e-01\n",
      " -5.20768720e-01  7.10273625e-01 -3.60557354e-01 -7.62461336e-01]\n",
      "------counter :121-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.68950147e-01 -7.82963637e-01  2.67180965e+00  7.31743243e-02\n",
      " -8.48985293e-01 -3.57010169e-01  1.10241836e+00 -1.17111846e+00\n",
      " -5.12489575e-01  4.38955460e-01 -2.91238519e-01  2.62431178e-01\n",
      "  3.19096650e-01  4.83686446e-01  1.06687823e+00  5.37121527e-01\n",
      "  1.73869875e+00 -6.04883063e-01  7.05944935e-01  6.66396346e+00\n",
      " -6.00326108e-01  8.90941819e-01 -4.90207138e-01  8.26360579e-01\n",
      " -3.79296343e-01 -2.45906269e-01  6.28446426e-01  1.30185500e-01\n",
      " -3.52214536e-01 -1.75192637e-01 -2.22141727e-01 -3.19466334e-01\n",
      " -1.71198486e-02  2.01053008e+00  1.63796386e-01 -1.84319152e-01\n",
      " -5.67725197e-01  3.67722277e-01  3.06274489e-01  4.46637200e-01\n",
      " -1.41526137e-01 -1.44984357e+00 -5.00859444e-01 -6.96542569e-01\n",
      "  1.01891324e-01 -5.84553457e-01  4.44459362e-01 -9.98435908e-02\n",
      " -1.61080898e+00  2.06329845e-01 -8.07407831e-01 -3.12975107e-01\n",
      "  4.45625482e-02  8.78527621e-01 -1.40519009e+00 -3.36298679e-01\n",
      " -2.83313812e-01 -1.51330213e+00  4.14074194e-01  7.80255380e-01\n",
      " -5.04844215e-02 -1.51789670e-01  2.64684510e+00  1.36533181e-01\n",
      "  1.25073683e+00 -5.36989966e-01  6.12563006e-01 -9.31142058e-01\n",
      "  2.02532981e-01 -7.04660271e-01 -5.35266121e-01  1.20241516e+00\n",
      "  5.28445572e-02 -2.68574483e-01  1.85972825e+00  3.01508323e-01\n",
      "  6.86214597e-02 -1.16325564e+00 -4.23520031e-01 -9.11438874e-01\n",
      "  3.46243064e-01 -1.70748220e-01  5.51786101e-02 -1.65055780e-02\n",
      " -8.22214322e-01 -2.15270873e+00  1.27919493e-01 -1.75741562e+00\n",
      " -9.14623398e-01  9.91375323e-01 -4.67444126e-02 -4.52216677e-01\n",
      "  4.85980750e+00 -5.55248860e-01  1.70653244e-01 -1.25675727e-02\n",
      " -3.43666414e-01  6.84124737e-02 -3.74199416e-01 -4.47206237e-01\n",
      "  4.22991529e+00  1.49602448e+00 -1.54312473e+00  1.76163987e+00\n",
      " -2.84857853e-01  2.22021320e-01  3.04715428e-01  4.18234836e-01\n",
      " -4.12406348e+00  8.20783806e-02 -4.06609236e-02 -6.44663181e-01\n",
      "  2.21871583e-01 -3.93419380e-01 -4.83927733e-01  3.88375209e+00\n",
      " -1.33061530e-01  7.13461838e-02  1.11834073e+00 -4.93528684e+00\n",
      "  1.71816313e-01  8.39614977e-01  5.25933746e-01  6.35802827e-01\n",
      "  5.14950694e-04 -2.44738642e-01  2.40272336e-02  1.00123517e+00\n",
      "  4.92390030e-01 -2.65599002e-01 -4.72884483e-01  7.68504054e-01\n",
      " -1.05454328e-01 -7.29807111e-01  3.08617214e-01 -1.52681503e+00\n",
      " -3.62070344e-01  5.87908072e-01 -7.03197969e-01  2.08934270e-01\n",
      " -4.90636257e-01 -6.30853480e-01 -1.43736341e+00  1.59857533e+00\n",
      " -1.16288011e-01 -2.00118317e-01  1.24143897e-02  1.64245021e-01\n",
      " -6.60402438e-01  1.71022394e-01  2.41515470e-02  3.02960933e-01\n",
      "  8.48939595e-01 -1.51392364e+00  3.03460103e-01 -1.62981038e+00\n",
      "  1.24792428e+00  1.58075479e-01 -2.03108906e+00 -4.76245913e-06\n",
      "  1.15418478e-01 -8.98548448e-02 -5.99081002e-01  5.34276405e-02\n",
      " -3.35096833e-01 -4.53777559e-01 -5.78986683e-02  4.14316522e-01\n",
      " -1.00999891e-01 -1.15795131e+00 -1.84353040e-01  9.29889830e-02\n",
      " -3.35318755e-02 -2.03325750e+00 -3.53441152e-01 -5.09927007e-01\n",
      " -4.00612364e-01 -2.98235419e-01 -3.05101440e-01  2.55345989e-01\n",
      "  6.27694151e-01  2.01341380e+00 -3.65710793e-01  2.78419588e-02\n",
      "  4.91875782e-01 -8.53288003e-01  1.47911933e-01  2.25330592e-01\n",
      "  4.87734635e-01 -7.99116309e-02  6.61790704e-01 -8.92327198e-01\n",
      " -5.04956469e-01  3.84883230e-01 -7.76513364e-01 -4.20528082e-01\n",
      " -5.11493591e-01 -3.72684515e-02 -1.66968184e-01 -6.62660515e-01]\n",
      "------counter :122-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.55106908e-01 -5.25856337e-01  2.51380422e+00  1.96763893e-01\n",
      "  4.41844401e-01  7.11751274e-01  1.07127000e+00 -1.19993245e+00\n",
      " -1.80436080e+00  5.20404114e-01 -4.95748375e-01  8.50343499e-01\n",
      "  2.45071408e-02  1.58243693e-01 -7.03415926e-01  1.79203419e-01\n",
      "  3.15050408e+00 -2.69381715e-01  7.18857677e-01  6.41429290e+00\n",
      "  2.02108628e-01  8.81627989e-01  3.77590329e-02 -9.16350918e-02\n",
      " -4.94107614e-02 -5.54296205e-01  2.34722994e-01 -3.46778470e-01\n",
      " -7.99204165e-01  1.90959339e+00 -3.56948858e-01 -3.55628070e-01\n",
      "  1.23362512e-01  1.15341730e+00  4.73402170e-01 -4.09017105e-01\n",
      " -9.62400702e-01  9.94265523e-02  3.81550078e-01  3.68052219e-01\n",
      " -9.89421186e-01 -1.47316880e+00  1.99600085e+00 -1.08641618e+00\n",
      " -6.96765352e-02 -3.57141344e-01  4.41219250e-01 -4.11977855e-01\n",
      "  1.10721317e+00  1.54195560e-01  3.18223175e-01 -1.02311826e+00\n",
      "  9.74792248e-02  5.92676341e-01 -1.14252227e+00 -6.04454490e-01\n",
      "  6.97108286e-01  6.07106055e-01  3.87197344e-02  7.32271610e-01\n",
      " -1.18574938e+00 -1.59634768e-01  1.82886479e+00  1.61773550e-01\n",
      "  3.60349951e+00  7.03773810e-01  4.67342394e-01 -9.65592855e-02\n",
      "  5.88313970e-01  1.64029981e-01 -8.96684789e-01  7.64343608e-01\n",
      " -1.03221102e-01 -4.26233321e-01  8.74556330e-01  7.21969810e-01\n",
      "  3.54439889e-01 -1.52260342e+00 -1.18995028e+00 -1.13247461e+00\n",
      " -3.41870314e-01 -1.19227037e-01 -9.75089510e-01 -2.65945033e-01\n",
      " -5.20492795e-01 -3.56907411e+00  8.92028023e-01 -6.41736007e-01\n",
      " -1.21437785e+00  1.10990305e+00  1.14874528e+00 -3.42030645e-02\n",
      "  2.11450742e+00 -5.10811376e-01  1.91240461e-01 -1.17699085e-02\n",
      " -4.30282119e-02  1.05165535e-01 -2.65935946e-01 -6.00361295e-01\n",
      "  2.31780812e+00  9.17936130e-01 -5.61941570e-01 -9.75174750e-01\n",
      " -6.70714149e-01  2.32000649e-01  7.61725806e-01 -1.34803146e+00\n",
      "  5.42760357e-01 -1.75494118e-01 -3.36229115e-01 -8.28786643e-01\n",
      "  1.07433351e-01 -2.90466665e-01 -7.06509035e-01 -1.09957594e+00\n",
      "  3.49748210e-01 -4.43986439e-01  1.57957939e+00 -1.06926505e+00\n",
      "  6.39894985e-01  7.42339301e-01 -2.83696386e-01  7.56655220e-01\n",
      " -6.48988893e-01 -5.93020272e+00  3.52537971e-01  6.45027989e-01\n",
      "  1.88723039e-01 -4.09006831e-01 -6.58711524e-01  5.50220656e-01\n",
      "  1.74772418e-01 -1.17757861e+00  2.70733808e-01 -3.29358000e-01\n",
      " -5.08174727e-01  3.38682616e-02 -5.91516708e-01 -1.71477276e-02\n",
      " -1.58130797e-01 -5.53814745e-01 -2.06913064e+00  1.29837268e+00\n",
      " -2.67774629e-01 -2.22846924e-01 -5.90514262e-01  2.12209607e-01\n",
      " -7.05166749e-01  5.17471224e-01  1.23099334e+00  2.92155342e-01\n",
      " -3.31982451e-01 -1.42111084e+00  4.07516409e-01 -7.77163107e-02\n",
      "  1.33813262e+00  3.90279093e-01 -1.23331164e-01  6.42620796e-01\n",
      "  2.31872775e-01  2.91615432e-01 -1.75490797e+00  1.35419415e-01\n",
      " -1.00857569e+00 -5.23013379e-01 -2.54589641e-01  5.84758550e-01\n",
      "  1.77656086e-01  6.91904950e-01 -7.78144001e-02 -2.99607184e-02\n",
      "  4.85929928e-01 -1.55798556e+00 -5.26082057e-01 -4.45514520e-01\n",
      " -4.98735999e-01  2.18165351e-01 -1.07813440e+00  4.66621166e-01\n",
      "  9.41596116e-01  4.90477793e-01 -1.36670711e-02  4.30293371e-01\n",
      "  1.47746479e+00 -9.43700059e-01 -1.44971084e-03  2.40349188e-01\n",
      "  7.20019775e-01 -2.89426652e-01  1.18596269e-01 -6.20357208e-01\n",
      " -5.59348979e-01  5.67166253e-01 -8.18618101e-01 -5.51516952e-01\n",
      " -7.72431567e-01 -2.99678530e-01 -1.36569180e-01 -7.48740610e-01]\n",
      "------counter :123-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.24153922e-01 -1.03189817e+00  1.83859907e+00  5.40590531e-01\n",
      " -5.30894361e-01  1.58589269e+00  1.82520736e+00 -3.52651987e-01\n",
      "  4.86150982e-01  3.65618522e-01 -1.29766621e-01  8.40392095e-01\n",
      "  7.45260763e-02 -3.05000783e-01 -7.83680575e-01 -7.54702642e-03\n",
      "  2.52652593e+00 -1.02351750e-01  7.39889383e-02  5.84086822e+00\n",
      "  7.72920330e-01  1.01843900e+00  1.34125420e-03 -1.84841286e+00\n",
      " -1.20524956e-01 -1.42045395e+00  2.45491979e-01 -9.46080740e-01\n",
      " -6.51748483e-01  1.00705615e+00 -2.33163220e-01  2.03557062e-01\n",
      " -8.39358471e-02  2.16222676e+00 -2.80369590e-01 -1.18337734e-02\n",
      " -6.55002361e-01  8.10391627e-01  4.82611679e-01  6.52622359e-01\n",
      " -8.41313100e-01 -1.32595457e+00  1.44341527e-01 -7.36708811e-01\n",
      "  4.43851547e-01 -3.54321544e-01 -4.07412566e-01 -3.41181189e-01\n",
      " -3.91849475e-01  4.23887460e-01  2.65153336e-02  5.64287637e-01\n",
      "  1.97567477e-01  1.10340622e+00 -1.87185618e+00 -4.35196167e-01\n",
      "  3.04238851e-01 -9.47735972e-01  1.10136676e+00  6.38857899e-01\n",
      " -1.10007199e-01  4.67521266e-01 -1.83233044e+00  4.79749938e-02\n",
      "  6.04840389e-01  2.97668134e-01  4.50575543e-01 -4.14019613e-01\n",
      "  2.43366122e-01  9.30945432e-01 -6.22050783e-01 -1.44044063e+00\n",
      "  3.99663752e-01 -1.57791733e-01  3.11036019e+00  4.01866504e-01\n",
      " -3.79051658e-01 -1.31300714e+00 -7.36134866e-01 -8.97582597e-01\n",
      "  1.21991819e-01  5.17778216e-02 -6.68280684e-01 -2.52942883e-01\n",
      " -3.72501257e-01 -1.44049796e+00  8.71038270e-01  1.44928408e+00\n",
      " -1.17294685e-01  3.02561558e-01  3.33879690e-01  3.56897267e-01\n",
      "  2.55450370e+00 -2.65314604e-01 -2.33937981e+00 -2.05073786e-01\n",
      "  1.88266952e-02  9.25263903e-02  5.04380589e-01  2.45484374e-01\n",
      "  2.01559761e+00  1.55698250e+00  1.79142175e-01 -2.63208262e-01\n",
      " -2.52974752e-01  1.84108554e-01  1.20365805e-01  1.37299169e+00\n",
      "  1.03630782e+00 -6.37413348e-01 -3.33151774e-01 -5.87188595e-01\n",
      "  3.92206525e-01  3.31320260e-02  3.60070072e-01  2.63297879e+00\n",
      "  4.33751493e-01 -1.29754335e-01  1.31110174e+00 -4.48690557e-03\n",
      "  5.07878374e-01  6.60864312e-01 -2.47179835e-01  8.55031727e-01\n",
      "  4.02971106e-01 -5.16395321e+00  3.46354739e-01 -2.79322164e-01\n",
      " -3.40647301e-01 -1.06760530e+00 -3.76610293e-01  3.52006097e-01\n",
      " -4.74929378e-02 -5.70583585e-01 -3.46369700e-01 -5.77775207e-01\n",
      "  3.08805562e-01  2.07253719e-01 -1.49672462e+00 -5.34807368e-01\n",
      "  5.02168244e-02 -3.95487026e-01 -1.48354548e+00  1.96150217e+00\n",
      " -2.74736347e-01  8.16322643e-02 -1.52202870e-01 -3.77672046e-01\n",
      " -4.28426243e-01 -1.43475311e+00  3.46958234e-01  7.96782629e-01\n",
      " -5.17614362e-01 -1.27065821e+00  8.98120956e-01 -4.55379929e-01\n",
      "  1.58170570e+00 -1.85031136e-02 -7.37413320e-01 -5.95366739e-02\n",
      "  3.95656111e-01  2.35980733e-01 -2.03328222e-01  3.22202058e-01\n",
      " -9.41806434e-04 -3.63237078e-01  4.16468428e-01  2.24570376e-01\n",
      " -1.65181764e-01 -4.67629684e-01  1.59335964e-01  9.91758882e-02\n",
      " -9.09052426e-01 -1.01094152e+00  7.74868748e-02 -2.91826671e-01\n",
      " -6.25996624e-01 -3.00237645e+00 -1.29933010e+00  5.36522080e-01\n",
      "  6.75829116e-01 -1.38513498e+00  2.58288372e-01 -1.13628054e-01\n",
      "  2.19561934e-01 -1.48566266e+00 -1.40564514e-01 -1.87418201e-01\n",
      "  4.87516868e-01 -1.48751857e+00 -1.83397499e-01 -2.35602603e-01\n",
      " -7.39102884e-02  7.34383074e-01  6.55280755e-02 -4.51910847e-01\n",
      " -4.85448756e-01 -1.14035717e+00  1.18612736e-01 -5.64936236e-01]\n",
      "------counter :124-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.92011441e-01 -2.89447879e-01  1.74703318e+00  5.99697689e-01\n",
      "  6.50928976e-01  4.65512001e-01  1.73102683e+00  8.75509812e-01\n",
      "  3.60465574e-01  5.35042773e-01 -2.99619016e-01 -5.17127307e-01\n",
      "  9.59400276e-02  6.45671893e-02 -7.87471076e-01  2.08663297e-01\n",
      "  1.52145290e+00 -4.34073051e-01  1.95988740e-01  5.86524421e+00\n",
      "  6.91852900e-02  8.24271037e-01 -1.42185811e-01  1.18671589e-01\n",
      " -1.28720377e-01 -3.10061907e-01 -1.37109899e+00  9.46486630e-01\n",
      " -7.38577720e-01  1.92138260e+00 -3.32053108e-02 -3.18620512e-02\n",
      " -1.18257389e-01  9.29951270e-01 -1.41361335e+00 -2.36200597e-01\n",
      " -2.02833177e-01  5.03418682e-01  5.53272905e-01  4.10791474e-01\n",
      "  5.44595701e-02 -1.70133406e+00  2.19074161e+00 -1.40785813e+00\n",
      " -6.07721563e-02  4.66758354e-01  3.54930981e-01 -5.84755497e-01\n",
      "  3.58309236e-01  2.97360022e-02  1.67962804e-01 -3.22660077e-01\n",
      " -3.77678704e-03  1.19611689e+00  5.57616039e-01 -2.38832448e-01\n",
      "  1.02886860e-02  3.50478200e+00  2.05402005e-01  5.30313293e-01\n",
      " -9.64816997e-01  8.92669354e-01 -1.85421986e+00 -1.53146765e-01\n",
      "  2.82731574e+00  3.14921168e-01  3.64052166e-01 -7.59486828e-01\n",
      "  1.45718387e-01  1.88355178e-01 -4.73796501e-01  1.62830341e+00\n",
      "  2.40606881e-01 -8.00529024e-01  1.49417547e+00  2.70427969e-03\n",
      " -1.23751335e-01  5.51778020e-01 -8.91927364e-01 -1.09909813e+00\n",
      " -5.43872489e-02  1.85127644e-01  1.48340754e-01 -7.03712969e-01\n",
      " -6.45507153e-01  2.90505679e+00 -4.11669688e+00  1.79397959e+00\n",
      "  2.20854690e-01  7.92732009e-01  7.46163872e-02  5.81671108e-01\n",
      "  1.62907908e+00 -2.35908433e-01 -2.91332597e+00  3.47900517e-01\n",
      "  6.38430607e-02  1.30139249e-01  1.73092336e-01 -6.69974261e-01\n",
      "  8.11283171e-01  9.88955658e-01 -1.77122514e+00 -1.97526897e+00\n",
      "  7.21488544e-02  9.14283501e-02  5.80578161e-01 -2.95513639e+00\n",
      " -2.12547695e+00 -8.13341434e-01 -3.88498345e-02 -6.13727507e-01\n",
      "  2.28591376e-01 -5.58287953e-01 -2.14705683e-01 -1.31741347e+00\n",
      "  5.40474403e-01 -3.52632564e-01  1.56861106e+00  8.40640296e-01\n",
      " -6.67684263e-02  5.45722830e-01 -7.90084878e-01  1.64183564e-01\n",
      " -3.52752750e-01  2.03682961e+00  9.32424998e-01 -5.46296409e-02\n",
      "  3.43193186e-03 -1.02251964e+00 -5.64156222e-01 -1.70605645e-01\n",
      "  5.80746586e-01 -1.23714981e+00  1.91956808e-01  1.30752588e-02\n",
      "  1.26742341e-01 -4.31956412e-01 -9.95992776e-01 -6.93804056e-01\n",
      " -3.39984281e-01 -8.18369595e-01 -1.74212094e+00 -1.90644203e+00\n",
      " -1.89950624e-01  1.79843634e-01 -4.12282438e-01  6.86514494e-01\n",
      " -7.12738276e-01 -2.42432934e-01  5.87791809e-01  2.27932521e-01\n",
      " -3.37826097e-01 -7.29685523e-01  1.00304201e+00 -5.05012360e-01\n",
      "  8.72881975e-01 -1.12655592e-01 -3.51267406e+00  4.79960987e-01\n",
      "  3.51301472e-01  1.30968991e+00  1.50132368e-01 -2.40231505e-01\n",
      "  2.29412760e-01 -8.79274785e-01  9.10388692e-02  7.23354038e-01\n",
      " -2.35928184e-01 -7.06435892e-01  6.82365270e-01 -6.47676140e-01\n",
      " -2.36819447e-01  1.39472045e-01 -2.70484250e-01 -6.12760639e-01\n",
      " -6.48887190e-01 -3.39007869e+00 -8.34260980e-01  1.95674514e-01\n",
      "  1.40415976e-02  1.16803359e+00  2.12060885e-01  1.40306948e-01\n",
      "  1.44151383e+00 -5.64885825e-01  1.23947284e-01 -1.23494393e-01\n",
      "  5.19031839e-01 -4.21536232e-01 -3.60283227e-01 -2.80719023e-01\n",
      "  2.48415996e-01  6.66812791e-01 -6.49887983e-02 -5.17642449e-01\n",
      " -1.69687279e-01 -2.36748848e-01  1.67543436e-01 -8.00771574e-01]\n",
      "------counter :125-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.97651487e-01 -2.01204684e-02  7.93843414e-01  3.29511784e-01\n",
      " -1.37792942e-01  1.06017571e+00  1.33937850e+00 -8.12348966e-01\n",
      "  3.11427866e-01  5.81405346e-01 -6.29845842e-01 -7.44908143e-01\n",
      " -9.39696909e-02 -1.39484256e-01 -1.50701777e+00 -4.60005383e-01\n",
      "  1.67831512e+00 -1.94296325e+00  1.95323859e-01  5.80690306e+00\n",
      "  2.46775084e-01  7.36574024e-01 -9.31010962e-02  7.06100557e-02\n",
      " -1.28263933e-02 -7.02721877e-01 -1.43071431e+00  2.81198236e-01\n",
      "  2.78385936e-01 -3.10396809e+00  5.25636103e-03 -9.05337088e-01\n",
      " -1.76631624e-01  3.94387434e-01 -1.98093914e+00  1.55637726e-02\n",
      " -4.85038229e-01  2.18174108e-01  5.26409075e-01  1.54438403e-02\n",
      "  3.65897171e-01 -1.65349907e+00 -2.62671756e-01 -1.48455699e+00\n",
      " -1.58049049e+00  8.55609538e-01  2.80326025e-01 -3.05846607e-01\n",
      " -4.50564946e-01  5.11808837e-01  3.17773665e-01 -3.07538111e-01\n",
      "  2.62671998e-01  1.03825626e+00  8.89776996e-01 -4.86603405e-01\n",
      "  3.89861531e-02  3.29079209e+00 -1.43576976e-01  1.00455332e-02\n",
      " -9.69641092e-02  1.05772677e+00  1.39623908e+00  6.50967657e-01\n",
      " -6.12450045e-01  1.12227440e-01  4.75829715e-01  1.16745591e+00\n",
      "  4.36408912e-01 -5.30223138e-01 -2.59143672e-01  4.24371247e-01\n",
      " -2.05291109e-01  6.21802844e-02 -1.19729122e+00  9.72748617e-01\n",
      " -5.69455716e-02  1.00150411e+00 -7.13615060e-01 -1.19346042e+00\n",
      "  6.20279896e-01 -2.58905679e-01 -2.38846725e-02 -8.82553208e-01\n",
      " -8.22783279e-01  5.66718529e-01 -1.32007037e+00 -5.77369554e-01\n",
      " -1.11268586e+00 -1.93296339e-01 -3.04981419e-01 -1.10265053e-01\n",
      "  2.41805670e+00 -3.59288271e-01  1.23935824e+00  3.46656274e-01\n",
      "  1.87686165e-01  7.59338213e-02 -4.94325906e-01 -7.17154561e-01\n",
      "  1.19213946e+00  7.87643081e-01 -1.29331262e+00  1.55512314e+00\n",
      " -3.97902422e-01 -3.33161659e-01  1.00190664e+00  1.42268897e+00\n",
      " -1.22727932e+00 -6.19634396e-01  2.97512347e-01  2.33519345e+00\n",
      " -1.63613205e-01 -4.20827315e-01 -7.98344865e-01  1.15662888e+00\n",
      "  5.70391927e-01 -1.09325398e+00 -2.20315775e+00 -9.33648451e-01\n",
      " -4.81498970e-01  3.66013150e-01  2.36042055e-01  7.22184037e-01\n",
      "  1.57418933e-01  1.74669997e+00  1.43670874e-01  6.22794570e-01\n",
      "  1.91547229e-01  4.78590981e-01 -6.46352957e-01  6.37832764e-01\n",
      " -2.60144525e-01  4.71107406e-02 -6.36397404e-03  4.83787428e-02\n",
      " -3.29060055e-01 -9.15224629e-01 -2.36720365e+00 -5.46361422e-01\n",
      " -4.26273680e-01 -5.57599006e-01  9.56657131e-03  2.19752213e-01\n",
      "  2.26517514e-01  3.57699801e-01 -1.46477817e+00  8.61729990e-01\n",
      " -5.94421879e-01  1.13940537e-01 -7.58049162e-01  3.58434131e-01\n",
      "  1.23794729e+00 -3.85740259e-01  7.74135513e-01  6.86084736e-02\n",
      "  5.54244028e-01 -2.57020003e-01 -1.66189026e+00  2.65654524e-01\n",
      "  3.64715620e-01  2.13303565e+00  1.27386697e+00  2.83026237e-01\n",
      " -1.63197249e-02  1.28239189e-02 -1.88571908e-01  1.37942351e+00\n",
      " -1.67883162e-01  9.45789276e-01  2.98339567e-01 -7.57601574e-01\n",
      "  3.50727251e-01 -6.10701942e-01 -6.36988399e-01 -4.30833481e-01\n",
      " -7.98599747e-01 -1.29183792e+00 -1.17915775e-01 -3.61394996e-02\n",
      " -2.05527034e+00  1.08688786e+00 -2.63449631e-01 -5.92291107e-02\n",
      "  8.53917337e-03 -1.17001763e+00  1.84393206e-01  3.05683250e-01\n",
      "  1.37361192e+00 -3.33168802e-01 -4.16816621e-01 -7.19177479e-01\n",
      "  1.27019276e+00  5.84347303e-01 -9.45370806e-01 -9.19851215e-01\n",
      " -2.92581992e-01 -5.25518644e-02  1.26543056e-01 -8.88365155e-01]\n",
      "------counter :126-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35793527 -0.10695014  1.42585232  0.46299801 -0.09660522  0.93304318\n",
      "  1.74204592 -1.13025207 -1.58613563  0.63141444 -0.59581126 -0.52369802\n",
      " -0.02043313  0.07570742 -1.63579083 -0.70907599  0.94393295 -1.21029411\n",
      "  0.80300842  5.72572067 -1.05006498  0.75924914 -0.10205375 -0.34543169\n",
      " -0.10219723  2.57650162 -1.13258646 -0.84072544 -1.06625061 -1.18248639\n",
      "  0.22405445  2.00378014 -0.12644177  0.0236962  -1.29776332 -0.08857816\n",
      " -0.28226706 -0.11031959  0.63606193 -0.11497302  0.11845925 -1.4454608\n",
      " -0.13010682 -0.67067349 -0.39353322  0.44345533 -0.84330665  0.05719416\n",
      " -0.52977402  0.54440009  0.76973806  0.49312685  0.29649618  0.98949134\n",
      "  2.47953274 -0.70665269  0.25771593 -3.11755407  1.44920228  0.84780394\n",
      " -0.38243434  0.1930391   1.09552413  0.12021581 -0.87473653  0.26228629\n",
      "  0.79288465  0.47148886  0.59034993 -0.67434353 -0.03949033  1.84183538\n",
      "  0.07860008 -0.30788777  3.46432649  0.50807717  0.04096173 -1.17949585\n",
      " -0.79634379 -1.09725459 -0.5240697   0.33502761 -0.92062139 -0.73932699\n",
      " -0.85387138  0.06498317 -1.02217265 -1.09930467  0.84307224 -0.75845727\n",
      "  0.29351932 -0.02436122  2.84970031 -0.46640988  1.53787768 -0.25107825\n",
      "  0.08855871  0.10239404  0.53056029 -0.57942283  0.97355925  1.59102431\n",
      " -2.28622572  2.31921806 -0.40950553 -0.19425876  0.14675004  1.29682205\n",
      "  0.72648669 -0.78799349 -0.15936949 -0.10667645  0.09529751  0.31490804\n",
      "  0.01359475  1.00798828  0.19816102 -0.80457898 -1.21776201 -0.07726789\n",
      " -0.34746077  0.51051396 -0.11009416  0.17396598 -1.84482236 -3.53770319\n",
      " -0.06728072  1.07986908  0.37331411 -0.8575462  -0.67655147  0.15041076\n",
      " -0.07709137  0.59906711  0.07764585 -0.24022632 -0.40686705 -0.79898724\n",
      "  3.01970365 -0.85294656 -0.04741431 -0.36935338  1.50255793 -2.75103518\n",
      "  0.01354794 -0.02289032 -3.08636541  0.65538719  0.2596576   1.12650161\n",
      " -0.2864142   0.42959993  0.61508041 -0.60181936  0.78961141 -0.16329737\n",
      " -2.51792687 -0.06205687 -1.38297341 -0.10662047 -0.05515729  2.02963199\n",
      " -0.66125299  0.08456545 -0.05581331 -0.17411689 -0.04602706  0.32077216\n",
      " -0.60735817  1.07495325  0.11750826 -0.346046    0.1436549  -0.69686221\n",
      " -0.4769632  -0.75232845 -1.01754998  1.30883666 -0.35168942 -1.11436836\n",
      " -1.23500843  0.58537384 -0.12800306  0.17116322  2.35621799 -0.64410233\n",
      "  0.07351675  0.34496135  0.96206057 -0.20432628 -0.23979273 -0.65449396\n",
      "  1.30005927  0.41151378 -0.83922409 -0.20089333 -0.26714316 -0.25281843\n",
      "  0.36218711 -1.00219921]\n",
      "------counter :127-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.89187944e-01 -1.82150660e-01  1.28912293e+00  5.63366557e-01\n",
      "  1.01023522e-01  5.13488106e-01  1.74273973e+00 -7.75914131e-01\n",
      " -1.73643415e+00  5.36569619e-01 -2.14206536e-01  1.24611856e-01\n",
      "  2.69608485e-01 -4.95225908e-01 -2.09840113e+00 -2.96872885e-01\n",
      "  6.50378656e-01 -1.61682454e+00  1.15741456e+00  3.50070506e+00\n",
      " -7.84494215e-01  6.70736195e-01  1.71074286e-03  6.68477293e-01\n",
      "  1.04730981e-01 -9.84895323e-01 -9.55214512e-01 -7.49052118e-01\n",
      " -7.88855282e-01 -7.68656144e-01  3.20405970e-01  1.71719083e+00\n",
      "  8.04209300e-01  5.19394182e-02 -1.64698653e+00 -2.90819198e-01\n",
      "  2.26627316e-01 -3.33032533e-03  6.62406433e-01 -3.92538653e-01\n",
      "  1.87845375e-01 -1.64980816e+00 -4.17716580e-01 -1.14333506e+00\n",
      "  1.39820270e+00  9.24711872e-01 -1.00188277e-01 -2.16259727e-01\n",
      " -2.60111271e+00  3.48787060e-01  1.03440636e+00  9.97023766e-01\n",
      "  4.04295133e-01  8.92624257e-01  1.69017517e+00 -2.79054502e-01\n",
      " -2.75685194e-01  1.17692333e+00 -1.53942822e-01  1.04485672e+00\n",
      " -7.56282586e-01  4.16128555e-01  2.40498750e+00  1.62897073e-01\n",
      "  5.49966789e-01  7.89925873e-01  1.71032025e+00  2.38956120e+00\n",
      "  1.85664319e-01 -3.19018732e-01 -1.37098385e+00 -6.16644906e-01\n",
      " -1.27729978e-01 -6.41058194e-01 -3.11007451e+00 -8.61910066e-01\n",
      " -2.21603061e-01 -1.19632578e+00  1.31354040e+00 -9.93169080e-01\n",
      "  2.30451273e-01  5.00559668e-01 -1.31150074e+00 -1.63687427e-01\n",
      " -4.72873356e-01  1.38710662e+00  2.47927764e+00 -7.80335084e-01\n",
      " -1.59241355e-01  3.87344150e-01  8.65640772e-01 -5.38265474e-01\n",
      " -1.18097733e+00 -7.85563365e-02  1.48351671e+00 -1.92016843e-01\n",
      "  3.52857430e-01  1.53864481e-01  8.65945200e-01 -3.73258132e-01\n",
      "  1.15229349e+00  1.32323937e+00  1.78682058e+00 -1.53857255e+00\n",
      " -4.83919052e-01  3.34948698e-02  1.02025589e+00 -2.51658217e+00\n",
      "  3.89248387e+00  1.56547551e+00 -1.85859892e-01  4.56209546e-02\n",
      " -5.14140118e-02  7.89371733e-01 -3.71141715e-02  3.49306583e-01\n",
      "  2.71212792e-01 -5.22373314e-01 -1.08256975e+00  1.00845490e-01\n",
      " -2.21379763e-01  6.24246363e-01  5.86265635e-01  7.70766817e-01\n",
      "  4.87787144e-01 -5.30273643e+00 -3.87087115e-02 -4.84876320e-01\n",
      " -6.59222591e-02 -9.30599788e-01 -6.49667032e-01  3.16748857e-01\n",
      "  2.11040074e-01 -2.06825058e-01  1.31447534e-01 -5.57580582e-01\n",
      " -2.76513384e-01 -9.68331025e-01  3.21754035e+00 -9.30408302e-01\n",
      " -1.44653064e-01 -6.37358947e-01 -6.46028498e-01 -2.31595859e+00\n",
      " -3.57558059e-02 -1.32523757e+00 -1.20417251e+00  4.48471621e-01\n",
      "  4.15845402e-03  9.04534540e-01 -7.10707882e-01  6.09540431e-01\n",
      " -2.92778496e-02 -4.73482750e-01  1.04774809e+00  2.14887157e-01\n",
      " -1.16040083e+00  1.88310042e-01 -2.59050860e+00  3.95709306e-01\n",
      "  2.82625624e-01  1.65361311e+00 -6.13251767e-01  2.67083611e-01\n",
      " -2.83818578e-03  3.04594328e-01  2.54517695e-01  4.54326276e-01\n",
      " -1.23327894e-01 -1.75715195e-01  3.55840109e-02  2.39210367e-01\n",
      "  4.72493995e-01 -9.84281511e-01 -3.11217049e-01 -3.53145470e-01\n",
      " -8.08908177e-01 -1.45696211e-01  2.78576975e-01 -2.07833853e-01\n",
      " -1.18043726e+00  6.21105786e-01  4.76212564e-02  1.29586761e-01\n",
      "  1.18955579e+00 -1.60915032e-01 -6.53760130e-02  1.02120189e-01\n",
      "  4.70971793e-01 -9.29008260e-02  8.99247285e-02 -3.77907838e-02\n",
      "  1.34127288e-01  5.54491610e-01 -6.57746698e-01 -3.23503862e-01\n",
      "  3.53403852e-01 -2.08860782e+00  4.73250171e-02 -7.47688718e-01]\n",
      "------counter :128-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.66264295e-02 -1.10408451e-01  1.58100889e+00 -2.12285427e-01\n",
      " -1.32608240e-01  1.45186743e+00  7.17527506e-01  2.32179442e-01\n",
      " -1.74370875e+00 -1.07558573e+00  3.34202847e-01  8.22819801e-01\n",
      " -4.04828745e-01  4.64105982e-01 -2.09779898e+00 -1.52295276e+00\n",
      "  6.75462559e-01  1.10587753e+00  7.12698857e-01 -3.89415179e-02\n",
      " -1.46323693e+00  1.08209743e+00 -1.58376392e-01  8.98480583e-01\n",
      " -1.18427091e-01  7.55586186e-01 -1.24339128e+00 -1.38982176e+00\n",
      " -5.15623747e-01  2.55364570e-01  9.69810702e-01 -1.08040516e+00\n",
      " -8.27449308e-01  1.18931911e+00 -2.29633657e-01 -1.76845321e-01\n",
      " -4.03205411e-01  8.27749821e-02  3.57948989e-01  1.40369290e+00\n",
      "  8.33159768e-01 -1.74734512e+00  2.85909504e+00 -9.43150914e-01\n",
      "  1.45345649e+00  7.24680351e-01  7.19811309e-01  9.16586009e-01\n",
      "  1.34831548e-01  6.79145655e-02  1.32937170e+00 -1.08275156e+00\n",
      "  5.85148695e-03  5.53819414e-01  6.41419480e-01 -4.71681892e-01\n",
      " -1.47593523e-01  1.76507598e+00  3.33348820e-01  9.24673921e-01\n",
      "  1.35870735e+00  5.08104683e-01  1.09726644e+00  1.11025609e+00\n",
      "  4.91514701e-02  1.92419264e-01  2.02982781e-01 -4.13578131e-01\n",
      "  6.34577506e-01 -6.95711998e-01 -1.16808494e+00 -2.11887848e+00\n",
      " -3.82899185e-02 -7.71455046e-01  3.49783340e+00 -2.85806839e-01\n",
      "  1.29054741e-01 -2.39323031e+00 -1.78568783e-01  1.47905412e-01\n",
      "  1.62454517e+00 -2.32354140e-01 -1.96403988e-01 -2.54751901e-01\n",
      " -7.01595757e-01 -7.25533429e+00  1.79656184e+00  3.17520600e-01\n",
      "  1.19206198e+00  2.64646804e-01 -6.90726737e-01  8.30749453e-01\n",
      " -6.79649929e-02  4.88652997e-02  2.36641490e+00 -7.95783566e-02\n",
      " -5.07800108e-01  3.23678404e-01  8.40629192e-01  1.17309920e+00\n",
      "  1.16821071e+00  1.11748806e+00 -1.65506492e+00  4.79263252e-01\n",
      "  3.75112547e-01  6.07505777e-02  6.36586608e-01 -2.68049891e+00\n",
      " -1.74675031e-01  3.83875082e-01  8.43308486e-01 -6.52528370e-01\n",
      "  1.31047104e-01  1.42097557e+00  4.03539328e-01  7.12908488e-02\n",
      "  3.74586007e-02 -7.44753292e-01 -2.60614333e+00  3.73410485e-01\n",
      " -7.58063258e-01  2.14103063e-01 -4.86824902e-01  3.65097154e-01\n",
      "  3.58683672e-01 -5.02561888e+00  3.25148501e-01 -1.12800716e-01\n",
      "  1.17123749e+00  1.10946093e+00 -6.42434370e-01  2.22309139e-01\n",
      "  3.01154613e-01 -3.91081250e-01  1.02998716e+00 -1.29594031e+00\n",
      "  1.82911278e-02 -1.03048080e+00 -4.71257148e-01 -9.53796322e-01\n",
      " -3.00362640e-01 -5.65256002e-01 -1.36585392e+00 -2.29129248e+00\n",
      " -8.05956435e-02  1.75175092e-01  1.58663720e+00  5.87557507e-01\n",
      "  8.19636491e-01  9.75010524e-01 -8.17210586e-01  5.06655765e-01\n",
      "  1.74171525e-01 -5.51750510e-01  6.59855637e-01  4.89078803e-01\n",
      " -1.02021675e+00  1.77686490e-01 -4.81419712e-01 -7.24336413e-01\n",
      "  4.15778368e-01  1.47491687e+00 -1.63883716e+00 -5.75709206e-01\n",
      "  4.62927057e-01 -9.90433427e-01  6.31916058e-01 -1.04888388e+00\n",
      " -7.90633990e-02 -3.30432615e-03  4.72700157e-01 -2.73316016e-01\n",
      "  1.38689395e+00  3.68069199e-01  7.95684811e-01 -6.92111135e-01\n",
      " -2.42013378e-01 -3.57551410e+00 -7.62901476e-01 -9.70268791e-01\n",
      " -7.96624385e-01  1.95281858e+00  2.24250729e-02  6.80857106e-01\n",
      "  9.91374781e-01  5.24488219e-02 -1.77164455e-01 -1.37670353e-02\n",
      "  8.27450622e-01  4.44303265e-01  1.07963270e-01 -8.04251766e-01\n",
      " -1.78940127e-01  8.00298278e-01 -4.24758777e-01 -1.20758735e-01\n",
      "  1.17411477e+00 -6.08460732e-01  3.32592419e-01 -8.85605167e-01]\n",
      "------counter :129-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.78993915e-01  1.14893179e+00  1.81072069e+00 -6.33900815e-01\n",
      " -3.51756848e-01  1.10831093e+00  8.30819816e-01  1.44098663e+00\n",
      " -2.76819253e+00  5.14143884e-01 -5.87978752e-02  6.17112522e-01\n",
      "  7.58262610e-01 -2.22831962e-01 -1.76481015e+00 -6.18744474e-01\n",
      "  1.73722447e+00  1.19260033e-01 -6.90044511e-01  2.51464600e+00\n",
      " -1.03198619e+00  5.35109104e-01 -3.09380920e-01  3.59062192e-01\n",
      "  8.47602772e-01 -8.40383130e-01 -1.47246402e+00 -6.25435219e-01\n",
      " -1.09355529e-01  1.24642708e+00  2.89438483e-01  2.95507652e-02\n",
      " -2.76923906e-01 -4.77814945e-01 -2.53677216e-01 -3.62655107e-01\n",
      " -4.70364921e-01  1.28450066e-01  9.23728098e-01 -1.48671510e+00\n",
      "  1.73480018e+00 -1.58732452e+00  8.54343843e-01 -1.97443405e-01\n",
      "  1.38182044e+00  6.34921520e-01  2.00389472e-01  1.12117996e+00\n",
      " -2.70268196e+00 -3.24479415e-01  2.53558404e-01  6.42745718e-01\n",
      "  6.51578510e-03  2.65708126e-01  1.32917626e+00 -3.23161395e-01\n",
      "  2.86921682e-02  1.57647060e+00  6.27220320e-01  7.47335062e-01\n",
      " -7.53680951e-02  5.32480731e-01 -3.63650221e+00  1.38876080e-02\n",
      "  1.85002033e+00  3.84199133e-01  2.00688839e+00 -1.96396878e+00\n",
      "  2.46261905e-02 -2.19785172e-01 -1.67338104e+00 -7.91091944e-01\n",
      " -1.74455228e-01 -9.42315760e-01  2.29544128e+00  3.75258305e-01\n",
      "  6.37229478e-01 -5.12601870e-01 -5.33065322e-02  3.02662397e-01\n",
      "  4.33132421e-01  3.05531794e-01 -8.40302930e-01 -4.49632555e-01\n",
      " -8.10104056e-01  1.44458489e+00  1.90499215e+00  6.89644408e-01\n",
      " -1.32057008e+00 -1.12055525e+00  4.81570461e-01  4.50964117e-01\n",
      "  9.31404806e-01 -2.08907230e-01 -1.19972944e+00 -1.84418454e-01\n",
      " -3.34173016e-01  4.33451529e-01 -5.41913035e-01  2.46944695e-01\n",
      "  1.43076593e+00 -2.86650850e+00  2.17496142e+00  1.19559183e+00\n",
      "  1.83626255e+00 -2.43815677e-01 -8.34914946e-01 -1.59454509e+00\n",
      "  2.55823713e+00 -3.81926886e-02 -3.46665474e-01  7.32395589e-02\n",
      " -4.30631144e-01  6.14799529e-01  1.50477721e+00 -2.59588469e-01\n",
      " -5.65763375e-01 -8.76998632e-01  1.75242172e+00  2.89210723e+00\n",
      "  2.11340938e-01  3.30688599e-01  8.01739411e-01 -7.95563956e-01\n",
      " -5.99609405e-01 -7.79269262e+00 -6.90145148e-02 -2.59230509e+00\n",
      "  2.42204847e-01  2.11385041e-01 -3.93714695e-01  3.69545012e-02\n",
      "  1.02528505e+00 -5.28942636e-01  3.04723336e-01 -8.41803553e-01\n",
      "  9.74657438e-01 -8.11084805e-01  3.07559018e+00  9.62051151e-01\n",
      "  5.24933207e-01 -5.50113457e-01 -5.61592386e-01 -2.74303139e+00\n",
      " -3.68382806e-01 -6.44040532e-02  5.82641300e-01  7.98505323e-01\n",
      "  9.45831556e-01  5.00763597e-01 -4.49539811e-01  4.79266623e-02\n",
      "  1.65073512e+00 -2.50902794e-01 -2.72495996e-01  1.73417151e+00\n",
      " -2.01305433e-01 -5.29110189e-03 -4.39480405e-01 -6.61925532e-01\n",
      " -4.00031245e-01  5.33441866e-01 -1.10414904e+00 -7.27911633e-01\n",
      "  2.64268974e-01 -8.35742149e-01 -7.00958870e-01 -7.02871345e-01\n",
      " -4.70950221e-01 -4.88088310e-01 -9.89420763e-02  1.11295577e+00\n",
      " -1.57064857e+00 -1.74864573e+00  7.95346522e-01 -8.60411861e-01\n",
      " -4.84691242e-01  2.12586968e+00 -6.62130969e-01 -4.35829778e-01\n",
      " -8.59633997e-01 -8.06667072e-01 -5.05791888e-03 -4.81208197e-01\n",
      " -1.14534467e+00  1.41223933e+00 -5.90784707e-01 -4.03207257e-01\n",
      " -6.74726293e-02  9.72214289e-01 -8.90439604e-01 -7.39850946e-01\n",
      " -3.80255900e-01  7.83470840e-01 -1.45461801e-01 -4.87803608e-01\n",
      "  8.23476846e-01  2.42035672e+00 -8.49654114e-01 -4.59446053e-01]\n",
      "------counter :130-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.60616365e-01  1.73679690e-01  2.12639796e+00  2.10159663e-02\n",
      "  2.67019984e-01  9.81044843e-01  2.41695658e+00 -1.32555910e+00\n",
      " -5.14461904e+00  3.86769243e-01 -3.44233687e-01 -1.26018023e+00\n",
      "  4.45758936e-01 -7.75255469e-01 -2.00703642e+00  8.37957954e-02\n",
      "  1.97866680e+00 -2.98756354e-01  4.87544750e-03  2.63839169e+00\n",
      " -1.25122533e+00  8.58858846e-01 -2.35403054e-01  3.41365663e-01\n",
      "  4.41980222e-01 -1.12913500e+00  1.94595930e-01 -4.79596652e-01\n",
      "  6.95953699e-01 -1.39071464e+00  2.28064300e-01 -1.90235041e-01\n",
      " -1.56283932e-01  3.84435229e-02  1.49356301e+00 -1.50091977e-01\n",
      " -6.21128187e-01  1.74543405e-01  6.42317944e-01  9.81432678e-01\n",
      "  8.68035185e-01 -1.77136686e+00 -2.33560365e+00 -4.95637104e-01\n",
      "  1.33356750e+00  1.06792338e+00  6.25592831e-01  5.45255924e-01\n",
      "  2.00722370e-01  3.69837669e-02  1.81319873e-02 -2.19294404e+00\n",
      "  8.74115681e-02  7.54688265e-01  1.19002358e+00 -1.80410227e-01\n",
      "  2.10334932e-01  1.57054751e+00  7.70920874e-01  7.37122872e-01\n",
      "  8.12488739e-02  7.13388782e-01 -4.04778982e+00  1.36804984e-01\n",
      "  2.41834065e+00  4.51456343e-01  6.62924021e-01 -6.14645825e-02\n",
      "  1.24489193e-01  4.93499049e-01 -1.75563632e+00 -2.23420734e+00\n",
      " -1.50466296e-02 -5.94485303e-01  3.36783928e+00 -1.26022497e+00\n",
      "  3.20925839e-01  5.88611239e-01 -5.04339339e-01  2.99229406e-01\n",
      " -1.55137824e+00 -2.32381173e-01 -5.64955937e-01  1.44725770e-01\n",
      " -6.97072843e-01  3.53986471e+00  5.16433712e-01 -3.36003164e-01\n",
      "  1.37208800e+00 -1.31341644e+00 -1.44622148e+00 -8.22826082e-01\n",
      "  7.07300414e+00 -5.98457678e-01  2.80279378e+00 -1.43211135e-01\n",
      " -3.78505042e-01  3.02097599e-01  4.05753862e-01  3.57717612e-01\n",
      "  1.33821321e+00  2.04835960e+00  5.84333141e-01 -1.07210223e+00\n",
      "  3.99386908e-01 -4.01934168e-01 -1.17044949e-01  2.08035338e-01\n",
      "  3.05517362e+00  1.73363080e-01 -4.59452109e-01  5.55775553e-02\n",
      "  8.17805022e-02  8.47081516e-01  6.45817376e-01  1.76485350e+00\n",
      "  1.66748673e-01 -5.93584715e-01 -1.34141802e+00  1.00269363e+00\n",
      "  1.42671199e-01  5.38594230e-01  1.20119249e+00 -2.65850169e-01\n",
      " -7.89124586e-01 -4.90879993e+00 -1.13745962e-04 -1.47517078e+00\n",
      "  1.73999310e-01 -1.89133596e+00 -4.32454875e-01 -6.53408014e-02\n",
      "  1.69728321e-01 -1.83249115e+00  4.81468630e-01 -4.70703351e-01\n",
      "  7.31934266e-01 -8.39815729e-01 -9.12174608e-01  3.42231131e-01\n",
      " -4.96115270e-01 -1.43059958e-01 -1.45773293e+00 -2.00349969e+00\n",
      " -2.41080916e-01  3.97082171e-01 -2.45819023e-01  1.58805369e-01\n",
      " -4.17795726e-01  5.97133667e-01 -5.86955993e-01  4.95695393e-01\n",
      "  2.64875117e-01  1.81726274e-01  3.20823687e-01  1.13442462e-01\n",
      "  6.34969900e-01  9.77766709e-01 -1.28124735e+00 -1.17850308e+00\n",
      " -7.38152631e-02  4.61334687e-01 -9.74839487e-01 -4.82344375e-01\n",
      "  4.50282176e-01 -3.13673061e-01 -2.11656488e-01 -4.77720013e-01\n",
      " -4.33860898e-01 -2.41515401e+00 -1.11474502e-01 -5.95049162e-01\n",
      " -8.39329132e-01 -9.47881129e-01 -2.72991780e-01 -7.51232189e-01\n",
      " -4.41782376e-01  2.08687714e+00 -4.16952428e-01 -4.08617573e-01\n",
      "  2.91529806e-02 -1.03129986e+00  1.52156315e-01 -2.64949171e-01\n",
      " -1.45942440e+00  2.12220866e+00 -1.37268460e-01 -1.95944751e-01\n",
      "  7.82164992e-01  8.82852765e-01  2.59939661e-01 -1.05656124e+00\n",
      " -4.24490525e-01  8.67476486e-01 -6.11457753e-01 -9.92912422e-02\n",
      "  5.70672738e-01  1.66988200e+00 -1.13618331e-01 -2.99492811e-01]\n",
      "------counter :131-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.83860393e-01 -2.64656270e-02  1.21916143e+00 -7.54557110e-02\n",
      " -8.99976746e-01  7.46504813e-01 -1.03017937e+00 -2.63153816e+00\n",
      " -1.54135116e+00  4.04877839e-02 -2.41390476e-01 -7.40847488e-01\n",
      " -6.72616534e-01  4.41469569e-01 -4.10437138e-01 -2.93176503e-01\n",
      "  5.97109382e-01 -1.47778377e+00  1.96358492e-01  2.36876791e+00\n",
      " -8.92391701e-01  7.11054808e-01 -1.27171909e-01 -1.21889467e-01\n",
      "  4.00190261e-01 -1.40851871e+00  4.60226942e-01 -5.93490443e-01\n",
      "  4.65076393e-03 -9.36996806e-01  1.69733443e-01  1.05426894e-01\n",
      " -1.11276253e-01 -4.74383526e-01 -1.07766104e+00 -2.94234744e-01\n",
      " -5.44587403e-01  2.10521307e-01  3.86010098e-01  7.87798398e-01\n",
      "  3.95374147e-01 -7.07137893e-01 -5.17309428e-01 -5.65506952e-01\n",
      "  6.62540563e-01  1.11134110e+00 -1.32525673e+00  3.73055920e-02\n",
      "  1.45881996e+00  1.03445697e-02  5.33960286e-01 -5.58769346e-01\n",
      "  7.50654758e-02  1.93392103e-01 -5.69259303e-01  1.65841263e-01\n",
      "  8.59326096e-03  2.24219939e+00 -1.87270683e+00  8.92217292e-01\n",
      " -6.65258568e-02  1.81764038e+00 -1.92630675e+00 -1.36133937e-04\n",
      "  2.42150219e+00  8.10070112e-01 -2.44323373e-01  2.69816333e-01\n",
      " -1.66793224e-01 -1.40155458e+00 -5.63042394e-01  1.39457211e+00\n",
      " -1.38457047e-01 -5.33781520e-01  2.70792830e+00  6.74953884e-01\n",
      " -3.40781960e-01  9.98400800e-01 -2.09422299e-01  1.13099040e-01\n",
      " -1.27349172e+00  2.46856344e-01 -1.30652236e+00  2.86088891e-01\n",
      " -5.06165125e-01  4.05978307e+00 -2.15375367e-01  5.01071847e-02\n",
      " -6.37709148e-02 -5.91429156e-01  9.80477486e-01 -4.29554405e-01\n",
      "  3.75263001e+00 -2.12407389e-01  1.44626900e+00 -2.66826170e-01\n",
      "  1.67790731e-01 -4.72690790e-02  4.65758459e-01  2.81432273e-02\n",
      "  8.79514996e-01  1.84206740e+00  1.12776302e-01 -5.43686013e-01\n",
      "  9.87192552e-02  1.11316299e-01  2.33610982e-01  3.86556947e-01\n",
      "  2.16557193e+00  4.39613736e-01  2.56151978e-01  2.02550877e-03\n",
      "  3.85106244e-02  7.42933801e-01 -1.48800159e-01  1.83457617e+00\n",
      "  2.87919516e-01 -5.05086920e-01 -3.43077195e-01  1.09570484e+00\n",
      "  1.41891400e-01  1.38872197e+00  1.46268515e+00 -2.25161126e-01\n",
      " -4.73066001e-01 -1.18920711e+00  7.53932988e-02 -9.49757061e-01\n",
      "  2.88280847e-01 -2.95554881e-01 -3.22624765e-01  3.97299983e-01\n",
      " -6.55070834e-01 -5.90658701e-01  4.81420262e-01  1.32069993e-01\n",
      "  7.21212217e-01  2.77512481e-01 -7.07187443e-01  8.63825381e-01\n",
      " -5.66798548e-02 -3.70749393e-01 -5.97905189e-01 -1.57250837e+00\n",
      " -2.18021273e-01  5.30842157e-02 -7.42249097e-01 -2.28347387e-01\n",
      "  3.62662795e-01  2.34161618e-01 -1.97359273e-01  6.57617476e-01\n",
      "  4.16877030e-01  1.14725614e-01  5.18327826e-01 -7.88497040e-01\n",
      "  8.38010650e-01  3.14535506e-01 -2.51189014e+00 -9.63254916e-01\n",
      " -5.09403289e-03  8.11517400e-01 -2.01996536e+00 -2.35349624e-01\n",
      "  2.34081719e-01 -3.75462644e-01  2.88739577e-01 -1.45240035e-01\n",
      " -5.22417535e-01 -2.80518202e+00 -1.64245584e-01  2.92080105e-01\n",
      " -2.19977073e-01 -7.97590700e-01  3.82288710e-02 -3.26939276e-01\n",
      " -3.62355873e-01 -2.63691519e+00 -2.83882041e-01 -2.73944084e-01\n",
      " -1.45816486e+00 -5.50843489e-01  3.87230119e-01 -2.54927375e-01\n",
      " -9.20594968e-01  9.06300144e-01  9.48872707e-02 -2.10202144e-01\n",
      "  1.00289657e+00  8.46087514e-01 -5.13306567e-01 -2.94571387e-01\n",
      " -1.00073213e-01  6.30769491e-01 -3.17808335e-01 -2.64427913e-01\n",
      " -8.79455652e-01  9.00325063e-01  2.72919883e-02 -4.89775173e-01]\n",
      "------counter :132-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.09312903e-02 -7.02064592e-01  1.39801558e+00 -2.65476208e-01\n",
      " -9.73189595e-01  1.03212756e+00  1.57646025e+00  1.81787749e+00\n",
      "  1.03797961e+00 -1.61504925e-01 -3.24077907e-02 -1.17420986e+00\n",
      "  4.12635952e-01  2.87896454e-01 -8.45721709e-01 -1.04114495e+00\n",
      " -7.15453136e-01 -1.18328776e+00  2.75783589e-01  2.43072110e+00\n",
      " -3.01229571e-01  5.88296872e-01 -2.42766964e-01 -2.60643482e-01\n",
      "  5.93466760e-01 -2.00042680e-01  7.73480080e-01 -1.32549624e-01\n",
      " -5.24087560e-01 -9.99093517e-01  3.37508707e-01 -1.43432123e+00\n",
      " -6.36717906e-01 -1.92563454e-01 -1.10448305e+00 -1.10471588e-01\n",
      " -4.46400484e-01  4.93729695e-01  4.20798270e-01  1.10102436e+00\n",
      "  4.13772017e-01 -2.02583255e+00 -4.47730173e-01 -5.01244471e-01\n",
      "  8.92967984e-01  1.35460548e+00 -4.04420753e-01  2.88041009e-01\n",
      " -7.09319049e-01  3.00006373e-01  7.01749899e-01  2.67296931e-02\n",
      "  1.65115946e-01  5.97493279e-01 -7.25044321e-02  3.47646350e-01\n",
      "  4.37047212e-01  2.30282747e+00 -3.03816087e+00  1.11771297e+00\n",
      " -9.49467287e-01  2.20013835e+00 -1.25218303e+00  1.31874567e-01\n",
      " -3.84001695e-01  1.36379509e+00 -1.33684842e+00 -6.92510917e-02\n",
      " -1.21330140e-01 -8.55231398e-01 -2.32726321e-01  1.51600157e-01\n",
      " -5.01744277e-01 -4.31520982e-01  6.42221520e-01  2.65150439e-02\n",
      " -7.50469631e-01 -1.45853087e+00  9.25888406e-03 -3.13467913e-01\n",
      " -4.60698300e-01 -1.20097864e+00 -2.73207565e+00  1.15708397e-01\n",
      " -1.24887532e+00  3.54005642e+00 -1.76899543e-01 -1.58980631e-01\n",
      "  1.59459538e+00  2.17346767e-01  1.35977667e+00 -2.07806685e-01\n",
      "  3.46756322e+00 -6.58420968e-02  1.49292474e+00 -4.05905038e-02\n",
      " -4.33943089e-01  2.74597141e-01 -1.26175680e-01  7.34481313e-01\n",
      "  1.10179786e+00  2.10656004e+00 -2.87262235e+00 -8.40650090e-01\n",
      "  1.16506846e-01  4.02118637e-01 -5.93351518e-01  2.04759942e+00\n",
      "  2.15453185e+00  8.37723998e-01 -4.40325685e-01 -5.30895696e-01\n",
      "  3.98530960e-01  8.53661707e-01 -1.94051865e+00 -1.26942715e+00\n",
      "  5.15482734e-01 -2.91238102e-01 -1.45322028e+00  9.96860734e-01\n",
      "  2.28591219e-01  1.28043665e+00  1.53459376e+00  7.17956129e-01\n",
      "  9.45735617e-01 -4.80608570e+00  2.20466423e-01 -1.63622841e+00\n",
      "  4.59198229e-01  2.79041357e-01 -6.71488664e-01  6.28193847e-03\n",
      "  2.33718357e-01 -1.85810234e+00  7.45499228e-01  3.33301552e-01\n",
      "  2.10244075e-01  1.49242745e-01 -1.27772103e+00  1.65761435e-01\n",
      " -1.56258461e-03 -6.99794260e-01 -4.15544872e-01 -1.09823998e+00\n",
      " -6.95499856e-01  1.42904897e+00  1.23263254e-01 -8.63488286e-01\n",
      "  1.22513111e+00  4.92402798e-01 -1.37444198e-01  1.12373432e+00\n",
      "  2.25962737e-01 -1.14746408e+00  1.44720223e+00 -4.66376393e-01\n",
      "  2.30399661e-01  7.49574903e-01 -1.01687280e+00 -5.21586654e-01\n",
      "  1.63977496e-03  1.17480202e+00  2.41579354e-01  2.68644946e-02\n",
      "  4.49234227e-01 -6.68765686e-01  6.36375109e-01  7.28718808e-03\n",
      "  1.01146199e-01 -1.57160411e+00  9.82059226e-03 -6.26990360e-01\n",
      "  5.20960494e-01 -7.98503695e-01  1.73637323e-01 -2.92882800e-01\n",
      " -1.48685369e+00  2.91014613e+00 -6.73961445e-01 -6.50561114e-01\n",
      " -1.53986121e+00 -2.89657432e-01  3.24546416e-01 -6.32734026e-01\n",
      "  1.14070027e+00 -1.58956932e+00  1.82141645e-01  3.74350458e-02\n",
      "  8.81590293e-01  1.21717706e+00  1.09775381e-01 -7.90072177e-02\n",
      " -8.93997442e-01  7.23737283e-01 -7.23272099e-01 -5.05661045e-01\n",
      " -5.56839931e-01  3.37296318e-01 -1.54706728e-02 -5.30470445e-01]\n",
      "------counter :133-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.39722560e-02 -1.53176815e+00 -2.73869176e-01 -5.24076265e-01\n",
      " -1.14167526e+00 -1.07424909e-01 -3.70490721e-01 -2.65630272e+00\n",
      " -1.67098886e+00 -4.30713446e-01  2.43229205e-01 -2.19799307e-01\n",
      "  6.04435310e-01 -1.41298488e+00 -9.94539648e-01 -8.70180872e-01\n",
      " -1.11772568e+00  1.63546063e+00  5.73160428e-01  3.69513758e+00\n",
      " -4.68600391e-01  5.89371153e-01  7.06173389e-02  2.02906927e-01\n",
      "  2.76968213e-01  3.48919956e-01  3.54555766e-01 -1.47435253e-01\n",
      "  1.38025002e-01 -3.44536918e+00  3.10014979e-01 -1.02427641e+00\n",
      "  3.17498160e-01  5.00373308e-01  9.69727368e-03 -4.41199519e-01\n",
      " -8.13953765e-02  4.98140135e-02  6.23608843e-01  1.83500383e+00\n",
      "  6.46627046e-01 -1.43353345e+00 -4.03247259e+00  3.07407699e+00\n",
      " -6.32495489e-02  1.67265740e+00 -8.94962870e-01 -2.01568399e+00\n",
      "  1.38544721e+00 -5.00213872e-02  1.57831544e+00  3.23337159e-01\n",
      "  5.06746597e-01  3.34812673e-02 -8.10352277e-01 -2.21136590e-01\n",
      "  1.17808136e+00  1.46706304e+00 -2.18091074e+00  1.57966835e+00\n",
      " -2.01479135e-01  2.30908825e+00  2.23049392e+00  2.99890795e-01\n",
      " -1.03120690e-03  1.57959893e+00  1.24380080e+00 -5.75355381e-01\n",
      " -6.67102535e-03 -8.63762545e-01  7.87726135e-02  2.87040503e+00\n",
      " -8.47044866e-01 -6.24058628e-01  1.87820745e+00  4.51682230e-01\n",
      " -6.32638418e-01  1.28000003e-01  3.42716486e-01 -4.90508836e-01\n",
      " -7.30174251e-01  1.48783941e-01 -1.85343745e+00  5.20227551e-01\n",
      " -1.34504645e+00 -1.10140095e+00 -4.07215289e+00 -9.31811014e-01\n",
      "  1.49776484e+00  1.71353272e-01 -7.14319507e-01  2.17874236e-01\n",
      "  2.16013303e+00 -1.16826255e-01 -4.01771814e+00 -8.25942469e-02\n",
      "  2.26809685e-01  2.36459318e-01 -5.88435314e-03  1.07786115e+00\n",
      "  9.52076804e-01  2.65824905e+00 -6.20921485e-01  1.29588008e+00\n",
      "  3.19549277e-01  5.42793764e-01  1.42533199e-01  6.35743515e-01\n",
      " -3.45578736e+00  8.93122200e-01  1.82254364e-02 -4.03358637e-01\n",
      "  7.64723029e-01 -4.94634559e-01  3.91356869e-01 -2.33707884e+00\n",
      "  5.10756623e-01 -4.04433848e-01 -1.80993603e+00 -8.71002757e-02\n",
      "  1.04410328e-01  1.32265905e+00  1.76212612e+00  4.25336022e-01\n",
      "  9.60384809e-01 -3.87962707e+00  5.17872502e-01  1.56243392e+00\n",
      "  5.60411989e-01 -4.80087371e-01 -1.97844781e-01  8.80520545e-01\n",
      " -1.11376639e+00 -1.40270489e+00 -8.69821184e-01  2.11673166e-01\n",
      "  3.72969573e-02 -6.98236443e-01 -2.40819145e-01  9.30807025e-01\n",
      "  1.27514165e-01 -4.57100640e-01 -4.02341119e-01 -1.05831440e+00\n",
      " -9.30611425e-01  3.70178204e-01  1.55176075e+00 -2.58245123e-01\n",
      "  4.71235762e-01  1.21786398e+00 -5.93132534e-01  1.40418335e+00\n",
      "  4.49252696e-01 -1.37442495e+00  2.16306136e+00  2.37170505e-01\n",
      "  4.21316687e-01 -5.31804250e-01 -2.32661495e+00  3.74380591e-01\n",
      "  1.42522297e-01  4.88468007e-02 -5.65706478e-01  8.91525476e-01\n",
      "  2.22249078e-01 -5.52954249e-01  8.87960758e-01  2.19859010e-01\n",
      " -1.61486200e-01  1.36934364e+00  9.39810739e-02  2.83907756e-01\n",
      "  5.93005362e-02 -7.30093540e-01  3.99242151e-01 -4.40025486e-01\n",
      " -1.88293218e+00  8.75113755e-01 -4.74049533e-01 -1.42160373e-01\n",
      " -1.13493085e+00 -2.07887478e-01  1.82549255e-01 -7.92648162e-01\n",
      "  1.11398586e+00  1.11086188e+00 -4.55884181e-01 -3.49634427e-01\n",
      "  4.51613450e-02  1.86849374e+00  5.21750961e-01  4.13652364e-01\n",
      "  7.77415718e-01  9.40725325e-01 -5.91567945e-01 -1.84267519e-01\n",
      " -3.20329448e-01  7.20523850e-01  8.26532426e-02 -7.86321017e-01]\n",
      "------counter :134-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09133982  1.781864    0.50051939 -0.68896851 -0.02236461  1.13975668\n",
      "  4.22240716 -2.07119257  0.39492683  0.61243486  0.89728238 -0.70170817\n",
      " -0.99384692 -0.05160326 -2.68763269 -1.44546693 -0.49469433  0.43969837\n",
      "  0.12167389  4.63909553  0.69942385  1.1957001  -0.12854621 -0.30203578\n",
      "  0.68929375  0.16222454  1.18733948 -0.57170205 -0.52147565 -1.00728306\n",
      "  0.12291414 -0.15602709  0.14398782  0.18488107 -1.24295371  0.0851136\n",
      "  0.28553133 -0.17079635 -0.30683272  0.26466093  0.49364357 -1.80676253\n",
      " -2.74047967 -0.705405   -0.33881112  0.91140349 -0.97656576  0.66185447\n",
      "  3.86368351  0.53301447  0.62712264 -2.66666388  1.18565731  0.75073845\n",
      " -2.13241022 -0.51211386  0.15091479 -0.77220928  1.30794767  1.29742561\n",
      " -0.28716388  2.11216357  4.37935409  0.07434711 -0.62485749  1.31743709\n",
      "  1.2022583   0.49077069  0.09426566 -0.81154203 -0.33519138  1.2491874\n",
      " -1.20421668 -0.46436802  1.97181231  0.7017706  -0.96145403 -0.86952549\n",
      " -0.19321352  1.06986023  0.27747172 -1.1729691  -1.39663505  0.63110862\n",
      " -1.35885565 -1.59717145 -3.15917557 -0.17596234 -1.3786078  -3.12470125\n",
      " -2.75436285  0.90169539  3.34697457 -1.44398471 -3.00102867 -0.34381127\n",
      " -1.27799037  0.01163176  1.29356379  0.6004222   0.45731034  2.63306197\n",
      "  0.90266913 -0.00716511  0.66119668  0.24335945  0.10943589 -0.45252522\n",
      "  0.82906759  0.8221151  -0.77027585 -0.38568285  0.12435958 -0.48077015\n",
      "  2.35528177 -1.76551159 -1.30605908 -0.16480751 -1.15374652  2.35697645\n",
      "  0.19201123  1.13198     2.10832787  0.11822767 -0.04505555 -1.6254413\n",
      " -0.69719092  0.76475032  0.21330799 -1.15812412 -0.85032621  0.87035978\n",
      " -0.52120334  0.9793687   0.16299366  0.43603004 -1.08476694 -0.2427381\n",
      " -1.03069192  0.50686827 -0.56985026 -0.48463671 -0.90182866 -1.14299737\n",
      " -0.93621421 -0.12832362  1.47961736  0.89037118  0.16493526  1.34288876\n",
      " -0.9332696   0.7938493  -1.90906269 -1.35917983  1.9144195  -0.68725232\n",
      "  0.40621061  0.63116959 -0.68005915 -0.43829359 -0.49640558  2.64881112\n",
      " -0.96515364  1.09332118  0.7180944  -0.82093981  0.96646632  0.03597626\n",
      " -0.19537624 -0.85182787  0.39331573 -0.62208275  1.25005348  1.51172544\n",
      " -0.07858584 -0.39876156 -1.4668088  -1.06976265 -0.59105206 -0.46417227\n",
      "  0.48821781  1.05383065  0.21719847 -1.10124537  1.0728471  -1.64003255\n",
      " -0.42771792 -0.36201492  0.27574689  1.48302891  0.50426975 -0.03858267\n",
      " -3.39074313  0.71867874 -1.09938222 -0.44747706 -0.2236924   1.10902099\n",
      "  0.28586783 -0.79967491]\n",
      "------counter :135-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.29222745  1.42447695 -0.47837858 -1.05295907 -0.83667725  0.84886121\n",
      "  3.46980932 -1.5424277  -0.42081225  0.14179498  0.0198417  -0.27492947\n",
      " -0.50198869 -1.0064411  -1.92292272 -0.85349005 -0.88708444 -2.40985591\n",
      " -0.39079446 -0.65039865 -0.84036595  1.14507472 -0.44948811 -0.34145217\n",
      "  0.65780111  0.0642151   1.06175715 -0.42772296 -0.74149227  0.25558083\n",
      " -0.04526478  0.41818078 -0.07842597  0.55449834 -0.70052347  0.02466943\n",
      " -0.15848933 -0.28391503 -0.30224103  0.48393751  0.65794317 -1.70751741\n",
      " -5.03430788 -0.18102524  1.6511397   1.20962179  1.06728507  0.27493452\n",
      "  2.51835322 -0.24358871  1.06433971 -0.93368729 -0.49373184  0.21682373\n",
      " -0.02412726 -0.39560556  1.0202334   0.07575926  2.65589014  0.12815054\n",
      " -0.09827461  1.95099576  4.4365277   0.09091856  3.69242569  0.96023081\n",
      "  1.02871881 -0.75109621  0.36958945 -0.93549062 -0.49078368  1.54288433\n",
      " -0.26178787 -0.25100041  1.90174325 -0.67440555  0.11066761 -0.64233942\n",
      "  0.01052959  1.08123696 -0.18540846  0.12125812 -1.27327968  0.58100936\n",
      " -1.67362098  0.94001574  0.8842274  -0.89376618  0.61870736 -1.18634738\n",
      "  0.25298777  0.18358948  1.12271109 -1.29679166  0.58449441 -0.31730322\n",
      " -0.70469451  0.11504989  1.05380141  0.79740504  1.0533468   1.95826162\n",
      " -0.27321153 -3.07062364  0.54431004  0.21529726  0.27694098  1.30991483\n",
      " -3.1877905   0.89507471 -0.12390317 -1.02109148  0.40740642 -0.24456135\n",
      "  0.39363289 -2.12148603  0.47349018 -0.81614082 -1.06003589  0.70027757\n",
      " -0.24793203  0.83112912  2.2973694   0.26442038 -1.0154454  -0.12152168\n",
      " -0.59106663 -0.11504863  0.3219939  -0.94151962 -1.07622986  0.41621188\n",
      " -0.98726829  0.76017574  0.06198241  1.04937752 -0.78010187 -0.28137192\n",
      "  2.76981199  0.52651153  0.14463789 -0.23508919 -1.21846118 -0.70344998\n",
      " -1.2372117  -0.17371835 -0.39803464  0.17149138  0.0199657   0.79740865\n",
      " -2.79884474  0.87456947 -1.55842358 -1.02506022  1.4291829  -0.90045226\n",
      "  0.5740817   1.51196236 -1.88793705 -0.08853557 -0.6357172   2.53357636\n",
      " -0.3553104   0.47921256  0.33446218 -1.13039458  0.4861877   0.01109254\n",
      "  0.64849709  0.76915136 -0.09989594 -1.24680329  0.9874681   0.77408722\n",
      " -0.6424643  -0.27509214 -2.20243609  1.01654246 -1.80754951 -0.07260572\n",
      " -1.45274219  0.93830417 -0.18298362 -0.41094187 -0.46070502 -1.36446462\n",
      " -0.11295209 -0.5201935  -0.22112997  1.52687858  0.26613897  0.254241\n",
      "  0.02198229  0.51708116 -0.84644723 -0.43518905 -1.05366667  2.12424018\n",
      "  0.13496866 -0.04504446]\n",
      "------counter :136-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.54691849  0.70266634  0.42690127 -0.5440958  -1.27448979  0.4180795\n",
      " -1.05265034  1.74615079 -1.07231395  0.34541834  0.26156098 -0.7812861\n",
      " -0.20721036  0.33983476 -2.26846036 -0.33316842 -0.72894066 -0.85893607\n",
      "  0.18108097  3.73907992 -0.69615143 -1.20213675  0.39188448 -0.19239477\n",
      "  1.07729655 -1.42891096  1.13357723 -0.16013776 -1.40880585 -0.82589507\n",
      " -0.4199428   0.80018601  0.06228263  0.63711521 -1.48368946 -0.40283549\n",
      " -0.56756656 -0.04065872  0.0987214   0.46511788  0.99608869 -2.21459336\n",
      " -3.65444922 -0.92648862 -0.00945629  1.02003977 -0.36279456  0.7849099\n",
      "  2.06567191  0.15341451 -0.18925577 -1.27696667 -0.49918929  0.74942831\n",
      "  0.06969929 -0.60216213  0.51924739  0.30896397  0.36581962  0.81689136\n",
      " -0.16483685  2.27101106  5.24416557  0.51577213  2.68121632  0.79366159\n",
      "  0.85016689 -0.65365259 -0.19588606 -0.45071066 -0.67049566  1.22290744\n",
      " -0.3774272  -1.09296699  3.39765769  0.90203288  0.09373042  1.77519045\n",
      " -0.22705687  1.51476965 -0.7615774  -1.62654305 -1.85387328  0.7961627\n",
      " -1.37127197  1.37791726 -2.29594207 -1.95839138  1.16343491 -0.95160292\n",
      "  0.67685096  0.60735723  2.60713898 -1.02381589  0.67773902  0.16367602\n",
      " -0.25131066  0.12482505 -0.03882634  0.8062393   0.71151915  2.31592421\n",
      " -1.01388971  1.10684994  1.32088422  0.21764652 -1.36453549 -0.7671874\n",
      "  1.79805038  1.59025128  0.04901048 -1.25588575  0.50221049  0.1294764\n",
      "  0.45004732 -1.15688256  0.36371389 -0.67029299 -1.10789834 -2.53619899\n",
      "  1.10596063  1.19217482  1.55489929 -0.38820792 -0.23786843  1.37164225\n",
      "  0.04264781 -1.81900312  0.20399059 -1.19614633 -0.36868887 -0.58145974\n",
      "  0.51082844 -1.65040622  0.2285621   0.7827626  -0.3049785  -0.87691954\n",
      " -0.7442251   0.38512662  0.06853085 -0.04486813 -2.0379309  -1.11240845\n",
      " -1.02563768 -0.35031868 -1.42653567  0.03683326  0.9743945   0.4348157\n",
      " -1.66339584  0.63541308  1.3709766  -1.09866782  1.76461721 -0.39156701\n",
      "  0.63239044  1.13489968  0.13994242 -0.03963416 -0.62837646  2.62725882\n",
      " -0.07347447 -0.85937065  0.07055479 -0.85004388  1.32656346  0.01055841\n",
      "  0.3084655  -0.71252618 -0.86257918 -0.45874626  1.582369    0.89008771\n",
      " -0.59184543 -0.04286336 -2.05999567  1.07459819 -2.02029225 -0.47826833\n",
      " -0.49167925 -0.5531583   0.42663681  0.34617505 -0.94764957 -1.49398856\n",
      "  0.05291435 -0.26314493 -0.94556736  1.59077454  0.20378737 -0.26821499\n",
      " -0.37537061  0.74608247 -0.80946299 -0.58082827 -0.56467872  1.73137159\n",
      "  0.17479355 -0.86783253]\n",
      "------counter :137-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.21385964e-01  5.46257443e-01 -1.80389950e-01 -4.57242150e-01\n",
      " -1.09388182e+00 -6.68948525e-02 -7.36291609e-01  3.79878464e-01\n",
      " -1.87319860e+00 -5.59738077e-03  2.95363151e-01  2.27923092e-01\n",
      " -9.33612639e-01 -1.35169494e+00 -2.13124564e+00 -1.42245853e+00\n",
      " -1.22214925e+00 -8.78380133e-01  8.86048091e-01  4.42112523e+00\n",
      " -1.03149002e+00  1.51559998e-01  1.01159494e+00 -6.77994575e-02\n",
      "  6.51431938e-01 -1.50619190e-01  1.21409764e+00  1.42897305e-01\n",
      " -2.76330001e+00 -2.56871078e+00 -2.38380913e-01  2.60598838e-01\n",
      " -1.62585534e+00  5.57863717e-01 -1.34326564e+00 -1.84145893e-02\n",
      " -4.59382751e-01 -3.78973701e-03 -8.73945040e-01  2.26096507e-01\n",
      "  1.17962546e+00 -1.87554461e+00 -3.83108945e+00 -7.36464782e-01\n",
      "  1.89833953e+00  8.44652468e-01 -1.34898153e+00  2.85521180e-01\n",
      "  1.79538744e+00  1.06614139e-01 -6.43469158e-01  2.15618357e-02\n",
      " -4.96836681e-01  7.19950692e-01  1.60429512e+00 -5.06705654e-01\n",
      "  1.48656606e+00  1.48408880e+00 -2.24226302e+00  9.82045972e-01\n",
      "  6.07536380e-02 -4.27205108e-01  4.99950587e+00  3.53698939e-01\n",
      "  1.47408485e+00  1.42574515e+00  6.48858588e-01 -1.03213796e-01\n",
      "  7.78358991e-02 -3.45063700e-01 -4.97989712e-01  9.40512487e-01\n",
      " -1.43331506e-01  6.52069263e-01  9.23042249e-01  3.08548311e-01\n",
      "  2.05215135e-02  5.29577698e-01 -9.15851040e-02  1.16897542e+00\n",
      " -1.63270199e+00  8.38456852e-01 -1.01537599e+00  1.17791756e+00\n",
      " -1.88588174e+00 -1.75992004e-01 -5.53604879e-01  1.88338533e+00\n",
      "  7.24643791e-01  7.76584931e-02  1.60629128e+00  1.17629242e+00\n",
      "  1.92806538e+00  1.89987134e-01  4.29654169e-01 -7.00891865e-02\n",
      " -3.59023218e-01  6.49856218e-01 -3.73462409e-03 -5.24176233e-02\n",
      "  1.38958858e+00  1.04403659e+00 -8.16674735e-01  1.23475639e+00\n",
      "  9.93704916e-01  2.26764131e-01 -1.02396168e+00 -6.93329602e-01\n",
      " -1.53057254e+00  1.04901505e+00  8.54418489e-02 -1.61021423e+00\n",
      "  5.28422092e-01  5.17237111e-01  7.25686507e-02 -2.02312752e-01\n",
      "  2.22777120e-01 -7.57204390e-01 -9.28259236e-01 -2.20504128e-01\n",
      "  9.36387435e-01  1.67456970e+00  1.14665380e+00 -2.08347571e-01\n",
      " -7.14462598e-01  1.19273797e+00 -1.59058739e-01 -3.75316018e+00\n",
      "  6.56759312e-02 -2.17349139e+00 -8.37818104e-01 -7.57296883e-01\n",
      "  8.80716526e-01 -1.97047494e+00  6.09226592e-01  1.40702204e+00\n",
      " -1.82847223e+00 -7.30656901e-01  1.34694386e+00 -1.38876726e-01\n",
      " -6.76580731e-03 -1.95299826e-01 -2.16064713e-01 -1.20288951e+00\n",
      " -1.39958032e+00 -2.25800700e-01 -2.43833575e-01 -7.60697912e-03\n",
      " -4.45734696e-01  3.88924435e-01 -3.97219395e+00  1.01923325e+00\n",
      "  7.89579878e-01 -1.82384384e-01  2.03634657e+00  2.96202015e+00\n",
      "  4.13100133e-02 -2.37929102e-01 -2.03455526e+00  1.52258621e+00\n",
      "  2.79885683e-01  1.28036479e+00  5.02277632e-01  2.06502698e-01\n",
      "  3.74369478e-01 -1.20828172e+00  1.33643476e+00 -5.67120342e-02\n",
      "  1.99096674e-02 -1.10740278e+00 -9.70998185e-02  3.79688360e-03\n",
      "  1.14538321e+00  3.14190178e-01 -5.56258132e-01 -1.92604849e-01\n",
      " -1.69147505e+00  1.77480671e+00 -1.26735254e+00 -4.13585176e-01\n",
      " -2.41997545e+00  2.82366578e-01  4.92503001e-01  4.32551909e-02\n",
      "  5.32497158e-02 -1.95429847e+00 -1.31372452e-02  8.14776703e-01\n",
      "  7.46791890e-01  9.46291367e-01  1.72722874e-01 -2.59766211e-01\n",
      "  2.39376392e+00  5.85869438e-01 -6.96440850e-01  2.12353112e+00\n",
      " -8.13627644e-01 -4.14025780e-01 -5.85512245e-01 -9.93327542e-01]\n",
      "------counter :138-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.81141318e-01 -2.29413205e+00  6.84128916e-03  7.80539956e-01\n",
      " -9.27295636e-01  6.26699329e-01 -4.87843089e+00  1.90526590e+00\n",
      "  1.64396605e+00  3.28472187e-01  1.38717432e+00  1.62737822e+00\n",
      " -8.74520256e-01 -2.32087035e+00  4.20103192e-01 -4.25496779e-01\n",
      " -3.71577818e+00 -3.51483823e-01 -1.48192935e+00  4.73619776e+00\n",
      " -2.21626128e+00  4.34874301e-01 -1.98538663e+00 -1.26487474e+00\n",
      "  1.21124360e+00  1.49615727e-01  1.40326798e+00 -6.99201909e-01\n",
      " -2.41464920e+00 -2.26497537e+00  4.48952294e-01  2.44024906e+00\n",
      " -5.88749931e-01 -2.71170041e+00  1.57475675e-02 -8.06273245e-01\n",
      " -7.27239602e-01  6.46813080e-01 -1.75161335e+00  2.30405545e+00\n",
      "  1.11319922e+00 -2.02519838e-01 -2.02703105e+00  1.24168643e+00\n",
      " -2.71937963e-01 -5.19369743e-01  1.35379076e+00 -1.78749897e+00\n",
      " -1.10085689e+00  9.04693745e-01 -1.20712419e+00  1.34102802e+00\n",
      "  2.73062594e-01  6.46246034e-01  2.00922979e+00  1.21421761e+00\n",
      " -5.82763417e-01  1.49324799e+00 -9.71250218e-01  1.07099306e+00\n",
      " -2.09989600e-01 -3.81864980e-01  4.22057200e+00 -1.73316340e-01\n",
      "  1.15567468e+00  2.34272920e-01 -1.01852616e+00  1.33738626e+00\n",
      "  1.19545309e+00 -1.25487044e+00 -9.75382832e-01 -7.96910175e-01\n",
      "  5.26266039e-01 -4.90877294e-01  2.64559321e+00  3.82759382e+00\n",
      "  3.26914848e-01 -2.56508071e-02  2.92804785e-01  1.88823913e+00\n",
      "  2.85953699e+00 -2.48669561e+00  8.18503674e-01 -2.95646900e-01\n",
      " -2.18857950e-01  1.16137018e+00  9.77263976e-01 -3.71174500e-01\n",
      "  2.00209213e+00  1.69424308e+00  1.63300929e+00  1.08117811e-01\n",
      " -9.63006016e+00  5.02034769e-01  3.71443457e+00 -1.22103154e-01\n",
      " -1.03624026e+00  7.44478799e-01  1.45275680e-01 -1.14294952e+00\n",
      " -1.12949320e+00  7.49039069e-01 -2.43417521e+00 -1.31988461e+00\n",
      "  2.19585522e+00 -1.04552013e-02 -2.84457296e-01  1.67255346e+00\n",
      " -3.95494879e+00  1.15403739e+00  1.73140143e+00 -5.31522060e-01\n",
      "  1.35637995e+00  1.22494028e-01 -2.60977465e+00 -3.00300921e+00\n",
      "  8.23244712e-01  1.40307562e+00 -2.07137999e+00  4.43550746e+00\n",
      "  9.29862512e-01  3.74393681e-01  1.58579836e+00 -4.69292044e-01\n",
      " -1.17714580e+00  6.32549793e+00 -5.00202143e-01 -2.92661088e-01\n",
      "  3.88693249e-01 -2.58046724e-01  1.56853129e-02 -1.32310043e+00\n",
      " -3.11044749e-02  8.23882108e-01 -4.28913690e-01 -1.16499546e+00\n",
      " -5.88861984e-01 -3.40235692e-01 -5.32400005e-01  2.88071552e-01\n",
      " -8.92031292e-01 -4.30662996e-01  1.31846674e+00 -9.59686322e-01\n",
      " -2.90338260e+00  1.68508751e+00 -4.06757481e-01  9.68942219e-01\n",
      "  4.80405701e-01  6.54771089e-01 -1.40424175e+00  6.27809173e-01\n",
      " -9.41550202e-01 -2.60561602e+00  6.83406921e-01 -1.22447092e+00\n",
      " -5.61108214e-01  2.62427864e-01  1.91070938e+00  1.49139761e+00\n",
      " -2.59639714e-01  8.44934840e-01 -2.42470098e-01 -2.83293118e-01\n",
      "  8.26410328e-01  1.11493538e+00  1.88633406e+00  1.16180584e+00\n",
      "  9.85374516e-01  6.91226738e-03  2.89309838e-01  3.70793836e-01\n",
      "  5.85204813e-01 -4.58933292e-01 -8.30619648e-01 -4.73436783e-01\n",
      " -2.03516042e+00 -4.20086313e+00 -1.56688240e+00 -1.98176570e-01\n",
      " -2.81796951e+00  2.16760396e+00 -3.00969158e-01 -1.06301486e+00\n",
      " -6.36705725e-01 -3.67570186e-01 -3.44531602e-01 -5.10007359e-01\n",
      "  4.94664806e-02  4.05370435e-01  5.74553252e-01  4.35365627e-01\n",
      "  2.36431149e+00  2.20014489e-01 -1.04735170e+00  2.10970860e-01\n",
      "  1.97234769e+00 -4.71521195e+00 -3.39800107e-01  4.78464009e-01]\n",
      "------counter :139-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3250846  -3.42842948 -0.20428628  0.05054189 -2.13108948  0.31926668\n",
      " -3.21747999  0.42448892 -0.65142532 -0.78410645  1.00685436 -0.12849177\n",
      " -0.30014147 -0.50105572  0.37326822 -1.48337098 -1.32015911 -2.43329783\n",
      "  0.42686443  3.56148051  0.9712877   1.36776714 -0.75143713 -1.7505024\n",
      "  0.65943551 -0.0163811   0.78346008  0.24781326  0.17633781 -2.04515112\n",
      "  0.89533977  1.71908065  0.08572755 -1.92219175 -0.56108897 -1.26450298\n",
      " -0.35666781  0.50454241 -0.1258046   3.09604645  0.86092451 -1.81587141\n",
      " -2.17236151  1.07562682 -0.80479181  0.60305894 -0.63045004  0.04549956\n",
      " -0.53806036 -1.07301358 -1.68241908  0.33964061  0.461719    1.00215336\n",
      "  0.76580186  0.32565757  1.15755257  1.29994742 -0.10574682 -0.07284231\n",
      "  0.81624255  0.09022501  3.99480087 -0.18540732 -0.86498623 -1.29875445\n",
      " -1.07454158 -0.19471477 -0.56718908 -0.47388083 -2.07143227  1.15658697\n",
      " -1.08625301 -0.72004058  3.4796097   1.24377513  0.03684223  0.33008226\n",
      "  0.80937729  0.57940966  0.78761656 -1.35646483 -0.56442595 -0.21505829\n",
      " -0.79864631  1.3512834  -0.23551411  1.73634144  1.80624008  0.99271023\n",
      "  0.33575828 -0.21702249 -0.37581008 -0.2401187   3.1031753  -0.44128107\n",
      " -1.06232516 -0.79740441  1.49802208 -2.19419177 -1.0813519   1.15842615\n",
      " -0.70844761  3.53650956 -0.06653415  0.33022992 -0.29019986  0.18630785\n",
      "  5.21594235  1.17459867  1.0614799  -0.79856366  1.02576458 -2.782834\n",
      "  0.20692649 -1.46855259  0.16556586  0.36822688  2.32126853  2.91246585\n",
      " -0.13310047 -0.50396623  1.25556515  0.14232166 -0.87578904 -2.38273127\n",
      "  0.20139614  2.49040431 -0.15664806  5.86323751 -0.5350612  -1.61134263\n",
      "  0.92141394 -0.12488515 -0.92267635 -0.28490808 -3.43843419 -0.11868545\n",
      "  0.90891221  0.93523489 -1.4220272  -0.66648285 -1.23173106 -1.15036525\n",
      " -2.13253335 -0.36299009 -0.68047493 -0.52607973 -0.32647002  2.3487286\n",
      " -3.21738599  0.58135253 -1.3367018  -1.28895722 -0.74675046 -1.7304756\n",
      "  0.49207671  0.09575808 -0.92149011  0.39385357 -0.16089226 -1.85638344\n",
      " -0.73942961  1.02531331 -0.79474216  0.23523129  1.26643106  0.17262292\n",
      " -0.31525376 -0.8440281  -0.63660239  1.07123227  0.57108924  2.85640513\n",
      " -0.69611818 -0.91745986 -0.15263787  6.21198384 -1.7424342  -1.10599178\n",
      " -0.05944029 -0.17625908 -0.35196031 -0.51581569  1.07968547 -0.9139927\n",
      " -0.00629913  0.60025444 -1.504609   -0.49504316  0.70955102 -0.5053752\n",
      "  1.5807536  -0.94691628 -0.15522523 -0.66292176  1.58139055 -0.97346849\n",
      "  0.65655707 -0.42982887]\n",
      "------counter :140-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.55924018e-01  2.43882549e+00  4.61935123e-01  3.65638514e-01\n",
      " -7.62137109e-01 -2.34028905e-01  2.38292764e+00 -1.46679537e+00\n",
      " -3.89859491e+00  5.45688016e-02  2.07085951e+00  2.50823098e+00\n",
      "  1.04017709e+00 -4.69517319e-01  1.62406477e+00 -2.63129690e-02\n",
      "  4.91509941e+00 -9.81195438e-01  4.04885898e-01  3.68328904e+00\n",
      "  3.40504456e+00  5.42010626e-01 -5.08447465e-01  6.84427776e-02\n",
      "  4.68946449e-01 -6.62348432e-01  1.53659734e+00  1.78935734e+00\n",
      "  5.01195907e-02 -3.29714324e+00  1.85088945e+00  1.67513230e+00\n",
      "  2.21800637e-01  8.21570110e-01 -2.00818903e-01  2.41919133e-01\n",
      " -1.84073022e+00  1.02780762e+00 -6.18475332e-01  1.89186344e+00\n",
      "  2.45344058e+00 -6.50295972e-01 -9.62528812e-01 -1.04415761e-02\n",
      "  3.78173343e-01  1.61112344e-01  1.43976574e+00 -7.18463511e-01\n",
      "  2.37986194e+00  3.51024717e-01 -3.03988550e+00 -3.53605278e+00\n",
      " -5.51508870e-01 -9.03470515e-02  1.05899115e-01 -2.22481331e+00\n",
      "  1.55679744e+00  1.73735478e+00 -5.31832392e-01 -1.06808818e+00\n",
      " -5.15912186e-01  4.43967308e-01 -9.60573630e-01  1.03031001e+00\n",
      " -8.58690734e-01  1.57749647e+00  1.50340185e+00 -4.29886725e+00\n",
      "  2.41304241e-01  2.17838289e-01 -2.79254722e+00 -1.66130855e+00\n",
      " -1.17768934e+00 -1.89990475e+00 -3.09965032e-01  3.26593681e-01\n",
      "  2.37188124e+00 -3.23992975e+00  7.47983561e-01  5.19317447e-01\n",
      "  2.86387688e+00  9.31946523e-01 -1.54351562e+00 -2.42402809e-01\n",
      " -3.35294268e-01 -5.99429297e+00  5.04817020e+00  3.94140154e+00\n",
      " -1.14667909e-03 -1.02403673e+00  3.38312617e+00 -9.39528547e-01\n",
      "  4.65400554e+00  1.74230930e-01  4.52706613e+00 -1.68012520e-01\n",
      " -1.16270788e-01 -5.21595384e+00 -6.79285786e-01  9.82129540e-01\n",
      " -3.91082313e+00  5.89585147e-01  5.90028598e-01  2.42850914e+00\n",
      "  2.23940420e-01 -1.12359584e+00 -8.18539118e-01  1.80587986e+00\n",
      " -1.37075419e+00 -1.39527822e+00 -4.09965802e-01  3.06324726e-01\n",
      "  8.60666011e-02 -3.75536432e+00  8.96744100e-01  4.21666190e-01\n",
      " -1.07659227e+00 -2.06354344e+00  2.09292295e+00 -1.90689812e+00\n",
      "  2.47861391e-01  3.13947756e-01  7.77796344e-01 -8.35987200e-01\n",
      " -1.19301138e-01 -3.29441652e+00 -5.52342606e-01  2.45909137e+00\n",
      " -1.05276435e+00  3.45311087e+00 -1.08041537e+00  1.62392384e-01\n",
      " -3.99001038e+00 -1.00988864e+00 -1.46837842e+00 -1.72441084e+00\n",
      " -1.46777489e-01 -9.70643421e-01 -2.46938183e+00  1.31629970e+00\n",
      " -1.59957797e-01 -1.20293301e+00  2.21945232e+00 -2.24944827e-01\n",
      " -2.65243880e+00 -9.15239321e-01 -1.43583535e+00  1.85590460e+00\n",
      "  5.53875542e-01  2.24510803e+00  9.15954698e-01  7.31910393e-01\n",
      "  5.37238351e-01 -2.51073624e+00  6.95223233e-03  8.89492116e-01\n",
      "  1.95405310e+00 -7.06543537e-01 -4.51368424e+00 -4.45600440e-01\n",
      " -4.00365953e-01  8.98215847e-01  2.00376140e+00  1.16420534e+00\n",
      " -9.80403981e-01  5.35478377e-01 -1.20846650e+00 -8.00953288e-01\n",
      " -4.18937181e-01 -3.84959191e+00 -3.84112842e-01 -2.64337299e+00\n",
      "  2.66635456e-01  3.13135854e+00 -2.66613898e+00 -9.45677688e-01\n",
      " -1.32950529e+00 -3.61556667e-02  8.17483895e-01  8.67872786e-02\n",
      "  1.57697950e+00  2.16404807e+00 -1.01002399e+00  8.16407788e-02\n",
      "  1.41698415e+00 -2.15770505e+00 -2.32372504e-01  6.17687104e-01\n",
      " -1.33059797e+00  2.77633255e-01  5.82425425e-01  1.86785501e-02\n",
      "  1.17653255e+00  1.14889060e+00  8.68442605e-01  1.02796215e+00\n",
      " -8.68655033e-01  2.43606151e+00  4.88416161e-01 -1.10101904e+00]\n",
      "------counter :141-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.76762109  1.48207178 -0.5927643  -0.87708707  0.31677565  0.21065673\n",
      "  0.16999032  2.37070869 -0.58008935  0.34287142  0.64201291  0.48093063\n",
      " -0.35848017 -0.44716093  0.11390289  1.01174815  3.92937795 -1.88405284\n",
      "  0.08750537  4.11868918  1.45174519 -0.14852517 -0.50521952 -1.08398592\n",
      "  0.21379094  0.81191156  0.51206567  0.20853819  1.02734506 -4.42965844\n",
      "  0.79939966  1.27830277 -0.60207361 -0.46541349 -1.4241514   0.06190275\n",
      " -0.06801819  0.01737791 -0.10478615  0.04021514  0.63159798 -0.96120223\n",
      " -1.61609276  0.2492964   0.27890603 -0.17421943 -0.25249513  0.84820628\n",
      " -1.47922087 -0.37522434  0.07951726 -3.50888636  0.6511901  -0.07933245\n",
      "  0.27850961 -0.98027816  2.72823108 -1.16682834 -0.59486543 -0.32156661\n",
      " -3.0680356   0.16074902  0.20983093  0.29107693  0.20165569  0.92698648\n",
      "  0.08888021  0.13876191  0.39880224  0.89047024 -1.09692355  0.22102133\n",
      " -0.61092871 -0.89195895  0.9958581   0.89621103  0.80963005 -2.0857402\n",
      "  0.03816585 -0.76271107  0.41065085  0.49142876 -0.96830381 -1.08264595\n",
      " -0.53468109  1.41429132  1.61429664  0.61156036 -0.76423065  0.51139278\n",
      "  0.86915213  0.66412984  1.2713584  -1.51604744  3.17579876 -0.58137723\n",
      " -0.77466079 -0.3130536  -0.56076226 -0.31431556 -2.11522566  2.44029653\n",
      " -0.51763664  1.31737176 -0.58535575 -0.4954695  -0.08856178 -1.11625289\n",
      "  2.92491434 -0.20610075  0.35586882 -0.50296191 -0.20960081 -1.35975889\n",
      " -0.32040181 -0.5847134  -1.24749955 -1.57962166  1.44518796 -0.30009545\n",
      "  0.44689994 -0.63318292  0.16705245 -0.2320708  -0.80737475  0.75603788\n",
      " -0.17171312  5.47008342  0.10754664 -0.37239815 -1.07362126 -0.25003334\n",
      "  1.34426112  0.40701647 -1.2031029  -0.25256324  1.38481434 -1.50702138\n",
      " -1.92904723  0.28741606 -0.05455519 -1.08870754  1.54524381 -1.77484886\n",
      " -1.84168811  0.42352105  4.24959004 -0.4145403  -0.37879597  1.15513876\n",
      " -0.16236057 -0.1097283  -1.03570332 -0.85005791  0.1981144  -0.45608863\n",
      " -0.60624511  1.19512451 -1.02536206  0.55414802 -0.31102008  0.17779135\n",
      "  0.46993976  0.33815773  0.30905728 -0.53999894 -0.75222565  0.97464761\n",
      " -0.70209744 -0.54355138 -0.16130575 -1.44310988 -1.19401598 -0.53594579\n",
      " -0.84333406 -1.2851395  -0.76595035 -0.58573562 -1.81376409 -0.43603736\n",
      "  0.13623596  3.43232252 -0.74074504 -0.48738563  0.71658472  0.85980882\n",
      "  0.52657588  0.32058829  0.01329415  0.4980409   1.14840841 -0.63609685\n",
      "  0.69592339  0.60927515  1.15172981  1.11721585 -0.42374821  0.1160568\n",
      " -0.4081379  -0.68966468]\n",
      "------counter :142-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.31129505e-01  2.07268228e-01 -4.85922549e-01 -1.13279916e+00\n",
      " -2.75958941e-01  1.73242496e-01  1.01465177e+00 -2.73482590e+00\n",
      " -3.09462579e+00  4.78978892e-01  8.46770417e-01  8.37229010e-01\n",
      "  3.50029966e-01 -4.38135456e-01  1.52365868e+00 -8.34542057e-03\n",
      "  2.52740867e+00 -2.16576496e+00  3.86730612e-01  5.47804386e+00\n",
      "  8.13173912e-01  3.15840069e-01 -6.39540606e-01 -8.78418306e-01\n",
      "  1.35768955e-01  1.33946808e+00  7.30562693e-01 -1.02651559e+00\n",
      "  1.19801084e+00 -9.25669142e-01  1.03469010e+00  1.25856239e+00\n",
      " -2.30751832e-01  5.12903767e-02 -1.71514882e+00 -1.43379024e-01\n",
      " -3.24824924e-01  1.50756568e-01 -2.23663708e-01 -5.34782148e-02\n",
      "  9.18331046e-01 -1.02287530e+00 -1.71895279e+00  5.20344926e-01\n",
      " -1.31243113e+00  1.74093223e-01 -4.25747752e-01  4.97515019e-01\n",
      "  9.72406741e-01 -5.37999323e-02 -4.25535321e-01  6.88488161e-01\n",
      "  7.07284022e-01  4.99362172e-01 -1.06214584e+00 -1.43181614e+00\n",
      "  1.88009144e+00  1.34925800e+00  1.32211728e+00  4.86724553e-01\n",
      " -3.17092008e+00 -7.54108560e-01 -8.67823988e-02  2.30382275e-01\n",
      "  2.43741020e+00  4.29795116e-01 -1.56361589e-01 -7.72570391e-01\n",
      "  1.00678548e-01  5.35393448e-01 -8.52374323e-01 -1.66157036e+00\n",
      "  6.93054159e-01 -4.76817706e-01 -3.53918153e+00  8.22630953e-01\n",
      "  6.55555205e-01 -1.70767097e-01  5.19415273e-01 -6.41294097e-02\n",
      "  9.49132884e-01  3.57812984e-01 -4.54293550e-01 -1.01839347e+00\n",
      " -7.33247419e-01  1.39480135e+00  8.12999965e-02  6.43169779e-02\n",
      " -7.64669903e-01  4.94545104e-01 -5.79991281e-01 -3.08927169e-01\n",
      "  3.64712493e-01 -5.42945160e-01  2.69337386e+00 -6.43244310e-01\n",
      " -1.23135452e+00 -3.34080047e-01 -9.04236101e-02  2.46339248e-02\n",
      " -1.49807263e+00  2.22684992e+00 -3.18398241e+00  1.70351203e+00\n",
      " -7.59910347e-01 -5.81337050e-01  1.25570084e-01 -2.26811808e+00\n",
      "  2.32685236e+00 -7.47564065e-02  4.68516036e-01 -7.28284663e-01\n",
      " -2.20750566e-01  1.46680550e-01 -2.10825623e+00 -4.79380658e-01\n",
      " -2.09935829e-01 -1.33537833e+00  9.54997213e-01  2.62406780e+00\n",
      " -1.46861877e-01 -6.61173726e-01  1.81267113e-01 -4.15414187e-01\n",
      " -6.97818261e-01 -5.34987255e-01 -5.21897224e-01 -1.53299389e+00\n",
      " -1.01410507e-01 -4.06218732e-01 -9.14486915e-01 -4.11659378e-02\n",
      "  1.33892987e+00 -2.09735045e-02 -4.14353711e-01  4.01391202e-01\n",
      " -3.23501068e-02 -3.86494747e-01  8.73787751e-01 -1.21403102e-01\n",
      " -2.68299395e-01 -9.10997958e-01  1.48733832e+00 -1.88212062e+00\n",
      " -1.55376953e+00 -1.17316283e-01  3.57349331e+00  8.35650653e-02\n",
      " -1.45143022e-01  6.04489480e-01 -1.06334732e-01 -2.17918541e-02\n",
      " -1.25493991e+00  1.21425313e+00  2.97215492e-01 -1.13250778e+00\n",
      " -9.31152655e-01  1.57318658e+00  1.57447296e-01  2.54601388e-01\n",
      " -3.62460420e-03  7.12437010e-01 -1.01733726e-01  3.00498491e-01\n",
      "  6.85567480e-01 -7.94742315e-01 -7.53539463e-01 -3.64574818e-02\n",
      " -5.93591915e-01  1.70988163e+00  2.26583942e-02 -2.01935626e+00\n",
      "  6.92289230e-01  2.52848806e+00 -1.56396081e-01 -1.02430497e+00\n",
      " -1.28697293e+00 -8.38328561e-01 -1.36622729e+00 -5.95733701e-01\n",
      " -1.07589551e+00  6.18811634e+00 -5.85046222e-01 -5.74131339e-01\n",
      "  1.59449069e+00  3.63258162e-01  2.38498885e-02  5.13073289e-01\n",
      " -2.44915114e-01 -2.16188291e-01  2.73096153e-01  1.95057810e-01\n",
      "  1.43105614e+00  7.09753413e-01  4.18616908e-01  2.24582897e-01\n",
      " -5.03449092e-01  7.51650952e-01 -5.12942677e-01 -4.78058747e-01]\n",
      "------counter :143-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.86098996e-01 -9.43825418e-01  1.36165373e+00 -8.72716288e-01\n",
      "  1.52720778e-01  7.63878218e-01  9.68124027e-01  6.58106277e-01\n",
      " -1.80089785e+00  6.31457565e-01  1.29168340e+00  3.83394221e-01\n",
      "  1.41157950e+00  5.61784259e-01  3.75566525e-01  4.88323772e-01\n",
      "  2.31580561e+00 -8.91396518e-01  9.12138220e-01 -5.06881862e-01\n",
      "  1.07933685e+00 -1.15056402e-01 -1.87759248e-01 -5.72996010e-02\n",
      "  1.14645771e-01 -1.02378580e+00  9.99540502e-01 -9.88383445e-01\n",
      "  1.02867620e+00 -2.77844587e+00  1.13598243e+00  1.40685734e+00\n",
      " -8.26526735e-02 -8.64194120e-01 -3.36260340e-01 -3.45498507e-01\n",
      " -1.03814295e-01  2.51539726e-01 -2.07800292e-01 -1.05496696e+00\n",
      " -5.35034512e-01 -3.60330413e-01  4.58774267e+00  3.90344842e-01\n",
      "  1.11375474e+00 -2.14812284e-01 -4.53694847e-01 -3.85022365e-01\n",
      " -3.26155049e-01 -8.99896800e-02 -5.26311258e-01  3.12963354e-01\n",
      "  5.23285204e-01  4.43336843e-01 -1.45055433e+00 -1.02764756e+00\n",
      "  2.25306951e+00 -1.42593825e-02 -5.46597459e-01  5.43855778e-01\n",
      " -3.13184144e+00 -4.43120206e-01  1.24908722e+00  2.40037684e-01\n",
      "  7.58930076e-01  4.71646861e-01  4.42210120e-01  1.51591492e-01\n",
      "  5.54104177e-02 -2.97496920e-01  5.87912760e-01 -2.40362724e+00\n",
      "  1.80334271e-01  4.16784556e-02 -2.98963555e+00  1.00443945e+00\n",
      "  6.65014717e-01 -1.28105325e+00  1.67516546e-01 -2.54015778e-03\n",
      "  1.87703104e+00 -2.43591668e-01  4.30776025e-01 -7.98596989e-01\n",
      " -4.81210288e-02  1.89529531e+00  2.22789440e+00  3.92965734e-01\n",
      " -3.21089031e-01  3.71042398e-01 -7.33954063e-01 -2.36224342e-01\n",
      "  1.36900383e+00 -1.47759112e+00 -1.11272395e+00 -5.22882392e-01\n",
      " -1.19272069e+00  1.22651498e-01 -1.63346374e-01  6.47626685e-01\n",
      "  1.91641481e-01  1.60008013e+00 -8.15442916e-01  1.18179650e+00\n",
      " -9.26039823e-01 -6.73930476e-01 -1.61410188e-01 -2.02030958e+00\n",
      "  2.89718927e+00 -8.81665863e-02  5.98582735e-01 -5.49454802e-01\n",
      "  4.18202811e-02  7.62375517e-01  1.64094138e+00 -1.55175540e+00\n",
      "  2.73025097e-01 -6.25694360e-01  1.82803907e+00 -1.54508221e+00\n",
      " -1.02579612e-01 -4.75735970e-01  2.26970073e-01  3.00508233e-02\n",
      " -6.40797902e-01  7.51201769e-01 -4.79134256e-01  5.88328365e-01\n",
      " -1.49276908e-01  5.66718396e-01 -9.31034783e-01 -3.95754038e-02\n",
      "  1.88886828e+00  9.96003367e-01 -1.11569034e+00  5.11272185e-01\n",
      "  1.07489105e+00 -4.77833987e-01 -2.28080820e+00  1.15817934e-01\n",
      " -2.78370651e-01  6.30393696e-03  1.20853685e+00 -1.75038659e+00\n",
      " -1.03124801e+00 -3.42856604e-01  2.14826716e+00  7.54781068e-01\n",
      " -5.59667517e-01  3.08073768e-01  3.14951922e-01  2.59921890e-01\n",
      " -4.65703975e-01 -5.34035776e-01  5.94358646e-01 -8.74451007e-02\n",
      " -1.37445525e+00  1.17012419e+00 -8.46837347e-01  7.98632445e-02\n",
      " -8.04380250e-03 -5.27404837e-02  1.11410768e+00  8.03725052e-01\n",
      "  3.66912308e-01 -9.53311440e-01 -6.62437071e-01  2.75677885e-01\n",
      " -5.25467093e-01  1.02297332e+00  1.02643085e-01 -1.93446567e+00\n",
      "  1.91644149e-02 -9.76713082e-01 -1.02221809e-01 -7.34942773e-01\n",
      " -7.75979130e-01 -2.88420506e+00 -2.14685711e+00 -5.63959973e-01\n",
      " -1.74517741e+00  2.90507324e-01 -7.17202733e-01 -3.77507392e-01\n",
      "  7.91332275e-01  1.53936298e-01 -4.20514120e-02  1.41564420e-01\n",
      " -9.69292644e-02 -2.07467168e-02  5.59859721e-01  7.23153969e-02\n",
      "  1.52411242e+00  6.09090149e-01  2.37567154e-01  3.22120158e-01\n",
      " -3.03698986e-01 -5.04889437e-01 -3.62395760e-01 -1.38646128e-01]\n",
      "------counter :144-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.96436717 -1.76727971  0.7707225  -0.53033097  0.29606808  1.2844045\n",
      "  0.68282524 -1.79463551 -2.10204264  0.29571438  0.98417094 -0.72003439\n",
      " -0.25522991 -0.73840398  1.06870895  0.277243    1.71368354 -1.46454412\n",
      "  0.95057015  4.41310152  0.55205814 -0.15094013 -0.47770592 -0.36933141\n",
      "  0.50076274 -1.46347196  0.27455492  0.21524749  0.12692221 -0.41275195\n",
      "  1.33507683  1.4947595  -0.38616022 -0.11053439 -0.66673659 -0.01245287\n",
      " -0.29073522  0.93643056 -0.14943109 -1.49984785  1.0107326  -0.67361138\n",
      " -1.69094381  0.26134586  1.42483522 -0.29019338 -0.17865188 -0.51009817\n",
      "  1.42745461 -0.16377076 -0.63921226 -1.21922431  0.48661263  0.42629272\n",
      "  0.0405007  -1.40179005  0.9734276   1.28281095  1.1440092  -0.06812858\n",
      " -2.72462294  0.62720907  1.27424509  0.16442287 -1.09538888  0.81054829\n",
      " -1.66159698 -0.73820508  1.08672672 -1.54329116 -1.45823109 -2.72403408\n",
      " -0.24433074 -0.17603672 -2.27608576 -0.96796274  0.35129904  1.76308832\n",
      "  0.69590619 -0.19927811  1.0864089   0.30698138  3.55921008 -0.95617716\n",
      " -0.53115126  4.32255636  0.36764811 -0.98066868  0.31340198 -0.60322965\n",
      " -0.55489522 -0.51225318  0.8794299  -0.41348225  1.04062576 -0.65220682\n",
      " -1.32858479 -0.02703262 -0.41507808  0.43064127  0.20021318  3.01800831\n",
      "  2.05606053  0.56189524 -0.97247059 -0.85726554 -0.01311833 -2.3285011\n",
      "  0.10763401 -0.2806975   0.57845314 -0.74306555  0.02328082 -2.0065775\n",
      "  1.43810702 -2.60454354 -0.32123196 -0.6926995   0.26660354  2.06468119\n",
      " -0.2750872  -0.18361322  0.10484715 -0.57952884 -0.89445064 -1.11428598\n",
      " -0.74849162  1.30908589 -0.39956508 -1.60157599 -1.05431361 -0.10422416\n",
      "  1.21269764  0.32311739 -0.68962567  0.04984457  1.04560649 -0.53601238\n",
      "  3.02810339  0.49290062 -0.36578712 -0.88334675 -1.97169298 -1.76656441\n",
      " -1.20530594  0.23482843  3.19306874  0.03134147 -1.01542389 -0.02483663\n",
      "  1.17395572  0.07188142  0.62062897 -2.01149962 -0.08482166  1.17126709\n",
      " -1.3532698   0.85017052 -0.06941188 -0.2472312  -0.22472856  1.40590066\n",
      "  0.75500585  0.3448307  -0.10838973 -0.92478824 -0.93678451  0.77245573\n",
      " -0.54415404  1.54098061 -0.01286922 -2.04976884  1.39229948 -0.15568184\n",
      "  0.13017588 -0.7516889  -0.65224541 -0.07977349 -1.3000248  -0.92564691\n",
      " -1.90726819  3.23629646 -0.61546886 -0.18830845  1.13389499  2.54895644\n",
      " -0.02533515  0.65691131 -0.15334952  0.35320741  1.02446944  0.19105746\n",
      "  0.54413535  0.58381304 -0.13269742 -0.18550678 -0.29637927  1.54167538\n",
      " -0.5109709  -0.4873623 ]\n",
      "------counter :145-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.75112421 -1.24374201 -1.41694232 -0.53851687 -0.8922476   0.80013757\n",
      "  0.5750477   1.64195405 -0.09524109  0.10049467  0.42643397 -0.70892778\n",
      "  0.10953981 -0.94842637  0.47741298 -0.38158592  3.84453417 -0.44938371\n",
      "  0.16976195  4.7720468  -0.36446665 -0.23187865 -0.46906098 -1.47125551\n",
      "  0.05015324  0.29004131  0.27577733 -0.08525228  0.45161296 -0.94801045\n",
      "  0.91576446  0.94420047 -0.5123394  -0.21307007  1.65083655 -0.55769829\n",
      "  0.10503448  0.4388577  -0.17035598  0.80355759  0.9444479  -0.61030128\n",
      "  6.28211266 -0.07986883 -0.05733276 -0.1912155  -0.16034373 -0.06106879\n",
      " -0.85191652 -0.08160298 -1.07821833 -0.92626907 -0.04469329  0.53331967\n",
      " -1.96379779 -1.44817168  0.99128857  2.06877436 -1.31926597  0.14720876\n",
      " -2.7531857   0.92044594 -1.31861268 -0.53644421  0.88049405  0.91093969\n",
      " -1.1693059  -1.38545102  0.9514108  -0.93354057 -1.19660515 -1.68065086\n",
      " -0.41294204 -0.31234613 -0.84894849  0.75316766  2.18978326  0.73582949\n",
      "  0.75552849 -0.56098632 -1.0138435   0.38376621  2.67269989 -0.60048709\n",
      " -0.57276238  3.78162294  0.25159338 -0.59295613  0.25002666 -0.01690922\n",
      " -0.81367911 -1.11200614  1.45225534  0.59063099  1.95227126 -0.78460528\n",
      " -1.67195752 -0.10649303 -1.24770499  0.27016466 -0.02561374 -5.55449106\n",
      " -2.95636311  3.61589439 -1.1587351  -0.8265486  -1.56808762 -2.11836608\n",
      "  2.86781657 -0.9447648   0.26346503 -0.69687144 -0.08283565  0.20955397\n",
      "  0.70772242 -1.19435706  0.14950054 -1.18240209  0.20205872  2.03031429\n",
      " -0.13053652  0.31004069  0.26528875 -0.4475231  -0.16614002 -2.21590602\n",
      " -0.29032484  1.5375558  -0.33153419 -1.46137181 -1.07272416 -0.17949951\n",
      " -0.70622079 -1.23736112 -0.13771026 -0.02013682  0.74970999 -0.72641282\n",
      "  1.4748886  -0.26511689 -0.57362836 -0.6533585  -2.51738855 -2.00869503\n",
      " -1.30984701 -0.30540025  3.29056258  1.32502779  0.13703851  0.90394226\n",
      "  0.32542496  0.18884942 -0.20683472 -1.73992378  0.40613327  0.46810109\n",
      " -1.00509909  0.26625493  0.12683533 -0.22442899 -0.30425906  1.08391922\n",
      " -0.09785749  0.50681683  0.13509229 -0.2170782  -1.03729933 -0.35648493\n",
      " -0.79754667  1.55112781  0.29748952 -1.89059694  1.00517713  2.5778059\n",
      "  0.42264753 -1.07384951 -0.80821895 -0.49286027 -1.83823317 -0.8205145\n",
      " -0.7272353   3.63762456 -0.60620732 -1.15160333  0.85191686  4.25336121\n",
      " -0.02177654  1.61375332 -0.03954892  0.23418671  0.98162978  0.47223872\n",
      "  1.9583999   0.67482687 -0.01078803  0.04799339 -0.20334053  1.33590139\n",
      " -0.78752139 -0.4854752 ]\n",
      "------counter :146-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5167474   4.13603463 -0.66579269 -1.11928654 -0.12341803  0.66686253\n",
      "  2.06441668 -1.22346548 -0.94083372  0.48227705  0.44371973  0.3642115\n",
      "  0.25471829  0.26060147  0.08152463  0.01670933  1.99978059 -1.64674569\n",
      " -0.17855747  3.66220803  3.71205085  0.13133098 -0.65983156 -0.36501745\n",
      "  0.03851543  0.64706452  0.04881207 -1.82665107  1.15019902 -1.57129237\n",
      "  1.03025993  1.33668776 -0.83448158  0.60690252  1.61800145 -0.54001443\n",
      " -0.03790818  0.75179321 -0.20618395  1.61844583  0.50299312 -0.73806744\n",
      " -1.77907505  0.61220631 -0.78818491 -0.23836557  0.15593051 -1.40136041\n",
      " -1.09471013 -0.02917485 -1.06592565 -0.25151292  0.63945052  0.42265058\n",
      " -0.24881606 -1.16869528  0.32533741 -2.81748613 -0.05467718 -0.49342334\n",
      " -2.57140639  0.63094132  0.24243563 -0.30674173  1.14254365  1.00860539\n",
      " -0.4581107  -0.87094974  0.74433046 -1.0308183  -0.671125   -1.24892097\n",
      " -0.71101042 -0.06672723  1.53315493  0.21377182  2.05014057  0.02908982\n",
      "  0.51755112 -0.38709542 -0.07398737  0.63799611  1.84281962 -0.8011128\n",
      " -0.46952541  6.24798401  0.78435317 -0.44438387  0.45885359 -0.89858722\n",
      "  0.47102017 -0.37607952  0.55015012  0.7424349   1.43775532 -0.54494173\n",
      " -0.98059767 -0.44301818 -0.45792704 -0.87613188 -0.66430454  2.50274125\n",
      " -2.71714354  1.53643848 -1.31655797 -0.74932665 -1.47144598  0.86474855\n",
      " -0.65102199 -0.27319803  0.68481063 -0.51926098 -0.03582126 -0.60125368\n",
      "  1.15291116  1.7825176   0.4066142  -0.82242849 -0.38956427  1.19054134\n",
      " -0.55236641  0.45475017  0.27391096 -0.33378033  0.98379453 -1.31946631\n",
      " -0.50065125  2.38427966 -0.76680717  0.0598663  -1.03763875 -0.09612605\n",
      " -0.94700475  0.34981393 -0.019733   -0.43319223 -0.64773574 -0.68561319\n",
      "  1.7687965   0.54824748 -0.08187164 -0.57117478 -0.15813503 -1.75731089\n",
      " -1.03010158 -0.39530935  1.48361647  1.46610682 -0.39256099  1.04550259\n",
      "  0.62805702  0.0897111  -0.41718685 -1.47058399  0.00733574 -1.20932152\n",
      " -0.52104443  1.43371232 -1.38918129 -0.26960443 -0.25879535  0.80605394\n",
      " -0.43838399  0.13091727 -0.20662008 -0.09790554 -0.57252445 -0.69497456\n",
      " -0.97985167  0.28436658  0.09041696 -1.746907    0.17082013  1.38522693\n",
      " -1.0373708  -0.77382332 -0.41173034 -4.30691048 -1.11810524 -1.34130482\n",
      " -0.41131223  1.97860181 -0.34878647 -0.97871785 -0.01360041  1.4065414\n",
      " -0.0645593   0.67110637  0.29410984  0.37726682 -0.13255009  0.40898289\n",
      "  0.2421249   0.29425811 -0.01556279  0.20684031  0.12814306  0.38417542\n",
      " -0.64228281 -0.30409569]\n",
      "------counter :147-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49475615  1.1762878  -1.74950939 -1.04271188 -0.07846737  1.17526642\n",
      "  0.80333908 -1.41170297 -2.37099927  0.39740799  0.23244448  1.12812585\n",
      "  0.62274342 -1.00854209  0.52729618 -0.32907261  1.64536695  0.09967467\n",
      " -0.2188227   3.355498    1.62033228 -0.22176841 -0.57980088 -0.26679565\n",
      "  0.19536712  0.18981859  0.1651594  -0.83548266 -0.44872761  1.52085112\n",
      "  0.71815381  1.30496146 -0.64751791 -0.42352013  1.12594996 -0.5125295\n",
      " -0.22890077  0.42943508 -0.15939423  0.80385934  0.01743388 -0.37539674\n",
      " -1.89885406 -0.98327638  0.38375632 -0.19100032  0.33763678 -1.42008289\n",
      "  0.19888488  0.38712198 -1.03586258 -1.98082598  0.06080039  0.34111122\n",
      "  1.55416403 -0.72478636  0.82625121 -1.1767262  -1.99639861 -0.50221557\n",
      " -2.47541786 -0.02515162 -3.34615707 -0.26781937  0.45468999  0.84265963\n",
      " -0.61251924 -0.86799992 -0.01107064 -0.8339125  -1.00222417  2.33906618\n",
      " -0.35917543 -0.55363584 -0.38071688 -0.89580293  0.8335688   0.2330365\n",
      "  1.07586802 -0.64180507 -0.64648125  0.01115909  0.70409834 -0.98631986\n",
      " -0.69316131  0.99777749  2.07758868  0.93573463 -0.43606642 -0.36015373\n",
      "  1.01143134 -0.60861373  2.24758308  1.02447621  1.13363329 -0.69085607\n",
      " -1.06396702 -0.3543561  -0.33078383 -0.29311711 -0.98428822  2.81722834\n",
      " -0.0929291  -1.98271551 -0.6485864  -1.06633959 -0.44947093 -0.45355524\n",
      "  1.88681751 -0.5286073  -0.06036817 -0.57243238 -0.10159652  2.20938782\n",
      "  0.57470757  0.63926364  0.09730903 -0.74598531 -0.35938989 -1.45241619\n",
      " -0.1398837   0.13839617  0.33808359 -0.40832541 -0.56867663  2.07175096\n",
      " -0.21401983  2.40691413 -0.91808652 -1.00391635 -0.76349305 -0.01359332\n",
      " -0.30475011 -0.969761   -0.44106702 -0.26943455 -0.17202186 -0.72658537\n",
      "  1.56097652  0.14536249 -0.49289372 -0.70147881 -0.65802782 -0.09689784\n",
      " -0.81587184  1.05512927  4.12384736  1.55286994 -0.20641111  0.65398539\n",
      "  0.47346201 -0.03117945 -0.09966144 -0.83001782 -0.17401082 -0.30733076\n",
      " -1.53851443  1.1661011  -0.59745821 -0.07970947 -0.27404583  0.59094569\n",
      " -1.55371429  0.46409874 -0.35635882  0.27088101 -0.87961148  0.98969653\n",
      " -0.99706192  0.51031266  0.43650442 -2.18580962  0.66161843  2.37565962\n",
      " -1.03618256 -1.14496311 -0.63950318 -0.26695807  0.21529054 -0.5980727\n",
      " -0.35575994  2.28240062 -0.46219739 -0.10181592  1.65219851  1.93437537\n",
      " -0.17812043  0.19714972  0.81208793  0.10415432  0.28014713 -0.022467\n",
      "  0.29534515  0.32224035  0.0916424   0.10605667  0.06586721  1.35099975\n",
      " -0.82028549 -0.22171696]\n",
      "------counter :148-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3335245   2.26403177 -0.06256488 -0.50477844  0.13329081  1.06169372\n",
      "  2.60064375 -1.69437266 -1.80960856  0.00713581  0.28494216  0.87896591\n",
      " -0.18462418  0.0462691   0.46937088 -0.56046869  2.40428998 -0.22323499\n",
      " -0.23732     2.84364134 -0.98197973 -0.20451986 -0.30103226 -0.04898641\n",
      " -0.18145021  0.15346003  0.20040603 -0.33470629 -0.67183666  1.79897515\n",
      "  0.50279508  1.47208838 -0.21655639 -0.29150593  0.67855709 -0.21848865\n",
      " -0.31931869 -0.11295453  0.12646909  0.77796346 -0.70909308  0.07074854\n",
      " -2.49953507 -0.47014379 -0.70382178 -0.16780964  0.39288791  0.83365177\n",
      "  0.80891099 -0.20123489 -0.87481267 -0.51901412  0.31104726 -0.04510895\n",
      "  0.85599605 -0.28162487  0.58737051  0.69395482  1.46360782 -0.12169227\n",
      " -2.45104842  0.88846326 -2.09156066 -0.55569522  0.3620781   0.96766253\n",
      " -0.49462664 -1.11832326  0.03502734 -0.73334097  0.07918878 -0.99021316\n",
      "  0.66163626 -0.24364962  1.84155063  0.13583256  0.43409814  0.87370055\n",
      "  1.17509544 -0.02773114 -1.25299287  0.06158927  0.73495842 -1.01810578\n",
      " -0.20948665 -2.50522628 -0.95935396 -0.13879592  0.13252145  0.48353101\n",
      "  0.76800889 -0.71303726  2.12983245 -0.16237988  0.70402518 -0.17215081\n",
      " -0.34864869 -1.56277986 -1.98829459  1.00830814 -0.79558623  3.3302275\n",
      " -0.74886537 -1.85988861 -0.66933811 -0.5534003   0.42735678  0.00670762\n",
      "  1.1626739  -0.53288902  0.16597344 -0.31993879  0.19319072  0.75454155\n",
      "  0.36678764 -1.08774786  0.04705885 -1.06704126  0.43432547  1.23400706\n",
      "  0.18931266 -0.14020705  0.4141591  -0.31804446 -0.44049494  1.4895439\n",
      "  0.39754591  0.81464042 -0.30269073 -0.10889101 -0.49082747 -0.35660056\n",
      "  0.22054967 -1.50360132 -0.21263577 -0.239018   -0.67179084 -0.27683902\n",
      "  3.0368008  -0.81282305 -0.16684315 -0.01276868 -1.29559346  0.54157767\n",
      " -0.98344589  0.68730344  3.92020933 -0.04810161 -0.36645574  0.37180129\n",
      " -0.86143781  0.0350654  -0.67944676 -1.92830289  0.04619754 -0.93075996\n",
      " -1.22049969  1.68270292  0.14408293  0.12407078 -0.18266486  0.23033817\n",
      " -0.85809709  0.5346368   0.06459724  0.16934754 -0.50382238 -1.19308385\n",
      " -0.58072977  0.40176316  0.29901261 -0.90830623 -0.11933468  0.73283518\n",
      " -0.96012808 -0.41626011 -0.57744608  2.70090507 -0.32804726 -0.14727576\n",
      " -2.24861399  0.63525835 -1.1249771   0.20956067 -1.34405228 -0.76767699\n",
      "  0.43906389  0.56919116  0.97234611  0.03719186  0.94083239  0.37184494\n",
      " -0.02675432  0.46745332 -0.69857015  0.42090915  0.21419884  0.55174566\n",
      " -0.37615884 -0.21173949]\n",
      "------counter :149-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.50977544e-01  1.85510991e+00  1.61748225e+00 -3.66709512e-01\n",
      " -2.74733596e-01 -9.16032383e-01  6.71757558e-01  1.52498825e+00\n",
      "  4.01862625e-02  3.31804727e-01 -1.33995753e-01  1.18119517e+00\n",
      " -6.39280301e-01  9.32213238e-01 -4.12007756e-01  2.67560541e-01\n",
      "  2.13050610e+00  1.91513556e+00 -4.73027102e-01  3.27952224e+00\n",
      " -1.47718399e+00  4.79165729e-02 -9.85288038e-01  2.18267829e-01\n",
      " -3.76344864e-01 -1.78375323e-01  2.60150373e-01  6.85892553e-01\n",
      "  4.00592841e-01  4.79403613e-01 -3.52005131e-01  1.41891929e+00\n",
      " -2.84181661e-01  1.45854715e+00 -2.69580085e-01 -1.60641002e-01\n",
      " -2.58912226e-01 -4.32908430e-01  8.90455308e-01 -2.31775506e-02\n",
      "  4.30468945e-01 -8.60327947e-01  9.99208486e-01  1.39902782e-01\n",
      " -4.78467826e-01 -3.59368019e-01  3.49340008e-01 -2.80901891e-02\n",
      " -1.38992162e+00 -2.36556257e-01 -1.18613242e+00 -3.93126644e-01\n",
      "  7.07165954e-01 -3.88464744e-01  8.03221920e-01 -4.53976558e-01\n",
      "  5.95637956e-01  5.42782190e-01  1.03986892e+00 -2.49462804e-01\n",
      " -2.44877464e+00  1.13425541e-01 -2.37071397e+00 -7.67969342e-01\n",
      "  1.67975102e+00  9.69684261e-01  2.14751939e-01 -7.71957066e-01\n",
      " -1.90601448e-02 -9.13823967e-01 -3.57438771e-01 -1.03671266e+00\n",
      " -7.03799495e-02 -8.43846205e-01 -9.10909745e-01  7.78226277e-01\n",
      "  4.34925143e-01  9.66670525e-01  5.78421419e-01 -2.58813670e-01\n",
      " -3.62975284e-01 -1.50723729e-01  4.21183661e-01 -7.88399549e-01\n",
      " -3.16709039e-01 -3.81327041e+00  1.61752278e+00  3.64103187e-01\n",
      "  5.55550307e-01 -1.79340897e-01 -2.63934167e-01 -5.95926055e-01\n",
      "  2.98623265e+00  5.11639502e-01  1.39622815e-01 -1.05080502e-01\n",
      " -4.03505817e-01  2.96038887e-01 -1.75445281e+00  9.62577055e-01\n",
      " -8.88977587e-01 -3.20967992e+00 -6.46104281e-01 -6.00578251e-01\n",
      "  4.27867153e-01 -6.97521724e-01  3.81202133e-01 -1.95622739e-01\n",
      "  3.25426891e-01 -5.72100911e-01  2.17608134e-02 -5.25486081e-01\n",
      " -2.12228487e-02  1.26643291e-01  3.47112631e-01 -1.47511525e+00\n",
      " -1.39370254e-01 -9.10882916e-01 -2.48648190e-03  2.13585601e+00\n",
      "  6.20279901e-01 -7.63623669e-01 -1.98140295e-01 -4.98878987e-01\n",
      " -8.77594615e-01  2.35687103e+00  3.12363462e-01  9.26795302e-01\n",
      " -3.96184953e-01 -1.06623466e-01 -7.26576661e-01 -7.84710822e-01\n",
      "  4.55630402e-01  6.00171920e-01 -8.51463786e-01  8.29029458e-02\n",
      " -5.37944227e-01 -7.31511219e-01  5.65165019e-01  3.47399735e-01\n",
      " -3.98038498e-01 -1.81166462e-01 -1.32572762e+00  2.79339686e-01\n",
      " -7.68417108e-01  5.75593140e-01  3.74113604e+00 -1.83888621e-03\n",
      " -5.15895300e-01 -3.80467294e-01  3.46150884e-01 -5.79379224e-01\n",
      "  2.64652688e-01 -8.49175967e-01 -3.01346294e-01 -1.12646875e+00\n",
      "  9.47764173e-01  1.28508802e+00  1.06379724e-01  1.44812036e-01\n",
      " -3.62135349e-01  2.81666101e+00  5.65377289e-01 -1.50895624e-01\n",
      " -3.91128657e-01 -1.18001511e-01 -6.77033334e-01 -5.68259906e-01\n",
      " -4.43724695e-01 -5.11171203e-01  5.61453855e-02 -1.47953268e+00\n",
      "  9.82517587e-01 -5.54609298e-03 -9.32652343e-01 -5.77559729e-01\n",
      " -4.19607851e-01  6.50878652e-02 -6.09442242e-02 -2.78591207e-01\n",
      " -1.62988513e+00  7.60041051e-01 -5.74389623e-01  2.42331558e-01\n",
      " -1.26989270e-01 -5.45169612e-01  5.82742905e-01  7.50594734e-01\n",
      "  7.33897883e-01 -5.02776288e-01  1.37704678e-01  5.51573770e-01\n",
      " -4.08405076e-01  4.96822565e-01 -4.23216889e-01  4.31653282e-01\n",
      " -3.30101470e-02  1.10538491e+00 -3.87009049e-01 -5.20498457e-01]\n",
      "------counter :150-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08907365 -1.19102909 -0.37898474 -0.23893076 -0.12015751 -0.95881761\n",
      " -0.02029317  1.98029016 -1.14358894  0.05974923 -0.20455255  0.3169567\n",
      "  0.10608693  1.24066135  0.82823164  0.04260935  1.72693961 -0.62085319\n",
      " -0.54883391  4.14114746 -0.21797001  0.44871704 -0.33163712  1.27968916\n",
      " -0.31640382  0.14410148  0.28727479  0.85551652 -0.81011305  0.20496801\n",
      " -0.32928945 -1.00345454 -0.55843856  1.50985904 -1.19008286  0.48814075\n",
      " -0.35225772 -0.86241863  0.68040351 -1.76598382 -1.15559335 -0.12565033\n",
      " -1.00454343  0.61152102 -0.31617019 -0.26668111  0.40466607  0.04365075\n",
      "  0.47048775 -0.90263527 -0.24724875  1.26830891  1.29058354 -0.47385705\n",
      " -1.62563763 -1.0099888   1.20335478 -1.38125384 -1.11119929 -0.37352776\n",
      " -1.62649447 -0.48357359  3.4181868  -1.30259008  0.81065892  0.86730326\n",
      " -0.0275323   0.01416183 -1.58013052 -0.60769314  0.85186939  0.80524894\n",
      "  0.48502206 -0.57253461  0.039024   -0.46370165  0.03136415  1.13787637\n",
      " -0.28251265  0.35848134 -0.78016137 -0.23673871  0.61640621 -0.12963715\n",
      "  0.15060008 -1.68113705 -1.68737524  0.43060243 -0.37443624  0.25575343\n",
      "  0.97260294 -0.21041563  0.7748285   0.46949369  0.71536707  0.47373722\n",
      "  0.41387924  0.45878369 -1.13116466 -0.51889434 -0.81701089 -0.71540325\n",
      "  0.89409676 -0.27929681  0.1856871  -0.63952197  0.8514747  -0.39920313\n",
      "  0.55909308  0.16072563 -0.43662657 -0.523246    0.04631548 -0.24545096\n",
      " -0.15097481 -3.28979979  0.40148215 -0.69020601 -2.23584924  2.34615668\n",
      "  0.57520775 -1.10884272 -0.23820832 -0.09784201 -0.15465128  2.05277695\n",
      "  0.78059428  1.55885815  0.39739125 -0.07540127 -0.51196255 -0.91621032\n",
      "  0.50377006  0.8020518  -0.97444626  0.02031621 -0.21210685 -0.46321449\n",
      "  2.39469721  0.67640024  0.14058695 -0.05524594  1.81262441  0.43235148\n",
      " -0.7744376   0.45782545  1.40529107 -0.46560902 -0.23758326 -1.18783518\n",
      "  0.24129545 -0.44401374  0.43777763 -1.17331772 -0.89687565 -0.47089868\n",
      "  1.01238001 -1.64250578  0.25719825 -0.08837963 -0.6738603   3.53932944\n",
      " -0.75529727  0.3162624  -0.34443198  0.16929454 -0.44679248 -0.6888365\n",
      " -0.40545706  0.05340817 -0.05587805 -1.66261034 -0.04536387 -0.0068949\n",
      " -1.42528575 -0.29260937  0.51515368  1.64019315 -1.99788661  0.891969\n",
      "  0.16974585 -1.82708921  0.1430598   1.13844377  0.53587732  1.16016405\n",
      "  0.80926744  0.11018405  0.28500234 -0.85635717  0.93051236  0.39650858\n",
      "  0.79107554 -0.03803665 -1.31078165  0.97083564  0.35219006  1.02145493\n",
      " -0.75180044 -0.38820317]\n",
      "------counter :151-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.08756587e-01 -4.08868515e-01  1.09914774e+00 -1.57107387e-01\n",
      "  2.75823951e-01  1.58018489e-01 -1.01321777e+00  1.01339837e+00\n",
      "  1.42302320e+00  2.00631601e-02 -1.03724228e-01  9.84342754e-01\n",
      "  7.56736657e-02  7.05534944e-02 -1.75778098e-01  3.74524205e-01\n",
      "  3.24681081e+00 -1.05731392e+00  4.25165873e-02  3.19210451e+00\n",
      " -7.19003913e-01  1.02869226e+00 -4.35657073e-01  5.29344775e-01\n",
      " -1.69546524e-01 -8.99179347e-01  3.89864408e-01  5.53706261e-01\n",
      " -1.57131964e+00 -1.27234771e+00 -2.74271832e-02 -2.02484047e+00\n",
      " -4.24327430e-01  7.23492128e-01 -3.64904180e-01  3.40701467e-01\n",
      "  1.96430121e-01 -1.02105459e+00  2.12816784e-01 -1.39096690e+00\n",
      " -1.66349686e-01  8.97489612e-01 -7.48034338e-01  1.13854142e+00\n",
      " -2.32140223e-01 -2.01724668e-01  4.21326643e-02 -1.55848210e-01\n",
      " -7.21449436e-01 -2.42440948e-01 -1.07467901e+00  7.02228351e-01\n",
      "  1.05893973e+00 -3.65374967e-01  1.21035762e+00 -3.92763385e-01\n",
      "  1.00650813e+00 -2.45310059e+00  3.18068536e-01 -5.87277962e-01\n",
      " -4.78620763e-01 -2.88775974e-02  2.02164984e+00 -9.98186268e-01\n",
      "  9.00880351e-01  8.83408565e-01  3.43732341e-01 -4.82498078e-01\n",
      " -1.61369449e+00 -7.27030591e-01  9.60881575e-01  1.29626802e+00\n",
      "  9.84151736e-01 -5.28574086e-01 -1.73625681e+00 -5.48338314e-02\n",
      " -8.15672589e-01  1.87116404e-01  1.67036758e-01  5.61574121e-01\n",
      " -4.90647134e-01  1.83993925e-01  1.38687500e+00  4.40284685e-01\n",
      " -1.80367851e-01  2.64137214e+00  1.48211576e+00 -1.54675569e+00\n",
      " -3.76034244e-02 -5.73153784e-01  1.83287038e-02  3.07670777e-02\n",
      " -3.06767664e+00  7.78998536e-01  5.32264526e-01 -1.74606776e-01\n",
      "  1.19264439e+00  9.34477479e-01 -7.97649756e-01 -1.73703428e-01\n",
      " -7.49542515e-01 -9.93882291e-01  2.35737214e-03 -9.47453479e-01\n",
      "  9.02361551e-01 -1.01175050e+00  1.06575724e+00  7.32902914e-02\n",
      "  2.41916674e+00  2.81603011e-01 -7.09149892e-01 -1.39471078e-03\n",
      "  4.43847866e-01 -1.97120568e+00 -6.50126545e-01  1.43207092e+00\n",
      "  1.12853933e-01 -1.26686240e-01 -1.34108930e+00  1.91260677e+00\n",
      " -5.25349923e-01 -8.21521813e-01  4.25042586e-01  1.83359565e-01\n",
      " -4.17365047e-01  1.15767835e+00  1.06496392e+00  1.31793212e+00\n",
      "  7.28774898e-01  1.82577268e-02 -1.04763298e-01 -1.32013930e+00\n",
      " -1.55023405e-02  9.35889324e-01 -2.57537349e-01 -5.89798089e-01\n",
      " -1.24661266e-01  6.14074834e-02  8.96932367e-01  5.34752009e-01\n",
      "  5.44712448e-01 -5.80806100e-01 -1.57121101e+00  9.62786618e-01\n",
      " -8.25474723e-01  7.30495247e-01 -2.57366038e+00 -8.26435961e-01\n",
      "  1.10620821e-01 -4.11800774e-01 -2.95158588e-01 -5.50170727e-01\n",
      " -7.36917822e-01 -7.17878665e-01 -4.06642006e-01  1.75668741e-01\n",
      "  1.64824493e-01 -2.27302820e+00 -5.20570453e-01 -6.98621773e-01\n",
      " -3.42616759e-01  3.18697791e+00 -8.82553697e-01  3.12968340e-01\n",
      " -2.73405431e-01  5.44356283e-01 -2.51277315e-01  6.47656667e-01\n",
      " -2.67761862e-01  2.18350732e-01  1.44029826e-01 -1.99250551e+00\n",
      "  1.04514248e-01 -1.84207600e-01 -3.10107984e+00 -6.33162058e-01\n",
      "  8.18054432e-01  1.58564984e+00 -1.08544506e+00 -1.10301110e-01\n",
      " -1.45233718e+00  1.03904987e+00  3.19145723e-01  9.64374031e-01\n",
      "  2.10552823e-01  9.61292653e-01  6.45331234e-01  3.00840897e-01\n",
      "  3.14407325e-01 -7.74958077e-01  8.37801460e-01  3.22502209e-01\n",
      "  3.00764026e-01  1.66271218e-01 -1.25985753e+00  5.41806759e-01\n",
      "  2.89128128e-01  3.64094578e-01 -3.50001363e-01 -4.49884276e-01]\n",
      "------counter :152-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.13726230e-01 -7.27540109e-01  1.54254136e+00 -2.57583012e-01\n",
      "  4.04869029e-01 -9.42582673e-01 -5.79182534e+00  2.59167422e+00\n",
      "  1.24491610e+00 -8.30499083e-01  1.42237663e+00 -1.54645101e-01\n",
      " -9.45926961e-01  4.74364835e-01 -8.40634509e-01  3.59735819e-01\n",
      "  1.64214107e+00 -8.06139467e-01  8.94973464e-02  2.69436519e+00\n",
      "  3.61122017e+00  1.02759461e+00  3.41742186e-01  7.41419396e-01\n",
      " -1.53445411e-01 -7.77328312e-02  3.08399020e-01  6.50374106e-01\n",
      " -5.35737577e-01 -4.96187020e-01 -2.62327587e-01 -1.58002630e+00\n",
      " -3.75017933e-01  1.29920143e+00 -6.21744637e-02  1.56737501e-01\n",
      "  4.78203617e-01 -9.36130718e-01  9.23949579e-01 -1.56863956e-01\n",
      " -3.82922959e-01  4.59510886e-01  3.58770370e+00  1.10090544e+00\n",
      " -7.38803278e-01 -1.66485170e-01 -2.62810314e-01  2.54523990e-01\n",
      " -1.00850435e+00  3.70707840e-01 -9.67308197e-01  1.82329474e+00\n",
      "  6.93802721e-01 -6.39681542e-01 -9.02015965e-01 -9.88932212e-02\n",
      "  1.21095570e+00 -2.08001597e+00  3.44112302e-01  9.56525188e-01\n",
      " -1.60654521e+00 -1.07121547e-01  1.98558906e+00 -1.02665933e+00\n",
      "  5.78590139e-01  7.78636283e-01  2.94436879e-02 -1.26852938e-01\n",
      " -1.71030168e+00 -9.03584399e-01  7.06066088e-01  2.75222333e+00\n",
      "  9.10238565e-01 -2.43107862e-01  5.35433385e-01 -6.29713508e-01\n",
      " -1.42922828e-01 -8.59432852e-01 -7.36859149e-02  5.76579358e-01\n",
      " -1.01891247e+00  1.22291531e-01  1.05068271e+00  4.36953909e-01\n",
      "  6.09126567e-02  4.21903404e+00  2.05129747e+00 -3.30834264e-01\n",
      " -4.50697122e-01  1.73125649e-01 -5.44814439e-01 -4.43419785e-01\n",
      " -5.72812407e-01  3.92572431e-01 -4.44535141e+00  4.23595478e-01\n",
      "  4.33023613e-01  5.82700549e-01  9.24758731e-02 -1.13479952e-01\n",
      " -1.23773466e-01 -2.23721531e+00  1.87046733e+00 -1.55520387e+00\n",
      "  5.43528510e-01 -6.62003535e-01  1.12846253e+00 -1.47714520e+00\n",
      "  4.14103791e-01 -3.06255388e-02 -5.15084925e-01 -1.40864365e-01\n",
      "  3.20955732e-01 -2.22819800e+00 -3.52067522e-01  4.87591233e-01\n",
      "  4.78118656e-01 -2.94815820e-01 -1.75616246e+00 -3.13715009e+00\n",
      "  6.50964854e-02 -8.68113719e-01  3.58451549e-01  3.00894087e-01\n",
      "  9.78641587e-01  6.18228301e-01  2.15191457e-01 -2.40290786e-01\n",
      " -6.38581207e-01 -1.82329757e+00 -1.65580294e-01 -1.13052580e+00\n",
      " -7.38272887e-01  1.24029030e-01 -2.74921057e-01 -5.57462647e-01\n",
      " -1.60720215e-01  5.01822566e-01  2.91115566e+00  7.82946696e-01\n",
      "  9.28860343e-01 -4.74974009e-03 -1.68943071e+00  8.83258390e-01\n",
      " -7.25085675e-01  3.45670755e-01  7.87713364e-01 -2.38368205e-01\n",
      " -3.06595325e-01 -2.84646775e-01  1.59702633e-01 -3.71577916e-01\n",
      " -5.58561954e-01 -8.56228116e-01 -7.36246462e-01  8.76179208e-01\n",
      " -8.23531782e-01 -1.57267442e+00  4.17466220e-01 -2.13794267e-01\n",
      " -3.00799525e-01  1.08327351e+00 -8.52495837e-01  2.17721637e-02\n",
      "  1.68216009e-01  5.44819861e-01 -1.98195823e-01 -5.27568053e-01\n",
      "  4.02633452e-02  2.63447375e-01  9.95470638e-02 -1.71738726e+00\n",
      " -2.27901786e-01 -6.00779529e-01 -1.55121159e+00 -4.43190486e-01\n",
      "  1.34250215e+00  3.45736590e+00 -3.19222282e+00  9.46952681e-01\n",
      " -2.48215428e+00 -7.27378436e-01  1.09915777e-02  1.16494839e+00\n",
      " -7.35525028e-01 -1.15063336e-01  1.20033213e-01  3.03474330e-01\n",
      "  9.40692855e-01 -9.74146876e-01  2.72532297e+00  7.71788200e-01\n",
      "  6.57507527e-01  8.04776076e-01 -9.04464814e-01  7.85429092e-01\n",
      "  2.93059169e-01 -4.72525319e-01 -1.76572409e-01 -7.37415584e-01]\n",
      "------counter :153-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40428638  1.81537064  1.78291005 -0.21874034  0.30985218 -1.04081061\n",
      " -4.60851191  1.1898394  -1.48798525  0.20163341  0.85100654  0.53542573\n",
      " -1.14738515  0.81868262 -0.50932557  0.6219184   0.80779622  0.80391843\n",
      " -0.19688795  3.71929044  2.2875333   0.90090376  0.94563478  0.6177111\n",
      " -0.15174817  0.03816067  0.1971463  -0.51404946 -1.8910982  -1.40882932\n",
      " -0.16120183 -1.62987465 -0.4294141   1.35538366  0.10300607  0.52306954\n",
      "  0.48415128 -1.18784898  1.29908493 -0.71900201 -1.23764954  1.2919964\n",
      "  2.25736136  1.32542123 -1.2519352  -0.15827767  0.40890201  0.34478483\n",
      " -0.96557647  0.44762828 -1.15644435  2.12824986  0.06007983 -0.57457255\n",
      " -0.67459394  0.26754277  1.40038682 -3.24421154 -0.36264867  0.56182785\n",
      "  0.46295311 -0.66923169 -1.80340145 -1.09221167 -2.09462657  0.59941783\n",
      "  0.94730843 -0.06478359 -1.48714858 -0.60538148  0.60461305  1.00306968\n",
      "  0.64271143 -0.19487995  1.355072    0.29054157 -0.72027155  0.65416212\n",
      "  0.16941717  0.53615462 -0.37970188 -0.26937139  1.46336284 -0.13013779\n",
      " -0.20479149  4.13058344  2.4220003   0.20609302  0.45745523 -0.93518888\n",
      " -1.77817382  0.34074341 -1.17711472  1.88744049 -2.24041686  0.52312809\n",
      " -0.22677119  0.27604443 -0.13177556  0.55392085 -0.17310005  2.81150975\n",
      " -2.57219361  3.41544613  1.58031056 -0.90362163  1.32437658 -1.11656674\n",
      " -2.40039046  0.16202604 -0.51740086 -0.05530417  0.30639853 -2.57688903\n",
      "  0.45433147  0.54308966 -1.24010433  0.01979553  1.1533407  -1.01006902\n",
      "  0.19441212 -0.77153168  0.09789214  0.09765993 -0.07721573  0.93978371\n",
      "  0.11969486 -0.36503778 -0.67080945 -0.04149866  0.14329467 -1.41732922\n",
      "  1.09143768  0.42602578 -0.46667064 -0.49782841 -0.6579845   0.03151427\n",
      " -3.18515365  0.54444131  0.23826501  0.39134939 -0.02290382  0.7372803\n",
      " -0.51012222  0.40277854 -1.59484778 -1.44339556 -0.30682057 -1.01442977\n",
      " -0.37009668 -0.31840376 -0.12915891 -1.03545826 -0.97358043 -2.68947551\n",
      " -0.92792028 -1.5367749  -0.18360867 -0.02599765 -0.54227647  2.13431562\n",
      " -0.8786095  -0.19279872  0.84345518  1.52158744 -0.17547508 -0.52022553\n",
      "  0.58272962  0.05062106  0.09249999 -1.08656014 -0.15908442 -0.23721863\n",
      " -1.04085141 -0.09696709  0.81968491  1.06513042 -1.12103011  1.41510909\n",
      " -2.10369453  1.18284215 -0.32253962  1.32906349  0.4554921  -1.10319913\n",
      "  0.98315596  0.23056904  0.42772856 -0.83161858  1.74039209  1.32741567\n",
      " -0.28865047  0.90196562 -0.61143104  0.79390271  0.21702377  1.23626952\n",
      " -0.10224912 -0.86332127]\n",
      "------counter :154-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28671283  3.30211502  1.53451878  0.21755214  0.58802198 -0.63504538\n",
      " -1.1099444   2.34684103 -1.25586104 -0.22847176  0.36482474  0.26661301\n",
      " -1.15808071  1.65475776 -0.77442027  0.65360303  0.34278462  0.93880464\n",
      "  0.11267404  4.17626828 -1.14383051  0.60169347  1.0984844   0.66761863\n",
      " -0.12607189 -0.45392804 -0.0972724   0.8276602  -0.73667195  1.28084713\n",
      " -0.24023839 -1.55258738  0.24034799  1.14587819 -0.58918793  0.73075025\n",
      "  0.75767783 -0.85462699  0.57225059 -1.57534741 -0.34356036  1.10014619\n",
      "  5.1226659   1.20406393 -1.26496261 -0.17979886  0.45136092  0.35489525\n",
      "  0.33526559  0.21971418 -0.15323125  1.46024624 -0.38418404 -0.88662022\n",
      " -0.52292661  0.20220959  0.55812592  1.29851193 -1.06856113  0.18679574\n",
      "  0.24909806 -0.68603066 -2.61726188 -1.5781056  -0.89541437 -0.21712731\n",
      "  0.91338384 -0.37519029 -1.03991581 -0.90089377  0.62881117 -2.00016987\n",
      "  1.63619333 -0.50217729  1.17248151 -0.53345756 -0.79067931 -1.09933393\n",
      "  0.40947266  0.12658101  2.19804418 -0.34268625  1.00094639  0.113728\n",
      " -0.24777791  0.06980452  1.31307978 -0.53690707 -1.07796696  0.1732783\n",
      " -1.76094552 -0.31563894  3.46347811 -0.90324331 -2.59381549  0.47281602\n",
      "  1.17284312  1.18841623  2.39387887  1.75585168  3.91357128  2.05443023\n",
      " -0.6322874   1.80725574  0.74888923 -0.9005926   1.03124869 -1.22223825\n",
      " -0.52511305 -0.31789087 -0.5712696  -0.72958822  0.33350177 -3.65236122\n",
      " -2.090715   -0.13877676 -0.262188   -0.64545916  0.18924096  0.85267035\n",
      "  0.1228974  -1.13487433 -0.08204527 -0.09329535 -0.62998488  0.15387707\n",
      "  0.42027731 -0.93273501 -0.7393237  -0.5816118  -0.30444751 -1.14665863\n",
      " -0.27069822 -0.81969995 -0.73207988 -0.44263494 -0.70067015 -0.0502483\n",
      " -1.88787021  0.36499823  0.90238407  0.19509095 -1.18564209  0.5230392\n",
      " -0.49136563  0.1470746  -2.52282666 -0.55375898 -0.30985608 -0.66688657\n",
      "  0.11459472 -0.93284335 -1.31097312 -1.36214499 -1.78401445 -0.56363238\n",
      "  1.64523992 -1.60111699 -1.46488965  0.03663435 -0.5651084   1.21197332\n",
      " -1.61123006 -0.23743729 -0.11293097  1.06150546 -0.66952214 -0.74997602\n",
      "  0.12943023 -0.74900521 -0.07977233 -0.92702369 -0.36982087 -0.89540831\n",
      "  0.46305121 -0.24348446  0.09629471  1.42181499 -1.24188124  1.08446921\n",
      "  0.55721722  0.85754903 -0.27770977  1.94539214 -0.32743288 -0.02160876\n",
      "  0.80412234  0.22237524  0.49654478 -1.4742524   0.2757615   0.25594749\n",
      " -0.4364514   1.12691159 -0.61212116  0.72877214  0.12731899  2.04726634\n",
      " -0.33676958 -0.84969593]\n",
      "------counter :155-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45872366 -3.20539062  1.991844    0.02361688  0.99231982  1.24432425\n",
      " -1.34414519  2.34851405 -0.97277364  0.91431721 -0.28558737  1.30613728\n",
      " -1.2370001   2.3346929  -1.37883757  1.43895997  1.36518447  1.61690116\n",
      " -0.2474815   2.34828934 -0.51711002  0.32630479  1.28866727  1.53935833\n",
      " -0.21902368 -0.12870253 -0.48645825  1.37702615 -1.31116905 -2.88674813\n",
      " -0.3244111  -1.71242929 -0.44586903  2.05267959 -1.20149877 -0.08700888\n",
      "  0.34683661 -0.98332141  0.34857243 -1.05228814  0.1281297   0.16272208\n",
      "  2.5936132   0.8280976  -0.67893927 -0.32904598  0.38418164  1.52474428\n",
      " -0.45628689 -0.55117433 -0.10474925  1.26536326 -0.33291568 -0.32083424\n",
      " -0.07550894 -0.10617506  0.15043568 -2.59993493 -2.43258097 -0.2574425\n",
      " -0.12284564 -1.17381097  1.53052894 -1.45910845 -1.49921954 -0.39068143\n",
      "  0.97383071 -0.41919844 -1.32493666 -0.99658436 -2.33936031  5.42437525\n",
      "  1.33330349 -1.12763727 -0.81023061 -0.47885535 -1.29001958  1.52127904\n",
      "  0.51994288  2.63290356  1.60627605 -0.35212831  0.2252232   1.66857008\n",
      "  0.01265476 -0.83435213  1.50232017  0.29858085 -0.79374673  0.65315483\n",
      " -2.58854467  0.94813608  1.38111627  0.54975159 -0.04936828  1.10346051\n",
      "  2.00975943  1.19732625  1.68898484  1.94563548  2.98516191  0.57035474\n",
      "  0.819422    1.37904235  1.47864464 -0.5877051   0.83642418 -0.86118261\n",
      " -1.48587321 -0.47277888 -1.60066792 -0.47583177 -0.03789999 -1.6864523\n",
      " -1.97065138 -1.69833306  0.21049866 -0.77443514  1.10419787 -0.37490444\n",
      "  1.03459022 -1.98585132 -0.75784053 -0.33539835  0.2817685   0.32780311\n",
      "  1.55720705  2.84708787  0.09101648  0.05257069 -0.31452216 -1.466789\n",
      " -0.43836769  0.5136099  -0.84868231  1.02495162 -0.5977623  -0.02117063\n",
      "  0.8439502   0.4604505   0.70656936 -0.02722465 -0.28789739  0.29394423\n",
      " -0.28923214  0.27698141 -2.93931439 -1.40377162 -0.7526174  -1.11369229\n",
      "  0.46853708 -1.49998317 -0.29809567 -1.267842   -1.88253124 -1.19233263\n",
      "  1.05548707 -1.49760222 -0.9946284  -0.26062737 -0.81804913  1.01844011\n",
      " -0.26570293  0.04668456 -0.33287015  0.01207146 -1.01063533 -0.85655234\n",
      " -0.44909247 -0.12404241 -0.53880711 -0.5726343  -0.36594699 -1.01809412\n",
      " -0.15444043  0.28527663  0.85066925 -4.98230416  0.52593447  0.38031729\n",
      "  1.90482724  0.57624987 -0.44371363  1.85484378  0.56605852 -1.97670321\n",
      "  0.86087867 -0.45882764  0.32274506 -1.42310723  1.21937631  0.25979272\n",
      "  0.39736397  0.68388403 -0.14567564  0.25478858 -0.26102877  1.51366566\n",
      " -0.24891715 -0.91070282]\n",
      "------counter :156-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.05211319e-01  1.96283715e+00  2.31156852e+00 -6.69209325e-01\n",
      "  2.19034768e-01  1.24852056e+00  2.49692943e-01  3.03709886e+00\n",
      "  4.76236177e-01  2.77876812e-01 -7.79185072e-01 -1.08286405e-01\n",
      " -1.04094351e+00  1.21881310e+00 -4.53418351e-01  1.08949085e+00\n",
      "  1.50867753e-01  1.15306499e+00  1.27011149e-01  1.67728843e+00\n",
      " -1.77450389e+00  6.71685201e-01  2.70401095e-01  1.25182286e+00\n",
      " -2.20837121e-01  1.39913462e-01 -8.24308740e-01  5.89492672e-01\n",
      " -1.23221481e+00 -3.80859950e-01 -3.12496048e-01 -1.62267206e+00\n",
      " -6.65885990e-01 -1.70491272e-01 -1.67698079e+00  5.46877443e-01\n",
      "  5.38430748e-01 -1.10690102e+00  1.04840650e+00  2.98984174e-02\n",
      "  2.70608977e-01  1.11615653e-01  2.37322052e+00  2.27529902e-01\n",
      "  7.30511669e-01 -6.87241433e-01  1.29562944e+00  1.32767057e+00\n",
      " -6.08346165e-01 -1.01811682e+00  5.47758183e-01  7.43796436e-01\n",
      "  3.29845629e-01  3.29204747e-01 -6.22082502e-02  9.11002094e-02\n",
      "  3.88738595e-01 -2.77464296e+00 -2.11715075e+00  1.68261972e-01\n",
      "  1.56334312e+00 -1.65919499e+00  1.40737293e+00 -8.14719043e-01\n",
      "  2.24674251e+00 -4.38471043e-01 -2.15160439e-01 -1.57460546e-02\n",
      " -1.18444458e+00 -1.83402080e-01  4.45509485e-02 -4.55087179e+00\n",
      "  9.94534269e-01 -5.51845322e-01  1.33262911e+00 -2.89721134e-01\n",
      "  8.96602069e-02  7.19352574e-01 -2.53589860e-01  1.58131439e+00\n",
      "  8.90030042e-01 -7.36614241e-01  8.90844723e-01  9.86254358e-01\n",
      "  1.23598354e-02 -2.89124150e+00 -6.65158627e-02  5.19583409e-02\n",
      " -2.31919818e-01 -1.53435272e+00  1.13299193e+00  3.58989222e-01\n",
      "  1.26463764e+00  7.02661898e-01  1.28380081e+00  5.22106162e-01\n",
      "  2.21008731e+00  9.47923919e-01  1.16336404e+00  1.61517442e+00\n",
      "  1.29509322e+00  1.97197903e+00 -4.38650535e-01  2.90599580e+00\n",
      " -9.96624651e-01 -4.81184657e-01  4.52818802e-01  3.37067969e+00\n",
      " -1.83309383e+00 -6.28614713e-01 -1.22853837e+00  9.83009390e-02\n",
      "  1.95339941e-01 -8.26508795e-01 -5.26927465e-02 -6.27903965e-01\n",
      " -3.61834904e-01  8.05291134e-01  4.54155476e-01  2.94093181e-01\n",
      "  1.18993974e+00 -1.81729197e+00 -1.82980369e+00 -9.94412718e-01\n",
      "  1.03158286e-03  1.33681016e+00  9.94995147e-01 -2.62409402e+00\n",
      "  7.31177638e-01  3.85631478e-01 -4.43125076e-03 -1.29080303e+00\n",
      " -7.28687747e-01  2.56413215e-01 -1.20181661e+00  6.91127306e-01\n",
      " -7.36948972e-01  4.51633445e-01  1.17442239e+00 -1.96761337e-01\n",
      "  6.67792211e-01  8.20196497e-01  1.57890294e+00  4.14052066e-01\n",
      "  5.83375249e-02 -2.42542703e-01  1.94602621e+00 -6.99464237e-01\n",
      " -6.01623498e-01 -6.89670052e-01 -1.12617694e+00 -1.90723387e+00\n",
      " -8.71979696e-01 -1.20388822e+00 -2.07336069e+00 -7.04664612e-01\n",
      " -4.18612592e-01  8.73702131e-01 -4.65694818e-01 -6.54827455e-01\n",
      " -4.48283702e-01  1.20450046e+00 -1.63814012e-01 -1.41786562e-01\n",
      " -1.00974549e+00  6.29632789e-01 -7.29892327e-01 -1.08471086e+00\n",
      " -6.54906057e-01 -1.93611430e+00 -2.99887595e-01 -6.45328807e-01\n",
      " -4.43822069e-01 -1.46542530e+00 -1.57076800e-01 -1.83472011e-01\n",
      "  9.17529778e-01 -1.23980945e+00  1.18461824e+00  6.48395805e-01\n",
      "  5.99711351e-01 -9.96783780e-01 -6.66184258e-02  2.19838022e-01\n",
      "  1.03758050e+00 -6.16055342e-01 -9.10098814e-02 -7.81377611e-01\n",
      "  2.03649405e-01 -1.90489932e+00  2.88359053e-01  6.31709182e-01\n",
      " -9.65301772e-01 -6.55781268e-01 -7.78807068e-01 -8.75165868e-01\n",
      "  6.05430231e-01 -3.37500062e-01 -3.93960914e-01 -1.06370433e+00]\n",
      "------counter :157-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.51003850e-01 -3.16034900e-01  8.54413676e-01  3.38095441e-02\n",
      "  1.57620573e-01 -1.31956005e-01 -8.48645492e-01  6.49579977e-01\n",
      "  2.73351114e-01  4.37521266e-01 -2.66627002e-01  4.37929365e-01\n",
      " -5.31650654e-01  1.85356218e+00 -3.70119158e-01  3.85871056e-01\n",
      " -2.43158913e-02 -1.83383569e-01  9.68305896e-02  1.80385174e+00\n",
      " -2.42972252e+00 -2.59460346e-01  1.75742462e-01  4.48266201e-01\n",
      " -3.84046467e-01  4.64563396e-01 -1.06624547e-01 -1.42152099e+00\n",
      " -9.33255321e-02 -1.01486412e+00 -4.67697953e-01 -1.31267550e+00\n",
      " -5.37909477e-01  1.72770331e+00 -7.70752354e-01  4.55305441e-01\n",
      "  1.69733176e-01 -6.99923885e-01  4.61837569e-01 -1.34778454e+00\n",
      "  4.72540650e-01 -1.66959815e-02 -1.04662416e+00  8.61118059e-01\n",
      " -1.93265849e-01 -7.42029414e-01 -1.07751830e+00  1.74594482e+00\n",
      "  3.83477157e-01 -7.68358106e-01  1.22134460e+00  3.22692496e-01\n",
      "  3.08756641e-01 -5.73074972e-02 -7.54832414e-01  1.49936514e-01\n",
      "  1.20683187e+00 -1.55765714e+00  1.40442376e+00  1.88357068e-01\n",
      "  2.59865504e+00 -1.25405371e+00  4.35707815e+00  2.75201838e-01\n",
      "  8.88266498e-01 -3.29243668e-01 -3.45438960e-02 -2.97315799e-01\n",
      "  5.00513988e-01 -6.60066528e-01 -8.12665102e-01  2.50992659e+00\n",
      "  3.41449472e-01 -4.70166124e-01 -5.52629986e-01 -1.35493470e-01\n",
      "  2.62011846e-01  5.23750167e-01  2.97484507e-01  1.21054411e+00\n",
      "  1.89884183e-01 -6.48121188e-01  1.02941236e+00  1.29660282e+00\n",
      "  2.92484652e-01  3.75127369e+00  1.05563733e-01 -3.23735068e-01\n",
      " -3.77585077e-01 -1.70244320e-01  4.73066060e-01  6.27982162e-01\n",
      "  1.74472924e+00 -7.16278009e-02  9.07788862e-01  8.57744982e-01\n",
      "  1.21775418e+00  7.51667018e-01 -3.74132111e-01  9.96898924e-01\n",
      "  4.75425521e-01  1.41700414e-01  1.86387335e+00  2.25784307e-02\n",
      " -6.35314068e-01 -5.33473616e-01  4.35359743e-01  3.49442543e-03\n",
      " -1.81735927e+00 -4.42187382e-01 -1.16357450e+00  5.85221768e-02\n",
      "  3.89826494e-01 -1.57192810e+00  3.36161394e-01 -2.54454274e+00\n",
      " -3.22115884e-01  9.42238647e-01  6.11567188e-01  1.58481658e+00\n",
      "  5.11549745e-01 -1.71826618e+00 -1.40010110e+00 -6.92608575e-01\n",
      " -3.08683561e-01  5.65888600e-01  2.05837719e-01 -2.85456753e-02\n",
      "  4.59113437e-01 -4.01987147e-01  5.49542171e-02 -5.30049477e-01\n",
      " -5.01645634e-01 -7.63511651e-01 -8.91285960e-01 -8.09831874e-02\n",
      " -5.57667450e-01  3.85379451e-01  6.23787709e-01  2.87155262e-01\n",
      "  6.31196647e-01  4.32876033e-01 -1.02693394e+00  8.04077111e-01\n",
      "  9.81349109e-01 -5.20727524e-01 -1.75382286e-01 -5.34641709e-01\n",
      " -9.83614788e-01 -6.74670907e-01 -8.72366436e-01 -1.17249447e+00\n",
      "  4.71478665e-01 -1.19570246e+00 -1.34453405e-01  3.21965197e-01\n",
      " -5.78400259e-01 -8.38596649e-01 -7.75093858e-01  1.69622804e-01\n",
      " -4.68094174e-01  1.55045657e+00  2.58830408e-01 -1.40659997e-01\n",
      " -7.70429944e-01 -5.96379489e-02 -4.82521026e-01  1.45760847e-01\n",
      " -1.56337855e-02 -1.91542090e+00 -4.14327629e-01  5.20288840e-01\n",
      " -3.78141592e-01 -2.92305677e-01 -6.72889875e-01 -2.54338387e-01\n",
      "  8.11821907e-01  1.16504737e-01  1.53930488e-01  3.73416160e-01\n",
      "  2.63085943e-01 -4.83828930e-01 -9.39411915e-02  5.17110451e-02\n",
      " -1.25163999e+00 -3.27746455e+00 -8.71094805e-02 -2.97784541e-01\n",
      "  1.92083451e-01 -9.66766492e-01  1.62294470e-01  1.91067510e+00\n",
      " -2.14542604e-01 -5.16703153e-01  3.24377481e-01 -6.10268228e-01\n",
      " -3.02671389e-01 -2.78629297e-01 -4.02380155e-01 -1.03669434e+00]\n",
      "------counter :158-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4031546   1.98687408  1.22944722 -0.17319488  0.50047663 -1.48669577\n",
      " -0.19210531  0.83024402 -3.77193736  0.52927705 -0.8678259   1.35621399\n",
      " -0.42074029  0.22935461  0.6324179   0.06392462  0.82110726  0.29763893\n",
      "  0.41699995 -0.44467346 -0.31382348 -0.22791945 -0.08807421  0.09122995\n",
      " -0.27020598  0.50871409  0.97373378  0.20817504 -2.20748796  1.51524067\n",
      " -0.65275481 -0.73714896 -0.24734307  1.2154217  -0.07811444  0.23651384\n",
      "  0.34138773 -0.79786017  0.03955348 -0.81596929  0.57527067  0.36836149\n",
      " -1.82857226  0.48582367 -0.08582011 -0.63587433  0.96171337  1.27890891\n",
      "  1.42010799 -0.34759632  0.93577484  0.52010641  0.08415483 -0.80018912\n",
      "  0.05991868 -0.95198364  0.31112966  0.74553264  1.16370149  0.6301419\n",
      "  0.44197473 -0.85623722 -0.80431762  0.49400849  0.71551981 -0.34867804\n",
      " -0.15097097  0.11391998 -0.8316098   0.3274281   0.55702198 -0.18855199\n",
      " -0.14423024  0.01780892  1.85063105 -0.31549059 -0.12691339  0.63836253\n",
      "  0.46886126  1.66541777 -0.59884253 -0.04222825  1.76287855  0.95273027\n",
      " -0.07494278  3.62936676 -0.18657595  0.09469506 -0.15183317 -0.40049277\n",
      "  0.19220701 -0.02499627  1.59695119 -1.26591855  2.28821914  0.44945324\n",
      "  0.65883061  0.57141472  0.83720481 -0.73275537  0.75578346  0.38901851\n",
      " -2.10542424  0.56381695  0.31615629  0.2268049   0.02591358 -0.59678158\n",
      " -0.29928721  0.51217879 -0.25740187  0.48272715  0.4254612   0.53372134\n",
      "  0.38649567 -1.86077618 -0.18488103  1.05222153 -0.29207258 -0.0582366\n",
      " -0.49673313 -0.54012916  0.16562338 -0.15908752 -0.01278151  0.51101907\n",
      "  0.51161667 -1.74735923  0.48505843  0.58727852 -0.07412814 -0.66670658\n",
      " -1.56833461  0.11680797 -0.38020056 -0.28400796 -2.00031453  0.06393133\n",
      "  0.88568972  0.09662574  0.3388962   0.21464854 -0.65369711 -1.55057167\n",
      " -0.38008263 -0.34054132 -1.34108443 -1.57908135 -1.09196689 -0.22705674\n",
      " -1.176015   -0.3108254   0.81210194  0.80097668 -0.17454263 -1.10703966\n",
      "  1.3249096   0.05042773 -1.09385211 -0.21274708 -0.53433747  2.32633991\n",
      "  1.03274791  0.17440039 -0.79169509 -0.27538614  0.06278449 -1.14274889\n",
      " -0.49523739 -0.50196117 -0.2578019  -0.06472098 -0.14362621  1.03953296\n",
      " -0.17699552 -0.34329817  0.54117373 -0.28018912  0.97845769  0.78870591\n",
      " -0.98189037 -1.61906248  0.36458216  0.59497334 -0.79183665 -1.60259698\n",
      " -0.05694843 -1.06513068  0.21059696 -0.68743642  0.10669107  1.30575056\n",
      " -0.67784005 -0.55960361 -0.56917168 -0.94942323 -0.80823809 -0.30839203\n",
      "  0.24220829 -0.49869689]\n",
      "------counter :159-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21909348 -0.82624458  0.88137926 -0.53020862 -0.35360902 -0.96644265\n",
      "  1.24152082  0.27305552 -0.75203255  0.50109378  0.01825367  1.05440433\n",
      " -0.32860145  0.79705797 -1.16362487 -0.91122156 -0.94788225  0.6044359\n",
      " -0.1032149   2.09216453 -0.64236261 -0.16527434 -0.82358187  0.41371687\n",
      " -0.23036355  0.22898072  1.02906935 -0.08588167 -1.64586315  0.25359418\n",
      " -0.58737291 -0.93625974 -0.22819073  0.95232663  0.24642917  0.40156837\n",
      "  0.13418939 -0.36679285 -0.11942468 -0.44813876  0.28823544 -0.74827253\n",
      " -0.84920664  0.44484496  0.68153442 -0.22862721  0.0287267   0.0757735\n",
      "  0.35798809 -0.73454392  1.09300172  0.02859699 -0.0484109  -0.14787243\n",
      "  0.19567521 -0.59255522  0.534482   -0.24635485 -0.03929101  0.32108639\n",
      "  2.03801338 -1.34808844  2.15644267  0.31395285  0.44405991  0.42483735\n",
      " -0.14657898  0.10900808 -0.06013188  0.04679424 -0.99726066  4.81525071\n",
      " -0.12411751 -0.13537981  0.43206409 -0.31648061  0.56367128  0.16954879\n",
      " -0.2486136   0.4988534   0.39394531 -0.18317099  1.61096259  0.28234714\n",
      " -0.08778154 -2.21122859 -1.62558426  0.75295512 -0.36665798 -0.18457947\n",
      "  0.57736565  0.2457671   0.10208215 -0.65156027  1.20400673  0.98975146\n",
      "  0.28832363  0.08959949  2.81620372 -0.39890184 -0.14996795  1.68239757\n",
      " -1.36537497  0.3403771  -0.03389347 -0.21074736 -0.00951125 -0.01952169\n",
      " -0.52644798 -1.16332488 -0.07391995  0.163048    0.05787937  0.47708054\n",
      "  0.14757276 -0.28084231  0.51165203 -0.00785113 -1.48761626  0.79493525\n",
      " -0.36850969 -0.33707986 -0.1697191   0.02829029  0.07673394 -0.23619389\n",
      "  0.23888552  0.53790218 -0.06918746  0.53841676 -0.33447033 -0.54328719\n",
      " -0.85057842 -0.61366464 -0.37913005 -0.33277958 -0.80543226 -0.62607842\n",
      "  0.19561462 -0.16018714  0.21266704 -0.38463226 -1.56145871 -2.0479275\n",
      " -0.00994781 -1.95887731  1.71378933  0.2771041  -0.96922761 -0.9610175\n",
      " -0.45571388  0.29292783  0.57481289 -1.69230061 -0.0303784  -0.26546689\n",
      "  2.78286953 -0.27374161 -0.6106688  -0.18632992 -0.25758055  2.26661537\n",
      " -0.01987735 -0.04523455 -0.60509496  0.1627496   0.55831696 -0.12807598\n",
      " -0.4230197  -0.27373157 -0.27787437 -0.26999428 -0.032304    0.65750915\n",
      " -0.35145695 -0.278938   -0.49943719 -0.72543456  0.34780143  0.25941891\n",
      " -1.10998123 -0.53403061 -0.3481064   0.8557666   0.72248453  1.36927922\n",
      " -0.72882062 -0.35073746  0.07243665  0.0327342  -0.38970776  1.60270742\n",
      " -0.37054244 -0.02065846 -0.44259517 -0.13904386  0.56296008  0.14869118\n",
      " -0.31795071 -0.63543892]\n",
      "------counter :160-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.86621622e-02  1.75887990e-01  7.18735442e-01 -3.35598435e-01\n",
      " -1.08127515e+00  1.44996341e+00  1.61136369e+00 -1.10344603e+00\n",
      " -1.13847072e+00  5.31872134e-01  3.55146180e-01  2.44783070e-01\n",
      " -2.32230529e-01  5.09114811e-01 -7.00546400e-01 -6.38066101e-01\n",
      " -7.18699998e-02  7.65434174e-01  3.10421902e-01  3.10010293e+00\n",
      "  1.05563197e+00  1.95028732e-01 -6.12709191e-01  5.86261133e-01\n",
      " -1.03345237e-01 -1.69150461e-01  1.75218768e+00  7.77429333e-02\n",
      " -1.48127836e+00  9.97094967e-01  1.10966393e+00 -9.92563551e-01\n",
      " -1.59056315e-01 -6.40750191e-01 -1.68787017e-03  3.69078316e-02\n",
      " -3.71945311e-01 -1.53493877e-01 -1.04822485e-01  4.88356739e-02\n",
      " -1.00921819e+00 -4.75908396e-01 -5.60396471e-01  1.35761528e-01\n",
      "  6.17428213e-01 -4.72570824e-01 -4.90703939e-01 -1.40346621e+00\n",
      " -1.89607867e-01  3.60347758e-01  1.64948217e-02 -1.46220594e-01\n",
      " -6.66921000e-02 -1.37076707e-01  1.10109900e+00 -4.76692534e-01\n",
      "  6.56664164e-01 -1.73489674e+00  2.98469856e-01  1.94488830e-01\n",
      "  8.82111273e-01 -8.94435851e-01  9.75674297e-01  4.10380912e-01\n",
      "  6.74118655e-01  1.70754408e-01 -1.46806850e-01 -6.61515253e-01\n",
      " -5.85525901e-01 -1.62899156e+00  4.97348813e-01  2.56997595e+00\n",
      " -3.13068172e-01  3.96217347e-01  4.65436361e-01 -5.73068298e-01\n",
      "  6.33000140e-01 -5.53074034e-01  3.60490502e-01  9.82508651e-01\n",
      " -2.32848754e-01 -7.63124814e-02  2.02198354e+00  9.89057847e-01\n",
      " -7.66538777e-01 -1.15795314e+00 -1.25124396e+00  2.33392960e-02\n",
      "  3.04492261e-01  1.19636342e+00 -1.11952718e+00  1.60427203e-01\n",
      "  3.99536553e-01 -7.05085883e-01  9.28190576e-01  9.62441163e-01\n",
      "  1.99035134e-01 -3.45261095e-02  2.16456921e+00  3.67971257e-01\n",
      "  1.72051783e-01 -1.08839019e+00 -1.80108507e-01 -3.68796648e-02\n",
      " -3.86670957e-01 -2.52680684e-01 -1.30433101e-01  3.75583773e-01\n",
      "  5.47865794e-01 -8.31666453e-01  2.67387243e-01  2.14626423e-01\n",
      "  7.30707413e-02  2.76491582e-01  6.06427431e-01 -3.09651570e-01\n",
      " -1.40368037e-01  1.08231057e-01  3.29933069e-01 -9.35325726e-01\n",
      " -1.12060731e-01  5.44950270e-01  2.54399587e-01  1.05199410e-01\n",
      "  4.55644437e-01  3.73081127e-01  1.11898905e-01  1.46274125e+00\n",
      "  8.75206769e-02  2.16087644e-01 -5.23474038e-01 -1.50318587e-01\n",
      " -3.19409320e-01 -6.46315109e-01  3.70921664e-01 -6.52326880e-01\n",
      " -3.53009392e-01 -5.93783928e-02  1.99011390e+00 -9.42444644e-02\n",
      "  2.37461574e-01 -6.02171802e-01 -2.19974809e+00 -1.86325814e+00\n",
      " -5.02164464e-01 -1.47647275e+00  1.11121787e+00 -2.00667448e-01\n",
      " -9.08943571e-01 -5.77062946e-01 -5.32215718e-01  8.50690161e-01\n",
      " -4.72384469e-01 -3.02841615e-01  2.77353117e-01 -3.05884636e-01\n",
      "  2.80336843e+00  2.47796141e-02 -1.63105594e+00 -2.77627738e-01\n",
      " -5.96286186e-01  2.51390521e+00  5.93392770e-01  6.15178994e-02\n",
      " -1.07711668e+00  4.33986909e-01  3.63793650e-01 -3.00966265e-01\n",
      " -7.50946024e-01  4.45392281e-01  6.01198825e-02 -6.82124582e-01\n",
      "  5.30191362e-01  4.33204520e-01 -8.19119138e-04 -8.82709061e-01\n",
      " -8.07890817e-01 -4.36621732e-01 -3.48983239e-01  1.49025813e-01\n",
      " -1.25986035e+00  1.13205466e-01 -1.21697604e-01 -2.12679407e-01\n",
      "  1.43963330e-01 -1.50174986e+00 -3.52710095e-01  2.26386381e-01\n",
      " -1.25622181e+00  6.09715009e-01 -1.30013110e-01  1.84063542e+00\n",
      "  8.25897228e-01  5.24229880e-01 -1.38370221e+00 -3.89525372e-01\n",
      " -1.01116517e+00  2.52568420e-01  3.02148301e-01 -1.99412114e+00]\n",
      "------counter :161-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.40197512e-01  2.91108282e+00  4.98560818e-01 -4.47988801e-01\n",
      " -5.27818273e-01  1.13592205e+00  2.32411704e+00 -2.10170326e+00\n",
      " -1.21332244e+00  4.30276849e-01  1.66334281e-01  7.02308104e-01\n",
      " -2.17159350e-01  4.47142239e-01  1.12691693e-01 -8.67940604e-01\n",
      " -8.95618955e-01  8.56840190e-01  3.26639793e-01  2.33382910e+00\n",
      " -5.91445809e-01  4.06520876e-01 -6.16849860e-01  6.29049592e-01\n",
      " -4.50043748e-02  3.36880151e-01  2.75439354e-01  1.75214324e-01\n",
      " -1.28959879e+00 -1.99745175e-01  1.24593610e+00  5.82094164e-01\n",
      " -2.76247329e-01 -4.85403917e-01 -1.75516643e-01 -4.31812960e-01\n",
      " -3.27177585e-02 -7.15722394e-02 -1.42366754e-01  3.28477611e-01\n",
      "  1.98761071e-01  4.77519027e-02  1.63240579e-01 -7.19159890e-02\n",
      " -4.12359158e-01 -1.17096989e+00 -8.16613058e-01 -8.99200025e-01\n",
      "  4.65662521e-01  2.71755691e-01 -2.45049014e-01 -1.20015590e-02\n",
      "  5.17298085e-02  3.16233109e-01  1.63280634e+00 -8.47049237e-01\n",
      " -1.59370370e-02 -9.57417536e-01  5.19149564e-01  4.92663561e-01\n",
      "  9.21806849e-01 -5.09733673e-01  8.99253419e-01  4.79930374e-01\n",
      "  9.57990692e-01  4.93615023e-01 -6.72967632e-01 -8.52295482e-01\n",
      " -2.36721434e-01 -1.15943690e+00  6.92393068e-01  1.67724030e+00\n",
      " -3.27623500e-01  6.58624175e-01  4.13792594e-01 -9.32210927e-01\n",
      " -1.34204514e+00 -1.01354067e+00  3.71602921e-01  8.98301200e-01\n",
      " -2.88925447e-01  8.03676917e-02  1.36042287e+00  1.13414507e+00\n",
      " -7.61872461e-01 -1.19966798e+00 -7.76798212e-01 -5.69802660e-01\n",
      "  2.47891180e-01  3.25721024e-01  2.28116521e-03  4.32800205e-01\n",
      "  1.53790941e-02 -2.83227061e-01  1.17875958e+00  8.58319796e-01\n",
      "  6.53464782e-01  2.13419613e-02  2.32979913e+00  1.14510375e+00\n",
      "  4.93620501e-01  3.85507715e-03 -9.49080750e-01 -2.20484355e-01\n",
      " -5.67862203e-01 -5.68293642e-01  1.10302608e-01  7.65850934e-01\n",
      "  5.82636590e-01 -1.48114939e+00  2.76062985e-01  1.31908714e-01\n",
      "  5.81661812e-01 -1.91056093e-01 -4.02780400e-01 -3.52020451e-01\n",
      "  6.78268174e-02  3.98773197e-02 -6.53249148e-01 -2.47632781e-01\n",
      "  2.87234588e-01  7.05845490e-01  3.25252513e-01  3.31061058e-01\n",
      " -4.56814219e-01 -6.69555879e-01 -4.71943688e-01  1.07616616e+00\n",
      "  3.55316968e-02  2.59251731e-01 -3.45703520e-01 -1.31808353e-01\n",
      "  2.66343856e-01 -1.86619249e+00  4.66727236e-01 -3.71608440e-01\n",
      " -2.28734876e-01 -3.11239098e-01  7.88513268e-01  7.57708527e-02\n",
      "  2.89056811e-01 -1.67184556e-01  4.04651044e+00 -8.54098671e-01\n",
      " -3.50965635e-01 -1.12375487e+00 -7.64243409e-01 -3.53143685e-01\n",
      " -6.51322454e-01  6.91219007e-01 -3.75796112e-01  5.11676541e-01\n",
      " -7.21919620e-01 -3.09897387e-01  1.73593532e-01 -1.98589209e-01\n",
      "  5.64134942e-01 -4.02206306e-01 -5.38288049e-01 -6.33118603e-02\n",
      " -3.51446745e-01  2.20314679e+00 -5.22644546e-01 -7.40366650e-02\n",
      " -7.74580705e-01 -1.54789670e+00  7.69601853e-01 -1.29018479e-01\n",
      " -2.98754239e-01  4.38725928e-02  2.98429376e-01 -8.61443496e-01\n",
      "  4.30821026e-01  4.73580833e-03 -1.08101992e+00 -7.42250619e-01\n",
      " -8.02700171e-01  3.78518299e-01  4.59695499e-01 -1.31710813e-02\n",
      " -9.97688668e-01 -4.35695153e-01  2.71337346e-01 -6.34428754e-01\n",
      " -2.84940155e-01 -2.07214102e+00 -1.32756957e+00 -5.54198863e-02\n",
      " -2.00967278e-01  1.35175600e-02  4.76044060e-03  1.94152508e+00\n",
      "  4.31542911e-01  3.81304361e-01 -1.48821575e+00 -6.39907734e-01\n",
      " -3.89360373e-01 -1.60318619e-01  4.60238820e-01 -6.63434636e-01]\n",
      "------counter :162-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.75081607  3.0878883   0.84586579 -0.42945142 -0.25117837  0.65032142\n",
      " -0.35849784 -2.00102131 -0.47503147 -0.67699076  0.3134395   0.43351005\n",
      " -0.12860656  0.42754354 -1.17422251 -1.10152215 -1.2843881   0.89044104\n",
      "  0.2424181  -0.83288146 -0.2795779   0.11764752 -0.99845257  0.3806903\n",
      " -0.07518529  0.35131511  0.57429176  0.1934501  -0.76436983  0.40994982\n",
      "  1.06361945  0.64871332 -0.40027759 -0.95047553 -0.19739121  0.08923029\n",
      " -0.06194971 -0.16029947 -0.00380567  0.08815599 -0.52755831 -0.45895893\n",
      " -0.36515995 -0.00790521 -0.41954938 -1.31097144 -0.57622984  0.40721304\n",
      "  1.01855404  0.2607885   0.08936884 -0.11802633 -0.33315216  0.4814986\n",
      "  1.47480318 -0.80963917  0.9950114  -0.99216814  0.71510269  0.74220175\n",
      "  0.89089875 -0.35589728  2.29371504  0.29908099  0.8407476  -0.03112248\n",
      " -0.2148797  -1.52522987 -0.1681505  -1.20404515 -0.20858068  0.29449687\n",
      " -0.17801788  0.25330963 -0.09942342 -1.04239163 -0.44983999 -0.66855358\n",
      "  0.18604406  0.49883915 -0.27381221 -0.01474329  1.21841418 -0.08777546\n",
      " -0.72675158  1.63136499  0.41332384 -0.77022279  0.37738467  0.01848414\n",
      "  0.84135453  0.44173938  3.66757198  0.20471344  1.13514944  0.76980994\n",
      "  0.31959565  0.06758717  0.95347964  1.01214373  1.27597498 -0.15058506\n",
      " -0.02623907 -0.13395058 -0.58092872 -0.65094204  0.49820785  0.69218907\n",
      "  1.36846079 -1.75320203  0.11992895  0.2724182   0.20401203  1.29626144\n",
      "  0.12932782 -0.32787367  0.06575758 -0.24929362 -0.58637262  0.10585869\n",
      " -0.16986804  0.22305809  0.29521025 -0.01505113 -1.10416443  0.06777609\n",
      "  0.61724901 -0.81015555  0.30963634 -0.09554616 -0.93869781 -0.50254276\n",
      "  0.22676486 -0.64389087  0.35790943  0.59001673 -0.98513356 -0.65713835\n",
      " -0.5272073  -0.07766829  0.23757653 -0.17332926  0.4317192  -0.96821115\n",
      " -0.55453223 -0.3000026   1.68391962 -0.90842797 -0.90779791  0.80569212\n",
      "  0.03442788  0.33156501 -1.21684352  0.02501328  0.43937076 -0.11328067\n",
      "  0.40495364  0.17999225 -0.01317468 -0.13644386 -0.8294099   2.47070933\n",
      "  0.3918987  -0.51291307 -1.01635184 -1.07147036 -0.16208405  0.33294475\n",
      " -0.09734274 -0.08993647  1.06162785 -1.20283615  0.75771652  0.02079834\n",
      " -0.88309689 -0.7537276  -0.20178192 -0.09854309 -0.26361016  0.33399542\n",
      " -1.13104391 -1.17945867  0.46250376 -0.43073772 -0.34208245 -0.71570319\n",
      " -1.25221545  0.60357151 -0.2583551   0.11171915  0.15524156  2.04605448\n",
      "  0.11312434  0.6200052  -1.64763578 -0.70843628 -0.58680736  0.05070774\n",
      " -0.0136622   0.57773768]\n",
      "------counter :163-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.12740952e-01  2.34460754e+00  7.87359060e-01 -5.71276427e-01\n",
      " -7.61374897e-01  3.00438031e-02  1.48076010e+00 -2.12142367e-01\n",
      "  5.20215273e-01 -1.57668347e-01  1.04144404e+00  5.19818933e-01\n",
      " -1.02495684e-01  8.84157284e-01 -5.14795787e-01 -7.42757188e-01\n",
      "  7.57762212e-01  7.40140014e-01  1.37510670e-01  1.69862655e+00\n",
      " -3.15616366e-01  1.22856241e-01 -9.67651160e-01 -4.52550566e-01\n",
      " -2.78247274e-01 -1.19894794e-01  8.40806507e-01  2.12045672e-02\n",
      " -1.11373166e+00  1.46567245e+00  7.42884950e-01  1.14555222e+00\n",
      " -6.49429211e-01  1.35995975e-01 -1.17131403e-01  8.67496422e-02\n",
      "  2.60379683e-01 -1.22160476e-01 -6.06345355e-03  1.09789124e-01\n",
      " -4.57845796e-01 -4.61409505e-01 -8.79403286e-02 -3.14205393e-01\n",
      "  3.67692387e-01 -1.23490282e+00  1.49182568e-01  3.05703502e-01\n",
      "  2.90617165e-01  1.62902406e-01 -2.12086007e-01  9.78852387e-02\n",
      "  3.78921961e-01  5.71689000e-01  6.81605543e-01 -8.35034383e-01\n",
      "  1.79905703e-01  2.11069637e-01  2.09963853e-01  6.82064132e-01\n",
      "  2.32167850e-01 -4.28404815e-01  4.28501948e-01  2.57580901e-01\n",
      " -1.28267659e+00  1.75698299e-01 -1.26981671e+00 -8.28122970e-01\n",
      " -2.48549616e-01 -5.98233635e-01 -3.72866051e-01 -5.33757629e-01\n",
      " -5.93330563e-01  3.39217009e-01  7.74691427e-01 -9.47031630e-01\n",
      " -3.09731586e-01  1.80889593e-01 -1.28554141e-03  2.35490576e-01\n",
      " -1.66752063e-01  1.44423096e-01  1.99796790e+00  4.01252231e-01\n",
      " -3.45305272e-01  2.65078364e+00 -1.48163925e-01 -6.92110208e-01\n",
      "  4.27106962e-01 -5.04302815e-01  1.02206458e-01  5.73446777e-01\n",
      "  1.14617120e+00  1.90038678e-01  9.96187793e-01  6.01997619e-01\n",
      "  1.29345911e-01  5.61476891e-02  4.64810316e-01  9.80406153e-01\n",
      "  8.43211429e-01 -3.21311764e-02 -3.70928861e-01 -3.74252427e-01\n",
      " -7.58599299e-01 -8.79577650e-01  5.89555457e-02  9.25715520e-01\n",
      "  9.51885752e-01 -7.54441188e-01  9.80763767e-02 -1.97869958e+00\n",
      "  2.89172295e-01  2.65662495e-01 -4.73112625e-01 -2.56537778e-01\n",
      " -5.88396967e-02 -2.49399632e-01 -1.24002823e+00  1.86229617e+00\n",
      " -5.13371607e-02  2.21629558e-01 -2.94666093e-02  2.96557766e-01\n",
      " -5.82574568e-01 -5.86021118e-03  4.77425938e-01 -9.17207839e-01\n",
      "  2.24335082e-01 -2.82277214e-01 -8.57246913e-01 -5.50160314e-01\n",
      "  1.49764163e-03 -1.55845177e+00  1.69908592e-01  5.01431076e-01\n",
      " -1.32433409e+00 -2.97081349e-01  7.75986566e-01 -4.25476643e-03\n",
      "  2.14148983e-01 -4.12335137e-01  2.59242871e-01 -1.54059534e+00\n",
      " -4.45523964e-01 -2.21800834e-01  3.74500771e-01 -9.00753433e-01\n",
      " -9.52726570e-01  1.33613187e+00  1.39035046e-01  4.33882243e-01\n",
      " -1.15914045e+00 -4.15233007e-01  2.10142253e-01 -1.68180177e-01\n",
      "  9.47784606e-01  1.10660148e+00 -3.71248039e-01 -1.89499194e-01\n",
      " -5.85598887e-01  2.01693895e+00  9.52519184e-01 -2.87632827e-01\n",
      " -1.02513052e+00 -1.15283612e+00 -1.74370520e-01  1.69892539e-01\n",
      "  9.66828356e-02 -2.89973876e-01  3.98200681e-01 -9.86563412e-01\n",
      "  2.01429277e-01 -2.33132160e-01 -1.15334421e+00 -9.19032611e-01\n",
      "  3.08095010e-02  1.52819993e+00 -5.96770397e-01  4.81012646e-01\n",
      " -2.72653980e+00  1.96951290e+00  5.11284631e-01 -3.30237954e-01\n",
      " -1.63517313e-01 -1.94751538e+00 -1.25090444e+00  2.21077761e-01\n",
      "  5.15157282e-02 -5.80511035e-02 -3.40403925e-01  1.37529243e+00\n",
      " -1.22815263e-01  6.34684428e-01 -1.70668287e+00 -9.50043737e-01\n",
      " -2.82517360e-01  2.63878129e-01  5.77957732e-01  4.22868505e-01]\n",
      "------counter :164-----------\n",
      "(5600, 15)\n",
      "(200, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window) # difference with previous value\n",
      "/tmp/ipykernel_27/1084247445.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dow\"] = df[\"date_id\"] % 5                 # Day of the week\n",
      "/tmp/ipykernel_27/1084247445.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
      "/tmp/ipykernel_27/1084247445.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  # Minutes\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
      "/tmp/ipykernel_27/1084247445.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0754131   0.28423224  0.56022283 -1.488577   -1.03084942  2.36151117\n",
      "  1.63087166 -0.42779804  0.72866057 -0.69206039  1.34438517  2.5688852\n",
      "  0.47815856  2.5816572  -1.98064451 -0.76928713 -2.28310459  0.50104679\n",
      "  2.01061605 -0.07628511 -0.40374853 -1.620792   -1.41066596  0.9987472\n",
      "  0.95280079 -0.89994487  5.88990427 -0.04825404 -3.10843349  2.43189525\n",
      "  1.48225174  2.92961711 -1.46470794  1.1952923   0.12893416 -0.30129495\n",
      " -0.30572223 -0.25473728 -0.56606034  0.18198697  1.49748374 -0.49034241\n",
      "  0.07332062 -0.35959608  1.26916133 -2.28349719 -1.23361792 -0.85994674\n",
      "  0.96418431  0.97271115 -1.6730443  -0.20687132 -0.2884918   0.97490414\n",
      " -0.26333715 -2.37185663  0.3610724  -0.11611046  1.05161372  0.87722085\n",
      "  0.53048491  2.54447593 -0.05388463  0.13572571 -0.83089679  0.79187001\n",
      " -0.96780368 -1.66486597 -0.50549644 -8.96248455 -0.03576052  0.92071767\n",
      " -0.05758293  2.04481738  2.61709688 -2.02071284 -0.03864915 -1.86155165\n",
      " -1.66945611 -1.70256994 -0.64483537  0.77460515 12.66684255 -0.38245313\n",
      " -0.57475229  4.55070419  1.9825016  -1.53188573  0.76772809  0.17988295\n",
      "  1.53607527  1.25827634  3.59032817  1.07522919  0.4344164   1.40665811\n",
      " -0.10119314  0.04647929 -3.0920596   3.88023888  5.81193034 -1.95453627\n",
      " -0.52834498  0.01789917 -2.67679408 -2.19370883 -0.46104776  2.10382236\n",
      "  2.68134169 -2.94686686 -0.03289779 -6.21457164 -0.2683718   0.07589309\n",
      " -0.22876427  0.1203223  -0.93377267 -4.59254973 -0.62459007 -5.26888007\n",
      "  1.81541202  0.93484344  2.67422013 -0.36736551 -1.03095975 -0.62129665\n",
      "  1.21775421  2.37240358  1.029422   -2.00503983 -0.05684882 -1.52822381\n",
      " -1.1555627  -2.06694857  2.3444499   1.23865133 -2.8247424  -0.90900277\n",
      " -1.39719863 -0.60428325  0.21172644 -0.28085043  0.02923233 14.40531061\n",
      " -1.13728666 -3.40950092  0.65915208 -2.76973794 -2.49782851  2.22227955\n",
      " -0.41075748  0.46347005 -2.21952754 -0.61729584  1.34543466  0.740454\n",
      "  5.58977154  1.07760761 -0.8904296  -1.12876417 -1.33057497  5.47909654\n",
      "  1.73904945 -0.73268914 -1.85298557 -5.14865886 -2.74404666  1.15806717\n",
      " -0.45017193 -0.56054581  1.41836287 -1.72414389  2.76668255 -1.65390734\n",
      " -3.24226497 -1.58819778 -1.24094757 -2.29203841 -1.28360127  1.43118458\n",
      " -0.97386838  0.80256278  1.13516635 -0.40222219  1.33553914 -1.37737531\n",
      " -2.89616047  1.18607877 -1.56853352  0.16870459 -0.57492383  3.09175033\n",
      "  0.2517168   0.92769109 -1.4440471  -2.46752424 -2.03887221  0.19013604\n",
      "  1.08633562 -2.87199586]\n"
     ]
    }
   ],
   "source": [
    "import optiver2023\n",
    "optiver2023.make_env.func_dict['__called__'] = False\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "\n",
    "cache = pd.DataFrame()\n",
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    if(\"currently_scored\" in test):\n",
    "        test=test.drop(\"currently_scored\",axis=1)\n",
    "        \n",
    "    cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "    if counter > 0: # take 4 week as windows\n",
    "        cache = cache.groupby(['stock_id']).tail(28).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "        \n",
    "    # ðŸ“Š Generate features based on the updated cache\n",
    "    print(f\"------counter :{counter}-----------\")\n",
    "    print(cache.shape)\n",
    "    print(test.shape)\n",
    "    test_df=preproccess(cache)# pick the last 200 record need to be predict\n",
    "    test_df=test_df[-test.shape[0]:]\n",
    "    pred = np.mean([model.predict(test_df) for model in models], axis=0)\n",
    "    pred= zero_sum_prediction(pred,test)\n",
    "    print(pred.values)\n",
    "    sample_prediction['target'] = pred\n",
    "        \n",
    "    env.predict(sample_prediction)\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da12d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T13:55:07.313376Z",
     "iopub.status.busy": "2023-12-03T13:55:07.312728Z",
     "iopub.status.idle": "2023-12-03T13:55:07.317273Z",
     "shell.execute_reply": "2023-12-03T13:55:07.316472Z"
    },
    "papermill": {
     "duration": 0.072429,
     "end_time": "2023-12-03T13:55:07.319287",
     "exception": false,
     "start_time": "2023-12-03T13:55:07.246858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1277.370423,
   "end_time": "2023-12-03T13:55:08.707556",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-03T13:33:51.337133",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
